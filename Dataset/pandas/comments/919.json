[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/9401899",
    "html_url": "https://github.com/pandas-dev/pandas/issues/919#issuecomment-9401899",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/919",
    "id": 9401899,
    "node_id": "MDEyOklzc3VlQ29tbWVudDk0MDE4OTk=",
    "user": {
      "login": "sanand0",
      "id": 63734,
      "node_id": "MDQ6VXNlcjYzNzM0",
      "avatar_url": "https://avatars3.githubusercontent.com/u/63734?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sanand0",
      "html_url": "https://github.com/sanand0",
      "followers_url": "https://api.github.com/users/sanand0/followers",
      "following_url": "https://api.github.com/users/sanand0/following{/other_user}",
      "gists_url": "https://api.github.com/users/sanand0/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sanand0/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sanand0/subscriptions",
      "organizations_url": "https://api.github.com/users/sanand0/orgs",
      "repos_url": "https://api.github.com/users/sanand0/repos",
      "events_url": "https://api.github.com/users/sanand0/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sanand0/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-10-13T08:04:59Z",
    "updated_at": "2012-10-13T08:04:59Z",
    "author_association": "NONE",
    "body": "This would be quite useful.\n\nFor example, if for an address book, data.groupby('city') lists 1000 cities, and we want those with over 100 entries,  would be useful to be able to say something like:\n\n```\ngrouped = data.groupby('city')\ngrouped.filter(grouped.size() > 100)\n```\n\n... and then compute on just that subset.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/9966115",
    "html_url": "https://github.com/pandas-dev/pandas/issues/919#issuecomment-9966115",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/919",
    "id": 9966115,
    "node_id": "MDEyOklzc3VlQ29tbWVudDk5NjYxMTU=",
    "user": {
      "login": "apratap",
      "id": 146127,
      "node_id": "MDQ6VXNlcjE0NjEyNw==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/146127?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/apratap",
      "html_url": "https://github.com/apratap",
      "followers_url": "https://api.github.com/users/apratap/followers",
      "following_url": "https://api.github.com/users/apratap/following{/other_user}",
      "gists_url": "https://api.github.com/users/apratap/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/apratap/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/apratap/subscriptions",
      "organizations_url": "https://api.github.com/users/apratap/orgs",
      "repos_url": "https://api.github.com/users/apratap/repos",
      "events_url": "https://api.github.com/users/apratap/events{/privacy}",
      "received_events_url": "https://api.github.com/users/apratap/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-10-31T23:30:03Z",
    "updated_at": "2012-10-31T23:30:03Z",
    "author_association": "NONE",
    "body": "FYI : without knowing about this open issue, I stumbled upon the same cleaning requirement. Would be nice to have this in pandas but for now I was able to move fwd.\n\nRef: http://stackoverflow.com/questions/13167391/filtering-grouped-df-in-pandas\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/9987197",
    "html_url": "https://github.com/pandas-dev/pandas/issues/919#issuecomment-9987197",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/919",
    "id": 9987197,
    "node_id": "MDEyOklzc3VlQ29tbWVudDk5ODcxOTc=",
    "user": {
      "login": "apratap",
      "id": 146127,
      "node_id": "MDQ6VXNlcjE0NjEyNw==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/146127?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/apratap",
      "html_url": "https://github.com/apratap",
      "followers_url": "https://api.github.com/users/apratap/followers",
      "following_url": "https://api.github.com/users/apratap/following{/other_user}",
      "gists_url": "https://api.github.com/users/apratap/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/apratap/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/apratap/subscriptions",
      "organizations_url": "https://api.github.com/users/apratap/orgs",
      "repos_url": "https://api.github.com/users/apratap/repos",
      "events_url": "https://api.github.com/users/apratap/events{/privacy}",
      "received_events_url": "https://api.github.com/users/apratap/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-11-01T16:53:59Z",
    "updated_at": "2012-11-01T16:53:59Z",
    "author_association": "NONE",
    "body": "Wesley: Can you please help me with the apply hack ? I still cant seem to filter grouped data. More details on the stackoverflow post.link above. Thanks! -Abhi\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/10205424",
    "html_url": "https://github.com/pandas-dev/pandas/issues/919#issuecomment-10205424",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/919",
    "id": 10205424,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEwMjA1NDI0",
    "user": {
      "login": "blounsbury-usbr",
      "id": 1508213,
      "node_id": "MDQ6VXNlcjE1MDgyMTM=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1508213?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/blounsbury-usbr",
      "html_url": "https://github.com/blounsbury-usbr",
      "followers_url": "https://api.github.com/users/blounsbury-usbr/followers",
      "following_url": "https://api.github.com/users/blounsbury-usbr/following{/other_user}",
      "gists_url": "https://api.github.com/users/blounsbury-usbr/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/blounsbury-usbr/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/blounsbury-usbr/subscriptions",
      "organizations_url": "https://api.github.com/users/blounsbury-usbr/orgs",
      "repos_url": "https://api.github.com/users/blounsbury-usbr/repos",
      "events_url": "https://api.github.com/users/blounsbury-usbr/events{/privacy}",
      "received_events_url": "https://api.github.com/users/blounsbury-usbr/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-11-08T21:22:23Z",
    "updated_at": "2012-11-08T21:22:23Z",
    "author_association": "NONE",
    "body": "Probably bad issue etiquette but just wanted to add my +1 for this enhancement. I grouped my data by year (hydrologic water year actually) and then wanted to remove years with less than 365 days of data. I used the stackoverflow answer of pandas.concat() to work around it. But that is pretty ugly.\n\nI agree with sanand0 that grouped.filter() would be easiest. Another possibility would be to add a 'drop()' function to a DataFrameGroupBy object. This would allow a loop over len(group.groups[name]).\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/10585011",
    "html_url": "https://github.com/pandas-dev/pandas/issues/919#issuecomment-10585011",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/919",
    "id": 10585011,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEwNTg1MDEx",
    "user": {
      "login": "wesm",
      "id": 329591,
      "node_id": "MDQ6VXNlcjMyOTU5MQ==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/329591?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/wesm",
      "html_url": "https://github.com/wesm",
      "followers_url": "https://api.github.com/users/wesm/followers",
      "following_url": "https://api.github.com/users/wesm/following{/other_user}",
      "gists_url": "https://api.github.com/users/wesm/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/wesm/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/wesm/subscriptions",
      "organizations_url": "https://api.github.com/users/wesm/orgs",
      "repos_url": "https://api.github.com/users/wesm/repos",
      "events_url": "https://api.github.com/users/wesm/events{/privacy}",
      "received_events_url": "https://api.github.com/users/wesm/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-11-21T04:12:33Z",
    "updated_at": "2012-11-21T04:12:33Z",
    "author_association": "MEMBER",
    "body": "another somewhat related reference: http://stackoverflow.com/questions/13446480/python-pandas-remove-entries-based-on-the-number-of-occurrences\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/10868527",
    "html_url": "https://github.com/pandas-dev/pandas/issues/919#issuecomment-10868527",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/919",
    "id": 10868527,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEwODY4NTI3",
    "user": {
      "login": "jalperin",
      "id": 129638,
      "node_id": "MDQ6VXNlcjEyOTYzOA==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/129638?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jalperin",
      "html_url": "https://github.com/jalperin",
      "followers_url": "https://api.github.com/users/jalperin/followers",
      "following_url": "https://api.github.com/users/jalperin/following{/other_user}",
      "gists_url": "https://api.github.com/users/jalperin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jalperin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jalperin/subscriptions",
      "organizations_url": "https://api.github.com/users/jalperin/orgs",
      "repos_url": "https://api.github.com/users/jalperin/repos",
      "events_url": "https://api.github.com/users/jalperin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jalperin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-11-29T22:03:53Z",
    "updated_at": "2012-11-29T22:03:53Z",
    "author_association": "NONE",
    "body": "another +1. I can't quite figure out what the best way to work around it is, in a generic way. Which of the SO answers do you recommend Wesley?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/19074197",
    "html_url": "https://github.com/pandas-dev/pandas/issues/919#issuecomment-19074197",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/919",
    "id": 19074197,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE5MDc0MTk3",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-06-06T21:07:08Z",
    "updated_at": "2013-06-06T21:07:08Z",
    "author_association": "CONTRIBUTOR",
    "body": "closed via #3680\n"
  }
]
