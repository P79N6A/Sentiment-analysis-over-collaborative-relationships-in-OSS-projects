[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/394862415",
    "html_url": "https://github.com/pandas-dev/pandas/issues/21331#issuecomment-394862415",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/21331",
    "id": 394862415,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NDg2MjQxNQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-05T21:13:44Z",
    "updated_at": "2018-06-05T21:13:56Z",
    "author_association": "CONTRIBUTOR",
    "body": "not sure what you are asking for here. by-definition an ``.apply`` will be slow as its essentially a python for loop. \r\n\r\nnote that some apply's can be written to be much more performant. pls give a specific example of what you think is slow."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/395302175",
    "html_url": "https://github.com/pandas-dev/pandas/issues/21331#issuecomment-395302175",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/21331",
    "id": 395302175,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NTMwMjE3NQ==",
    "user": {
      "login": "h-vetinari",
      "id": 33685575,
      "node_id": "MDQ6VXNlcjMzNjg1NTc1",
      "avatar_url": "https://avatars1.githubusercontent.com/u/33685575?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/h-vetinari",
      "html_url": "https://github.com/h-vetinari",
      "followers_url": "https://api.github.com/users/h-vetinari/followers",
      "following_url": "https://api.github.com/users/h-vetinari/following{/other_user}",
      "gists_url": "https://api.github.com/users/h-vetinari/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/h-vetinari/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/h-vetinari/subscriptions",
      "organizations_url": "https://api.github.com/users/h-vetinari/orgs",
      "repos_url": "https://api.github.com/users/h-vetinari/repos",
      "events_url": "https://api.github.com/users/h-vetinari/events{/privacy}",
      "received_events_url": "https://api.github.com/users/h-vetinari/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-07T05:57:21Z",
    "updated_at": "2018-06-07T05:57:21Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jreback The code I linked to is still a python for-loop, but much more efficient by using integers to represent the groups, and index slices if groups are ordered already.\r\n\r\nMy situation is having to maintain a deduplicated, processed dataset, say `tgt`, where the source data stays duplicated (and changes over time).\r\n\r\nSo I have a bridge-table `redup` that maintains a mapping of the indices (`dedup_ind`) in `tgt` back to their original indices (`redup_ind`) in the source. This is easy to calculate, and if any of the source records change, I need to recalculate the corresponding deduplicated record. Since this is expensive, I only want to do it where necessary.\r\n\r\nSo, after loading the saved previous bridge table and joining with the new one, I have a have a DataFrame along the lines of:\r\n```\r\n#            dedup_ind  dedup_ind_old\r\n# redup_ind                          \r\n# 0                  0            0.0\r\n# 1                  0            0.0\r\n# 2                  0            4.0\r\n# 3                  1            1.0\r\n# 4                  1            1.0\r\n# 5                  2            2.0\r\n# 6                  2            NaN\r\n# 7                  3            3.0\r\n# 8                  4            4.0\r\n# 9                  4            4.0\r\n```\r\n\r\nThen, a simplified version of what I want to do is:\r\n```\r\ndef update_dedup2redup(gr):\r\n    # if any record involved in a deduplicate has changed, we recalculate the deduplicate;\r\n    # this means we need all the involved redup indices!\r\n    if (gr.dedup_ind != gr.dedup_ind_old).any():\r\n        return pd.Series(True, index=gr.index, name='updated')\r\n    return pd.Series(False, index=gr.index, name='updated')\r\ndf.groupby('dedup_ind').apply(update_dedup2redup).reset_index(level=0).updated\r\n```\r\n\r\nSince this was extremely slow, I ended up looking for something faster and found the `Groupby` thing linked in the OP.\r\n\r\n```\r\ndef update_dedup2redup_np(gr):\r\n    # optimized version for use with Groupby-class\r\n    if (gr[:, 0] != gr[:, 1]).any():\r\n        return 1\r\n    return 0\r\n# # same as above (but this is ~100-1000x faster)\r\nGroupby(df.dedup_ind).apply(update_dedup2redup_np,\r\n                            df[['dedup_ind', 'dedup_ind_old']].values,\r\n                            broadcast=True).astype(bool)\r\n```\r\n\r\nNow, because I simplified my case so much, there actually exists a fully vectorised form which is obviously the fastest, but that's not the point. For example, an interesting difference is whether the data being grouped is sorted already. \r\n\r\n```\r\nN = 100000\r\nddi = np.random.randint(0, N/2, (N,))\r\nerr = np.random.choice([-1, 0, 1], N, p=[0.1, 0.8, 0.1])\r\ndf = pd.DataFrame({'dedup_ind' : ddi, 'dedup_ind_old' : ddi + err}, index=pd.Index(range(N), name='redup_ind'))\r\ntic = timeit.default_timer()\r\ndf.groupby('dedup_ind').apply(update_dedup2redup).reset_index(level=0)\r\ntoc = timeit.default_timer()\r\nprint(f'naive: {toc-tic:.2f} sec.')\r\ntic = timeit.default_timer()\r\nGroupby(df.dedup_ind).apply(update_dedup2redup_np, df[['dedup_ind', 'dedup_ind_old']].values, broadcast=True).astype(bool)\r\ntoc = timeit.default_timer()\r\nprint(f'Groupby (unsorted): {toc-tic:.2f} sec.')\r\ndf = df.sort_values('dedup_ind')\r\ntic = timeit.default_timer()\r\nGroupby(df.dedup_ind).apply(update_dedup2redup_np, df[['dedup_ind', 'dedup_ind_old']].values, broadcast=True).astype(bool)\r\ntoc = timeit.default_timer()\r\nprint(f'Groupby (sorted): {toc-tic:.2f} sec.')\r\ntic = timeit.default_timer()\r\ndf.dedup_ind.isin(df.dedup_ind.loc[df.dedup_ind != df.dedup_ind_old])\r\ntoc = timeit.default_timer()\r\nprint(f'vectorised: {toc-tic:.2f} sec.')\r\n# naive: 42.94 sec.\r\n# Groupby (unsorted): 34.02 sec.\r\n# Groupby (sorted): 0.39 sec.\r\n# vectorised: 0.01 sec.\r\n```\r\n\r\nSo my point is: can any of these tricks be used to accelerate custom groupbys? In particular \r\n* should the data being grouped be pre-sorted internally?\r\n* should an integer representation of groups be used? (haven't looked at how it's done currently, but if it uses dict-lookups, that can add up, I guess)\r\n* etc."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/395319006",
    "html_url": "https://github.com/pandas-dev/pandas/issues/21331#issuecomment-395319006",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/21331",
    "id": 395319006,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NTMxOTAwNg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-07T07:19:45Z",
    "updated_at": "2018-06-07T07:19:45Z",
    "author_association": "CONTRIBUTOR",
    "body": "this is just a special case of an ordered group by - there is an issue somewhere about this \r\n\r\nimho this is not that common a case"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/395326097",
    "html_url": "https://github.com/pandas-dev/pandas/issues/21331#issuecomment-395326097",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/21331",
    "id": 395326097,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NTMyNjA5Nw==",
    "user": {
      "login": "h-vetinari",
      "id": 33685575,
      "node_id": "MDQ6VXNlcjMzNjg1NTc1",
      "avatar_url": "https://avatars1.githubusercontent.com/u/33685575?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/h-vetinari",
      "html_url": "https://github.com/h-vetinari",
      "followers_url": "https://api.github.com/users/h-vetinari/followers",
      "following_url": "https://api.github.com/users/h-vetinari/following{/other_user}",
      "gists_url": "https://api.github.com/users/h-vetinari/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/h-vetinari/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/h-vetinari/subscriptions",
      "organizations_url": "https://api.github.com/users/h-vetinari/orgs",
      "repos_url": "https://api.github.com/users/h-vetinari/repos",
      "events_url": "https://api.github.com/users/h-vetinari/events{/privacy}",
      "received_events_url": "https://api.github.com/users/h-vetinari/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-07T07:48:17Z",
    "updated_at": "2018-06-07T07:48:17Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jreback \r\nHow is this a special case? - it's imho the most basic case to do a groupby on a single column. I also tested the \"naive\" apply with pre-sorted data as well, and there was no time difference.\r\n\r\nBut even if it is a special case, a speed-up factor of >100 is not a small improvement."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/395367602",
    "html_url": "https://github.com/pandas-dev/pandas/issues/21331#issuecomment-395367602",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/21331",
    "id": 395367602,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NTM2NzYwMg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-07T10:09:43Z",
    "updated_at": "2018-06-07T10:09:43Z",
    "author_association": "CONTRIBUTOR",
    "body": "you are welcome to try "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/395381917",
    "html_url": "https://github.com/pandas-dev/pandas/issues/21331#issuecomment-395381917",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/21331",
    "id": 395381917,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NTM4MTkxNw==",
    "user": {
      "login": "h-vetinari",
      "id": 33685575,
      "node_id": "MDQ6VXNlcjMzNjg1NTc1",
      "avatar_url": "https://avatars1.githubusercontent.com/u/33685575?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/h-vetinari",
      "html_url": "https://github.com/h-vetinari",
      "followers_url": "https://api.github.com/users/h-vetinari/followers",
      "following_url": "https://api.github.com/users/h-vetinari/following{/other_user}",
      "gists_url": "https://api.github.com/users/h-vetinari/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/h-vetinari/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/h-vetinari/subscriptions",
      "organizations_url": "https://api.github.com/users/h-vetinari/orgs",
      "repos_url": "https://api.github.com/users/h-vetinari/repos",
      "events_url": "https://api.github.com/users/h-vetinari/events{/privacy}",
      "received_events_url": "https://api.github.com/users/h-vetinari/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-07T11:06:17Z",
    "updated_at": "2018-06-07T11:06:17Z",
    "author_association": "CONTRIBUTOR",
    "body": "Could you adapt the tags to reflect the situation, please? Cheers"
  }
]
