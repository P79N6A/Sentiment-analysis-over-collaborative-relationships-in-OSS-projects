[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/41387684",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6963#issuecomment-41387684",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6963",
    "id": 41387684,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMzg3Njg0",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-25T12:39:04Z",
    "updated_at": "2014-04-25T12:39:04Z",
    "author_association": "CONTRIBUTOR",
    "body": "cc @immerrr  \n\nI think after #6745 this will be straightforward to fix\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/41390102",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6963#issuecomment-41390102",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6963",
    "id": 41390102,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMzkwMTAy",
    "user": {
      "login": "immerrr",
      "id": 579798,
      "node_id": "MDQ6VXNlcjU3OTc5OA==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/579798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/immerrr",
      "html_url": "https://github.com/immerrr",
      "followers_url": "https://api.github.com/users/immerrr/followers",
      "following_url": "https://api.github.com/users/immerrr/following{/other_user}",
      "gists_url": "https://api.github.com/users/immerrr/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/immerrr/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/immerrr/subscriptions",
      "organizations_url": "https://api.github.com/users/immerrr/orgs",
      "repos_url": "https://api.github.com/users/immerrr/repos",
      "events_url": "https://api.github.com/users/immerrr/events{/privacy}",
      "received_events_url": "https://api.github.com/users/immerrr/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-25T13:07:15Z",
    "updated_at": "2014-04-25T13:07:15Z",
    "author_association": "CONTRIBUTOR",
    "body": "The main issue is how to align indices that both have duplicate items, as of now, indexing with dupes does strange things:\n\n``` python\nIn [1]: pd.Index([1,1,2])\nOut[1]: Int64Index([1, 1, 2], dtype='int64')\n\nIn [2]: _1.get_indexer_for(_1)\nOut[2]: Int64Index([0, 1, 0, 1, 2], dtype='int64')\n```\n\nApparently, for each non-unique element found in destination, get_indexer tries to insert all locs of this element. I can hardly thinkg of a use case when I'd want to do a `reindex(['x', 'y'])` and getting `(['x', 'x', 'x', 'y'])` instead would do.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/41390592",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6963#issuecomment-41390592",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6963",
    "id": 41390592,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMzkwNTky",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-25T13:12:28Z",
    "updated_at": "2014-04-25T13:12:28Z",
    "author_association": "CONTRIBUTOR",
    "body": "The dup indexers came out of having duplicates indexers on a unique index, so you have to dup \n\n```\nIn [1]: df = DataFrame(np.arange(10).reshape(5,2))\n\nIn [2]: df\nOut[2]: \n   0  1\n0  0  1\n1  2  3\n2  4  5\n3  6  7\n4  8  9\n\n[5 rows x 2 columns]\n\nIn [5]: df.loc[:,[0,1,1,0]]\nOut[5]: \n   0  1  1  0\n0  0  1  1  0\n1  2  3  3  2\n2  4  5  5  4\n3  6  7  7  6\n4  8  9  9  8\n\n[5 rows x 4 columns]\n```\n\nNow maybe outlaw that I suppose\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/41391465",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6963#issuecomment-41391465",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6963",
    "id": 41391465,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMzkxNDY1",
    "user": {
      "login": "immerrr",
      "id": 579798,
      "node_id": "MDQ6VXNlcjU3OTc5OA==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/579798?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/immerrr",
      "html_url": "https://github.com/immerrr",
      "followers_url": "https://api.github.com/users/immerrr/followers",
      "following_url": "https://api.github.com/users/immerrr/following{/other_user}",
      "gists_url": "https://api.github.com/users/immerrr/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/immerrr/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/immerrr/subscriptions",
      "organizations_url": "https://api.github.com/users/immerrr/orgs",
      "repos_url": "https://api.github.com/users/immerrr/repos",
      "events_url": "https://api.github.com/users/immerrr/events{/privacy}",
      "received_events_url": "https://api.github.com/users/immerrr/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-25T13:22:10Z",
    "updated_at": "2014-04-25T13:25:24Z",
    "author_association": "CONTRIBUTOR",
    "body": "Maybe it would make more sense to require destination index to have the same count of duplicate entries for each element present in source, i.e.:\n\n``` python\n\n# e.g. these should be ok\npd.Index([1,1,2]).get_indexer_for([1,1,2]) # should be ok and return [0, 1, 2]\npd.Index([1,1,2]).get_indexer_for([2]) # return [2]\npd.Index([1,1,2]).get_indexer_for([1,2,1]) # return [0, 2, 1]\n\n# but these should be forbidden\npd.Index([1,1,2]).get_indexer_for([1,2]) # which one of `1` did you want?\npd.Index([1,1,2]).get_indexer_for([1,1,1,2]) # which `1` should be duplicated?\n```\n\n_UPD: or maybe cycle over duplicate elements like np.putmask does..._\n\n``` python\nx = np.arange(5)\nnp.putmask(x, x>1, [-33, -44])\nprint x\narray([  0,   1, -33, -44, -33])\n\n# so that\npd.Index([1,1,2]).get_indexer_for([1,1,2,1,1]) # return [0,1,2,0,1] ?\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/41391757",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6963#issuecomment-41391757",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6963",
    "id": 41391757,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMzkxNzU3",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-25T13:25:29Z",
    "updated_at": "2014-04-25T13:25:29Z",
    "author_association": "CONTRIBUTOR",
    "body": "right, so that's a duplicate of a duplicate; yes, that would need to be handled differently\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/329960837",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6963#issuecomment-329960837",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6963",
    "id": 329960837,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyOTk2MDgzNw==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-09-16T10:42:40Z",
    "updated_at": "2017-09-16T10:42:40Z",
    "author_association": "MEMBER",
    "body": "Some more example from #17552 (with `axis=1`, different error messages, but the idea is the same: you only get the error when there are duplicate + different labels):\r\n\r\n```\r\nIn [113]: df1 = pd.DataFrame(np.zeros((2,2)), index=[0, 1], columns=['a', 'b'])\r\n     ...: df2 = pd.DataFrame(np.ones((2,2)), index=[2, 2], columns=['c', 'd'])\r\n\r\nIn [114]: pd.concat([df1, df2], axis=1)\r\n...\r\nValueError: Shape of passed values is (4, 6), indices imply (4, 4)\r\n\r\nIn [115]: df1 = pd.DataFrame(np.zeros((2,2)), index=[0, 1], columns=['a', 'b'])\r\n     ...: df2 = pd.DataFrame(np.ones((2,2)), index=pd.DatetimeIndex([2, 2]), columns=['c', 'd'])\r\n\r\nIn [116]: pd.concat([df1, df2], axis=1)\r\n...\r\nTypeError: 'NoneType' object is not iterable\r\n```\r\n"
  }
]
