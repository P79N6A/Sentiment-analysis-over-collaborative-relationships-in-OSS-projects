[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235579646",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235579646",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235579646,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTU3OTY0Ng==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-27T13:10:02Z",
    "updated_at": "2016-07-27T13:10:02Z",
    "author_association": "CONTRIBUTOR",
    "body": "Can you say a bit more about why this would be useful to you? Typically `chunksize` is used to manage larger-than-memory datasets that are on disk. The `data` argument to `from_records` is presumably already in memory.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235582713",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235582713",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235582713,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTU4MjcxMw==",
    "user": {
      "login": "achapkowski",
      "id": 5131271,
      "node_id": "MDQ6VXNlcjUxMzEyNzE=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5131271?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/achapkowski",
      "html_url": "https://github.com/achapkowski",
      "followers_url": "https://api.github.com/users/achapkowski/followers",
      "following_url": "https://api.github.com/users/achapkowski/following{/other_user}",
      "gists_url": "https://api.github.com/users/achapkowski/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/achapkowski/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/achapkowski/subscriptions",
      "organizations_url": "https://api.github.com/users/achapkowski/orgs",
      "repos_url": "https://api.github.com/users/achapkowski/repos",
      "events_url": "https://api.github.com/users/achapkowski/events{/privacy}",
      "received_events_url": "https://api.github.com/users/achapkowski/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-27T13:21:53Z",
    "updated_at": "2016-07-27T13:21:53Z",
    "author_association": "NONE",
    "body": "@TomAugspurger - I can do my best.  The idea of using a cursor like object with a `__next__()` implemented is that it allows you to go line by line through a dataset table/file, whatever.  If you have a large dataset, let's say bigger than memory, then you need to limit the number of rows a user works with at one time.  This means you maybe able to work row by row, but you won't get the advantage of DataFrame object, where as if we can chunk it, it will load better.\n\n`read_csv` has the chunksize, but the `from_records` does not.  It should because sometimes you need to limit the number rows that can be processed at once.  \n\nThanks  \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235584861",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235584861",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235584861,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTU4NDg2MQ==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-27T13:29:29Z",
    "updated_at": "2016-07-27T13:30:08Z",
    "author_association": "CONTRIBUTOR",
    "body": "Thanks, that's perfectly reasonable. The other option is to chunk your dataset before passing it to `from_records`, using e.g. `toolz.partition_all`\n\n``` python\nstream = ...\ndfs = (pd.DataFrame(chunk, ...) for chunk in toolz.partition_all(chunksize, stream))\n```\n\nIs adding the parameter worth the extra complexity / maintenance?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235591585",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235591585",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235591585,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTU5MTU4NQ==",
    "user": {
      "login": "achapkowski",
      "id": 5131271,
      "node_id": "MDQ6VXNlcjUxMzEyNzE=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5131271?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/achapkowski",
      "html_url": "https://github.com/achapkowski",
      "followers_url": "https://api.github.com/users/achapkowski/followers",
      "following_url": "https://api.github.com/users/achapkowski/following{/other_user}",
      "gists_url": "https://api.github.com/users/achapkowski/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/achapkowski/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/achapkowski/subscriptions",
      "organizations_url": "https://api.github.com/users/achapkowski/orgs",
      "repos_url": "https://api.github.com/users/achapkowski/repos",
      "events_url": "https://api.github.com/users/achapkowski/events{/privacy}",
      "received_events_url": "https://api.github.com/users/achapkowski/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-27T13:53:02Z",
    "updated_at": "2016-07-27T13:53:02Z",
    "author_association": "NONE",
    "body": "@TomAugspurger - I think it would be worth it in the long run.  All the supported datasets should probably allow for chunking not just a couple.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235727478",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235727478",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235727478,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTcyNzQ3OA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-27T21:30:38Z",
    "updated_at": "2016-07-27T21:30:38Z",
    "author_association": "CONTRIBUTOR",
    "body": "what is the actual use case for this? if you have a rec-array by-definition its in memory, so not sure how this helps at all.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235866492",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235866492",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235866492,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTg2NjQ5Mg==",
    "user": {
      "login": "achapkowski",
      "id": 5131271,
      "node_id": "MDQ6VXNlcjUxMzEyNzE=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5131271?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/achapkowski",
      "html_url": "https://github.com/achapkowski",
      "followers_url": "https://api.github.com/users/achapkowski/followers",
      "following_url": "https://api.github.com/users/achapkowski/following{/other_user}",
      "gists_url": "https://api.github.com/users/achapkowski/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/achapkowski/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/achapkowski/subscriptions",
      "organizations_url": "https://api.github.com/users/achapkowski/orgs",
      "repos_url": "https://api.github.com/users/achapkowski/repos",
      "events_url": "https://api.github.com/users/achapkowski/events{/privacy}",
      "received_events_url": "https://api.github.com/users/achapkowski/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-28T11:12:49Z",
    "updated_at": "2016-07-28T11:12:49Z",
    "author_association": "NONE",
    "body": "There are other 3rd party objects out there that implement iterator and generator objects.  \n\nFor example, spatial data, there is an [arcpy.da.SearchCursor](http://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-data-access/searchcursor-class.htm).  This object is your standard iterator object over a table, but I may not want to load the whole table into memory at once to do my work, but rather, I want to piece it together much like with csv files.  \n\nThe concept here is to process large generator/iterators into smaller pieces to be more efficient when it comes to memory consumption.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235867264",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235867264",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235867264,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTg2NzI2NA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-28T11:17:12Z",
    "updated_at": "2016-07-28T11:17:12Z",
    "author_association": "CONTRIBUTOR",
    "body": "and u can easily do that\n\nwhy should pandas add this very narrow case\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235872303",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235872303",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235872303,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTg3MjMwMw==",
    "user": {
      "login": "achapkowski",
      "id": 5131271,
      "node_id": "MDQ6VXNlcjUxMzEyNzE=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5131271?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/achapkowski",
      "html_url": "https://github.com/achapkowski",
      "followers_url": "https://api.github.com/users/achapkowski/followers",
      "following_url": "https://api.github.com/users/achapkowski/following{/other_user}",
      "gists_url": "https://api.github.com/users/achapkowski/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/achapkowski/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/achapkowski/subscriptions",
      "organizations_url": "https://api.github.com/users/achapkowski/orgs",
      "repos_url": "https://api.github.com/users/achapkowski/repos",
      "events_url": "https://api.github.com/users/achapkowski/events{/privacy}",
      "received_events_url": "https://api.github.com/users/achapkowski/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-28T11:45:46Z",
    "updated_at": "2016-07-28T11:45:46Z",
    "author_association": "NONE",
    "body": "@jreback because iterators and generators are common ways to get data and it allows a more generic method to load data into dataframes.\n\nCan you provide guidance on how to implement it if it is very easy?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235876981",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235876981",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235876981,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTg3Njk4MQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-28T12:11:00Z",
    "updated_at": "2016-07-28T12:11:00Z",
    "author_association": "CONTRIBUTOR",
    "body": "@achapkowski this would be extremely inefficient, but I suppose a usecase exists.\n\nI said its easy to do externally.\n\n`pd.concat(list(generator))`\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235878077",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235878077",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235878077,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTg3ODA3Nw==",
    "user": {
      "login": "achapkowski",
      "id": 5131271,
      "node_id": "MDQ6VXNlcjUxMzEyNzE=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5131271?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/achapkowski",
      "html_url": "https://github.com/achapkowski",
      "followers_url": "https://api.github.com/users/achapkowski/followers",
      "following_url": "https://api.github.com/users/achapkowski/following{/other_user}",
      "gists_url": "https://api.github.com/users/achapkowski/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/achapkowski/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/achapkowski/subscriptions",
      "organizations_url": "https://api.github.com/users/achapkowski/orgs",
      "repos_url": "https://api.github.com/users/achapkowski/repos",
      "events_url": "https://api.github.com/users/achapkowski/events{/privacy}",
      "received_events_url": "https://api.github.com/users/achapkowski/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-28T12:19:06Z",
    "updated_at": "2016-07-28T12:19:06Z",
    "author_association": "NONE",
    "body": "@jreback but aren't you just loading the whole dataset into memory then?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235879526",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235879526",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235879526,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTg3OTUyNg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-28T12:25:49Z",
    "updated_at": "2016-07-28T12:25:49Z",
    "author_association": "CONTRIBUTOR",
    "body": "of course. a Dataframe is a fixed size. Expanding it requires reallocattion and copying, which is quite expensive.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235879671",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235879671",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235879671,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTg3OTY3MQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-28T12:26:31Z",
    "updated_at": "2016-07-28T12:26:31Z",
    "author_association": "CONTRIBUTOR",
    "body": "you can see #5902 if you want to see the discussion\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235880684",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235880684",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235880684,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTg4MDY4NA==",
    "user": {
      "login": "achapkowski",
      "id": 5131271,
      "node_id": "MDQ6VXNlcjUxMzEyNzE=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5131271?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/achapkowski",
      "html_url": "https://github.com/achapkowski",
      "followers_url": "https://api.github.com/users/achapkowski/followers",
      "following_url": "https://api.github.com/users/achapkowski/following{/other_user}",
      "gists_url": "https://api.github.com/users/achapkowski/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/achapkowski/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/achapkowski/subscriptions",
      "organizations_url": "https://api.github.com/users/achapkowski/orgs",
      "repos_url": "https://api.github.com/users/achapkowski/repos",
      "events_url": "https://api.github.com/users/achapkowski/events{/privacy}",
      "received_events_url": "https://api.github.com/users/achapkowski/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-28T12:31:23Z",
    "updated_at": "2016-07-28T12:31:23Z",
    "author_association": "NONE",
    "body": "But the chunksize, like in the csv file returns an iterator of dataframe of size x, why couldn't that be done for and iterator object?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/235891980",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-235891980",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 235891980,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNTg5MTk4MA==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-28T13:19:55Z",
    "updated_at": "2016-07-28T13:19:55Z",
    "author_association": "CONTRIBUTOR",
    "body": "@achapkowski one is I have with adding it is that all the `DataFrame.from_*` methods return a DataFrame. IIUC, your `DataFrame.from_records(., chunksize=10)` wouldn't actually return a DataFrame, but rather an iterator similar to `read_csv`'s `TextFileReader`. I feel like this breaks the convention that `from_*` methods are alternative constructors that return an instance of the object itself.\n\nThat, plus the fact that using something like `toolz.partition_all` or [this](http://stackoverflow.com/a/8991553/1889400) recipe from the standard lib aren't _too_ bad to write, means I'm slightly against adding the `chunksize` kwarg to `from_records`. I'd prefer to keep `from_*` to always return a DataFrame, and require the user to chunk the data before using the constructor.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/237208043",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-237208043",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 237208043,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNzIwODA0Mw==",
    "user": {
      "login": "tinproject",
      "id": 3742174,
      "node_id": "MDQ6VXNlcjM3NDIxNzQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/3742174?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/tinproject",
      "html_url": "https://github.com/tinproject",
      "followers_url": "https://api.github.com/users/tinproject/followers",
      "following_url": "https://api.github.com/users/tinproject/following{/other_user}",
      "gists_url": "https://api.github.com/users/tinproject/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/tinproject/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/tinproject/subscriptions",
      "organizations_url": "https://api.github.com/users/tinproject/orgs",
      "repos_url": "https://api.github.com/users/tinproject/repos",
      "events_url": "https://api.github.com/users/tinproject/events{/privacy}",
      "received_events_url": "https://api.github.com/users/tinproject/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-03T11:06:25Z",
    "updated_at": "2016-08-03T11:06:25Z",
    "author_association": "CONTRIBUTOR",
    "body": "@TomAugspurger @achapkowski `from_records` already have a _chunksize_ atribute, it's called [**nrows**](https://github.com/pydata/pandas/blob/b2a14459cf97af53ecc5edf51659ce3a9f1125b4/pandas/core/frame.py#L989), I believe it's name should be changed to **count** because it's purpose is to indicate how many records are going to be taken from an iterator, `chunksize` is a bad name because implies that there are chunks in pandas and there are not.\n\nAPI things apart, the way pandas create a DataFrame from an iterator/generator is putting the iterator contents on a list, and then build the DataFrame from that list. As jreback points you could read the discussion on #5902.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/237281928",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13818#issuecomment-237281928",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13818",
    "id": 237281928,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzNzI4MTkyOA==",
    "user": {
      "login": "achapkowski",
      "id": 5131271,
      "node_id": "MDQ6VXNlcjUxMzEyNzE=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5131271?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/achapkowski",
      "html_url": "https://github.com/achapkowski",
      "followers_url": "https://api.github.com/users/achapkowski/followers",
      "following_url": "https://api.github.com/users/achapkowski/following{/other_user}",
      "gists_url": "https://api.github.com/users/achapkowski/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/achapkowski/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/achapkowski/subscriptions",
      "organizations_url": "https://api.github.com/users/achapkowski/orgs",
      "repos_url": "https://api.github.com/users/achapkowski/repos",
      "events_url": "https://api.github.com/users/achapkowski/events{/privacy}",
      "received_events_url": "https://api.github.com/users/achapkowski/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-03T16:00:20Z",
    "updated_at": "2016-08-03T16:00:20Z",
    "author_association": "NONE",
    "body": "@tinproject - nrows parameters seems like the value will only take say 5000 rows from the datasource then stop reading it.  Is that not correct?\n"
  }
]
