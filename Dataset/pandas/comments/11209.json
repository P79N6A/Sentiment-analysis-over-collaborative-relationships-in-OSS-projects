[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/144991851",
    "html_url": "https://github.com/pandas-dev/pandas/pull/11209#issuecomment-144991851",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11209",
    "id": 144991851,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NDk5MTg1MQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-02T11:08:11Z",
    "updated_at": "2015-10-02T11:08:11Z",
    "author_association": "CONTRIBUTOR",
    "body": "this would be confusing to a user as read_gbq should return s frame\ndoes it here?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/144994694",
    "html_url": "https://github.com/pandas-dev/pandas/pull/11209#issuecomment-144994694",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11209",
    "id": 144994694,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NDk5NDY5NA==",
    "user": {
      "login": "parthea",
      "id": 5184014,
      "node_id": "MDQ6VXNlcjUxODQwMTQ=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/5184014?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/parthea",
      "html_url": "https://github.com/parthea",
      "followers_url": "https://api.github.com/users/parthea/followers",
      "following_url": "https://api.github.com/users/parthea/following{/other_user}",
      "gists_url": "https://api.github.com/users/parthea/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/parthea/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/parthea/subscriptions",
      "organizations_url": "https://api.github.com/users/parthea/orgs",
      "repos_url": "https://api.github.com/users/parthea/repos",
      "events_url": "https://api.github.com/users/parthea/events{/privacy}",
      "received_events_url": "https://api.github.com/users/parthea/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-02T11:28:50Z",
    "updated_at": "2015-10-02T11:30:56Z",
    "author_association": "CONTRIBUTOR",
    "body": "Yes, `read_gbq()` still returns a DataFrame with the query results regardless if these additional parameters are set. I've just tried the following scenarios:\n- In the first test, I set the `destination_table` and confirmed a destination table was created and DataFrame was returned.\n- In the second test, I set the `destination_table` and `allow_large_results` and confirmed a destination table was created and DataFrame was returned.\n\nI will add a unit tests now for the above mentioned scenarios (I missed it the first time around)\n\nAll tests pass locally. Could this make it into the 0.17.0 release? I think it is a very useful feature.\n\n```\ntony@tonypc:~/pandas-parthea/pandas/io/tests$ nosetests test_gbq.py -v\ntest_should_be_able_to_get_a_bigquery_service (pandas.io.tests.test_gbq.TestGBQConnectorIntegration) ... ok\ntest_should_be_able_to_get_results_from_query (pandas.io.tests.test_gbq.TestGBQConnectorIntegration) ... ok\ntest_should_be_able_to_get_schema_from_query (pandas.io.tests.test_gbq.TestGBQConnectorIntegration) ... ok\ntest_should_be_able_to_get_valid_credentials (pandas.io.tests.test_gbq.TestGBQConnectorIntegration) ... ok\ntest_should_be_able_to_make_a_connector (pandas.io.tests.test_gbq.TestGBQConnectorIntegration) ... ok\ntest_bad_project_id (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_bad_table_name (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_column_order (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_column_order_plus_index (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_download_dataset_larger_than_200k_rows (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_index_column (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_malformed_query (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_redirect_query_results_to_destination_table_dataset_does_not_exist (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_redirect_query_results_to_destination_table_default (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_redirect_query_results_to_destination_table_if_table_exists_append (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_redirect_query_results_to_destination_table_if_table_exists_fail (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_redirect_query_results_to_destination_table_if_table_exists_replace (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_should_properly_handle_arbitrary_timestamp (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_should_properly_handle_empty_strings (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_should_properly_handle_false_boolean (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_should_properly_handle_null_boolean (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_should_properly_handle_null_floats (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_should_properly_handle_null_integers (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_should_properly_handle_null_strings (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_should_properly_handle_null_timestamp (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_should_properly_handle_timestamp_unix_epoch (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_should_properly_handle_true_boolean (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_should_properly_handle_valid_floats (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_should_properly_handle_valid_integers (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_should_properly_handle_valid_strings (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_unicode_string_conversion_and_normalization (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_zero_rows (pandas.io.tests.test_gbq.TestReadGBQIntegration) ... ok\ntest_read_gbq_with_no_project_id_given_should_fail (pandas.io.tests.test_gbq.TestReadGBQUnitTests) ... ok\ntest_should_return_bigquery_booleans_as_python_booleans (pandas.io.tests.test_gbq.TestReadGBQUnitTests) ... ok\ntest_should_return_bigquery_floats_as_python_floats (pandas.io.tests.test_gbq.TestReadGBQUnitTests) ... ok\ntest_should_return_bigquery_integers_as_python_floats (pandas.io.tests.test_gbq.TestReadGBQUnitTests) ... ok\ntest_should_return_bigquery_strings_as_python_strings (pandas.io.tests.test_gbq.TestReadGBQUnitTests) ... ok\ntest_should_return_bigquery_timestamps_as_numpy_datetime (pandas.io.tests.test_gbq.TestReadGBQUnitTests) ... ok\ntest_that_parse_data_works_properly (pandas.io.tests.test_gbq.TestReadGBQUnitTests) ... ok\ntest_to_gbq_should_fail_if_invalid_table_name_passed (pandas.io.tests.test_gbq.TestReadGBQUnitTests) ... ok\ntest_to_gbq_with_no_project_id_given_should_fail (pandas.io.tests.test_gbq.TestReadGBQUnitTests) ... ok\ntest_create_dataset (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_create_table (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_dataset_does_not_exist (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_dataset_exists (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_delete_dataset (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_delete_table (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_generate_schema (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_google_upload_errors_should_raise_exception (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_list_dataset (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_list_table (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_list_table_zero_results (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_table_does_not_exist (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_upload_data (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_upload_data_if_table_exists_append (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_upload_data_if_table_exists_fail (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\ntest_upload_data_if_table_exists_replace (pandas.io.tests.test_gbq.TestToGBQIntegration) ... ok\npandas.io.tests.test_gbq.test_requirements ... ok\npandas.io.tests.test_gbq.test_generate_bq_schema_deprecated ... ok\n\n----------------------------------------------------------------------\nRan 59 tests in 379.762s\n\nOK\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/144994919",
    "html_url": "https://github.com/pandas-dev/pandas/pull/11209#issuecomment-144994919",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11209",
    "id": 144994919,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NDk5NDkxOQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-02T11:30:35Z",
    "updated_at": "2015-10-02T11:30:35Z",
    "author_association": "CONTRIBUTOR",
    "body": "this is bloating the API \n\nif u r returning a frame then simply use to_gbq and push it back up\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/144997893",
    "html_url": "https://github.com/pandas-dev/pandas/pull/11209#issuecomment-144997893",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11209",
    "id": 144997893,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NDk5Nzg5Mw==",
    "user": {
      "login": "parthea",
      "id": 5184014,
      "node_id": "MDQ6VXNlcjUxODQwMTQ=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/5184014?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/parthea",
      "html_url": "https://github.com/parthea",
      "followers_url": "https://api.github.com/users/parthea/followers",
      "following_url": "https://api.github.com/users/parthea/following{/other_user}",
      "gists_url": "https://api.github.com/users/parthea/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/parthea/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/parthea/subscriptions",
      "organizations_url": "https://api.github.com/users/parthea/orgs",
      "repos_url": "https://api.github.com/users/parthea/repos",
      "events_url": "https://api.github.com/users/parthea/events{/privacy}",
      "received_events_url": "https://api.github.com/users/parthea/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-02T11:55:23Z",
    "updated_at": "2015-10-02T12:19:11Z",
    "author_association": "CONTRIBUTOR",
    "body": "I agree that it doesn't make sense to return the data in a DataFrame when a destination table is specified (since you can use to_gbq to push it back up). My preference would be to return an empty DataFrame when a destination table is specified in order to avoid the unnecessary download and upload of data when users want to create smaller datasets from larger ones. The ability to run queries and send the query results directly to a table (in an efficient manner) could be useful.\n\nRegarding the `allow_large_results` parameter:\nFrom https://cloud.google.com/bigquery/quota-policy#queries, query results > 128 MB compressed require the  `'allowLargeResults'` option to be set in the job configuration. One of the requirements for allowing large results is that you must specify a destination table.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/144999198",
    "html_url": "https://github.com/pandas-dev/pandas/pull/11209#issuecomment-144999198",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11209",
    "id": 144999198,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NDk5OTE5OA==",
    "user": {
      "login": "parthea",
      "id": 5184014,
      "node_id": "MDQ6VXNlcjUxODQwMTQ=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/5184014?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/parthea",
      "html_url": "https://github.com/parthea",
      "followers_url": "https://api.github.com/users/parthea/followers",
      "following_url": "https://api.github.com/users/parthea/following{/other_user}",
      "gists_url": "https://api.github.com/users/parthea/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/parthea/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/parthea/subscriptions",
      "organizations_url": "https://api.github.com/users/parthea/orgs",
      "repos_url": "https://api.github.com/users/parthea/repos",
      "events_url": "https://api.github.com/users/parthea/events{/privacy}",
      "received_events_url": "https://api.github.com/users/parthea/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-02T12:05:46Z",
    "updated_at": "2015-10-02T12:06:12Z",
    "author_association": "CONTRIBUTOR",
    "body": "Another potential solution, is to create a new function `gbq.query_to_table()` which does not return a DataFrame.  `gbq.query_to_table()` would require a destination table to be specified and would support a parameter `allow_large_results`. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/145002217",
    "html_url": "https://github.com/pandas-dev/pandas/pull/11209#issuecomment-145002217",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11209",
    "id": 145002217,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NTAwMjIxNw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-02T12:25:33Z",
    "updated_at": "2015-10-02T12:25:33Z",
    "author_association": "CONTRIBUTOR",
    "body": "@parthea I am not averse to these changes. But would like 0.17.0 to release and settle before considering api change.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/145002413",
    "html_url": "https://github.com/pandas-dev/pandas/pull/11209#issuecomment-145002413",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11209",
    "id": 145002413,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NTAwMjQxMw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-02T12:26:39Z",
    "updated_at": "2015-10-02T12:26:39Z",
    "author_association": "CONTRIBUTOR",
    "body": "further crafting a nice useful, non-duplicative api is actually tricky. You want to have the limited set of things that one could 'do' in an intuitve way. So one of the big issues is how to pass in options (.e.g like `allow_large_result`, which is really a 'user' option. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/145043677",
    "html_url": "https://github.com/pandas-dev/pandas/pull/11209#issuecomment-145043677",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11209",
    "id": 145043677,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NTA0MzY3Nw==",
    "user": {
      "login": "parthea",
      "id": 5184014,
      "node_id": "MDQ6VXNlcjUxODQwMTQ=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/5184014?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/parthea",
      "html_url": "https://github.com/parthea",
      "followers_url": "https://api.github.com/users/parthea/followers",
      "following_url": "https://api.github.com/users/parthea/following{/other_user}",
      "gists_url": "https://api.github.com/users/parthea/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/parthea/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/parthea/subscriptions",
      "organizations_url": "https://api.github.com/users/parthea/orgs",
      "repos_url": "https://api.github.com/users/parthea/repos",
      "events_url": "https://api.github.com/users/parthea/events{/privacy}",
      "received_events_url": "https://api.github.com/users/parthea/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-02T14:42:02Z",
    "updated_at": "2015-10-02T14:42:02Z",
    "author_association": "CONTRIBUTOR",
    "body": "Do you think it would be better to close this pull request, and request that we support this feature in the odo project instead (assuming that odo will support gbq) since the odo project is aimed at data migration?\n\nThe functionality in this pull request could be similar to the following pull request in odo which adds ability to append query results to a table : blaze/odo#37\n"
  }
]
