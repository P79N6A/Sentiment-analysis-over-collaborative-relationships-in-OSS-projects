[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/185708667",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12381#issuecomment-185708667",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12381",
    "id": 185708667,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4NTcwODY2Nw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-18T12:59:05Z",
    "updated_at": "2016-02-18T12:59:05Z",
    "author_association": "CONTRIBUTOR",
    "body": "you seem to be a bit misinformed.\n- Both `pickle` and `HDF5` provide perfect fidelity when round-tripped thru serialization. This is certainly not true for most other formats.\n- When round tripping you essentially have to pick from: fidelity, performance, and compatibility, you have varying degrees of each.\n- your reference to cyrill's blog is nonsensical, he is referring to a very special case of a large multi-user collaboration. Clearly not what you are referring.\n- further yes Apache Arrow is vaporware, and will have all of the same constraints / restrictions as the above (they are choosing compatibility, so certainly will lose on the fidelity aspects from a particular platforms perspective).\n\nOf course this is issue not about this at all, rather about persisting a workspace which is in `jupyter`'s domain, or if you want a desktop app, use [spyder](https://pythonhosted.org/spyder/)\n\nSo not really sure what you are asking from pandas. We have quite a suite of IO compatibility, see the docs [here](http://pandas.pydata.org/pandas-docs/stable/io.html), you as the user need to choose how to use it.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/185725217",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12381#issuecomment-185725217",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12381",
    "id": 185725217,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4NTcyNTIxNw==",
    "user": {
      "login": "sandys",
      "id": 76883,
      "node_id": "MDQ6VXNlcjc2ODgz",
      "avatar_url": "https://avatars2.githubusercontent.com/u/76883?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sandys",
      "html_url": "https://github.com/sandys",
      "followers_url": "https://api.github.com/users/sandys/followers",
      "following_url": "https://api.github.com/users/sandys/following{/other_user}",
      "gists_url": "https://api.github.com/users/sandys/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sandys/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sandys/subscriptions",
      "organizations_url": "https://api.github.com/users/sandys/orgs",
      "repos_url": "https://api.github.com/users/sandys/repos",
      "events_url": "https://api.github.com/users/sandys/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sandys/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-18T13:41:30Z",
    "updated_at": "2016-02-18T13:41:30Z",
    "author_association": "NONE",
    "body": "oh wow - thanks for the info. there's been a lot of retweets for https://blogs.apache.org/foundation/entry/the_apache_software_foundation_announces87\nwith the following quote \n\n> \"Arrow's cross platform and cross system strengths will enable Python and R to become first-class languages across the entire Big Data stack,\" said Wes McKinney, creator of Pandas.\n\nBTW - none of these are my claims, this is info that I have gotten from people on pydata IRC channels when I have been attempting to move from R to Pandas.  So your comment on nonsensical is perhaps a consequence of _widespread_ misinformation.\n\nJust to be clear - I'm not talking about persisting a workspace configuration. I am talking of persisting the data frames inside a pandas session (which could even be 8-10 GB). For example, [here's](https://gist.github.com/LeiG/8094753a6cc7907c716f) a snippet on how you can actually load a persisted RData dump into Pandas dataframes.\n\nI'm trying to figure out a production flow for Pandas where I need to have 8-10 GB of data in memory and then incrementally update that every hour. We do this in R by snapshotting all the data frames in one shot, backing them to S3 and then continuing. If our machine fails (on AWS for example), we restore the last snapshot from S3 and just resume. So in that respect, I think I'm close to cyrill's blog.\n\nIs that  a feature request that could be accepted ?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/185732786",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12381#issuecomment-185732786",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12381",
    "id": 185732786,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4NTczMjc4Ng==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-18T13:52:30Z",
    "updated_at": "2016-02-18T13:52:30Z",
    "author_association": "CONTRIBUTOR",
    "body": "@sandys what exactly are requesting.\n\nHDF5 is THE best IMHO solution for something like this. \n\ncyrilles solutions IMHO just make another set of issues. When dealing with multi-user mutli-source systems are not trivial.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/185735595",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12381#issuecomment-185735595",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12381",
    "id": 185735595,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4NTczNTU5NQ==",
    "user": {
      "login": "sandys",
      "id": 76883,
      "node_id": "MDQ6VXNlcjc2ODgz",
      "avatar_url": "https://avatars2.githubusercontent.com/u/76883?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sandys",
      "html_url": "https://github.com/sandys",
      "followers_url": "https://api.github.com/users/sandys/followers",
      "following_url": "https://api.github.com/users/sandys/following{/other_user}",
      "gists_url": "https://api.github.com/users/sandys/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sandys/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sandys/subscriptions",
      "organizations_url": "https://api.github.com/users/sandys/orgs",
      "repos_url": "https://api.github.com/users/sandys/repos",
      "events_url": "https://api.github.com/users/sandys/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sandys/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-18T14:03:39Z",
    "updated_at": "2016-02-18T14:03:39Z",
    "author_association": "NONE",
    "body": "Jeff,\nI'm requesting for something like R save.image which works something like\nDill (a python library for saving ALL the data structures in memory).\n\nSaving an individual data frame works perfectly, but saving _everything_ is\nwhat's a little tricky (for a data scientist... I'm sure Pandas developers\nfind this pretty easy).\n\nIt is one of  the most productivity enhancing commands in R.\nOn Feb 18, 2016 7:22 PM, \"Jeff Reback\" notifications@github.com wrote:\n\n> @sandys https://github.com/sandys what exactly are requesting.\n> \n> HDF5 is THE best IMHO solution for something like this.\n> \n> cyrilles solutions IMHO just make another set of issues. When dealing with\n> multi-user mutli-source systems are not trivial.\n> \n> —\n> Reply to this email directly or view it on GitHub\n> https://github.com/pydata/pandas/issues/12381#issuecomment-185732786.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/185737878",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12381#issuecomment-185737878",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12381",
    "id": 185737878,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4NTczNzg3OA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-18T14:10:52Z",
    "updated_at": "2016-02-18T14:10:52Z",
    "author_association": "CONTRIBUTOR",
    "body": "@sandys then use dill or pls put in a request for spyer and/or jupyter. This is out of scope for pandas.\n\npython is about being explict, while R has _somewhat_ of an opposite philosphy. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/185783111",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12381#issuecomment-185783111",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12381",
    "id": 185783111,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4NTc4MzExMQ==",
    "user": {
      "login": "sandys",
      "id": 76883,
      "node_id": "MDQ6VXNlcjc2ODgz",
      "avatar_url": "https://avatars2.githubusercontent.com/u/76883?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sandys",
      "html_url": "https://github.com/sandys",
      "followers_url": "https://api.github.com/users/sandys/followers",
      "following_url": "https://api.github.com/users/sandys/following{/other_user}",
      "gists_url": "https://api.github.com/users/sandys/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sandys/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sandys/subscriptions",
      "organizations_url": "https://api.github.com/users/sandys/orgs",
      "repos_url": "https://api.github.com/users/sandys/repos",
      "events_url": "https://api.github.com/users/sandys/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sandys/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-18T15:43:16Z",
    "updated_at": "2016-02-18T15:43:16Z",
    "author_association": "NONE",
    "body": "Thanks for the reply. Will do - just wanted to highlight one last time that\nthe reason why I believe this should be part of pandas is because this is a\nfairly common production flow.. Especially in context of the \"cloud\" (where\nanything may fail at any moment).\n\nI hesitate to file it on jupyter because I'm not really looking at it as a\nworkspace configuration but rather a data snapshot strategy.\n\nThanks!\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/185783910",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12381#issuecomment-185783910",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12381",
    "id": 185783910,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4NTc4MzkxMA==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-18T15:45:31Z",
    "updated_at": "2016-02-18T15:45:31Z",
    "author_association": "CONTRIBUTOR",
    "body": "Agreed with @jreback that this doesn't feel very pythonic. Even some R people seem [down on workspace images](https://twitter.com/hadleywickham/status/561146907519500288).\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/185790791",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12381#issuecomment-185790791",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12381",
    "id": 185790791,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4NTc5MDc5MQ==",
    "user": {
      "login": "sandys",
      "id": 76883,
      "node_id": "MDQ6VXNlcjc2ODgz",
      "avatar_url": "https://avatars2.githubusercontent.com/u/76883?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sandys",
      "html_url": "https://github.com/sandys",
      "followers_url": "https://api.github.com/users/sandys/followers",
      "following_url": "https://api.github.com/users/sandys/following{/other_user}",
      "gists_url": "https://api.github.com/users/sandys/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sandys/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sandys/subscriptions",
      "organizations_url": "https://api.github.com/users/sandys/orgs",
      "repos_url": "https://api.github.com/users/sandys/repos",
      "events_url": "https://api.github.com/users/sandys/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sandys/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-18T16:01:07Z",
    "updated_at": "2016-02-18T16:01:07Z",
    "author_association": "NONE",
    "body": "hi Tom,\njust trying to reply to you -\nhttps://stat.ethz.ch/pipermail/r-sig-db/2013q1/001272.html  or\nhttps://stat.ethz.ch/pipermail/r-sig-db/2013q1/001272.html\n\nthere are tons of usecases where models are run in production using\nsnapshots. In a lot of ways, it can be argued that Docker snapshots are\nun-linux like (exactly what a lot of people from the Puppet or Chef world\nargue about system composability).\n\nBut it is a godsend for production. if I had to guess.. I would say the\nvast majority of R production flows work like this.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/185791241",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12381#issuecomment-185791241",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12381",
    "id": 185791241,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4NTc5MTI0MQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-18T16:02:15Z",
    "updated_at": "2016-02-18T16:02:15Z",
    "author_association": "CONTRIBUTOR",
    "body": "@sandys I appreciate you want to make it 'easy', but in reality you should have a cleaner / reproducible workflow. Simply saving a workspace IMHO is not a good answer, except in 1-off small scale situations.\n\n> But it is a godsend for production. if I had to guess.. I would say the\n> vast majority of R production flows work like this.\n\nNot to inflame language wars, but this is just a recipe for disaster. Sure may work right now, but it is not security, resilent, nor reproducible.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/185812782",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12381#issuecomment-185812782",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12381",
    "id": 185812782,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4NTgxMjc4Mg==",
    "user": {
      "login": "sandys",
      "id": 76883,
      "node_id": "MDQ6VXNlcjc2ODgz",
      "avatar_url": "https://avatars2.githubusercontent.com/u/76883?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sandys",
      "html_url": "https://github.com/sandys",
      "followers_url": "https://api.github.com/users/sandys/followers",
      "following_url": "https://api.github.com/users/sandys/following{/other_user}",
      "gists_url": "https://api.github.com/users/sandys/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sandys/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sandys/subscriptions",
      "organizations_url": "https://api.github.com/users/sandys/orgs",
      "repos_url": "https://api.github.com/users/sandys/repos",
      "events_url": "https://api.github.com/users/sandys/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sandys/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-18T16:52:54Z",
    "updated_at": "2016-02-18T16:52:54Z",
    "author_association": "NONE",
    "body": "hi jeff,\nI grant you that  I might be totally wrong - in which case I am trying to\nfind out how do people build a 10GB model that gets updated incrementally\n(every 6 hours based on new data) ? What happens if the machine breaks down\nand I have to spin another server up - I dont want to recompute the 10GB.\n\ndo we use a database with Pandas to persist the model - I'm ok with that,\nbut I cant find any real documentation on what are the best practices\naround that. If I may say so - the only form of serialization is the\ndisk-based ones (that you linked).\n\nSo I'm really confused and wondering if the canonical recommended way is to\nrecompute everytime. Is this something that can stand upto the conditions\nof cloud servers\n\nOn Thu, Feb 18, 2016 at 9:32 PM, Jeff Reback notifications@github.com\nwrote:\n\n> @sandys https://github.com/sandys I appreciate you want to make it\n> 'easy', but in reality you should have a cleaner / reproducible workflow.\n> Simply saving a workspace IMHO is not a good answer, except in 1-off small\n> scale situations.\n> \n> But it is a godsend for production. if I had to guess.. I would say the\n> vast majority of R production flows work like this.\n> \n> Not to inflame language wars, but this is just a recipe for disaster. Sure\n> may work right now, but it is not security, resilent, nor reproducible.\n> \n> —\n> Reply to this email directly or view it on GitHub\n> https://github.com/pydata/pandas/issues/12381#issuecomment-185791241.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/185814117",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12381#issuecomment-185814117",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12381",
    "id": 185814117,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4NTgxNDExNw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-18T16:55:52Z",
    "updated_at": "2016-02-18T16:55:52Z",
    "author_association": "CONTRIBUTOR",
    "body": "@sandys this is a vast and complicated topic. you should start simple and see if that serves your needs. 10GB to be honest is not that big nowadays, you could easily do this with HDF5. E.g. saving intermediate state, and then append, or use a db, or even a flat file and recompute. as the data owner you will have to weight the costs/beneifts and esp the complexity here. Using an opaque tool to do this (like `save.image()`) does not really help you at all.\n"
  }
]
