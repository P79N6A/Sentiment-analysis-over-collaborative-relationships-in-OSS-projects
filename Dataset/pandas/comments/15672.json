[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/286150430",
    "html_url": "https://github.com/pandas-dev/pandas/issues/15672#issuecomment-286150430",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/15672",
    "id": 286150430,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI4NjE1MDQzMA==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-03-13T15:52:53Z",
    "updated_at": "2017-03-13T15:52:53Z",
    "author_association": "MEMBER",
    "body": "Almost all methods in pandas *return a new object*, instead of mutating in place, and this is not something we are going to change \r\n(there are a few where inplace=True, and those typically stem from being consistent with list/array, eg `Series.sort`, but we are rather deprecating those)\r\n\r\nAlso, what is the intended way for extending a Series, if the data, like some kind of measurements, is accumulated over time?\r\n\r\nYou can use `append` for that as you did in the example. More general is `concat` (you can concat multiple parts at once). Typically you first gather all pieces in a list, and only then concatenate them at once using `concat`."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/286153394",
    "html_url": "https://github.com/pandas-dev/pandas/issues/15672#issuecomment-286153394",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/15672",
    "id": 286153394,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI4NjE1MzM5NA==",
    "user": {
      "login": "egorf",
      "id": 7365554,
      "node_id": "MDQ6VXNlcjczNjU1NTQ=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/7365554?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/egorf",
      "html_url": "https://github.com/egorf",
      "followers_url": "https://api.github.com/users/egorf/followers",
      "following_url": "https://api.github.com/users/egorf/following{/other_user}",
      "gists_url": "https://api.github.com/users/egorf/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/egorf/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/egorf/subscriptions",
      "organizations_url": "https://api.github.com/users/egorf/orgs",
      "repos_url": "https://api.github.com/users/egorf/repos",
      "events_url": "https://api.github.com/users/egorf/events{/privacy}",
      "received_events_url": "https://api.github.com/users/egorf/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-03-13T16:01:58Z",
    "updated_at": "2017-03-13T16:01:58Z",
    "author_association": "NONE",
    "body": "Hi and thanks for the fast answer,\r\n\r\nWhat would be the correct approach if I want to accumulate some data over time and, for example, know the standard deviation at each step?\r\n\r\nI can't seem to find a way to calculate the **std** iteratively, as I need to recreate the Series every time new data comes along. \r\n\r\nIs this something pandas is not designed for? \r\n\r\n\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/286422879",
    "html_url": "https://github.com/pandas-dev/pandas/issues/15672#issuecomment-286422879",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/15672",
    "id": 286422879,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI4NjQyMjg3OQ==",
    "user": {
      "login": "chris-b1",
      "id": 1924092,
      "node_id": "MDQ6VXNlcjE5MjQwOTI=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1924092?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/chris-b1",
      "html_url": "https://github.com/chris-b1",
      "followers_url": "https://api.github.com/users/chris-b1/followers",
      "following_url": "https://api.github.com/users/chris-b1/following{/other_user}",
      "gists_url": "https://api.github.com/users/chris-b1/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/chris-b1/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/chris-b1/subscriptions",
      "organizations_url": "https://api.github.com/users/chris-b1/orgs",
      "repos_url": "https://api.github.com/users/chris-b1/repos",
      "events_url": "https://api.github.com/users/chris-b1/events{/privacy}",
      "received_events_url": "https://api.github.com/users/chris-b1/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-03-14T13:37:21Z",
    "updated_at": "2017-03-14T13:37:21Z",
    "author_association": "CONTRIBUTOR",
    "body": "@egorf - if the data is reasonably sized and you're not super performance bound, you can just keep recreating the `Series`.  Each recreation will take a copy of the underlying data, which as long as your number of iterations is reasonable, is pretty fast.\r\n\r\nIf that's an issue, the other option is create a large, empty array / series with a single allocation, then place data into it.  More complex, but something like this.\r\n\r\n```\r\ndata = np.empty(100000)\r\ndata[:] = np.nan\r\ns = pd.Series(data)\r\n\r\nloc = 0\r\nfor new_data in source:  # your iterative data source\r\n    n = len(new_data)\r\n    s.iloc[loc:n+loc] = new_data\r\n    loc += len(new_data)\r\n    # iterative std\r\n    new_std = s.iloc[:loc].std()\r\n```\r\n  "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/286442717",
    "html_url": "https://github.com/pandas-dev/pandas/issues/15672#issuecomment-286442717",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/15672",
    "id": 286442717,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI4NjQ0MjcxNw==",
    "user": {
      "login": "egorf",
      "id": 7365554,
      "node_id": "MDQ6VXNlcjczNjU1NTQ=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/7365554?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/egorf",
      "html_url": "https://github.com/egorf",
      "followers_url": "https://api.github.com/users/egorf/followers",
      "following_url": "https://api.github.com/users/egorf/following{/other_user}",
      "gists_url": "https://api.github.com/users/egorf/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/egorf/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/egorf/subscriptions",
      "organizations_url": "https://api.github.com/users/egorf/orgs",
      "repos_url": "https://api.github.com/users/egorf/repos",
      "events_url": "https://api.github.com/users/egorf/events{/privacy}",
      "received_events_url": "https://api.github.com/users/egorf/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-03-14T14:43:16Z",
    "updated_at": "2017-03-14T14:43:16Z",
    "author_association": "NONE",
    "body": "Thanks for the tip, but I decided to go with the [online algorithm](https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Online_algorithm) instead and use for pandas for data storage and manipulation, rather than accumulation. "
  }
]
