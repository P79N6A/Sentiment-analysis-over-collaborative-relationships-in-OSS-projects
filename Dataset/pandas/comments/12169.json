[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/176318135",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12169#issuecomment-176318135",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12169",
    "id": 176318135,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjMxODEzNQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-01-28T18:18:44Z",
    "updated_at": "2016-01-28T18:18:44Z",
    "author_association": "CONTRIBUTOR",
    "body": "hmm, does appear a little buggy.\n\nyou shouldn't need to specify the dtype on aggregations they are inferred. Here I think there is an embedded exception which is caught in stead of actuallly computing correctly.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/176318670",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12169#issuecomment-176318670",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12169",
    "id": 176318670,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjMxODY3MA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-01-28T18:19:41Z",
    "updated_at": "2016-01-28T18:19:41Z",
    "author_association": "CONTRIBUTOR",
    "body": "I look after #11841  as the timedelta resampling is tested a bit more there (but not enough!)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/179645204",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12169#issuecomment-179645204",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12169",
    "id": 179645204,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3OTY0NTIwNA==",
    "user": {
      "login": "BranYang",
      "id": 4443076,
      "node_id": "MDQ6VXNlcjQ0NDMwNzY=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/4443076?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/BranYang",
      "html_url": "https://github.com/BranYang",
      "followers_url": "https://api.github.com/users/BranYang/followers",
      "following_url": "https://api.github.com/users/BranYang/following{/other_user}",
      "gists_url": "https://api.github.com/users/BranYang/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/BranYang/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/BranYang/subscriptions",
      "organizations_url": "https://api.github.com/users/BranYang/orgs",
      "repos_url": "https://api.github.com/users/BranYang/repos",
      "events_url": "https://api.github.com/users/BranYang/events{/privacy}",
      "received_events_url": "https://api.github.com/users/BranYang/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-04T05:24:42Z",
    "updated_at": "2016-02-04T05:24:42Z",
    "author_association": "CONTRIBUTOR",
    "body": "The root cause of this issue is that, when construct Series from a dict with TimedeltaIndex as key, it will treat the value as float64. See pandas/core/series.py, from line 172 to 185\n\n``` python\ntry:\n    if isinstance(index, DatetimeIndex):\n        if len(data):\n            # coerce back to datetime objects for lookup\n            data = _dict_compat(data)\n            data = lib.fast_multiget(data, index.astype('O'),\n                                     default=np.nan)\n        else:\n            data = np.nan\n    elif isinstance(index, PeriodIndex):\n        data = ([data.get(i, nan) for i in index]\n                if data else np.nan)\n    else:\n        data = lib.fast_multiget(data, index.values,\n                                 default=np.nan)\n```\n\nI believe just change `isinstance(index, PeriodIndex):` to `isinstance(index, (PeriodIndex, TimedeltaIndex):` would solve this issue\n\nBefore\n\n``` Python\nIn [5]: fxx = d2.resample('10s', how=lambda x: (x.value_counts().index[0]))\n\nIn [6]: fxx\nOut[6]:\n         Group_obj  Group\n00:00:00         A    NaN\n00:00:10         A    NaN\n```\n\nAfter\n\n``` Python\nIn [5]: fxx = d2.resample('10s', how=lambda x: (x.value_counts().index[0]))\n\nIn [6]: fxx\nOut[6]:\n         Group_obj Group\n00:00:00         A     A\n00:00:10         A     A\n```\n"
  }
]
