[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/147451179",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11296#issuecomment-147451179",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11296",
    "id": 147451179,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NzQ1MTE3OQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-12T16:21:08Z",
    "updated_at": "2015-10-12T16:21:08Z",
    "author_association": "CONTRIBUTOR",
    "body": "this is a dupe of #7895. `.ffill` is not implemented in cython on a groupby operation (though it certainly could be), and instead calls python space on each group.\n\nhere's an easy way to do this.\n\n```\nIn [45]: df\nOut[45]: \n                                 Value     Id\nDate       InputTime                         \n2001-10-06 2001-10-06 05:00:00     NaN    NaN\n           2001-10-06 13:00:00       2      1\n           2001-10-06 21:00:00     NaN    NaN\n2001-10-07 2001-10-07 05:00:00     NaN    NaN\n           2001-10-07 13:00:00       8      4\n           2001-10-07 21:00:00     NaN    NaN\n...                                ...    ...\n2093-01-07 2093-01-07 13:00:00  199988  99994\n           2093-01-07 21:00:00     NaN    NaN\n2093-01-08 2093-01-08 05:00:00     NaN    NaN\n           2093-01-08 13:00:00  199994  99997\n           2093-01-08 21:00:00     NaN    NaN\n2093-01-09 2093-01-09 05:00:00     NaN    NaN\n\n[100000 rows x 2 columns]\n\n# you MUST be sorted\nIn [46]: df.index.is_lexsorted()\nOut[46]: True\n\nIn [47]: df3 = df.reset_index()\n```\n\nwe take the indexer of the first element of each group. note you cannot use `.first` here as that would skip the nans.\n\n```\nIn [48]: indexer = df3.groupby('Date',as_index=False).nth(0).index\n\nIn [49]: indexer\nOut[49]: \nInt64Index([    0,     3,     6,     9,    12,    15,    18,    21,    24,    27,\n            ...\n            99972, 99975, 99978, 99981, 99984, 99987, 99990, 99993, 99996, 99999], dtype='int64', length=33334)\n\nIn [50]: df3.loc[indexer].head()\nOut[50]: \n         Date           InputTime  Value  Id\n0  2001-10-06 2001-10-06 05:00:00    NaN NaN\n3  2001-10-07 2001-10-07 05:00:00    NaN NaN\n6  2001-10-08 2001-10-08 05:00:00    NaN NaN\n9  2001-10-09 2001-10-09 05:00:00    NaN NaN\n12 2001-10-10 2001-10-10 05:00:00    NaN NaN\n```\n\nMake these a non-NaN value that you don't have in your frame.\n\n```\nIn [51]: df3.loc[indexer,'Value'] = -1\n```\n\npad the `NaN`s, which by definition since sorted and -1 are in the first row will not propogate beyond groups. Then replace the -1 with nan again.\n\n```\nIn [52]: df3.ffill().replace(-1,np.nan)\nOut[52]: \n            Date           InputTime   Value     Id\n0     2001-10-06 2001-10-06 05:00:00     NaN    NaN\n1     2001-10-06 2001-10-06 13:00:00       2      1\n2     2001-10-06 2001-10-06 21:00:00       2      1\n3     2001-10-07 2001-10-07 05:00:00     NaN      1\n4     2001-10-07 2001-10-07 13:00:00       8      4\n5     2001-10-07 2001-10-07 21:00:00       8      4\n...          ...                 ...     ...    ...\n99994 2093-01-07 2093-01-07 13:00:00  199988  99994\n99995 2093-01-07 2093-01-07 21:00:00  199988  99994\n99996 2093-01-08 2093-01-08 05:00:00     NaN  99994\n99997 2093-01-08 2093-01-08 13:00:00  199994  99997\n99998 2093-01-08 2093-01-08 21:00:00  199994  99997\n99999 2093-01-09 2093-01-09 05:00:00     NaN  99997\n\n[100000 rows x 4 columns]\n```\n\nI did this on both columns to show the difference.\n\nThis is completely vectorized and will be quite efficient.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/147457137",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11296#issuecomment-147457137",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11296",
    "id": 147457137,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NzQ1NzEzNw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-12T16:41:38Z",
    "updated_at": "2015-10-12T16:41:38Z",
    "author_association": "CONTRIBUTOR",
    "body": "actually we don't have a fillna-groupby perf issue...so will leave this one open\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/147461736",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11296#issuecomment-147461736",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11296",
    "id": 147461736,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NzQ2MTczNg==",
    "user": {
      "login": "squeniart",
      "id": 15088142,
      "node_id": "MDQ6VXNlcjE1MDg4MTQy",
      "avatar_url": "https://avatars2.githubusercontent.com/u/15088142?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/squeniart",
      "html_url": "https://github.com/squeniart",
      "followers_url": "https://api.github.com/users/squeniart/followers",
      "following_url": "https://api.github.com/users/squeniart/following{/other_user}",
      "gists_url": "https://api.github.com/users/squeniart/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/squeniart/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/squeniart/subscriptions",
      "organizations_url": "https://api.github.com/users/squeniart/orgs",
      "repos_url": "https://api.github.com/users/squeniart/repos",
      "events_url": "https://api.github.com/users/squeniart/events{/privacy}",
      "received_events_url": "https://api.github.com/users/squeniart/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-12T17:03:58Z",
    "updated_at": "2015-10-12T17:03:58Z",
    "author_association": "NONE",
    "body": "Hello,\n\nI've tested your workaround but it can only work on the specific example I've given because it makes some assumptions on where are the NaN values. My example was built to get a big dataframe for the issue but this is not the exact reality of what are my data.\n\nSuppose the very simple dataframe:\n\n![image](https://cloud.githubusercontent.com/assets/15088142/10433448/2c83cbce-7112-11e5-811e-b7043fbe08a2.png)\n\nIf I apply our code on this example, below is what I get:\n\n![image](https://cloud.githubusercontent.com/assets/15088142/10433564/3329fee8-7113-11e5-8494-98b586a0d4d7.png)\n\nAs you can see, some non NaN values have been replaced by NaN values which is not expected. And the first value for a given date is not always NaN so the code doesn't behave as I would like.\n\nHere is what I want to get after fillforward:\n\n![image](https://cloud.githubusercontent.com/assets/15088142/10433586/65ef34ce-7113-11e5-85dd-b2984d5a7ee8.png)\n\nFurthermore, when I tested your code on the example, I have measured times over the second which is really too slow for my use case :-( Indeed, I need to make this operation a lot in my code.\n\nThanks for your help\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/147470443",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11296#issuecomment-147470443",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11296",
    "id": 147470443,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NzQ3MDQ0Mw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-12T17:34:53Z",
    "updated_at": "2015-10-12T17:34:53Z",
    "author_association": "CONTRIBUTOR",
    "body": "pls don't post pictures of frames they are simply not helpful\ninstead show code to repro\n\nyour frame is likely not sorted\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/147521562",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11296#issuecomment-147521562",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11296",
    "id": 147521562,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NzUyMTU2Mg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-12T21:02:34Z",
    "updated_at": "2015-10-12T21:02:34Z",
    "author_association": "CONTRIBUTOR",
    "body": "Error in the work-around\n\n```\nIn [60]: df\nOut[60]: \n                                Value\nDate       Input Date                \n2015-01-31 2015-02-01 09:00:00    NaN\n           2015-02-01 10:00:00   5.00\n           2015-03-01 09:00:00   5.25\n           2015-03-01 10:00:00    NaN\n           2015-04-01 08:00:00   5.50\n2015-02-28 2015-03-01 09:00:00   6.00\n           2015-03-01 10:00:00    NaN\n           2015-04-01 07:00:00    NaN\n           2015-04-01 08:00:00   6.30\n2015-03-01 2015-04-01 07:00:00    NaN\n           2015-04-01 08:00:00   7.00\n\nIn [61]: filler(df)\nOut[61]: \n                                Value\nDate       Input Date                \n2015-01-31 2015-02-01 09:00:00    NaN\n           2015-02-01 10:00:00   5.00\n           2015-03-01 09:00:00   5.25\n           2015-03-01 10:00:00   5.25\n           2015-04-01 08:00:00   5.50\n2015-02-28 2015-03-01 09:00:00   6.00\n           2015-03-01 10:00:00   6.00\n           2015-04-01 07:00:00   6.00\n           2015-04-01 08:00:00   6.30\n2015-03-01 2015-04-01 07:00:00    NaN\n           2015-04-01 08:00:00   7.00\n```\n\nThis is what I mean by copy-pastable\n\n```\nimport pandas as pd\nimport numpy as np\n\nTimestamp = pd.Timestamp\ndf = pd.DataFrame({'Value' : [np.nan,5,5.25,np.nan,5.5,6,np.nan,np.nan,6.3,np.nan,7]})\ndf.index = pd.MultiIndex.from_tuples([ (Timestamp('2015-01-31 00:00:00', offset='M'), Timestamp('2015-02-01 09:00:00')),\n                                       (Timestamp('2015-01-31 00:00:00', offset='M'), Timestamp('2015-02-01 10:00:00')),\n                                       (Timestamp('2015-01-31 00:00:00', offset='M'), Timestamp('2015-03-01 09:00:00')),\n                                       (Timestamp('2015-01-31 00:00:00', offset='M'), Timestamp('2015-03-01 10:00:00')),\n                                       (Timestamp('2015-01-31 00:00:00', offset='M'), Timestamp('2015-04-01 08:00:00')),\n                                       (Timestamp('2015-02-28 00:00:00', offset='M'), Timestamp('2015-03-01 09:00:00')),\n                                       (Timestamp('2015-02-28 00:00:00', offset='M'), Timestamp('2015-03-01 10:00:00')),\n                                       (Timestamp('2015-02-28 00:00:00', offset='M'), Timestamp('2015-04-01 07:00:00')),\n                                       (Timestamp('2015-02-28 00:00:00', offset='M'), Timestamp('2015-04-01 08:00:00')),\n                                       (Timestamp('2015-03-01 00:00:00', offset='M'), Timestamp('2015-04-01 07:00:00')),\n                                       (Timestamp('2015-03-01 00:00:00', offset='M'), Timestamp('2015-04-01 08:00:00'))],\n                                     names=['Date','Input Date'])\n\n\ndef filler(x):\n   names = x.index.names\n   x = x.reset_index()\n   indexer = x.groupby('Date',as_index=False).nth(0).index\n   indexer = indexer[x.loc[indexer,'Value'].isnull()]\n   x.loc[indexer,'Value'] = -1\n   return x.ffill().replace(-1,np.nan).set_index(names)\n```\n\nAnd on the original frame\n\n```\nIn [75]: %timeit filler(df)\n1 loops, best of 3: 634 ms per loop\n\nIn [77]: df.info()\n<class 'pandas.core.frame.DataFrame'>\nMultiIndex: 100000 entries, (2001-10-06 00:00:00, 2001-10-06 05:00:00) to (2093-01-09 00:00:00, 2093-01-09 05:00:00)\nData columns (total 2 columns):\nValue    33333 non-null float64\nId       33333 non-null float64\ndtypes: float64(2)\nmemory usage: 3.3+ MB\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/147712034",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11296#issuecomment-147712034",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11296",
    "id": 147712034,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NzcxMjAzNA==",
    "user": {
      "login": "squeniart",
      "id": 15088142,
      "node_id": "MDQ6VXNlcjE1MDg4MTQy",
      "avatar_url": "https://avatars2.githubusercontent.com/u/15088142?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/squeniart",
      "html_url": "https://github.com/squeniart",
      "followers_url": "https://api.github.com/users/squeniart/followers",
      "following_url": "https://api.github.com/users/squeniart/following{/other_user}",
      "gists_url": "https://api.github.com/users/squeniart/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/squeniart/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/squeniart/subscriptions",
      "organizations_url": "https://api.github.com/users/squeniart/orgs",
      "repos_url": "https://api.github.com/users/squeniart/repos",
      "events_url": "https://api.github.com/users/squeniart/events{/privacy}",
      "received_events_url": "https://api.github.com/users/squeniart/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-13T13:21:42Z",
    "updated_at": "2015-10-13T13:21:42Z",
    "author_association": "NONE",
    "body": "Sorry for the pics. I understand  your point and I will provide the code to let you easily create the dataframes next time.\n\nI confirm your last workaround is working well since I get the expected results. And the performances are better compared to:\n- a simple rows iteration algorithm to fill NA looking except when the date is changing\n- the ffill apply on the groupby result\n\nBut the performances are still 100 times slower compared to a simple fill forward and unfortunately, this is preventing me from using pandas in my project (~20/30 ms could be acceptable time). Do you think this performance issue could be addressed in a near future?\n\nThank you a lot for your help!\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/147714943",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11296#issuecomment-147714943",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11296",
    "id": 147714943,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NzcxNDk0Mw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-13T13:31:25Z",
    "updated_at": "2015-10-13T13:31:25Z",
    "author_association": "CONTRIBUTOR",
    "body": "@squeniart well, pull-requests are accepted. \n\nIf you are constantly calling this in a time sensistive way then you are simply doing it wrong. Use caching or other techniques or roll-your own.\n\nThis is very easy to do in numba/cython.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/157399421",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11296#issuecomment-157399421",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11296",
    "id": 157399421,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE1NzM5OTQyMQ==",
    "user": {
      "login": "vitteloil",
      "id": 370841,
      "node_id": "MDQ6VXNlcjM3MDg0MQ==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/370841?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vitteloil",
      "html_url": "https://github.com/vitteloil",
      "followers_url": "https://api.github.com/users/vitteloil/followers",
      "following_url": "https://api.github.com/users/vitteloil/following{/other_user}",
      "gists_url": "https://api.github.com/users/vitteloil/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vitteloil/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vitteloil/subscriptions",
      "organizations_url": "https://api.github.com/users/vitteloil/orgs",
      "repos_url": "https://api.github.com/users/vitteloil/repos",
      "events_url": "https://api.github.com/users/vitteloil/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vitteloil/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-11-17T15:15:21Z",
    "updated_at": "2015-11-19T12:14:31Z",
    "author_association": "NONE",
    "body": "Hi, I'm from the same team as @squeniart .\n\nI tried to see where the culprit is, in pandas. It appears, when using groupby().fillna(method='ffill')), the cythonized code pad_2d (generated by generate_code.py) IS applied.\n\nProblem is, in this particular example in the first message of this issue, the pad_2d_XXX code is called 66668 times, on series with only 3 elements in it. All the underlying code is in python, and is also very slow.\n1. grouping operations = 30% of the total time\n2. fillna operations = 30% of the total time\n3. merge&concat operations = 40% of the total time\n\nfigures taken from cProfiling dataframe.ffill(), profile output available here https://drive.google.com/file/d/0B3pyL0DQV74ic1p4dW5FaS12QVE/view?usp=sharing\n\nI wonder if that would be acceptable, in a pull request, to add a method which does what we want to do. This method, for example, dataframe.ffill_reset(Column) would take a column name as a parameter, and would fill forward all the other columns, according to this Column argument. Every time the Column value changes, the fill forward stops and resets.\n\nFor example this cython function which would be the core of this new ffill_reset() function, and would be broke down for the different data types (from bool to floats, etc..):\n\n``` python\ndef xpropagate_int64(ndarray[uint64_t, ndim=1] vdate,\n                            ndarray[int64_t, ndim=1] vdata):\n\n    # Set prev value to NA\n    cdef uint64_t dateprev = 0\n    cdef int64_t valprev\n    cdef Py_ssize_t vsize = (<object> vdata).size\n\n    # Go through date axis and fill forward NA values\n    for i in range(vsize):\n        # Is it a new date?\n        date = vdate[i]\n        val = vdata[i]\n\n        if date != dateprev:\n            valprev = val\n            dateprev = date\n            continue\n\n        # this is the same date than the one before\n        # and the value is NA => fill with previous value\n        # val != val is how we test for NaN\n        if val != val:\n            vdata[i] = valprev\n            continue\n\n        # this is the same date than the one before\n        # and the value is not NA => just keep in mind this value\n        valprev = val\n```\n\nThanks for your suggestions and help on the matter.\nHenri\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/364607324",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11296#issuecomment-364607324",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11296",
    "id": 364607324,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDYwNzMyNA==",
    "user": {
      "login": "WillAyd",
      "id": 609873,
      "node_id": "MDQ6VXNlcjYwOTg3Mw==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/609873?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/WillAyd",
      "html_url": "https://github.com/WillAyd",
      "followers_url": "https://api.github.com/users/WillAyd/followers",
      "following_url": "https://api.github.com/users/WillAyd/following{/other_user}",
      "gists_url": "https://api.github.com/users/WillAyd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/WillAyd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/WillAyd/subscriptions",
      "organizations_url": "https://api.github.com/users/WillAyd/orgs",
      "repos_url": "https://api.github.com/users/WillAyd/repos",
      "events_url": "https://api.github.com/users/WillAyd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/WillAyd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-10T00:25:29Z",
    "updated_at": "2018-02-10T00:25:29Z",
    "author_association": "MEMBER",
    "body": "@jreback while I'm working on Cython optimizations I can take a look at this one. Just curious if we view the fact that `ffill` and `bfill`retain the grouping in it's own column as a feature or something up for discussion. To illustrate:\r\n\r\n```python\r\nIn []: df = pd.DataFrame({'key': ['a']*5, 'val': range(5)})\r\nIn []: df.groupby('key').rank()\r\nOut []:\r\n   val\r\n0  1.0\r\n1  2.0\r\n2  3.0\r\n3  4.0\r\n4  5.0\r\n\r\nIn []: df.groupby('key').ffill()  # retains key in output; same for bfill\r\nOut []:\r\n  key  val\r\n0   a    0\r\n1   a    1\r\n2   a    2\r\n3   a    3\r\n4   a    4\r\n```\r\n\r\nIf `bfill` and `ffill` didn't return the grouping in a fashion similar to `rank` then we could leverage the same call signatures as the rest of the transformations"
  }
]
