[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/120414916",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10540#issuecomment-120414916",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10540",
    "id": 120414916,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyMDQxNDkxNg==",
    "user": {
      "login": "bashtage",
      "id": 5585221,
      "node_id": "MDQ6VXNlcjU1ODUyMjE=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5585221?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bashtage",
      "html_url": "https://github.com/bashtage",
      "followers_url": "https://api.github.com/users/bashtage/followers",
      "following_url": "https://api.github.com/users/bashtage/following{/other_user}",
      "gists_url": "https://api.github.com/users/bashtage/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bashtage/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bashtage/subscriptions",
      "organizations_url": "https://api.github.com/users/bashtage/orgs",
      "repos_url": "https://api.github.com/users/bashtage/repos",
      "events_url": "https://api.github.com/users/bashtage/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bashtage/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-07-10T13:46:24Z",
    "updated_at": "2015-07-10T13:46:24Z",
    "author_association": "CONTRIBUTOR",
    "body": "For numeric data it is probably fastest to use `np.diff(x,axis)==0` to find the dupes.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/120429388",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10540#issuecomment-120429388",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10540",
    "id": 120429388,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyMDQyOTM4OA==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-07-10T14:58:24Z",
    "updated_at": "2015-07-10T14:58:24Z",
    "author_association": "MEMBER",
    "body": "I think this is indeed a very useful feature. \nBut, we should think a bit about the API. As there could also be some kind of `groupby` that does this (where this drop_duplicates would then be a `consecutive_groupby().first()`). See #5494, #7387\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/120453608",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10540#issuecomment-120453608",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10540",
    "id": 120453608,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyMDQ1MzYwOA==",
    "user": {
      "login": "kawochen",
      "id": 10709573,
      "node_id": "MDQ6VXNlcjEwNzA5NTcz",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10709573?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/kawochen",
      "html_url": "https://github.com/kawochen",
      "followers_url": "https://api.github.com/users/kawochen/followers",
      "following_url": "https://api.github.com/users/kawochen/following{/other_user}",
      "gists_url": "https://api.github.com/users/kawochen/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/kawochen/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/kawochen/subscriptions",
      "organizations_url": "https://api.github.com/users/kawochen/orgs",
      "repos_url": "https://api.github.com/users/kawochen/repos",
      "events_url": "https://api.github.com/users/kawochen/events{/privacy}",
      "received_events_url": "https://api.github.com/users/kawochen/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-07-10T16:34:46Z",
    "updated_at": "2015-07-10T16:34:46Z",
    "author_association": "CONTRIBUTOR",
    "body": "You could find the duplicates using `itertools.groupby` as well, or `groupby` something like `[[(i, x) for i, g in groupby(df['a']) for x in g]]`, but it's pretty ugly and doesn't handle `nan` well.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/233765702",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10540#issuecomment-233765702",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10540",
    "id": 233765702,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzMzc2NTcwMg==",
    "user": {
      "login": "sinhrks",
      "id": 1696302,
      "node_id": "MDQ6VXNlcjE2OTYzMDI=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1696302?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sinhrks",
      "html_url": "https://github.com/sinhrks",
      "followers_url": "https://api.github.com/users/sinhrks/followers",
      "following_url": "https://api.github.com/users/sinhrks/following{/other_user}",
      "gists_url": "https://api.github.com/users/sinhrks/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sinhrks/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sinhrks/subscriptions",
      "organizations_url": "https://api.github.com/users/sinhrks/orgs",
      "repos_url": "https://api.github.com/users/sinhrks/repos",
      "events_url": "https://api.github.com/users/sinhrks/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sinhrks/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-19T21:06:10Z",
    "updated_at": "2016-07-19T21:06:10Z",
    "author_association": "MEMBER",
    "body": "You can do:\n\n```\ndf[df['poll_support'] != df['poll_support'].shift(1)]\n#             poll_support\n# 2002-01-01           0.3\n# 2002-01-02           0.4\n# 2002-01-05           0.3\n\ndf.groupby((df['poll_support'] != df['poll_support'].shift(1)).cumsum()).count()\n#               poll_support\n# poll_support              \n# 1                        1\n# 2                        3\n# 3                        1\n```\n\nI prefer this to be on cookbook rather than new method / options as user may want more flexible, e.g. drop 3 consective.\n"
  }
]
