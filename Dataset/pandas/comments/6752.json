[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/39169649",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6752#issuecomment-39169649",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6752",
    "id": 39169649,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTY5NjQ5",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-01T04:22:17Z",
    "updated_at": "2014-04-01T04:22:17Z",
    "author_association": "CONTRIBUTOR",
    "body": "pls post a sample of your file along with the code you are reading\n\nand show the exact code for the 2nd operation \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/39171653",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6752#issuecomment-39171653",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6752",
    "id": 39171653,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTcxNjUz",
    "user": {
      "login": "chrisb13",
      "id": 5499680,
      "node_id": "MDQ6VXNlcjU0OTk2ODA=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/5499680?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/chrisb13",
      "html_url": "https://github.com/chrisb13",
      "followers_url": "https://api.github.com/users/chrisb13/followers",
      "following_url": "https://api.github.com/users/chrisb13/following{/other_user}",
      "gists_url": "https://api.github.com/users/chrisb13/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/chrisb13/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/chrisb13/subscriptions",
      "organizations_url": "https://api.github.com/users/chrisb13/orgs",
      "repos_url": "https://api.github.com/users/chrisb13/repos",
      "events_url": "https://api.github.com/users/chrisb13/events{/privacy}",
      "received_events_url": "https://api.github.com/users/chrisb13/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-01T05:16:23Z",
    "updated_at": "2014-04-01T05:16:23Z",
    "author_association": "NONE",
    "body": "Sorry, closed this accidentally.\n\njreback, thanks for the message.\n\nSo here's my code extracted to it's bare bits so you can see what I'm talking about. Both operations are covered.\n\n```\nimport pandas as pd\nimport numpy as np\nimport time\nimport datetime\nprint \"pandas ver\", pd.__version__\n\n#PUT wothwhile code here!\ndef with_indexing2(year,month,day,seconds):                              \n   return datetime.datetime(*map(int, [year,month,day,0,0,seconds])) \n\nsfnames=['parnum','longitude','latitude','depth_m','quan_par','year','month','day','seconds','velocity']\n\nprint \"pandas 0.13.1 friendly\"\nstart=time.time()\nseedDF = pd.read_csv('seedfileBIG',delim_whitespace=True,names=sfnames,parse_dates={'Date': [5,6,7,8]}, date_parser=with_indexing2,iterator=True, chunksize=1000)\ndf = pd.concat([chunk for chunk in seedDF], ignore_index=True)\nfinish=time.time()\nprint \"time for reading: \",finish-start\n\nprint \"pandas 0.12.0 friendly\"\nstart=time.time()\nseedDF=pd.read_csv('seedfileBIG',delim_whitespace=True,names=sfnames, iterator=True, chunksize=1000)\nSEEDFILE = pd.concat([chunk for chunk in seedDF], ignore_index=True)\nfinish=time.time()\nprint \"time for reading two: \",finish-start\n\nstart=time.time()\nSEEDFILE['tmp_refdate'] = SEEDFILE[['year','month','day','seconds']].apply(lambda x: pd.datetime(x['year'], x['month'], x['day'],0,0,x['seconds']), axis=1) \nfinish=time.time()\nprint \"this op takes longer on 0.13.1 compared to 0.12.0: \",finish-start\n\nprint type(SEEDFILE['tmp_refdate'].ix[5])\nmoo=SEEDFILE['tmp_refdate'].astype(datetime.datetime)\nprint type(moo.ix[5])\n\nstart=time.time()\noffset=pd.Series(np.random.randint(86400,86400*50,[np.shape(df)[0]]))\noffset=offset.apply(lambda x: datetime.timedelta(seconds=int(x)))\nfinish=time.time()\nprint \"time for setting up the offset: \",finish-start\n\ndealbreaker=offset+ SEEDFILE['tmp_refdate']  \ndealbreaker=-offset+ SEEDFILE['tmp_refdate']  \n\nprint \"this works on pandas 0.12.0 but not new ver\"\ndealbreaker=offset+ moo\ndealbreaker=-offset+ moo\n\n```\n\nHere's output from 0.12.0\n\n```\npandas ver 0.12.0\npandas 0.13.1 friendly\ntime for reading:  25.6217610836\npandas 0.12.0 friendly\ntime for reading two:  1.81773400307\nthis op takes longer on 0.13.1 compared to 0.12.0:  14.1035928726\n<class 'pandas.tslib.Timestamp'>\n<type 'datetime.datetime'>\ntime for setting up the offset:  3.76751995087\nthis works on pandas 0.12.0 but not new ver\n```\n\nAnd here's output from 0.13.1\n\n```\npandas ver 0.13.1\npandas 0.13.1 friendly\ntime for reading:  8.33899307251\npandas 0.12.0 friendly\ntime for reading two:  2.15691804886\nthis op takes longer on 0.13.1 compared to 0.12.0:  59.5941419601\n<class 'pandas.tslib.Timestamp'>\n<type 'datetime.datetime'>\ntime for setting up the offset:  4.70446419716\nthis works on pandas 0.12.0 but not new ver\nTraceback (most recent call last):\n  File \"testforpandas.py\", line 136, in <module>\n    dealbreaker=offset+ moo\n  File \"/share/apps/python/2.7.5/lib/python2.7/site-packages/pandas-0.13.1-py2.7-linux-x86_64.egg/pandas/core/ops.py\", line 464, in wrapper\n    time_converted = _TimeOp.maybe_convert_for_time_op(left, right, name)\n  File \"/share/apps/python/2.7.5/lib/python2.7/site-packages/pandas-0.13.1-py2.7-linux-x86_64.egg/pandas/core/ops.py\", line 431, in maybe_convert_for_time_op\n    return cls(left, right, name)\n  File \"/share/apps/python/2.7.5/lib/python2.7/site-packages/pandas-0.13.1-py2.7-linux-x86_64.egg/pandas/core/ops.py\", line 247, in __init__\n    rvalues = self._convert_to_array(right, name=name, other=lvalues)\n  File \"/share/apps/python/2.7.5/lib/python2.7/site-packages/pandas-0.13.1-py2.7-linux-x86_64.egg/pandas/core/ops.py\", line 329, in _convert_to_array\n    values = tslib.array_to_datetime(values)\nTypeError: Argument 'values' has incorrect type (expected numpy.ndarray, got Series)\n```\n\nHere's a small data sample\n\n```\n00001 111.2 -25.0 625.0 1 1984 6 13 0 0.052918882406948815\n00002 111.0 -25.0 275.0 1 1985 12 15 0 0.02881595443009843\n00003 110.8 -25.0 1375.0 1 1991 4 13 0 0.02003115550905939\n00004 111.4 -25.0 1125.0 1 1976 4 21 0 0.019681222220233868\n00005 110.3 -25.0 1225.0 1 2003 1 20 0 0.01849325474918594\n00006 111.0 -25.0 675.0 1 1999 11 2 0 0.07869970157971946\n00007 111.6 -25.0 625.0 1 1965 8 7 0 0.027609350773164763\n00008 111.0 -25.0 75.0 1 1964 10 21 0 0.05199770797475089\n00009 111.0 -25.0 425.0 1 1981 3 21 0 0.014744420543867197\n00010 111.4 -25.0 825.0 1 1974 2 21 0 0.02907558202919826\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/39196368",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6752#issuecomment-39196368",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6752",
    "id": 39196368,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTk2MzY4",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-01T11:49:57Z",
    "updated_at": "2014-04-01T11:49:57Z",
    "author_association": "CONTRIBUTOR",
    "body": "Well don't use apply when a vectorized soln exists (this will work in both 0.12 and 0.13.1). Don't convert the dates on read in at all.\n\n```\nIn [12]: %timeit pd.to_datetime(dfbig['year']*10000+dfbig['month']*100+dfbig['day'],format='%Y%m%d')+dfbig['seconds'].astype('timedelta64[s]').astype('timedelta64[ns]')\n1 loops, best of 3: 1.09 s per loop\n\nIn [13]: dfbig.shape\nOut[13]: (1000000, 10)\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/39196731",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6752#issuecomment-39196731",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6752",
    "id": 39196731,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTk2NzMx",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-01T11:55:04Z",
    "updated_at": "2014-04-01T11:55:04Z",
    "author_association": "CONTRIBUTOR",
    "body": "don't read in very small chunks; a millions lines can be read all at once\n\ndon't use apply again for the 2nd issue\n\n```\nIn [23]: %timeit dates+offset.astype('timedelta64[s]').astype('timedelta64[ns]')\n1 loops, best of 3: 264 ms per loop\n\nIn [24]: dates+offset.astype('timedelta64[s]').astype('timedelta64[ns]')\nOut[24]: \n0    1984-06-18 05:44:01\n1    1986-01-09 10:33:11\n2    1991-05-01 11:14:14\n3    1976-06-02 16:45:44\n4    2003-03-08 17:21:32\n5    1999-11-29 22:43:53\n6    1965-08-15 07:30:05\n7    1964-12-04 11:27:51\n8    1981-04-13 09:07:17\n9    1974-03-20 05:58:54\n10   1984-06-18 05:44:01\n11   1986-01-09 10:33:11\n12   1991-05-01 11:14:14\n13   1976-06-02 16:45:44\n14   2003-03-08 17:21:32\n...\n999985   1999-11-29 22:43:53\n999986   1965-08-15 07:30:05\n999987   1964-12-04 11:27:51\n999988   1981-04-13 09:07:17\n999989   1974-03-20 05:58:54\n999990   1984-06-18 05:44:01\n999991   1986-01-09 10:33:11\n999992   1991-05-01 11:14:14\n999993   1976-06-02 16:45:44\n999994   2003-03-08 17:21:32\n999995   1999-11-29 22:43:53\n999996   1965-08-15 07:30:05\n999997   1964-12-04 11:27:51\n999998   1981-04-13 09:07:17\n999999   1974-03-20 05:58:54\nLength: 1000000, dtype: datetime64[ns]\n\n```\n\nHere is the way to use `pd.to_timedelta` see here: http://pandas.pydata.org/pandas-docs/stable/timeseries.html#time-deltas\n\n(though their is a currently a perf issue with this for large series)\n\n```\nIn [26]: pd.to_timedelta(pd.Series(np.random.randint(86400,86400*50,[np.shape(df)[0]])),unit='s')\nOut[26]: \n0   35 days, 00:00:39\n1   15 days, 20:47:09\n2   28 days, 11:32:09\n3   47 days, 21:56:21\n4   29 days, 04:37:26\n5    6 days, 18:51:45\n6   28 days, 11:03:50\n7    2 days, 05:49:45\n8   23 days, 17:23:41\n9   30 days, 18:38:48\ndtype: timedelta64[ns]\n\n```\n"
  }
]
