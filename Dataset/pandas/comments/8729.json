[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/61716193",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-61716193",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 61716193,
    "node_id": "MDEyOklzc3VlQ29tbWVudDYxNzE2MTkz",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-11-04T21:18:15Z",
    "updated_at": "2014-11-04T21:18:15Z",
    "author_association": "MEMBER",
    "body": "How do you know it does not write the records in batches? (the end result should be the same, you normally don't notice it)\n\nThat it takes a bit longer is not surprising I think, as more insert statements are called.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/61719304",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-61719304",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 61719304,
    "node_id": "MDEyOklzc3VlQ29tbWVudDYxNzE5MzA0",
    "user": {
      "login": "gayathri89",
      "id": 9558666,
      "node_id": "MDQ6VXNlcjk1NTg2NjY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/9558666?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gayathri89",
      "html_url": "https://github.com/gayathri89",
      "followers_url": "https://api.github.com/users/gayathri89/followers",
      "following_url": "https://api.github.com/users/gayathri89/following{/other_user}",
      "gists_url": "https://api.github.com/users/gayathri89/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gayathri89/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gayathri89/subscriptions",
      "organizations_url": "https://api.github.com/users/gayathri89/orgs",
      "repos_url": "https://api.github.com/users/gayathri89/repos",
      "events_url": "https://api.github.com/users/gayathri89/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gayathri89/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-11-04T21:38:29Z",
    "updated_at": "2014-11-04T21:54:19Z",
    "author_association": "NONE",
    "body": "Hi Joris,\n\nThank you very much for the reply. It almost takes me an hour to write\n50,000 records.\nWhen i query my DB I don't find any records until the successful completion\nof the python code.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/61721941",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-61721941",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 61721941,
    "node_id": "MDEyOklzc3VlQ29tbWVudDYxNzIxOTQx",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-11-04T21:55:56Z",
    "updated_at": "2014-11-04T21:55:56Z",
    "author_association": "MEMBER",
    "body": "> Thank you very much for the reply. It almost takes me an hour to write 50,000 records. \n\nHow many columns do you have? An hour seems very long for 50000 records.\n\n> When i query my DB I don't find any records until the successful completion of the python code.\n\nThat is expected, as the transaction is only committed when all chunks are written\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/61722482",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-61722482",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 61722482,
    "node_id": "MDEyOklzc3VlQ29tbWVudDYxNzIyNDgy",
    "user": {
      "login": "gayathri89",
      "id": 9558666,
      "node_id": "MDQ6VXNlcjk1NTg2NjY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/9558666?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gayathri89",
      "html_url": "https://github.com/gayathri89",
      "followers_url": "https://api.github.com/users/gayathri89/followers",
      "following_url": "https://api.github.com/users/gayathri89/following{/other_user}",
      "gists_url": "https://api.github.com/users/gayathri89/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gayathri89/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gayathri89/subscriptions",
      "organizations_url": "https://api.github.com/users/gayathri89/orgs",
      "repos_url": "https://api.github.com/users/gayathri89/repos",
      "events_url": "https://api.github.com/users/gayathri89/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gayathri89/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-11-04T21:59:19Z",
    "updated_at": "2014-11-05T10:08:58Z",
    "author_association": "NONE",
    "body": "I have 40 columns and 49365 rows.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/61785411",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-61785411",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 61785411,
    "node_id": "MDEyOklzc3VlQ29tbWVudDYxNzg1NDEx",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-11-05T10:11:29Z",
    "updated_at": "2014-11-05T10:11:29Z",
    "author_association": "MEMBER",
    "body": "As a small test, a DataFrame with that size full of floats takes in my computer 3.8 seconds to write to an in memory sqlite database:\n\n```\nIn [3]:   engine = create_engine('sqlite:///:memory:') #, echo='debug')\n\nIn [4]:   df = pd.DataFrame(np.random.randn(49365, 40))\n\nIn [5]:   %timeit df.to_sql('test', engine, if_exists='replace')\n1 loops, best of 3: 3.82 s per loop\n```\n\nWith other dtypes, it can take a bit longer, but not that much. It seems you have a very slow connection to the database.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/61848568",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-61848568",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 61848568,
    "node_id": "MDEyOklzc3VlQ29tbWVudDYxODQ4NTY4",
    "user": {
      "login": "phobson",
      "id": 1163939,
      "node_id": "MDQ6VXNlcjExNjM5Mzk=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/1163939?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/phobson",
      "html_url": "https://github.com/phobson",
      "followers_url": "https://api.github.com/users/phobson/followers",
      "following_url": "https://api.github.com/users/phobson/following{/other_user}",
      "gists_url": "https://api.github.com/users/phobson/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/phobson/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/phobson/subscriptions",
      "organizations_url": "https://api.github.com/users/phobson/orgs",
      "repos_url": "https://api.github.com/users/phobson/repos",
      "events_url": "https://api.github.com/users/phobson/events{/privacy}",
      "received_events_url": "https://api.github.com/users/phobson/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-11-05T17:36:33Z",
    "updated_at": "2014-11-05T17:36:33Z",
    "author_association": "NONE",
    "body": "With 50k records, `chunksize=100` seems awfully small. Try 5000 and see if that speeds things up.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/62176891",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-62176891",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 62176891,
    "node_id": "MDEyOklzc3VlQ29tbWVudDYyMTc2ODkx",
    "user": {
      "login": "gayathri89",
      "id": 9558666,
      "node_id": "MDQ6VXNlcjk1NTg2NjY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/9558666?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gayathri89",
      "html_url": "https://github.com/gayathri89",
      "followers_url": "https://api.github.com/users/gayathri89/followers",
      "following_url": "https://api.github.com/users/gayathri89/following{/other_user}",
      "gists_url": "https://api.github.com/users/gayathri89/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gayathri89/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gayathri89/subscriptions",
      "organizations_url": "https://api.github.com/users/gayathri89/orgs",
      "repos_url": "https://api.github.com/users/gayathri89/repos",
      "events_url": "https://api.github.com/users/gayathri89/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gayathri89/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-11-07T17:09:11Z",
    "updated_at": "2014-11-08T12:34:45Z",
    "author_association": "NONE",
    "body": "Joris,\n\nI tried with my local machine database and it didnt work.\n\nIs it because i use SQL Server and pydhoc?\n\nThank you\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/62256259",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-62256259",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 62256259,
    "node_id": "MDEyOklzc3VlQ29tbWVudDYyMjU2MjU5",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-11-08T12:35:45Z",
    "updated_at": "2014-11-08T12:35:45Z",
    "author_association": "MEMBER",
    "body": "@gayathri89 sorry I have no experience with SQL Server\n\nDid you try to write the dataframe just without specifying `chunksize` ?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/64892870",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-64892870",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 64892870,
    "node_id": "MDEyOklzc3VlQ29tbWVudDY0ODkyODcw",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-11-28T13:17:06Z",
    "updated_at": "2014-11-28T13:17:06Z",
    "author_association": "MEMBER",
    "body": "Closing this as a usage question and not a bug, as far as I can see. \n@gayathri89 Feel free to reopen if you have more information to diagnose this.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/134754606",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-134754606",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 134754606,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzNDc1NDYwNg==",
    "user": {
      "login": "florianverhein",
      "id": 4240669,
      "node_id": "MDQ6VXNlcjQyNDA2Njk=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/4240669?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/florianverhein",
      "html_url": "https://github.com/florianverhein",
      "followers_url": "https://api.github.com/users/florianverhein/followers",
      "following_url": "https://api.github.com/users/florianverhein/following{/other_user}",
      "gists_url": "https://api.github.com/users/florianverhein/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/florianverhein/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/florianverhein/subscriptions",
      "organizations_url": "https://api.github.com/users/florianverhein/orgs",
      "repos_url": "https://api.github.com/users/florianverhein/repos",
      "events_url": "https://api.github.com/users/florianverhein/events{/privacy}",
      "received_events_url": "https://api.github.com/users/florianverhein/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-08-25T22:00:38Z",
    "updated_at": "2015-08-25T22:00:38Z",
    "author_association": "NONE",
    "body": "I'm seeing the same bug. However, as I'm writing to redshift, I can see the insert query that is being generated in it's logs. It is inserting one row at a time despite chunksize = None or (for example) 20000. And since a single redshift query has a few seconds overhead (at the least) per query, this is very obvious and is a blocker for inserting a modest number of rows.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/134756098",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-134756098",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 134756098,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzNDc1NjA5OA==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-08-25T22:05:53Z",
    "updated_at": "2015-08-25T22:05:53Z",
    "author_association": "MEMBER",
    "body": "@florianverhein Can you provide some more info? (some code, part of the logs that shows the inserts, ...)\n\nAs in the code, one insert statement with all the data is executed: https://github.com/pydata/pandas/blob/master/pandas/io/sql.py#L725\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/134757753",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-134757753",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 134757753,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzNDc1Nzc1Mw==",
    "user": {
      "login": "florianverhein",
      "id": 4240669,
      "node_id": "MDQ6VXNlcjQyNDA2Njk=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/4240669?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/florianverhein",
      "html_url": "https://github.com/florianverhein",
      "followers_url": "https://api.github.com/users/florianverhein/followers",
      "following_url": "https://api.github.com/users/florianverhein/following{/other_user}",
      "gists_url": "https://api.github.com/users/florianverhein/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/florianverhein/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/florianverhein/subscriptions",
      "organizations_url": "https://api.github.com/users/florianverhein/orgs",
      "repos_url": "https://api.github.com/users/florianverhein/repos",
      "events_url": "https://api.github.com/users/florianverhein/events{/privacy}",
      "received_events_url": "https://api.github.com/users/florianverhein/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-08-25T22:15:37Z",
    "updated_at": "2015-08-25T22:15:37Z",
    "author_association": "NONE",
    "body": "@jorisvandenbossche Sure. Here's one query (minor edit for anon.) that was submitted to redshift. I'm able to see this in the \"queries\" tab in the AWS console. It looks like one row is being inserted at a  time. The to_sql call still hasn't completed, and I suspect there are thousands of inserts now backlogged somewhere. I'm attempting to insert just over 50,000 rows. \n\n```\nINSERT\nINTO\n    temp_audit_analysis_1\n    (foo, date, problem)\nVALUES\n    ('BAR', '201505', false) \n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/134758795",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-134758795",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 134758795,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzNDc1ODc5NQ==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-08-25T22:21:41Z",
    "updated_at": "2015-08-25T22:21:41Z",
    "author_association": "MEMBER",
    "body": "Can you also give: the pandas code you use, the python db driver you are using. I would also try it with with only a few rows (that is enough to figure out what is happening). \nAnd with sqlalchemy, you can also set `echo=True` when creating the engine. This will also output some logs of what is going on. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/134761482",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-134761482",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 134761482,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzNDc2MTQ4Mg==",
    "user": {
      "login": "florianverhein",
      "id": 4240669,
      "node_id": "MDQ6VXNlcjQyNDA2Njk=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/4240669?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/florianverhein",
      "html_url": "https://github.com/florianverhein",
      "followers_url": "https://api.github.com/users/florianverhein/followers",
      "following_url": "https://api.github.com/users/florianverhein/following{/other_user}",
      "gists_url": "https://api.github.com/users/florianverhein/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/florianverhein/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/florianverhein/subscriptions",
      "organizations_url": "https://api.github.com/users/florianverhein/orgs",
      "repos_url": "https://api.github.com/users/florianverhein/repos",
      "events_url": "https://api.github.com/users/florianverhein/events{/privacy}",
      "received_events_url": "https://api.github.com/users/florianverhein/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-08-25T22:36:14Z",
    "updated_at": "2015-08-25T22:36:14Z",
    "author_association": "NONE",
    "body": "thanks, I'll give that a go once I've fixed the query backlog in redshift somehow... i can verify that there are 1000s of single row insert queries..  \n\ncode snippet (current example):\n\n```\nif_exists = 'fail' # 'replace\ndfs.to_sql(rs_problem_table,engine,schema=rs_schema,if_exists=if_exists,index=False,chunksize=20000)\n```\n\nnote that index must be false otherwise it fails for redshift.\ndfs has shape (50305, 3)\ndriver: postgresql+psycopg2\nengine created by create_engine in sqlalchemy\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/134768601",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-134768601",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 134768601,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzNDc2ODYwMQ==",
    "user": {
      "login": "florianverhein",
      "id": 4240669,
      "node_id": "MDQ6VXNlcjQyNDA2Njk=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/4240669?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/florianverhein",
      "html_url": "https://github.com/florianverhein",
      "followers_url": "https://api.github.com/users/florianverhein/followers",
      "following_url": "https://api.github.com/users/florianverhein/following{/other_user}",
      "gists_url": "https://api.github.com/users/florianverhein/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/florianverhein/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/florianverhein/subscriptions",
      "organizations_url": "https://api.github.com/users/florianverhein/orgs",
      "repos_url": "https://api.github.com/users/florianverhein/repos",
      "events_url": "https://api.github.com/users/florianverhein/events{/privacy}",
      "received_events_url": "https://api.github.com/users/florianverhein/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-08-25T23:20:53Z",
    "updated_at": "2015-08-25T23:20:53Z",
    "author_association": "NONE",
    "body": "Ok, with echo=True on, I can see this on a toy example (3 row data frame):\n\n```\nINFO:sqlalchemy.engine.base.Engine:INSERT INTO foo (date, problem) VALUES (%(date)s, %(problem)s)\nINFO:sqlalchemy.engine.base.Engine:({'date': '201505', 'problem': True}, {'date': '201505', 'problem': False}, {'date': '201505', 'problem': False})\n```\n\nwhich would suggest the engine is getting the whole chunk??\nHowever this results in 3 distinct insert statements hitting redshift. \nDoes this mean it's a driver issue?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/134769532",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-134769532",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 134769532,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzNDc2OTUzMg==",
    "user": {
      "login": "florianverhein",
      "id": 4240669,
      "node_id": "MDQ6VXNlcjQyNDA2Njk=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/4240669?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/florianverhein",
      "html_url": "https://github.com/florianverhein",
      "followers_url": "https://api.github.com/users/florianverhein/followers",
      "following_url": "https://api.github.com/users/florianverhein/following{/other_user}",
      "gists_url": "https://api.github.com/users/florianverhein/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/florianverhein/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/florianverhein/subscriptions",
      "organizations_url": "https://api.github.com/users/florianverhein/orgs",
      "repos_url": "https://api.github.com/users/florianverhein/repos",
      "events_url": "https://api.github.com/users/florianverhein/events{/privacy}",
      "received_events_url": "https://api.github.com/users/florianverhein/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-08-25T23:27:01Z",
    "updated_at": "2015-08-25T23:27:24Z",
    "author_association": "NONE",
    "body": "... hmm, perhaps less likely to be the driver(?) -- a colleague unknowingly ran into this as well, but using a different driver: `postgresql+pg8000`. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/165622723",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-165622723",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 165622723,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE2NTYyMjcyMw==",
    "user": {
      "login": "XinCindyChen",
      "id": 3255053,
      "node_id": "MDQ6VXNlcjMyNTUwNTM=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/3255053?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/XinCindyChen",
      "html_url": "https://github.com/XinCindyChen",
      "followers_url": "https://api.github.com/users/XinCindyChen/followers",
      "following_url": "https://api.github.com/users/XinCindyChen/following{/other_user}",
      "gists_url": "https://api.github.com/users/XinCindyChen/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/XinCindyChen/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/XinCindyChen/subscriptions",
      "organizations_url": "https://api.github.com/users/XinCindyChen/orgs",
      "repos_url": "https://api.github.com/users/XinCindyChen/repos",
      "events_url": "https://api.github.com/users/XinCindyChen/events{/privacy}",
      "received_events_url": "https://api.github.com/users/XinCindyChen/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-12-18T00:21:57Z",
    "updated_at": "2015-12-18T00:28:18Z",
    "author_association": "NONE",
    "body": "It seems I run into the same problem as well. I'm using postgresql+psycopg2. The postgres database is running on an AWS EC2 instance. I have a table with 260,000 rows with only 5 columns, and I tried different chunksize, and it takes awfully long time to insert to the database. Is there a solution yet? \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/165623514",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-165623514",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 165623514,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE2NTYyMzUxNA==",
    "user": {
      "login": "XinCindyChen",
      "id": 3255053,
      "node_id": "MDQ6VXNlcjMyNTUwNTM=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/3255053?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/XinCindyChen",
      "html_url": "https://github.com/XinCindyChen",
      "followers_url": "https://api.github.com/users/XinCindyChen/followers",
      "following_url": "https://api.github.com/users/XinCindyChen/following{/other_user}",
      "gists_url": "https://api.github.com/users/XinCindyChen/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/XinCindyChen/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/XinCindyChen/subscriptions",
      "organizations_url": "https://api.github.com/users/XinCindyChen/orgs",
      "repos_url": "https://api.github.com/users/XinCindyChen/repos",
      "events_url": "https://api.github.com/users/XinCindyChen/events{/privacy}",
      "received_events_url": "https://api.github.com/users/XinCindyChen/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-12-18T00:26:55Z",
    "updated_at": "2015-12-18T00:26:55Z",
    "author_association": "NONE",
    "body": "Here are part of the logs with echo = True in sqlalchemy engine creation. This means it takes 3 min to insert one chunk. Then with 260,000/5000 chunks, it will take about 2 hours and a half to insert all these rows.  \n2015-12-17 16:19:09,987 INFO sqlalchemy.engine.base.Engine INSERT INTO \n2015-12-17 16:22:08,682 INFO sqlalchemy.engine.base.Engine INSERT INTO\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/165715835",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-165715835",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 165715835,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE2NTcxNTgzNQ==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-12-18T08:46:20Z",
    "updated_at": "2015-12-18T08:46:20Z",
    "author_association": "MEMBER",
    "body": "@XinCindyChen What version of postgresql is used on the AWS instance?\n\nIf possible, could you try to log all the queries that are executed in the database? And then write a small part of the dataframe to the database, and look if it uses a multiple insert or single ones.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/165890763",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-165890763",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 165890763,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE2NTg5MDc2Mw==",
    "user": {
      "login": "florianverhein",
      "id": 4240669,
      "node_id": "MDQ6VXNlcjQyNDA2Njk=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/4240669?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/florianverhein",
      "html_url": "https://github.com/florianverhein",
      "followers_url": "https://api.github.com/users/florianverhein/followers",
      "following_url": "https://api.github.com/users/florianverhein/following{/other_user}",
      "gists_url": "https://api.github.com/users/florianverhein/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/florianverhein/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/florianverhein/subscriptions",
      "organizations_url": "https://api.github.com/users/florianverhein/orgs",
      "repos_url": "https://api.github.com/users/florianverhein/repos",
      "events_url": "https://api.github.com/users/florianverhein/events{/privacy}",
      "received_events_url": "https://api.github.com/users/florianverhein/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-12-18T20:25:19Z",
    "updated_at": "2015-12-18T20:25:19Z",
    "author_association": "NONE",
    "body": "BTW **I worked around this** for my case by creating a wrapper that (transparently) writes the dataframe to S3, creates the table in Redshift (reusing pandas sql builder for the create statement), makes RedShift copy into the table from S3, and finally cleans up after itself (on S3). Works great and is a more scalable solution for RedShift integration.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/165893642",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-165893642",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 165893642,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE2NTg5MzY0Mg==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-12-18T20:41:59Z",
    "updated_at": "2015-12-18T20:41:59Z",
    "author_association": "CONTRIBUTOR",
    "body": "FYI: https://gist.github.com/ajsmith007/d1adb79e152f5f23503b is maybe useful for redshift users.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/165899710",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-165899710",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 165899710,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE2NTg5OTcxMA==",
    "user": {
      "login": "florianverhein",
      "id": 4240669,
      "node_id": "MDQ6VXNlcjQyNDA2Njk=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/4240669?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/florianverhein",
      "html_url": "https://github.com/florianverhein",
      "followers_url": "https://api.github.com/users/florianverhein/followers",
      "following_url": "https://api.github.com/users/florianverhein/following{/other_user}",
      "gists_url": "https://api.github.com/users/florianverhein/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/florianverhein/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/florianverhein/subscriptions",
      "organizations_url": "https://api.github.com/users/florianverhein/orgs",
      "repos_url": "https://api.github.com/users/florianverhein/repos",
      "events_url": "https://api.github.com/users/florianverhein/events{/privacy}",
      "received_events_url": "https://api.github.com/users/florianverhein/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-12-18T21:17:41Z",
    "updated_at": "2015-12-18T21:17:57Z",
    "author_association": "NONE",
    "body": "@TomAugspurger I hadn't seen that before, thanks! That's pretty much what I did too. Would definitely recommend this approach to redshift users.  \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/165902732",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8729#issuecomment-165902732",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8729",
    "id": 165902732,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE2NTkwMjczMg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-12-18T21:35:46Z",
    "updated_at": "2015-12-18T21:35:46Z",
    "author_association": "CONTRIBUTOR",
    "body": "@cpcloud IIRC doesn't `odo` do this kind of bulk upload (to redshift) automatically?\n"
  }
]
