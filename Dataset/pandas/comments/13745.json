[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/264463727",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13745#issuecomment-264463727",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13745",
    "id": 264463727,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDQ2MzcyNw==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-12-02T14:19:05Z",
    "updated_at": "2016-12-02T14:19:05Z",
    "author_association": "MEMBER",
    "body": "@mrocklin do you have an example case of such an intensive merge where you do not see an speedup by parallellizing? On some examples I tried, I already do see some speedup (but probably can be improved).\r\n\r\nFor example, with\r\n\r\n```\r\nleft = pd.DataFrame({'key': list(range(1,11)) * 100000})\r\nright = pd.DataFrame({'key': range(10), 'val': range(10)})\r\n```\r\n\r\nI already see some speedup:\r\n\r\n```\r\ndef f():\r\n    left.merge(right, how='inner')\r\n    \r\ndef g4():\r\n    for i in range(4):\r\n        f()\r\n        \r\nfrom pandas.util.testing import test_parallel\r\n\r\n@test_parallel(num_threads=4)\r\ndef pg4():\r\n    f()\r\n```\r\n\r\n```\r\nIn [21]: %timeit g4()\r\n10 loops, best of 3: 149 ms per loop\r\n\r\nIn [22]: %timeit pg4()\r\n10 loops, best of 3: 99.2 ms per loop\r\n\r\n```\r\n\r\nWhen I profile this merge operation ([prof_merge3.out](https://github.com/pandas-dev/pandas/files/627296/prof_merge3.out.zip)), the main operations that take time are (the number are for this specific example, but with others I get similar trends):\r\n\r\n- factorization (ca 36%) -> hastable Factorizer -> this is already releases the GIL where possible I think\r\n- the actual inner join (ca 31%)\r\n  - ca 2/3 of the time is spend in `algos.groupsort_indexer` -> this also already releases the GIL([code](https://github.com/pandas-dev/pandas/blob/b787468ca2af344baac83758fea3026ebd8a419c/pandas/algos.pyx#L1018))\r\n  - the remaining logic in the `_join.inner_join` function itself -> this can further release the GIL, but I think is only ca 10% of overall time of merge operation\r\n- combining the results (ca 20%) -> comes down to mainly `take_1d/2d` algos -> these also already release the GIL to some extent (at least the 1d ones, 2d for some reason not) \r\n\r\nSo from a first quick exploration, there are certainly some small improvements to be made, but seems the bigger ones are already done (but with further analysis quite possible that it can further be improved). \r\n\r\n\r\n\r\n\r\n\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/264466039",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13745#issuecomment-264466039",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13745",
    "id": 264466039,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDQ2NjAzOQ==",
    "user": {
      "login": "mrocklin",
      "id": 306380,
      "node_id": "MDQ6VXNlcjMwNjM4MA==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/306380?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mrocklin",
      "html_url": "https://github.com/mrocklin",
      "followers_url": "https://api.github.com/users/mrocklin/followers",
      "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
      "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
      "organizations_url": "https://api.github.com/users/mrocklin/orgs",
      "repos_url": "https://api.github.com/users/mrocklin/repos",
      "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mrocklin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-12-02T14:29:43Z",
    "updated_at": "2016-12-02T14:29:43Z",
    "author_association": "CONTRIBUTOR",
    "body": "OK.  Let me come up with a few examples and get back to you.  If as you say most of this is already done then I'll be quite happy to be incorrect here :)"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/264467364",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13745#issuecomment-264467364",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13745",
    "id": 264467364,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDQ2NzM2NA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-12-02T14:35:36Z",
    "updated_at": "2016-12-02T14:35:36Z",
    "author_association": "CONTRIBUTOR",
    "body": "FYI: https://github.com/jreback/pandas/commit/a295e83cdd1b0e26afdd0fac2ac2b56e7ced8eda\r\n\r\nthis makes factorization about 30% faster and releases the gil in the core parts (but this currently breaks other stuff)."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/264467724",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13745#issuecomment-264467724",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13745",
    "id": 264467724,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDQ2NzcyNA==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-12-02T14:37:23Z",
    "updated_at": "2016-12-02T14:37:23Z",
    "author_association": "MEMBER",
    "body": "But still, I only get a speed improvement of factor 1.5 on 4 cores, so it also not that impressive."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/264468963",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13745#issuecomment-264468963",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13745",
    "id": 264468963,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDQ2ODk2Mw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-12-02T14:42:47Z",
    "updated_at": "2016-12-02T14:42:47Z",
    "author_association": "CONTRIBUTOR",
    "body": "@mrocklin I think to make this a truly parallel merge, you would need to change the problem a bit I think. e.g. partition across workers, replicate the Dataframe, then concat?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/264477005",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13745#issuecomment-264477005",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13745",
    "id": 264477005,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDQ3NzAwNQ==",
    "user": {
      "login": "mrocklin",
      "id": 306380,
      "node_id": "MDQ6VXNlcjMwNjM4MA==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/306380?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mrocklin",
      "html_url": "https://github.com/mrocklin",
      "followers_url": "https://api.github.com/users/mrocklin/followers",
      "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
      "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
      "organizations_url": "https://api.github.com/users/mrocklin/orgs",
      "repos_url": "https://api.github.com/users/mrocklin/repos",
      "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mrocklin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-12-02T15:15:31Z",
    "updated_at": "2016-12-02T15:15:31Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jreback yes, it could be that by operating on different dataframes we have less memory contention and would see larger speedups?\r\n\r\n@jorisvandenbossche I'm hearing two things:\r\n\r\n1.  We can get about a 50% speedup on 4 cores\r\n2.  Most of the gains have already occurred\r\n\r\nThis raises the question of fundamentally why isn't something closer to a 4x speedup possible?  Is this a memory hierarchy bound operation?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/264477837",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13745#issuecomment-264477837",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13745",
    "id": 264477837,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDQ3NzgzNw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-12-02T15:18:46Z",
    "updated_at": "2016-12-02T15:18:46Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jorisvandenbossche is your test with processes? or threads?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/264479035",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13745#issuecomment-264479035",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13745",
    "id": 264479035,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDQ3OTAzNQ==",
    "user": {
      "login": "mrocklin",
      "id": 306380,
      "node_id": "MDQ6VXNlcjMwNjM4MA==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/306380?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mrocklin",
      "html_url": "https://github.com/mrocklin",
      "followers_url": "https://api.github.com/users/mrocklin/followers",
      "following_url": "https://api.github.com/users/mrocklin/following{/other_user}",
      "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions",
      "organizations_url": "https://api.github.com/users/mrocklin/orgs",
      "repos_url": "https://api.github.com/users/mrocklin/repos",
      "events_url": "https://api.github.com/users/mrocklin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mrocklin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-12-02T15:23:37Z",
    "updated_at": "2016-12-02T15:23:37Z",
    "author_association": "CONTRIBUTOR",
    "body": "```\r\nfrom pandas.util.testing import test_parallel\r\n\r\n@test_parallel(num_threads=4)\r\ndef pg4():\r\n    f()\r\n```"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/264483068",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13745#issuecomment-264483068",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13745",
    "id": 264483068,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDQ4MzA2OA==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-12-02T15:39:18Z",
    "updated_at": "2016-12-02T15:39:18Z",
    "author_association": "MEMBER",
    "body": "Yes, I was using the `test_parallel` decorator, so was testing with threads. \r\n\r\nI don't have much experience with this, but the fact that the GIL free operations are spread throughout the merge operation (the full merge operation separately releases the GIL in potentially 5 or 6 different algos), is this is a reason for overhead and less efficient use of multiple threads / less speedup?"
  }
]
