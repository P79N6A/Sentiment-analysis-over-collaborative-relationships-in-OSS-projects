[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/257999741",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-257999741",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 257999741,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI1Nzk5OTc0MQ==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-11-02T21:08:55Z",
    "updated_at": "2016-11-02T21:08:55Z",
    "author_association": "MEMBER",
    "body": "This would be nice functionality, but the main problem is that we want it to be database-flavor independent and based on sqlalchemy core (so not sqlalchemy ORM) for inclusion in pandas itself. \nWhich will make this difficult to implement ..\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/258003458",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-258003458",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 258003458,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI1ODAwMzQ1OA==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-11-02T21:23:41Z",
    "updated_at": "2016-11-02T21:23:41Z",
    "author_association": "CONTRIBUTOR",
    "body": "Yeah, I think this is out of scope for pandas since upserts aren't supported by all db engines.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/258652035",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-258652035",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 258652035,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI1ODY1MjAzNQ==",
    "user": {
      "login": "kjford",
      "id": 5677849,
      "node_id": "MDQ6VXNlcjU2Nzc4NDk=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5677849?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/kjford",
      "html_url": "https://github.com/kjford",
      "followers_url": "https://api.github.com/users/kjford/followers",
      "following_url": "https://api.github.com/users/kjford/following{/other_user}",
      "gists_url": "https://api.github.com/users/kjford/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/kjford/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/kjford/subscriptions",
      "organizations_url": "https://api.github.com/users/kjford/orgs",
      "repos_url": "https://api.github.com/users/kjford/repos",
      "events_url": "https://api.github.com/users/kjford/events{/privacy}",
      "received_events_url": "https://api.github.com/users/kjford/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-11-06T00:33:30Z",
    "updated_at": "2016-11-06T00:33:30Z",
    "author_association": "CONTRIBUTOR",
    "body": "While an `INSERT OR UPDATE` isn't supported by all engines, an `INSERT OR REPLACE` can be made engine agnostic by deleting rows from the target table for the set of primary keys in the DataFrame index followed by an insert of all rows in the DataFrame.  You'd want to do this in a transaction.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/299987102",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-299987102",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 299987102,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTk4NzEwMg==",
    "user": {
      "login": "neilfrndes",
      "id": 24529221,
      "node_id": "MDQ6VXNlcjI0NTI5MjIx",
      "avatar_url": "https://avatars2.githubusercontent.com/u/24529221?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/neilfrndes",
      "html_url": "https://github.com/neilfrndes",
      "followers_url": "https://api.github.com/users/neilfrndes/followers",
      "following_url": "https://api.github.com/users/neilfrndes/following{/other_user}",
      "gists_url": "https://api.github.com/users/neilfrndes/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/neilfrndes/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/neilfrndes/subscriptions",
      "organizations_url": "https://api.github.com/users/neilfrndes/orgs",
      "repos_url": "https://api.github.com/users/neilfrndes/repos",
      "events_url": "https://api.github.com/users/neilfrndes/events{/privacy}",
      "received_events_url": "https://api.github.com/users/neilfrndes/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-05-08T20:51:01Z",
    "updated_at": "2017-05-08T20:51:01Z",
    "author_association": "NONE",
    "body": "@TomAugspurger Could we add the upsert option for supported db engines and throw an error for unsupported db engines ? "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/306553059",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-306553059",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 306553059,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwNjU1MzA1OQ==",
    "user": {
      "login": "ldacey",
      "id": 12517855,
      "node_id": "MDQ6VXNlcjEyNTE3ODU1",
      "avatar_url": "https://avatars0.githubusercontent.com/u/12517855?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ldacey",
      "html_url": "https://github.com/ldacey",
      "followers_url": "https://api.github.com/users/ldacey/followers",
      "following_url": "https://api.github.com/users/ldacey/following{/other_user}",
      "gists_url": "https://api.github.com/users/ldacey/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ldacey/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ldacey/subscriptions",
      "organizations_url": "https://api.github.com/users/ldacey/orgs",
      "repos_url": "https://api.github.com/users/ldacey/repos",
      "events_url": "https://api.github.com/users/ldacey/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ldacey/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-06T17:07:38Z",
    "updated_at": "2017-06-07T12:16:57Z",
    "author_association": "NONE",
    "body": "I'd like to see this as well. I am caught in between using pure SQL and SQL Alchemy (haven't gotten this to work yet, I think it has something to do with how I pass the dicts). I use psycopg2 COPY to bulk insert, but I would love to use pd.to_sql for tables where values might change over time and I don't mind it inserting a bit slower.\r\n\r\n```\r\ninsert_values = df.to_dict(orient='records')\r\ninsert_statement = sqlalchemy.dialects.postgresql.insert(table).values(insert_values)\r\nupsert_statement = insert_statement.on_conflict_do_update(\r\n    constraint='fact_case_pkey',\r\n    set_= df.to_dict(orient='dict')\r\n)\r\n```\r\n\r\nAnd pure SQL:\r\n\r\n```\r\ndef create_update_query(df, table=FACT_TABLE):\r\n    \"\"\"This function takes the Airflow execution date passes it to other functions\"\"\"\r\n    columns = ', '.join([f'{col}' for col in DATABASE_COLUMNS])\r\n    constraint = ', '.join([f'{col}' for col in PRIMARY_KEY])\r\n    placeholder = ', '.join([f'%({col})s' for col in DATABASE_COLUMNS])\r\n    values = placeholder\r\n    updates = ', '.join([f'{col} = EXCLUDED.{col}' for col in DATABASE_COLUMNS])\r\n    query = f\"\"\"INSERT INTO {table} ({columns}) \r\n    VALUES ({placeholder}) \r\n    ON CONFLICT ({constraint}) \r\n    DO UPDATE SET {updates};\"\"\"\r\n    query.split()\r\n    query = ' '.join(query.split())\r\n    return query\r\n\r\ndef load_updates(df, connection=DATABASE):\r\n    \"\"\"Uses COPY from STDIN to load to Postgres\r\n     :param df: The dataframe which is writing to StringIO, then loaded to the the database\r\n     :param connection: Refers to a PostgresHook\r\n    \"\"\"\r\n    conn = connection.get_conn()\r\n    cursor = conn.cursor()\r\n    df1 = df.where((pd.notnull(df)), None)\r\n    insert_values = df1.to_dict(orient='records')\r\n    for row in insert_values:\r\n        cursor.execute(create_update_query(df), row)\r\n        conn.commit()\r\n    cursor.close()\r\n    del cursor\r\n    conn.close()\r\n```"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/312362503",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-312362503",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 312362503,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjM2MjUwMw==",
    "user": {
      "login": "ODemidenko",
      "id": 11488142,
      "node_id": "MDQ6VXNlcjExNDg4MTQy",
      "avatar_url": "https://avatars2.githubusercontent.com/u/11488142?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ODemidenko",
      "html_url": "https://github.com/ODemidenko",
      "followers_url": "https://api.github.com/users/ODemidenko/followers",
      "following_url": "https://api.github.com/users/ODemidenko/following{/other_user}",
      "gists_url": "https://api.github.com/users/ODemidenko/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ODemidenko/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ODemidenko/subscriptions",
      "organizations_url": "https://api.github.com/users/ODemidenko/orgs",
      "repos_url": "https://api.github.com/users/ODemidenko/repos",
      "events_url": "https://api.github.com/users/ODemidenko/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ODemidenko/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-30T20:11:43Z",
    "updated_at": "2017-07-01T21:21:50Z",
    "author_association": "NONE",
    "body": "@ldacey this style worked for me (insert_statement.excluded is an alias to the row of data that violated the constraint):\r\n```\r\ninsert_values = merged_transactions_channels.to_dict(orient='records')\r\n insert_statement = sqlalchemy.dialects.postgresql.insert(orders_to_channels).values(insert_values)\r\n    upsert_statement = insert_statement.on_conflict_do_update(\r\n        constraint='orders_to_channels_pkey',\r\n        set_={'channel_owner': insert_statement.excluded.channel_owner}\r\n    )\r\n```"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/370767919",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-370767919",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 370767919,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM3MDc2NzkxOQ==",
    "user": {
      "login": "rajbiswas",
      "id": 3483744,
      "node_id": "MDQ6VXNlcjM0ODM3NDQ=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/3483744?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rajbiswas",
      "html_url": "https://github.com/rajbiswas",
      "followers_url": "https://api.github.com/users/rajbiswas/followers",
      "following_url": "https://api.github.com/users/rajbiswas/following{/other_user}",
      "gists_url": "https://api.github.com/users/rajbiswas/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rajbiswas/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rajbiswas/subscriptions",
      "organizations_url": "https://api.github.com/users/rajbiswas/orgs",
      "repos_url": "https://api.github.com/users/rajbiswas/repos",
      "events_url": "https://api.github.com/users/rajbiswas/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rajbiswas/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-03-06T12:36:12Z",
    "updated_at": "2018-03-06T12:36:12Z",
    "author_association": "NONE",
    "body": "@cdagnino This snippet might not work in the case of composite keys, that scenario has to be taken care of also. I'll try to find a way to do the same"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/385735585",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-385735585",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 385735585,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTczNTU4NQ==",
    "user": {
      "login": "danich1",
      "id": 3505417,
      "node_id": "MDQ6VXNlcjM1MDU0MTc=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/3505417?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/danich1",
      "html_url": "https://github.com/danich1",
      "followers_url": "https://api.github.com/users/danich1/followers",
      "following_url": "https://api.github.com/users/danich1/following{/other_user}",
      "gists_url": "https://api.github.com/users/danich1/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/danich1/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/danich1/subscriptions",
      "organizations_url": "https://api.github.com/users/danich1/orgs",
      "repos_url": "https://api.github.com/users/danich1/repos",
      "events_url": "https://api.github.com/users/danich1/events{/privacy}",
      "received_events_url": "https://api.github.com/users/danich1/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-05-01T17:39:34Z",
    "updated_at": "2018-05-01T17:39:34Z",
    "author_association": "NONE",
    "body": "One way to solve this update issue is to use sqlachemy's [bulk_update_mappings](http://docs.sqlalchemy.org/en/latest/orm/session_api.html#sqlalchemy.orm.session.Session.bulk_update_mappings). This function takes in a list of dictionary values and updates each row based on the tables primary key. \r\n```python\r\nsession.bulk_update_mappings(\r\n  Table,\r\n  pandas_df.to_dict(orient='records)\r\n)\r\n```"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/441371820",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-441371820",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 441371820,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MTM3MTgyMA==",
    "user": {
      "login": "joshhornby",
      "id": 5455767,
      "node_id": "MDQ6VXNlcjU0NTU3Njc=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5455767?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/joshhornby",
      "html_url": "https://github.com/joshhornby",
      "followers_url": "https://api.github.com/users/joshhornby/followers",
      "following_url": "https://api.github.com/users/joshhornby/following{/other_user}",
      "gists_url": "https://api.github.com/users/joshhornby/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/joshhornby/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/joshhornby/subscriptions",
      "organizations_url": "https://api.github.com/users/joshhornby/orgs",
      "repos_url": "https://api.github.com/users/joshhornby/repos",
      "events_url": "https://api.github.com/users/joshhornby/events{/privacy}",
      "received_events_url": "https://api.github.com/users/joshhornby/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-24T14:28:27Z",
    "updated_at": "2018-11-24T14:28:27Z",
    "author_association": "NONE",
    "body": "I agree with @neilfrndes, shouldn't allow a nice feature like this not to be implemented because some DBs don't support. Is there any chance this feature might happen?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/441390474",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-441390474",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 441390474,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MTM5MDQ3NA==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-24T19:31:51Z",
    "updated_at": "2018-11-24T19:31:51Z",
    "author_association": "CONTRIBUTOR",
    "body": "Probably. if someone makes a PR. On further consideration, I don't think I'm opposed to this on the principle that some databases don't support it. However, I'm not too familiar with the sql code, so I'm not sure what the best approach is."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/441694764",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-441694764",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 441694764,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MTY5NDc2NA==",
    "user": {
      "login": "kjford",
      "id": 5677849,
      "node_id": "MDQ6VXNlcjU2Nzc4NDk=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5677849?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/kjford",
      "html_url": "https://github.com/kjford",
      "followers_url": "https://api.github.com/users/kjford/followers",
      "following_url": "https://api.github.com/users/kjford/following{/other_user}",
      "gists_url": "https://api.github.com/users/kjford/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/kjford/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/kjford/subscriptions",
      "organizations_url": "https://api.github.com/users/kjford/orgs",
      "repos_url": "https://api.github.com/users/kjford/repos",
      "events_url": "https://api.github.com/users/kjford/events{/privacy}",
      "received_events_url": "https://api.github.com/users/kjford/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-26T16:05:39Z",
    "updated_at": "2018-11-26T16:05:39Z",
    "author_association": "CONTRIBUTOR",
    "body": "One possibility is to provide some examples for upserts using the `method` callable if this PR is introduced: https://github.com/pandas-dev/pandas/pull/21401\r\n\r\nFor [postgres](https://docs.sqlalchemy.org/en/latest/dialects/postgresql.html#insert-on-conflict-upsert) that would look something like (untested):\r\n\r\n```python\r\nfrom sqlalchemy.dialects import postgresql\r\n\r\ndef pg_upsert(table, conn, keys, data_iter):\r\n    for row in data:\r\n        row_dict = dict(zip(keys, row))\r\n        stmt = postgresql.insert(table).values(**row_dict)\r\n        upsert_stmt = stmt.on_conflict_do_update(\r\n            index_elements=table.index,\r\n            set_=row_dict)\r\n        conn.execute(upsert_stmt)\r\n```\r\n\r\nSomething similar could be done for [mysql](https://docs.sqlalchemy.org/en/latest/dialects/mysql.html#insert-on-duplicate-key-update-upsert)."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/442150776",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-442150776",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 442150776,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MjE1MDc3Ng==",
    "user": {
      "login": "ldacey",
      "id": 12517855,
      "node_id": "MDQ6VXNlcjEyNTE3ODU1",
      "avatar_url": "https://avatars0.githubusercontent.com/u/12517855?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ldacey",
      "html_url": "https://github.com/ldacey",
      "followers_url": "https://api.github.com/users/ldacey/followers",
      "following_url": "https://api.github.com/users/ldacey/following{/other_user}",
      "gists_url": "https://api.github.com/users/ldacey/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ldacey/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ldacey/subscriptions",
      "organizations_url": "https://api.github.com/users/ldacey/orgs",
      "repos_url": "https://api.github.com/users/ldacey/repos",
      "events_url": "https://api.github.com/users/ldacey/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ldacey/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-27T17:42:18Z",
    "updated_at": "2018-11-27T17:43:56Z",
    "author_association": "NONE",
    "body": "For postgres I am using execute_values. In my case, my query is a jinja2 template to flag whether I should **do update set** or **do nothing**. This has been quite quick and flexible. Not as fast as using COPY or copy_expert but it works well.\r\n\r\n\r\n\r\n`from psycopg2.extras import execute_values`\r\n\r\n```\r\ndf = df.where((pd.notnull(df)), None)\r\ntuples = [tuple(x) for x in df.values]\r\n```\r\n\r\n\r\n```\r\nwith pg_conn:\r\n    with pg_conn.cursor() as cur:\r\n        execute_values(cur=cur,\r\n                                 sql=insert_query,\r\n                                 argslist=tuples,\r\n                                 template=None,\r\n                                           )`"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/447395819",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-447395819",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 447395819,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NzM5NTgxOQ==",
    "user": {
      "login": "cristianionescu92",
      "id": 43008086,
      "node_id": "MDQ6VXNlcjQzMDA4MDg2",
      "avatar_url": "https://avatars2.githubusercontent.com/u/43008086?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cristianionescu92",
      "html_url": "https://github.com/cristianionescu92",
      "followers_url": "https://api.github.com/users/cristianionescu92/followers",
      "following_url": "https://api.github.com/users/cristianionescu92/following{/other_user}",
      "gists_url": "https://api.github.com/users/cristianionescu92/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cristianionescu92/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cristianionescu92/subscriptions",
      "organizations_url": "https://api.github.com/users/cristianionescu92/orgs",
      "repos_url": "https://api.github.com/users/cristianionescu92/repos",
      "events_url": "https://api.github.com/users/cristianionescu92/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cristianionescu92/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-14T17:32:38Z",
    "updated_at": "2018-12-14T17:32:38Z",
    "author_association": "NONE",
    "body": "@danich1 can you, please, set an example of how this would work?\r\n\r\nI tried to have a look into bulk_update_mappings but I got really lost and couldn't make it to work.\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/449078530",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-449078530",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 449078530,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0OTA3ODUzMA==",
    "user": {
      "login": "danich1",
      "id": 3505417,
      "node_id": "MDQ6VXNlcjM1MDU0MTc=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/3505417?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/danich1",
      "html_url": "https://github.com/danich1",
      "followers_url": "https://api.github.com/users/danich1/followers",
      "following_url": "https://api.github.com/users/danich1/following{/other_user}",
      "gists_url": "https://api.github.com/users/danich1/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/danich1/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/danich1/subscriptions",
      "organizations_url": "https://api.github.com/users/danich1/orgs",
      "repos_url": "https://api.github.com/users/danich1/repos",
      "events_url": "https://api.github.com/users/danich1/events{/privacy}",
      "received_events_url": "https://api.github.com/users/danich1/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-20T17:40:22Z",
    "updated_at": "2018-12-20T17:40:22Z",
    "author_association": "NONE",
    "body": "@cristianionescu92 An example would be this:\r\nI have a table called User with the following fields: id and name. \r\n\r\n| id | name | \r\n| --- | --- | \r\n| 0 | John |\r\n| 1 | Joe |\r\n| 2 | Harry |\r\n\r\nI have a pandas data frame with the same columns but updated values:\r\n\r\n| id | name | \r\n| --- | --- | \r\n| 0 | Chris |\r\n| 1 | James |\r\n\r\nLet's also assume that we have a session variable open to access the database. By calling this method:\r\n\r\n```python\r\nsession.bulk_update_mappings(\r\nUser,\r\n<pandas dataframe above>.to_dict(orient='records')\r\n)\r\n```\r\nPandas will convert the table into a list of dictionaries [{id: 0, name: \"chris\"}, {id: 1, name:\"james\"}] that sql will use to update the rows of the table. So final table will look like:\r\n\r\n| id | name | \r\n| --- | --- | \r\n| 0 | Chris |\r\n| 1 | James |\r\n| 2 | Harry |\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/453130670",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14553#issuecomment-453130670",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14553",
    "id": 453130670,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1MzEzMDY3MA==",
    "user": {
      "login": "cristianionescu92",
      "id": 43008086,
      "node_id": "MDQ6VXNlcjQzMDA4MDg2",
      "avatar_url": "https://avatars2.githubusercontent.com/u/43008086?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cristianionescu92",
      "html_url": "https://github.com/cristianionescu92",
      "followers_url": "https://api.github.com/users/cristianionescu92/followers",
      "following_url": "https://api.github.com/users/cristianionescu92/following{/other_user}",
      "gists_url": "https://api.github.com/users/cristianionescu92/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cristianionescu92/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cristianionescu92/subscriptions",
      "organizations_url": "https://api.github.com/users/cristianionescu92/orgs",
      "repos_url": "https://api.github.com/users/cristianionescu92/repos",
      "events_url": "https://api.github.com/users/cristianionescu92/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cristianionescu92/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-10T15:15:07Z",
    "updated_at": "2019-01-10T15:15:07Z",
    "author_association": "NONE",
    "body": "Hi, @danich1  and thanks a lot for your response. I figured out myself the mechanics of how the update would work. Unfortunately I don't know work how to work with a session, I am quite beginner.\r\n\r\nLet me show you what I am doing:\r\n\r\n`    import pypyodbc\r\n    from to_sql_newrows import clean_df_db_dups, to_sql_newrows #these are 2 functions I found on GitHub, unfortunately I cannot remember the link. Clean_df_db_dups excludes from a dataframe the rows which already exist in an SQL table by checking several key columns and to_sql_newrows is a function which inserts into sql the new rows.\r\n    \r\n    from sqlalchemy import create_engine\r\n    engine = create_engine(\"engine_connection_string\")\r\n    \r\n    #Write data to SQL\r\n    Tablename = 'Dummy_Table_Name'\r\n    Tablekeys = Tablekeys_string\r\n    dftoupdateorinsertinSQL= random_dummy_dataframe\r\n    \r\n    #Connect to sql server db using pypyodbc\r\n    cnxn = pypyodbc.connect(\"Driver={SQL Server};\"\r\n                            \"Server=ServerName;\"\r\n                            \"Database=DatabaseName;\"\r\n                            \"uid=userid;pwd=password\")\r\n  \r\n    newrowsdf= clean_df_db_dups(dftoupdateorinsertinSQL, Tablename, engine, dup_cols=Tablekeys)\r\n    newrowsdf.to_sql(Tablename, engine, if_exists='append', index=False, chunksize = 140)\r\n    end=timer()\r\n    \r\n    tablesize = (len(newrowsdf.index))\r\n   \r\n    print('inserted %r rows '%(tablesize))`\r\n\r\nThe above code is basically excluding from a dataframe the rows which I already have in SQL and only inserts the new rows. What I need is to update the rows which exists. Can you, please, help me understand what I should do next?"
  }
]
