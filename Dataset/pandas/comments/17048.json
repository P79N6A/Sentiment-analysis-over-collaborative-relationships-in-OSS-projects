[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317048026",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-317048026",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 317048026,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzA0ODAyNg==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-21T16:31:14Z",
    "updated_at": "2017-07-21T16:31:14Z",
    "author_association": "MEMBER",
    "body": "@louispotok : that behavior does sound buggy to me, but before I label it as such, could you provide a minimal reproducible example for us?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317077127",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-317077127",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 317077127,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzA3NzEyNw==",
    "user": {
      "login": "louispotok",
      "id": 5413548,
      "node_id": "MDQ6VXNlcjU0MTM1NDg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5413548?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/louispotok",
      "html_url": "https://github.com/louispotok",
      "followers_url": "https://api.github.com/users/louispotok/followers",
      "following_url": "https://api.github.com/users/louispotok/following{/other_user}",
      "gists_url": "https://api.github.com/users/louispotok/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/louispotok/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/louispotok/subscriptions",
      "organizations_url": "https://api.github.com/users/louispotok/orgs",
      "repos_url": "https://api.github.com/users/louispotok/repos",
      "events_url": "https://api.github.com/users/louispotok/events{/privacy}",
      "received_events_url": "https://api.github.com/users/louispotok/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-21T18:26:05Z",
    "updated_at": "2017-07-21T18:26:05Z",
    "author_association": "CONTRIBUTOR",
    "body": "Happy to, but what exactly would constitute an example here? I can provide an example json file, but how would you suggest I reproduce the memory capacity and allocation on my machine?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317095505",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-317095505",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 317095505,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzA5NTUwNQ==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-21T19:46:11Z",
    "updated_at": "2017-07-21T19:46:11Z",
    "author_association": "MEMBER",
    "body": "> I can provide an example json file, but how would you suggest I reproduce the memory capacity and allocation on my machine?\r\n\r\nJust provide the smallest possible JSON file that causes this `MemoryError` to occur."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317136590",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-317136590",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 317136590,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzEzNjU5MA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-21T23:48:23Z",
    "updated_at": "2017-07-21T23:48:23Z",
    "author_association": "CONTRIBUTOR",
    "body": "The ``lines=True`` impl  is currently not designed this way. If you subsittue your soln into the current impl does it pass the test suite?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317136617",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-317136617",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 317136617,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzEzNjYxNw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-21T23:48:39Z",
    "updated_at": "2017-07-21T23:48:39Z",
    "author_association": "CONTRIBUTOR",
    "body": "cc @aterrel "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317329131",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-317329131",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 317329131,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzMyOTEzMQ==",
    "user": {
      "login": "louispotok",
      "id": 5413548,
      "node_id": "MDQ6VXNlcjU0MTM1NDg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5413548?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/louispotok",
      "html_url": "https://github.com/louispotok",
      "followers_url": "https://api.github.com/users/louispotok/followers",
      "following_url": "https://api.github.com/users/louispotok/following{/other_user}",
      "gists_url": "https://api.github.com/users/louispotok/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/louispotok/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/louispotok/subscriptions",
      "organizations_url": "https://api.github.com/users/louispotok/orgs",
      "repos_url": "https://api.github.com/users/louispotok/repos",
      "events_url": "https://api.github.com/users/louispotok/events{/privacy}",
      "received_events_url": "https://api.github.com/users/louispotok/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-24T06:16:42Z",
    "updated_at": "2017-07-24T06:16:42Z",
    "author_association": "CONTRIBUTOR",
    "body": "@gfyoung I'm still not sure exactly what would be most helpful for you here. \r\n\r\nI tried doing `head -n 10 path/to/file | testing.py`, where testing.py contains: `df = pd.read_json(sys.stdin, lines=True)`, and then varying how many lines to pass.\r\n\r\n**Results:**\r\nEvery million lines is about .8 GB, according to `head -n 1000000 path/to/file | wc -c`. And I did these each a few times in varying orders, always the same results.\r\n\r\n- 1Million lines: success.\r\n- 1.3M lines: success\r\n- 2M lines: got \"Killed\" and also killed a `watch` in another terminal window, with message \"unable to fork process: Cannot allocate memory\"\r\n- 3M lines: got \"MemoryError\" (I had a `watch` running here too, no problems at all)\r\n- Full file: got \"MemoryError\""
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317329207",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-317329207",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 317329207,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzMyOTIwNw==",
    "user": {
      "login": "louispotok",
      "id": 5413548,
      "node_id": "MDQ6VXNlcjU0MTM1NDg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5413548?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/louispotok",
      "html_url": "https://github.com/louispotok",
      "followers_url": "https://api.github.com/users/louispotok/followers",
      "following_url": "https://api.github.com/users/louispotok/following{/other_user}",
      "gists_url": "https://api.github.com/users/louispotok/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/louispotok/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/louispotok/subscriptions",
      "organizations_url": "https://api.github.com/users/louispotok/orgs",
      "repos_url": "https://api.github.com/users/louispotok/repos",
      "events_url": "https://api.github.com/users/louispotok/events{/privacy}",
      "received_events_url": "https://api.github.com/users/louispotok/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-24T06:17:17Z",
    "updated_at": "2017-07-24T06:17:17Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jreback I think your question was for me, but I don't know how to do what you described. Are there instructions you could point me to?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317331210",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-317331210",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 317331210,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzMzMTIxMA==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-24T06:31:26Z",
    "updated_at": "2017-07-24T06:31:26Z",
    "author_association": "MEMBER",
    "body": "> 1.3M lines: success\r\n\r\nYikes!  That's a pretty massive file.  That does certainly help us with regards to what we would need to do to reproduce this issue."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317331806",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-317331806",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 317331806,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzMzMTgwNg==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-24T06:35:26Z",
    "updated_at": "2017-07-24T06:35:26Z",
    "author_association": "MEMBER",
    "body": "> I think your question was for me, but I don't know how to do what you described. \r\n\r\n<a href=\"https://pandas.pydata.org/pandas-docs/stable/contributing.html\">Here</a> is the documentation for making contributions to the repository.  Essentially @jreback is asking if you could somehow incorporate your workaround in your issue description into the implementation of `read_json`, which you can find in `pandas/io/json/json.py`.\r\n\r\nA quick glance there indicates what might be the issue: we're putting ALL of the lines into a list in memory!  Your workaround might be able to address that."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317468984",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-317468984",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 317468984,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzQ2ODk4NA==",
    "user": {
      "login": "louispotok",
      "id": 5413548,
      "node_id": "MDQ6VXNlcjU0MTM1NDg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5413548?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/louispotok",
      "html_url": "https://github.com/louispotok",
      "followers_url": "https://api.github.com/users/louispotok/followers",
      "following_url": "https://api.github.com/users/louispotok/following{/other_user}",
      "gists_url": "https://api.github.com/users/louispotok/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/louispotok/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/louispotok/subscriptions",
      "organizations_url": "https://api.github.com/users/louispotok/orgs",
      "repos_url": "https://api.github.com/users/louispotok/repos",
      "events_url": "https://api.github.com/users/louispotok/events{/privacy}",
      "received_events_url": "https://api.github.com/users/louispotok/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-24T15:58:21Z",
    "updated_at": "2017-07-24T15:58:21Z",
    "author_association": "CONTRIBUTOR",
    "body": "Thanks! I added it for one of the possible input types. You can see it [here](https://github.com/louispotok/pandas/commit/fe1cfbd00a0795c40a4b725ea8e95aaa522705b4). It passes all the existing tests, and I'm now able to use it to load that file.\r\n\r\nI think this is *much* slower than the previous implementation, and I don't know whether it can be extended to other input types. We could make it faster by increasing the chunk size or doing fewer `concat`s, but at the cost of more memory usage."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317470090",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-317470090",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 317470090,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzQ3MDA5MA==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-24T16:01:48Z",
    "updated_at": "2017-07-24T16:01:48Z",
    "author_association": "MEMBER",
    "body": "> We could make it faster by increasing the chunk size or doing fewer concats, but at the cost of more memory usage.\r\n\r\nI think it would make sense to add such a parameter.  We have it for `read_csv`.  Try adding that and let us know how that works!  This looks pretty good so far."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317760708",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-317760708",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 317760708,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzc2MDcwOA==",
    "user": {
      "login": "louispotok",
      "id": 5413548,
      "node_id": "MDQ6VXNlcjU0MTM1NDg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5413548?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/louispotok",
      "html_url": "https://github.com/louispotok",
      "followers_url": "https://api.github.com/users/louispotok/followers",
      "following_url": "https://api.github.com/users/louispotok/following{/other_user}",
      "gists_url": "https://api.github.com/users/louispotok/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/louispotok/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/louispotok/subscriptions",
      "organizations_url": "https://api.github.com/users/louispotok/orgs",
      "repos_url": "https://api.github.com/users/louispotok/repos",
      "events_url": "https://api.github.com/users/louispotok/events{/privacy}",
      "received_events_url": "https://api.github.com/users/louispotok/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-25T14:45:07Z",
    "updated_at": "2017-07-25T14:45:07Z",
    "author_association": "CONTRIBUTOR",
    "body": "Using the chunksize param in `read_csv` returns a `TextFileReader`, though, right? Won't that be confusing?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317767779",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-317767779",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 317767779,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzc2Nzc3OQ==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-25T15:06:08Z",
    "updated_at": "2017-07-25T15:06:16Z",
    "author_association": "MEMBER",
    "body": "@louispotok : IMO, it would not because there's more confusion when people try to pass in the same parameters to one `read_*` function that they're used to passing in for another and found out they don't work or don't exist.  Thus, you would be doing all `read_json` users a service by adding a similar parameter as exists in `read_csv`. 😄 "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/318410828",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-318410828",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 318410828,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxODQxMDgyOA==",
    "user": {
      "login": "louispotok",
      "id": 5413548,
      "node_id": "MDQ6VXNlcjU0MTM1NDg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5413548?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/louispotok",
      "html_url": "https://github.com/louispotok",
      "followers_url": "https://api.github.com/users/louispotok/followers",
      "following_url": "https://api.github.com/users/louispotok/following{/other_user}",
      "gists_url": "https://api.github.com/users/louispotok/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/louispotok/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/louispotok/subscriptions",
      "organizations_url": "https://api.github.com/users/louispotok/orgs",
      "repos_url": "https://api.github.com/users/louispotok/repos",
      "events_url": "https://api.github.com/users/louispotok/events{/privacy}",
      "received_events_url": "https://api.github.com/users/louispotok/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-27T16:14:01Z",
    "updated_at": "2017-07-27T16:14:01Z",
    "author_association": "CONTRIBUTOR",
    "body": "@gfyoung Makes sense. [Here's the latest](https://github.com/louispotok/pandas/commit/0a474731fc680bb41e339e328dd687a577118962) with the chunksize param.\r\n\r\nI still don't know how to make it work on any of the other filepath_or_buffer branches or really what are the input types that would trigger those. I would need an explanation of what's happening there to extend this."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/318417791",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-318417791",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 318417791,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxODQxNzc5MQ==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-27T16:39:34Z",
    "updated_at": "2017-07-27T16:39:34Z",
    "author_association": "MEMBER",
    "body": ">  I would need an explanation of what's happening there to extend this.\r\n\r\nCertainly.  We accept three types of inputs for `read_json`:\r\n\r\n* file-path (this option BTW is not clearly documented, so a PR to make this clearer is welcome!)\r\n* file-object\r\n* valid JSON string\r\n\r\nYour contribution would address the first two options.  You have at this addressed the first one.  The second comes in the conditional that checks if the `filepath_or_buffer` has a `read` method.  Thus, you should also add your logic there under that check (we'll handle refactoring later)."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/320080748",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-320080748",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 320080748,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDA4MDc0OA==",
    "user": {
      "login": "louispotok",
      "id": 5413548,
      "node_id": "MDQ6VXNlcjU0MTM1NDg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5413548?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/louispotok",
      "html_url": "https://github.com/louispotok",
      "followers_url": "https://api.github.com/users/louispotok/followers",
      "following_url": "https://api.github.com/users/louispotok/following{/other_user}",
      "gists_url": "https://api.github.com/users/louispotok/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/louispotok/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/louispotok/subscriptions",
      "organizations_url": "https://api.github.com/users/louispotok/orgs",
      "repos_url": "https://api.github.com/users/louispotok/repos",
      "events_url": "https://api.github.com/users/louispotok/events{/privacy}",
      "received_events_url": "https://api.github.com/users/louispotok/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-03T20:27:42Z",
    "updated_at": "2017-08-03T20:27:42Z",
    "author_association": "CONTRIBUTOR",
    "body": "Okay @gfyoung , Thanks for your help. I added it to that conditional you mentioned as well.  Latest [here](https://github.com/louispotok/pandas/commit/68063d82c6b03ff5833ae8c93848e99de8eef444). Passes the tests.\r\n\r\nI also changed the behavior so that if chunksize is not explicitly passed, we try to read it all at once. My thinking is that using chunksize changes the performance drastically, and better to let people make this tradeoff explicitly without changing the default behavior.\r\n\r\nFrom here, what are the next steps? There's probably a bit of cleanup you'd like me to do -- let me know. Thanks again!"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/320081028",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-320081028",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 320081028,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDA4MTAyOA==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-03T20:28:43Z",
    "updated_at": "2017-08-03T20:28:43Z",
    "author_association": "MEMBER",
    "body": "@louispotok : Sure thing.  Just submit a PR, and we'll be happy to review!"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/320093490",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-320093490",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 320093490,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDA5MzQ5MA==",
    "user": {
      "login": "louispotok",
      "id": 5413548,
      "node_id": "MDQ6VXNlcjU0MTM1NDg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5413548?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/louispotok",
      "html_url": "https://github.com/louispotok",
      "followers_url": "https://api.github.com/users/louispotok/followers",
      "following_url": "https://api.github.com/users/louispotok/following{/other_user}",
      "gists_url": "https://api.github.com/users/louispotok/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/louispotok/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/louispotok/subscriptions",
      "organizations_url": "https://api.github.com/users/louispotok/orgs",
      "repos_url": "https://api.github.com/users/louispotok/repos",
      "events_url": "https://api.github.com/users/louispotok/events{/privacy}",
      "received_events_url": "https://api.github.com/users/louispotok/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-03T21:21:07Z",
    "updated_at": "2017-08-03T21:21:07Z",
    "author_association": "CONTRIBUTOR",
    "body": "Here goes: https://github.com/pandas-dev/pandas/pull/17168. "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/405014387",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-405014387",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 405014387,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwNTAxNDM4Nw==",
    "user": {
      "login": "alessandrobenedetti",
      "id": 513195,
      "node_id": "MDQ6VXNlcjUxMzE5NQ==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/513195?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/alessandrobenedetti",
      "html_url": "https://github.com/alessandrobenedetti",
      "followers_url": "https://api.github.com/users/alessandrobenedetti/followers",
      "following_url": "https://api.github.com/users/alessandrobenedetti/following{/other_user}",
      "gists_url": "https://api.github.com/users/alessandrobenedetti/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/alessandrobenedetti/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/alessandrobenedetti/subscriptions",
      "organizations_url": "https://api.github.com/users/alessandrobenedetti/orgs",
      "repos_url": "https://api.github.com/users/alessandrobenedetti/repos",
      "events_url": "https://api.github.com/users/alessandrobenedetti/events{/privacy}",
      "received_events_url": "https://api.github.com/users/alessandrobenedetti/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-07-14T10:28:44Z",
    "updated_at": "2018-07-14T10:28:44Z",
    "author_association": "NONE",
    "body": "Hi,\r\nI am experimenting with Json of various sizes.\r\nI am using the Pandas read_json with lines=True and noticing a great memory output in the parsing phase.\r\nUsing a chunksize of 10.000 to experiment : \r\nFor example : \r\n**Input Json** : 280 Mb **Memory Usage** : up to 2.6 Gb **Resulting Data Frame** : 400 Mb (because of dtypes, not much I can do with this)\r\n**Input Json** : 4Gb **Memory Usage** : up to 28 Gb **Resulting Data Frame** : 6Gb .\r\nIt seems the memory necessary to parse the Json is definitely too much ( not sure if there are better ways to read big Json in Pandas).\r\nFurthermore it seems this memory remains allocated to the Python process.\r\nNow I am a Python newbie, so this may be perfectly fine and this memory may just remain for Python in a buffer to be used in case of necessity ( it doesn't grow up when the data frame start getting processed).\r\nBut it look suspicious.\r\nLet me know if you noticed the same and find out any tips or tricks for that!\r\nThanks in advance"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/405062113",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-405062113",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 405062113,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwNTA2MjExMw==",
    "user": {
      "login": "louispotok",
      "id": 5413548,
      "node_id": "MDQ6VXNlcjU0MTM1NDg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5413548?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/louispotok",
      "html_url": "https://github.com/louispotok",
      "followers_url": "https://api.github.com/users/louispotok/followers",
      "following_url": "https://api.github.com/users/louispotok/following{/other_user}",
      "gists_url": "https://api.github.com/users/louispotok/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/louispotok/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/louispotok/subscriptions",
      "organizations_url": "https://api.github.com/users/louispotok/orgs",
      "repos_url": "https://api.github.com/users/louispotok/repos",
      "events_url": "https://api.github.com/users/louispotok/events{/privacy}",
      "received_events_url": "https://api.github.com/users/louispotok/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-07-15T02:08:21Z",
    "updated_at": "2018-07-15T02:08:21Z",
    "author_association": "CONTRIBUTOR",
    "body": "@alessandrobenedetti \r\n\r\nI've definitely experienced some of what you're describing. \r\n\r\nFirst, the read_json function probably uses more memory overall than it needs to. I don't fully know why that is or how to improve it - that probably belongs in a separate issue if it's important to what you're doing.\r\n\r\nSecond, when lines=True, I think you're right that all the memory isn't actually being used, it's just not being released back to the OS, so it's a bit spurious. \r\n\r\nThird, if you read with lines=True and a small chunksize, you should be fine either way."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/405210306",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-405210306",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 405210306,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwNTIxMDMwNg==",
    "user": {
      "login": "alessandrobenedetti",
      "id": 513195,
      "node_id": "MDQ6VXNlcjUxMzE5NQ==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/513195?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/alessandrobenedetti",
      "html_url": "https://github.com/alessandrobenedetti",
      "followers_url": "https://api.github.com/users/alessandrobenedetti/followers",
      "following_url": "https://api.github.com/users/alessandrobenedetti/following{/other_user}",
      "gists_url": "https://api.github.com/users/alessandrobenedetti/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/alessandrobenedetti/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/alessandrobenedetti/subscriptions",
      "organizations_url": "https://api.github.com/users/alessandrobenedetti/orgs",
      "repos_url": "https://api.github.com/users/alessandrobenedetti/repos",
      "events_url": "https://api.github.com/users/alessandrobenedetti/events{/privacy}",
      "received_events_url": "https://api.github.com/users/alessandrobenedetti/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-07-16T10:48:46Z",
    "updated_at": "2018-07-16T10:48:46Z",
    "author_association": "NONE",
    "body": "hi @louispotok , thank you for the kind answer.\r\nI just noticed that even using  simpler approaches such as : \r\n`with open(interactions_input_file) as json_file:\r\n    data_lan = []\r\n    for line in json_file:\r\n        data_lan.append(pd.io.json.loads(line))\r\n\r\nall_columns = data_lan[0].keys()\r\nprint(\"Size \"+str(len(data_lan)))\r\ninteractions = pd.DataFrame(columns=all_columns, data=data_lan)`\r\n\r\nI have similar memory outputs.\r\nI will stop the conversation here as it's slighly off topic.\r\nShould I assume that parsing json lines in Python is just that expensive ?\r\nwe are talking about 5-7 times more ram than the initial file..."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/407208663",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-407208663",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 407208663,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwNzIwODY2Mw==",
    "user": {
      "login": "rosswait",
      "id": 1779015,
      "node_id": "MDQ6VXNlcjE3NzkwMTU=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1779015?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rosswait",
      "html_url": "https://github.com/rosswait",
      "followers_url": "https://api.github.com/users/rosswait/followers",
      "following_url": "https://api.github.com/users/rosswait/following{/other_user}",
      "gists_url": "https://api.github.com/users/rosswait/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rosswait/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rosswait/subscriptions",
      "organizations_url": "https://api.github.com/users/rosswait/orgs",
      "repos_url": "https://api.github.com/users/rosswait/repos",
      "events_url": "https://api.github.com/users/rosswait/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rosswait/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-07-23T21:34:29Z",
    "updated_at": "2018-07-23T21:34:29Z",
    "author_association": "NONE",
    "body": "I'm having a similar experience with this function as well, @alessandrobenedetti.  I ended up regenerating my data to use **read_csv** instead, which is using a dramatically smaller amount of ram."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/407351912",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-407351912",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 407351912,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwNzM1MTkxMg==",
    "user": {
      "login": "alessandrobenedetti",
      "id": 513195,
      "node_id": "MDQ6VXNlcjUxMzE5NQ==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/513195?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/alessandrobenedetti",
      "html_url": "https://github.com/alessandrobenedetti",
      "followers_url": "https://api.github.com/users/alessandrobenedetti/followers",
      "following_url": "https://api.github.com/users/alessandrobenedetti/following{/other_user}",
      "gists_url": "https://api.github.com/users/alessandrobenedetti/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/alessandrobenedetti/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/alessandrobenedetti/subscriptions",
      "organizations_url": "https://api.github.com/users/alessandrobenedetti/orgs",
      "repos_url": "https://api.github.com/users/alessandrobenedetti/repos",
      "events_url": "https://api.github.com/users/alessandrobenedetti/events{/privacy}",
      "received_events_url": "https://api.github.com/users/alessandrobenedetti/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-07-24T10:01:14Z",
    "updated_at": "2018-07-24T10:01:14Z",
    "author_association": "NONE",
    "body": "thanks @rosswait , I have a small update if that helps...\r\n\r\nMy file was heavily String and Lists based ( each line was a Json object with a lot of Strings and lists of Strings).\r\nFor a matter of fact, those Strings were actually Integer ids, so, after I got that information I switched the Strings to Int and Lists of int.\r\nThis first of all brought down the size of the Json from 4.5 Gb to 3 Gb and the memory output from 30 GB to 10 GB.\r\nIf I end up with stricter memory requirements I will definitely take a look to the csv option.\r\nThanks!"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/461908151",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17048#issuecomment-461908151",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17048",
    "id": 461908151,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ2MTkwODE1MQ==",
    "user": {
      "login": "vamlumber",
      "id": 28856086,
      "node_id": "MDQ6VXNlcjI4ODU2MDg2",
      "avatar_url": "https://avatars3.githubusercontent.com/u/28856086?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vamlumber",
      "html_url": "https://github.com/vamlumber",
      "followers_url": "https://api.github.com/users/vamlumber/followers",
      "following_url": "https://api.github.com/users/vamlumber/following{/other_user}",
      "gists_url": "https://api.github.com/users/vamlumber/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vamlumber/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vamlumber/subscriptions",
      "organizations_url": "https://api.github.com/users/vamlumber/orgs",
      "repos_url": "https://api.github.com/users/vamlumber/repos",
      "events_url": "https://api.github.com/users/vamlumber/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vamlumber/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-02-08T18:56:57Z",
    "updated_at": "2019-02-08T18:56:57Z",
    "author_association": "NONE",
    "body": "The problem still exists , I am loading a 5GB json file with 16 GB ram ,but still i get memory error . The lines true attribute doesnot work as expected still "
  }
]
