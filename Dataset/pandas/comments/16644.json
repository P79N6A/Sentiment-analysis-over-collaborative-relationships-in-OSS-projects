[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/307273617",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-307273617",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 307273617,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzI3MzYxNw==",
    "user": {
      "login": "shoyer",
      "id": 1217238,
      "node_id": "MDQ6VXNlcjEyMTcyMzg=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shoyer",
      "html_url": "https://github.com/shoyer",
      "followers_url": "https://api.github.com/users/shoyer/followers",
      "following_url": "https://api.github.com/users/shoyer/following{/other_user}",
      "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions",
      "organizations_url": "https://api.github.com/users/shoyer/orgs",
      "repos_url": "https://api.github.com/users/shoyer/repos",
      "events_url": "https://api.github.com/users/shoyer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shoyer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-09T01:52:35Z",
    "updated_at": "2017-06-09T01:52:35Z",
    "author_association": "MEMBER",
    "body": "Unfortunately it is very hard to debug such a large example -- a lot of different things could be doing wrong. Could please make a [Minimal, Complete, and Verifiable example](https://stackoverflow.com/help/mcve)? Thanks"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/307281957",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-307281957",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 307281957,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzI4MTk1Nw==",
    "user": {
      "login": "jupiterjosh",
      "id": 29292793,
      "node_id": "MDQ6VXNlcjI5MjkyNzkz",
      "avatar_url": "https://avatars3.githubusercontent.com/u/29292793?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jupiterjosh",
      "html_url": "https://github.com/jupiterjosh",
      "followers_url": "https://api.github.com/users/jupiterjosh/followers",
      "following_url": "https://api.github.com/users/jupiterjosh/following{/other_user}",
      "gists_url": "https://api.github.com/users/jupiterjosh/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jupiterjosh/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jupiterjosh/subscriptions",
      "organizations_url": "https://api.github.com/users/jupiterjosh/orgs",
      "repos_url": "https://api.github.com/users/jupiterjosh/repos",
      "events_url": "https://api.github.com/users/jupiterjosh/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jupiterjosh/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-09T02:56:18Z",
    "updated_at": "2017-06-09T02:56:18Z",
    "author_association": "NONE",
    "body": "Thanks for the link!  I will post something shortly."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/307286081",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-307286081",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 307286081,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzI4NjA4MQ==",
    "user": {
      "login": "jupiterjosh",
      "id": 29292793,
      "node_id": "MDQ6VXNlcjI5MjkyNzkz",
      "avatar_url": "https://avatars3.githubusercontent.com/u/29292793?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jupiterjosh",
      "html_url": "https://github.com/jupiterjosh",
      "followers_url": "https://api.github.com/users/jupiterjosh/followers",
      "following_url": "https://api.github.com/users/jupiterjosh/following{/other_user}",
      "gists_url": "https://api.github.com/users/jupiterjosh/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jupiterjosh/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jupiterjosh/subscriptions",
      "organizations_url": "https://api.github.com/users/jupiterjosh/orgs",
      "repos_url": "https://api.github.com/users/jupiterjosh/repos",
      "events_url": "https://api.github.com/users/jupiterjosh/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jupiterjosh/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-09T03:30:00Z",
    "updated_at": "2017-06-09T03:30:00Z",
    "author_association": "NONE",
    "body": "Okay, I can replicate the 0.19.2 to 0.20.1 performance degradation with the following code, but the 0.20.2 performance is roughly the same as the 0.19.2 performance (i.e., the __get_item__ issues appears to have been corrected in version 0.20.2 for my verifiable code example).  I will look at what else is in my original code and revise the verifiable example tomorrow to try to replicate the 3x performance degradation I saw in my original script.  I have also included images for the new code from the Spyder profiler after running Pandas versions 0.19.2, 0.20.1 and 0.20.2 respectively.\r\n\r\n```\r\n#%%\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n\r\n#%%\r\n_M = 10\r\n_N = 1000\r\ntuples = [(i,j) for i in range(_M) for j in range(_N)]\r\nindex = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\r\ndf = pd.DataFrame(np.random.rand(_N*_M,4),columns=['A','B','C','D'],index=index)\r\n\r\n#%%\r\nimport itertools\r\nfor u,v in itertools.combinations(range(_M),2):\r\n    for w in range(_N):\r\n        someval1 = df.A.loc[u,w] - df.A.loc[v,w]\r\n        someval2 = df.B.loc[u,w] - df.B.loc[v,w]\r\n\r\n```\r\n``\r\n![image](https://user-images.githubusercontent.com/29292793/26959933-588c650c-4ca1-11e7-9671-02c49c1f6bce.png)\r\n\r\n![image](https://user-images.githubusercontent.com/29292793/26959939-6589af62-4ca1-11e7-8f66-387bbbb7a8b1.png)\r\n\r\n![image](https://user-images.githubusercontent.com/29292793/26959947-7118c2e6-4ca1-11e7-8e7e-88490406b7eb.png)\r\n\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/307359412",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-307359412",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 307359412,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzM1OTQxMg==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-09T10:55:56Z",
    "updated_at": "2017-06-09T10:55:56Z",
    "author_association": "MEMBER",
    "body": "@jupiterjosh The related issue with the MultiIndex indexing performance regression: https://github.com/pandas-dev/pandas/issues/16319 (and PRs https://github.com/pandas-dev/pandas/pull/16324 and https://github.com/pandas-dev/pandas/pull/16346)"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/307359662",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-307359662",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 307359662,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzM1OTY2Mg==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-09T10:57:27Z",
    "updated_at": "2017-06-09T10:57:27Z",
    "author_association": "MEMBER",
    "body": "If you can get the remaining slowdown between 0.19.2 and 0.20.2 in a smaller reproducible example, that would be nice!"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/307441433",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-307441433",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 307441433,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzQ0MTQzMw==",
    "user": {
      "login": "jupiterjosh",
      "id": 29292793,
      "node_id": "MDQ6VXNlcjI5MjkyNzkz",
      "avatar_url": "https://avatars3.githubusercontent.com/u/29292793?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jupiterjosh",
      "html_url": "https://github.com/jupiterjosh",
      "followers_url": "https://api.github.com/users/jupiterjosh/followers",
      "following_url": "https://api.github.com/users/jupiterjosh/following{/other_user}",
      "gists_url": "https://api.github.com/users/jupiterjosh/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jupiterjosh/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jupiterjosh/subscriptions",
      "organizations_url": "https://api.github.com/users/jupiterjosh/orgs",
      "repos_url": "https://api.github.com/users/jupiterjosh/repos",
      "events_url": "https://api.github.com/users/jupiterjosh/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jupiterjosh/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-09T16:50:28Z",
    "updated_at": "2017-06-09T18:55:47Z",
    "author_association": "NONE",
    "body": "@jorisvandenbossche Thanks.  I will track down the remaining slowdown.\r\n\r\n@jreback I would have preferred if this was closed with some sort of comment since I did observe a slowdown between 0.19.2 and 0.20.2.  I will repost when I have figured out where the remaining slowdown is occurring and I can create a better verifiable example.  It is somewhere buried in get_loc, but I can't tease out where as of yet.  Btw, I don't know if this helps for your performance benchmarking, but as a performance use-case I routinely pull in dataframes with north of 1 million records. \r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/307471685",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-307471685",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 307471685,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzQ3MTY4NQ==",
    "user": {
      "login": "jupiterjosh",
      "id": 29292793,
      "node_id": "MDQ6VXNlcjI5MjkyNzkz",
      "avatar_url": "https://avatars3.githubusercontent.com/u/29292793?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jupiterjosh",
      "html_url": "https://github.com/jupiterjosh",
      "followers_url": "https://api.github.com/users/jupiterjosh/followers",
      "following_url": "https://api.github.com/users/jupiterjosh/following{/other_user}",
      "gists_url": "https://api.github.com/users/jupiterjosh/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jupiterjosh/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jupiterjosh/subscriptions",
      "organizations_url": "https://api.github.com/users/jupiterjosh/orgs",
      "repos_url": "https://api.github.com/users/jupiterjosh/repos",
      "events_url": "https://api.github.com/users/jupiterjosh/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jupiterjosh/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-09T18:55:21Z",
    "updated_at": "2017-06-09T18:55:21Z",
    "author_association": "NONE",
    "body": "@jorisvandenbossche \r\n\r\nThe remaining slowdown is due to whether get_loc from pandas_libs.index.MultiIndexObjectEngine is preferred by the dataframe (this method returns quickly) or whether get_loc from pandas_libs.index.MultiIndexHashEngine is used (much much slower).  The MultIndexHashEngine uses a function called \"_combine_hash_arrays\" which appears to be the code causing the slowdown.\r\n\r\nI am not familiar with the pandas codebase enough to alter the code below to trigger MultiIndexHashEngine to be preferred over MultiIndexObjectEngine.  Any ideas?  I tried mixing the types on my index, but that didn't trigger MultIndexHashEngine, and yet the script that I run in my original code causes this to be used.  I also tried loading from a file (my original script calls read_csv) thinking that might change the type of index engine, but that also did not work.\r\n\r\n`\r\n#%%\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n\r\n#%%\r\n_M = 10\r\n_N = 1000\r\ntuples = [(i,j) for i in range(_M) for j in range(_N)]\r\nindex = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\r\ndf = pd.DataFrame(np.random.rand(_N*_M,4),columns=['A','B','C','D'],index=index)\r\n\r\n#%%\r\nimport itertools\r\nfor u,v in itertools.combinations(range(_M),2):\r\n    for w in range(_N):\r\n        someval1 = df.A.loc[u,w] - df.A.loc[v,w]\r\n        someval2 = df.B.loc[u,w] - df.B.loc[v,w]`\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/307512731",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-307512731",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 307512731,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzUxMjczMQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-09T22:17:26Z",
    "updated_at": "2017-06-09T22:17:26Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jupiterjosh I am happy to keep around an issue that demonstrates a clear example of a performance regression, meaning it is a minimal reproducible example. pls format the code and show timing differences with a version on each.\r\n\r\nfurther you in fact stated this\r\n\r\n> Okay, I can replicate the 0.19.2 to 0.20.1 performance degradation with the following code, but the 0.20.2 performance is roughly the same as the 0.19.2 performance (i.e., the get_item issues appears to have been corrected in version 0.20.2 for my verifiable code example). I will look at what else is in "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/307604756",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-307604756",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 307604756,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzYwNDc1Ng==",
    "user": {
      "login": "jupiterjosh",
      "id": 29292793,
      "node_id": "MDQ6VXNlcjI5MjkyNzkz",
      "avatar_url": "https://avatars3.githubusercontent.com/u/29292793?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jupiterjosh",
      "html_url": "https://github.com/jupiterjosh",
      "followers_url": "https://api.github.com/users/jupiterjosh/followers",
      "following_url": "https://api.github.com/users/jupiterjosh/following{/other_user}",
      "gists_url": "https://api.github.com/users/jupiterjosh/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jupiterjosh/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jupiterjosh/subscriptions",
      "organizations_url": "https://api.github.com/users/jupiterjosh/orgs",
      "repos_url": "https://api.github.com/users/jupiterjosh/repos",
      "events_url": "https://api.github.com/users/jupiterjosh/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jupiterjosh/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-11T03:57:31Z",
    "updated_at": "2017-06-11T03:57:31Z",
    "author_association": "NONE",
    "body": "@jreback -- perhaps you could comment on this:\r\n\r\n> I am not familiar with the pandas codebase enough to alter the code below to trigger MultiIndexHashEngine to be preferred over MultiIndexObjectEngine. Any ideas? I tried mixing the types on my index, but that didn't trigger MultIndexHashEngine, and yet the script that I run in my original code causes this to be used. I also tried loading from a file (my original script calls read_csv) thinking that might change the type of index engine, but that also did not work.\r\n`\r\n\r\nPandas is doing some sort of type inferencing to determine when the MultiIndexHashEngine is used over the MultiIndexObjectEngine.  If you could give me a pointer on how to set up a multiindex that triggers the use of the MultiIndexHashEngine then I will post code and profiler results.\r\n\r\n  "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/307616043",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-307616043",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 307616043,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzYxNjA0Mw==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-11T09:10:16Z",
    "updated_at": "2017-06-11T09:10:16Z",
    "author_association": "MEMBER",
    "body": "Yes, there are indeed two mechanisms to index MultiIndexes, and which is used depends on the size of the index: https://github.com/pandas-dev/pandas/blob/1564a6e0e9fa3a640f5c1999c4fb118b8e5a4411/pandas/core/indexes/multi.py#L635-L646\r\n\r\nSo the current cut-off is a size of 10000.\r\nEach of both has advantages and disadvantages (speeds of creation and less memory usage vs speed of indexing). You can see in https://github.com/pandas-dev/pandas/pull/16324 some discussion about this and some plots showing the tradeoff in speed.\r\n\r\nNote that a \"minimal reproducible example\" does not need to use a small dataframe. I mean you can create with minimal code a large frame, and so trigger the use the hash-based engine."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/308003857",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-308003857",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 308003857,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwODAwMzg1Nw==",
    "user": {
      "login": "jupiterjosh",
      "id": 29292793,
      "node_id": "MDQ6VXNlcjI5MjkyNzkz",
      "avatar_url": "https://avatars3.githubusercontent.com/u/29292793?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jupiterjosh",
      "html_url": "https://github.com/jupiterjosh",
      "followers_url": "https://api.github.com/users/jupiterjosh/followers",
      "following_url": "https://api.github.com/users/jupiterjosh/following{/other_user}",
      "gists_url": "https://api.github.com/users/jupiterjosh/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jupiterjosh/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jupiterjosh/subscriptions",
      "organizations_url": "https://api.github.com/users/jupiterjosh/orgs",
      "repos_url": "https://api.github.com/users/jupiterjosh/repos",
      "events_url": "https://api.github.com/users/jupiterjosh/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jupiterjosh/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-13T04:31:01Z",
    "updated_at": "2017-06-13T04:37:31Z",
    "author_association": "NONE",
    "body": "@jorisvandenbossche \r\n> If you can get the remaining slowdown between 0.19.2 and 0.20.2 in a smaller reproducible example, that would be nice!\r\n\r\n@jreback \r\n> @jupiterjosh I am happy to keep around an issue that demonstrates a clear example of a performance regression...\r\n\r\nI can demonstrate the 3x slowdown in the code below.  There are two files attached to this comment with my timeit results (I used IPython's \"timeit\" magic command). I don't know if one needs to reopen the issue or start a new one.  After playing with the indexing for awhile, I could see that the memory management in the new version is really good, I just think the cutoff for triggering it may be too low given the 3x performance penalty (assuming that can't be fixed).\r\n\r\nThe attached timeit results show a roughly 40us execution time on my machine for up to 100,000,000 indices using version 0.19.2 and roughly 120us on my machine for indices greater than 10k and up to 10MM indices using 0.20.2.\r\n\r\nAs I said before, the memory management in the new version is very good, but the 10k cutoff feels low.  Multiindices by their very nature get large (i.e, curse of dimensionality), and 10,000 indices corresponds to a really small 100 by 100 multiindex.  The difference in memory footprint for 10,000,000 indices was roughly 500Mb between the two versions.  I personally would consider anything under 1GB a small price to pay for some additional breathing room and a 66% reduction in execution time.\r\n\r\nAlso, this is just fyi, but I don't know if the memory performance is working exactly how you want it to.  I have a decent amount of RAM on my box and I was able to see both engines in action on a large dataset.  In version 0.19.2, the dataframe with 100MM indices ate up around 24GB of ram and didn't let it go. The new version peaked at 18GB before settling down to 11GB.  At first I thought it was a garbage collection issue because the code is building dataframes in a loop and so I cleaned out everything, ran just the 10BB scenario and got the same result.  So I'm wondering if the idea is to make the memory footprint smaller, is the initial ballooning in the engine a problem?  It certainly would be for the 1BB case if you had 16GB of ram, since you'd be paging the hdd (and hanging the box) as the footprint approaches 18GB before settling down to 11GB.\r\n\r\n```python\r\n#%%\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n\r\n#%%\r\n# Construct a dummy dataframe with a 2d multindex of size m-by-n\r\ndef dummy_df(m,n):\r\n    _M = m\r\n    _N = n\r\n    \r\n    tuples = [(i,j) for i in range(_M) for j in range(_N)]\r\n    \r\n    index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\r\n    df = pd.DataFrame(np.random.rand(_N*_M,4),columns=['A','B','C','D'],index=index)\r\n    return df\r\n\r\n#%%\r\n# Test data accessing\r\nn = 1000\r\nfor m in [5,9,20,100,500,1000,10000,100000]:\r\n    \r\n    df = dummy_df(m,n)\r\n    \r\n    print(str(m*n) + ' indices =>')\r\n    \r\n    # Time a random value with IPython's timeit magic command\r\n    %timeit df.A.loc[3,25] \r\n```\r\n\r\nSee attached files for timeit results (I decided to inline them after the initial post):\r\n\r\nUsing Pandas version 0.19.2\r\n\r\n> 5000 indices =>\r\nThe slowest run took 76.93 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n10000 loops, best of 3: 32.9 µs per loop\r\n9000 indices =>\r\nThe slowest run took 61.72 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n10000 loops, best of 3: 33.5 µs per loop\r\n20000 indices =>\r\nThe slowest run took 95.47 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n10000 loops, best of 3: 34.3 µs per loop\r\n100000 indices =>\r\nThe slowest run took 681.66 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n10000 loops, best of 3: 34 µs per loop\r\n500000 indices =>\r\nThe slowest run took 5370.16 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n1 loop, best of 3: 39.4 µs per loop\r\n1000000 indices =>\r\nThe slowest run took 6176.82 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n1 loop, best of 3: 41.2 µs per loop\r\n10000000 indices =>\r\nThe slowest run took 69808.91 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n1 loop, best of 3: 41.2 µs per loop\r\n100000000 indices =>\r\nThe slowest run took 656410.45 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n1 loop, best of 3: 43.4 µs per loop\r\n\r\nUsing Pandas 0.20.2:\r\n\r\n> 5000 indices =>\r\nThe slowest run took 68.16 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n10000 loops, best of 3: 35.5 µs per loop\r\n9000 indices =>\r\nThe slowest run took 67.65 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n10000 loops, best of 3: 37.3 µs per loop\r\n20000 indices =>\r\nThe slowest run took 17.95 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n10000 loops, best of 3: 132 µs per loop\r\n100000 indices =>\r\nThe slowest run took 68.23 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n10000 loops, best of 3: 130 µs per loop\r\n500000 indices =>\r\nThe slowest run took 520.37 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n10000 loops, best of 3: 126 µs per loop\r\n1000000 indices =>\r\nThe slowest run took 1032.61 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n10000 loops, best of 3: 129 µs per loop\r\n10000000 indices =>\r\nThe slowest run took 8144.94 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n1 loop, best of 3: 145 µs per loop\r\n100000000 indices =>\r\nThe slowest run took 121455.49 times longer than the fastest. This could mean that an intermediate result is being cached.\r\n1 loop, best of 3: 164 µs per loop\r\n\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/308074061",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-308074061",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 308074061,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwODA3NDA2MQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-13T10:25:58Z",
    "updated_at": "2017-06-13T10:25:58Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jupiterjosh the cutoff is 100k elements ATM. I suppose going to 1M wouldn't hurt. But you would have to show conclusive gains like this: https://github.com/pandas-dev/pandas/pull/16346#issuecomment-301929604. You can add an asv for 1M I suppose. @jorisvandenbossche also had a nice graph of this. Which if we can add memory usage would be nice.\r\n\r\nIf you are actually querying 1M times itself then you are doing things in an inefficient manner as well. You can easily use list / boolean indexing."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/308140143",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-308140143",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 308140143,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwODE0MDE0Mw==",
    "user": {
      "login": "jupiterjosh",
      "id": 29292793,
      "node_id": "MDQ6VXNlcjI5MjkyNzkz",
      "avatar_url": "https://avatars3.githubusercontent.com/u/29292793?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jupiterjosh",
      "html_url": "https://github.com/jupiterjosh",
      "followers_url": "https://api.github.com/users/jupiterjosh/followers",
      "following_url": "https://api.github.com/users/jupiterjosh/following{/other_user}",
      "gists_url": "https://api.github.com/users/jupiterjosh/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jupiterjosh/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jupiterjosh/subscriptions",
      "organizations_url": "https://api.github.com/users/jupiterjosh/orgs",
      "repos_url": "https://api.github.com/users/jupiterjosh/repos",
      "events_url": "https://api.github.com/users/jupiterjosh/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jupiterjosh/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-13T14:45:35Z",
    "updated_at": "2017-06-13T14:45:35Z",
    "author_association": "NONE",
    "body": "Thanks @jreback.  I will look at adding an asv.\r\n\r\nIs the 100k cutoff in the 0.20.2 release or a dev build?  I hit it at 10k elements in 0.20.2.  \r\n\r\nYou're right btw, I will change my indexing strategy.  I don't know the pandas code-base, but I was more concerned with the indexing slowdown potentially impacting other pandas functions (joins or groupbys maybe?) since indexing seems to be something that you'd want to be as fast (and atomic) as possible.\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/308271732",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-308271732",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 308271732,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwODI3MTczMg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-13T22:55:01Z",
    "updated_at": "2017-06-13T22:55:01Z",
    "author_association": "CONTRIBUTOR",
    "body": "> more concerned with the indexing slowdown potentially impacting other pandas functions (joins or groupbys maybe?) since indexing seems to be something that you'd want to be as fast (and atomic) \r\n\r\ngroupbys and joins are running vectorized code. indexing is by definition initiated by the user. you should not be doing repeated single indexing."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/308374432",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16644#issuecomment-308374432",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16644",
    "id": 308374432,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwODM3NDQzMg==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-14T09:19:54Z",
    "updated_at": "2017-06-14T09:19:54Z",
    "author_association": "MEMBER",
    "body": "Cutoff is currently indeed only 10k as @jupiterjosh finds ([code](https://github.com/pandas-dev/pandas/blob/1564a6e0e9fa3a640f5c1999c4fb118b8e5a4411/pandas/core/indexes/multi.py#L635-L646))\r\n\r\nFigure for timings is here: https://github.com/pandas-dev/pandas/blob/1564a6e0e9fa3a640f5c1999c4fb118b8e5a4411/pandas/core/indexes/multi.py#L635-L646\r\n\r\nI am certainly in favor of increasing the cutoff to at least 100k.\r\n\r\nAt the time, I tried to make similar plots for memory, but this was a bit more complicated and didn't get consistent results."
  }
]
