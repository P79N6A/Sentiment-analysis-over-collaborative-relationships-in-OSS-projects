[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/455764462",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-455764462",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 455764462,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NTc2NDQ2Mg==",
    "user": {
      "login": "PN12",
      "id": 46820227,
      "node_id": "MDQ6VXNlcjQ2ODIwMjI3",
      "avatar_url": "https://avatars0.githubusercontent.com/u/46820227?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/PN12",
      "html_url": "https://github.com/PN12",
      "followers_url": "https://api.github.com/users/PN12/followers",
      "following_url": "https://api.github.com/users/PN12/following{/other_user}",
      "gists_url": "https://api.github.com/users/PN12/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/PN12/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/PN12/subscriptions",
      "organizations_url": "https://api.github.com/users/PN12/orgs",
      "repos_url": "https://api.github.com/users/PN12/repos",
      "events_url": "https://api.github.com/users/PN12/events{/privacy}",
      "received_events_url": "https://api.github.com/users/PN12/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-19T09:34:27Z",
    "updated_at": "2019-01-19T13:29:09Z",
    "author_association": "NONE",
    "body": "Hi,\r\nI am getting an intermittent MemoryError while running code. The same code runs fine on re-installing Anaconda or while re-starting Jupyter Notebook / Sypder Kernel.\r\nThe system is 8GB RAM , 64bit OS.\r\nAs per the inputs received from Spyder community , this error relates to pandas. Please suggest the resolution steps.\r\nPlease note the same error occurs while running pd.read_csv command as well. \r\n\r\nBelow is the snapshot of the same.\r\n\r\n***********************************************************************************************\r\nFile \"\", line 23, in \r\ndf_hist_trans_group = df_hist_trans.groupby ('card_id').agg(aggs)\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\", line 4656, in aggregate\r\nreturn super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\", line 4087, in aggregate\r\nresult, how = self._aggregate(arg, _level=_level, *args, **kwargs)\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\base.py\", line 490, in _aggregate\r\nresult = _agg(arg, _agg_1dim)\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\base.py\", line 441, in _agg\r\nresult[fname] = func(fname, agg_how)\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\base.py\", line 424, in _agg_1dim\r\nreturn colg.aggregate(how, _level=(_level or 0) + 1)\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\", line 3485, in aggregate\r\n(_level or 0) + 1)\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\", line 3558, in _aggregate_multiple_funcs\r\nresults[name] = obj.aggregate(func)\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\", line 3479, in aggregate\r\nreturn getattr(self, func_or_funcs)(*args, **kwargs)\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\", line 3744, in nunique\r\nids, _, _ = self.grouper.group_info\r\n\r\nFile \"pandas_libs\\properties.pyx\", line 36, in pandas._libs.properties.CachedProperty.get\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\", line 2335, in group_info\r\ncomp_ids, obs_group_ids = self._get_compressed_labels()\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\", line 2351, in _get_compressed_labels\r\nall_labels = [ping.labels for ping in self.groupings]\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\", line 2351, in \r\nall_labels = [ping.labels for ping in self.groupings]\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\", line 3070, in labels\r\nself._make_labels()\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\", line 3103, in _make_labels\r\nself.grouper, sort=self.sort)\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\util_decorators.py\", line 178, in wrapper\r\nreturn func(*args, **kwargs)\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\", line 630, in factorize\r\nna_value=na_value)\r\n\r\nFile \"C:\\Users\\Prachi\\Anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\", line 476, in _factorize_array\r\nna_value=na_value)\r\n\r\nFile \"pandas_libs\\hashtable_class_helper.pxi\", line 1420, in pandas._libs.hashtable.StringHashTable.get_labels\r\n\r\nMemoryError\r\n\r\nAnother snapshot while using pd.read_csv in Jupyter Notebook is as below - \r\n*********************************************************************************************\r\nMemoryError                               Traceback (most recent call last)\r\n<ipython-input-3-f3225df00930> in <module>\r\n----> 1 df_hist_trans = pd.read_csv(r'C:\\Users\\Prachi\\Downloads\\all\\historical_transactions.csv')\r\n\r\n~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py in parser_f(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\r\n    676                     skip_blank_lines=skip_blank_lines)\r\n    677 \r\n--> 678         return _read(filepath_or_buffer, kwds)\r\n    679 \r\n    680     parser_f.__name__ = name\r\n\r\n~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py in _read(filepath_or_buffer, kwds)\r\n    444 \r\n    445     try:\r\n--> 446         data = parser.read(nrows)\r\n    447     finally:\r\n    448         parser.close()\r\n\r\n~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py in read(self, nrows)\r\n   1034                 raise ValueError('skipfooter not supported for iteration')\r\n   1035 \r\n-> 1036         ret = self._engine.read(nrows)\r\n   1037 \r\n   1038         # May alter columns / col_dict\r\n\r\n~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py in read(self, nrows)\r\n   1846     def read(self, nrows=None):\r\n   1847         try:\r\n-> 1848             data = self._reader.read(nrows)\r\n   1849         except StopIteration:\r\n   1850             if self._first_chunk:\r\n\r\npandas\\_libs\\parsers.pyx in pandas._libs.parsers.TextReader.read()\r\n\r\npandas\\_libs\\parsers.pyx in pandas._libs.parsers.TextReader._read_low_memory()\r\n\r\npandas\\_libs\\parsers.pyx in pandas._libs.parsers.TextReader._read_rows()\r\n\r\npandas\\_libs\\parsers.pyx in pandas._libs.parsers.TextReader._convert_column_data()\r\n\r\npandas\\_libs\\parsers.pyx in pandas._libs.parsers.TextReader._convert_tokens()\r\n\r\npandas\\_libs\\parsers.pyx in pandas._libs.parsers.TextReader._convert_with_dtype()\r\n\r\npandas\\_libs\\parsers.pyx in pandas._libs.parsers._try_int64()\r\n\r\nMemoryError:  "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/455833333",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-455833333",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 455833333,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NTgzMzMzMw==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-20T02:59:13Z",
    "updated_at": "2019-01-20T02:59:13Z",
    "author_association": "MEMBER",
    "body": "@PN12 : Thanks for reporting this!  In order for us to help you, could you do two things in your original issue that you posted:\r\n\r\n* Provide output of `pandas.show_versions` ?\r\n* Provide the code sample that causes this massive traceback?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/455839339",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-455839339",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 455839339,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NTgzOTMzOQ==",
    "user": {
      "login": "PN12",
      "id": 46820227,
      "node_id": "MDQ6VXNlcjQ2ODIwMjI3",
      "avatar_url": "https://avatars0.githubusercontent.com/u/46820227?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/PN12",
      "html_url": "https://github.com/PN12",
      "followers_url": "https://api.github.com/users/PN12/followers",
      "following_url": "https://api.github.com/users/PN12/following{/other_user}",
      "gists_url": "https://api.github.com/users/PN12/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/PN12/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/PN12/subscriptions",
      "organizations_url": "https://api.github.com/users/PN12/orgs",
      "repos_url": "https://api.github.com/users/PN12/repos",
      "events_url": "https://api.github.com/users/PN12/events{/privacy}",
      "received_events_url": "https://api.github.com/users/PN12/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-20T05:31:47Z",
    "updated_at": "2019-01-20T05:31:47Z",
    "author_association": "NONE",
    "body": "@gfyoung - Please find below the details - \r\n\r\n**- Provide output of pandas.show_versions ?**\r\n\r\n****Code** - pd.show_versions (as_json = False)**\r\n\r\n**Output** - \r\n*******************************\r\npd.show_versions (as_json = False)\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.7.1.final.0\r\npython-bits: 64\r\nOS: Windows\r\nOS-release: 10\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 158 Stepping 10, GenuineIntel\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en\r\nLOCALE: None.None\r\n\r\npandas: 0.23.4\r\npytest: 4.0.2\r\npip: 18.1\r\nsetuptools: 40.6.3\r\nCython: 0.29.2\r\nnumpy: 1.15.4\r\nscipy: 1.1.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 7.2.0\r\nsphinx: 1.8.2\r\npatsy: 0.5.1\r\ndateutil: 2.7.5\r\npytz: 2018.7\r\nblosc: None\r\nbottleneck: 1.2.1\r\ntables: 3.4.4\r\nnumexpr: 2.6.8\r\nfeather: None\r\nmatplotlib: 3.0.2\r\nopenpyxl: 2.5.12\r\nxlrd: 1.2.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 1.1.2\r\nlxml: 4.2.5\r\nbs4: 4.6.3\r\nhtml5lib: 1.0.1\r\nsqlalchemy: 1.2.15\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: None\r\npandas_gbq: None\r\npandas_datareader: None\r\n********************************************************\r\n**- Provide the code sample that causes this massive traceback?**\r\n\r\n**- The code sample is as below -**\r\n \r\nMemory Error is encountered through the below commands -\r\n\r\n1. df_hist_trans_group = df_hist_trans.groupby ('card_id').agg(aggs)\r\n\r\n2. df_hist_trans = pd.read_csv(r'C:\\Users\\Prachi\\Downloads\\all\\historical_transactions.csv')_\r\n\r\n*************************\r\n`# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Sat Jan 19 19:53:23 2019\r\n\r\n@author: Prachi\r\n\"\"\"\r\nimport numpy as np\r\nimport pandas as pd\r\nimport datetime\r\nimport gc\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\nimport lightgbm as lgb\r\nfrom sklearn.model_selection import StratifiedKFold\r\nfrom sklearn.metrics import mean_squared_error\r\nimport warnings\r\nwarnings.filterwarnings('ignore')\r\nnp.random.seed(4590)\r\n\r\ndf_train = pd.read_csv(r'C:\\Users\\Prachi\\Downloads\\all\\train.csv')\r\ndf_test = pd.read_csv(r'C:\\Users\\Prachi\\Downloads\\all\\test.csv')\r\n\r\ndf_hist_trans = pd.read_csv(r'C:\\Users\\Prachi\\Downloads\\all\\historical_transactions.csv')\r\n\r\ndf_new_merchant_trans = pd.read_csv(r'C:\\Users\\Prachi\\Downloads\\all\\new_merchant_transactions.csv')\r\n\r\nfor df in [df_hist_trans,df_new_merchant_trans]:\r\n    df['category_2'].fillna(1.0,inplace=True)\r\n    df['category_3'].fillna('A',inplace=True)\r\n    df['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)\r\n    \r\ndef get_new_columns (name , aggs):\r\n    return (name + '_' + k + '_' + agg \r\n                for k in aggs.keys() \r\n                    for agg in aggs[k])\r\n\r\nfor df in [df_hist_trans,df_new_merchant_trans]:\r\n    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\r\n    df['year'] = df['purchase_date'].dt.year\r\n    df['weekofyear'] = df['purchase_date'].dt.weekofyear\r\n    df['month'] = df['purchase_date'].dt.month\r\n    df['dayofweek'] = df['purchase_date'].dt.dayofweek\r\n    df['weekend'] = (df.purchase_date.dt.weekday >=5).astype(int)\r\n    df['hour'] = df['purchase_date'].dt.hour\r\n    df['authorized_flag'] = df['authorized_flag'].map({'Y':1, 'N':0})\r\n    df['category_1_n'] = df['category_1'].map({'Y': 1, 'N': 0}) \r\n    df['month_diff'] = ((datetime.datetime.today() - df['purchase_date']).dt.days)//30\r\n    df['month_diff'] += df['month_lag']\r\n    df['purchase_date_n'] = df['purchase_date'].dt.date\r\n    df['purchase_date_n_sq'] = pd.to_datetime (df['purchase_date_n'])\r\n\r\n#df_hist_trans['purchase_date_n']\r\n\r\naggs = {}\r\n\r\nfor col in ['month' , 'hour','weekofyear','dayofweek', 'year','subsector_id','merchant_id','merchant_category_id']:\r\n    aggs[col] = ['nunique']\r\n\r\naggs['purchase_amount'] = ['sum','max','min','mean','var']\r\naggs['installments'] = ['sum','max','min','mean','var']\r\naggs['purchase_date_n_sq'] = ['max','min']\r\naggs['month_lag'] = ['max','min','mean','var']\r\naggs['month_diff'] = ['mean']\r\naggs['authorized_flag'] = ['sum', 'mean']\r\naggs['weekend'] = ['sum', 'mean']\r\naggs['category_1_n'] = ['sum', 'mean']\r\naggs['card_id'] = ['size']\r\n\r\nfor col in ['category_2' , 'category_3']:\r\n    df_hist_trans[col+'_mean'] = df_hist_trans.groupby([col])['purchase_amount'].transform('mean')\r\n    aggs[col+'_mean'] = ['mean']\r\n\r\nnew_columns = get_new_columns ('hist', aggs) \r\n\r\n#type(new_columns)\r\n\r\n#list(df_hist_trans.columns)\r\n\r\n#pd.set_option('display.max_columns', 30)\r\n#df_hist_trans.head()\r\n\r\ndf_hist_trans['today'] = str(datetime.datetime.today()).split()[0]\r\n\r\ndf_hist_trans['today_nsq'] = pd.to_datetime (df_hist_trans['today'])\r\n\r\n#print (df_hist_trans['today_nsq'] ,  df_hist_trans['purchase_date_nsq'])\r\n        \r\ndf_hist_trans_group = df_hist_trans.groupby('card_id').agg(aggs)\r\n    \r\npd.set_option('display.max_columns', 30)\r\n\r\ndf_hist_trans_group.columns = new_columns\r\n\r\ntype (df_hist_trans_group)\r\n\r\nnew_columns\r\n\r\ndf_hist_trans_group.columns\r\n\r\n\r\npd.show_versions\r\n\r\n\r\npd.show_versions (as_json = False)\r\n\r\n`\r\n******************************************************************************\r\n\r\n\r\nThanks\r\n "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/455839491",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-455839491",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 455839491,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NTgzOTQ5MQ==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-20T05:36:42Z",
    "updated_at": "2019-01-20T05:36:58Z",
    "author_association": "MEMBER",
    "body": "@PN12 : Thanks!  Is it also to provide the CSV files?  It would be difficult to run your code otherwise (and reproduce your issue)."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/455841209",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-455841209",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 455841209,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NTg0MTIwOQ==",
    "user": {
      "login": "PN12",
      "id": 46820227,
      "node_id": "MDQ6VXNlcjQ2ODIwMjI3",
      "avatar_url": "https://avatars0.githubusercontent.com/u/46820227?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/PN12",
      "html_url": "https://github.com/PN12",
      "followers_url": "https://api.github.com/users/PN12/followers",
      "following_url": "https://api.github.com/users/PN12/following{/other_user}",
      "gists_url": "https://api.github.com/users/PN12/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/PN12/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/PN12/subscriptions",
      "organizations_url": "https://api.github.com/users/PN12/orgs",
      "repos_url": "https://api.github.com/users/PN12/repos",
      "events_url": "https://api.github.com/users/PN12/events{/privacy}",
      "received_events_url": "https://api.github.com/users/PN12/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-20T06:19:50Z",
    "updated_at": "2019-01-20T06:19:50Z",
    "author_association": "NONE",
    "body": "\r\n@gfyoung - Please find the [link](https://drive.google.com/file/d/1zxE6DfAIdk6z7GYA4ARPLCM4owNStvC-/view?usp=sharing) for file and code.\r\n\r\n\r\n\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/456211099",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-456211099",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 456211099,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NjIxMTA5OQ==",
    "user": {
      "login": "WillAyd",
      "id": 609873,
      "node_id": "MDQ6VXNlcjYwOTg3Mw==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/609873?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/WillAyd",
      "html_url": "https://github.com/WillAyd",
      "followers_url": "https://api.github.com/users/WillAyd/followers",
      "following_url": "https://api.github.com/users/WillAyd/following{/other_user}",
      "gists_url": "https://api.github.com/users/WillAyd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/WillAyd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/WillAyd/subscriptions",
      "organizations_url": "https://api.github.com/users/WillAyd/orgs",
      "repos_url": "https://api.github.com/users/WillAyd/repos",
      "events_url": "https://api.github.com/users/WillAyd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/WillAyd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-21T22:08:18Z",
    "updated_at": "2019-01-21T22:08:27Z",
    "author_association": "MEMBER",
    "body": "I see that the file itself is 550 MB and that you have quite a number of aggregations you are performing, so it's not infeasible to exhaust memory on an 8 GB system. \r\n\r\nIf you have tangible numbers and expectations around what that should be and feel that pandas is grossly exceeding that please share but otherwise closing as it's not clear there is even a problem here.\r\n\r\nJust as a tip make sure you have the appropriate dtypes defined for your data as using object dtypes will be inefficient and possibly even cause undesirable aggregations to exhaust more memory"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/456272037",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-456272037",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 456272037,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NjI3MjAzNw==",
    "user": {
      "login": "PN12",
      "id": 46820227,
      "node_id": "MDQ6VXNlcjQ2ODIwMjI3",
      "avatar_url": "https://avatars0.githubusercontent.com/u/46820227?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/PN12",
      "html_url": "https://github.com/PN12",
      "followers_url": "https://api.github.com/users/PN12/followers",
      "following_url": "https://api.github.com/users/PN12/following{/other_user}",
      "gists_url": "https://api.github.com/users/PN12/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/PN12/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/PN12/subscriptions",
      "organizations_url": "https://api.github.com/users/PN12/orgs",
      "repos_url": "https://api.github.com/users/PN12/repos",
      "events_url": "https://api.github.com/users/PN12/events{/privacy}",
      "received_events_url": "https://api.github.com/users/PN12/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-22T05:02:19Z",
    "updated_at": "2019-01-22T05:06:35Z",
    "author_association": "NONE",
    "body": "@WillAyd - \r\nSorry, but the \r\n1. The same code did ran perfect earlier on the same laptop with 8GB RAM config.\r\n2. Plus the Memory Error encountered above has been faced while performing pd.read_csv on the shared historical_transactions.csv file which is 2.65 GB. This operation was performed before the aggregations part. \r\n3. The issue I would like to understand is while the similar size files have been working fine in my data modelling projects. Then facing MemoryError multiple times for a pd.read_csv command is not understandable.  While the same file works fine on re-installing Anaconda or restarting Spyder altogether. \r\n4. Also, 550MB file size has worked well till now on spyder and Jupyter both. \r\n\r\nWould be helpful if you can guide us to the root cause and thus we can rectify it .\r\n\r\nA re-opening of the issue would be of help as well here.\r\n\r\nThanks."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/456272404",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-456272404",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 456272404,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NjI3MjQwNA==",
    "user": {
      "login": "PN12",
      "id": 46820227,
      "node_id": "MDQ6VXNlcjQ2ODIwMjI3",
      "avatar_url": "https://avatars0.githubusercontent.com/u/46820227?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/PN12",
      "html_url": "https://github.com/PN12",
      "followers_url": "https://api.github.com/users/PN12/followers",
      "following_url": "https://api.github.com/users/PN12/following{/other_user}",
      "gists_url": "https://api.github.com/users/PN12/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/PN12/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/PN12/subscriptions",
      "organizations_url": "https://api.github.com/users/PN12/orgs",
      "repos_url": "https://api.github.com/users/PN12/repos",
      "events_url": "https://api.github.com/users/PN12/events{/privacy}",
      "received_events_url": "https://api.github.com/users/PN12/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-22T05:05:13Z",
    "updated_at": "2019-01-22T05:05:13Z",
    "author_association": "NONE",
    "body": "@gfyoung - Please let us know if you have inputs on the above as well which could help rectify the issue.\r\n\r\nThanks.\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/456273178",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-456273178",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 456273178,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NjI3MzE3OA==",
    "user": {
      "login": "WillAyd",
      "id": 609873,
      "node_id": "MDQ6VXNlcjYwOTg3Mw==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/609873?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/WillAyd",
      "html_url": "https://github.com/WillAyd",
      "followers_url": "https://api.github.com/users/WillAyd/followers",
      "following_url": "https://api.github.com/users/WillAyd/following{/other_user}",
      "gists_url": "https://api.github.com/users/WillAyd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/WillAyd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/WillAyd/subscriptions",
      "organizations_url": "https://api.github.com/users/WillAyd/orgs",
      "repos_url": "https://api.github.com/users/WillAyd/repos",
      "events_url": "https://api.github.com/users/WillAyd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/WillAyd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-22T05:10:54Z",
    "updated_at": "2019-01-22T05:10:54Z",
    "author_association": "MEMBER",
    "body": "> 2\\. Plus the Memory Error encountered above has been faced while performing pd.read_csv on the shared historical_transactions.csv file which is 2.65 GB. This operation was performed before the aggregations part.\r\n\r\nIf this is the case then please make your example as *minimal* as possible to reproduce the issue and provide versions where it was working before but where you feel there was now a regression.\r\n\r\nThere is unfortunately way too much unnecessary code and a variety of confounding factors being provided as is. \r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/456273927",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-456273927",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 456273927,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NjI3MzkyNw==",
    "user": {
      "login": "PN12",
      "id": 46820227,
      "node_id": "MDQ6VXNlcjQ2ODIwMjI3",
      "avatar_url": "https://avatars0.githubusercontent.com/u/46820227?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/PN12",
      "html_url": "https://github.com/PN12",
      "followers_url": "https://api.github.com/users/PN12/followers",
      "following_url": "https://api.github.com/users/PN12/following{/other_user}",
      "gists_url": "https://api.github.com/users/PN12/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/PN12/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/PN12/subscriptions",
      "organizations_url": "https://api.github.com/users/PN12/orgs",
      "repos_url": "https://api.github.com/users/PN12/repos",
      "events_url": "https://api.github.com/users/PN12/events{/privacy}",
      "received_events_url": "https://api.github.com/users/PN12/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-22T05:15:57Z",
    "updated_at": "2019-01-22T05:15:57Z",
    "author_association": "NONE",
    "body": "\r\nIf this is the case then please make your example as minimal as possible to reproduce the issue and provide versions where it was working before but where you feel there was now a regression.\r\n\r\n@WillAyd - Please advise on the required information and I shall share the same.\r\n\r\nThanks.\r\n\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/456274164",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-456274164",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 456274164,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NjI3NDE2NA==",
    "user": {
      "login": "WillAyd",
      "id": 609873,
      "node_id": "MDQ6VXNlcjYwOTg3Mw==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/609873?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/WillAyd",
      "html_url": "https://github.com/WillAyd",
      "followers_url": "https://api.github.com/users/WillAyd/followers",
      "following_url": "https://api.github.com/users/WillAyd/following{/other_user}",
      "gists_url": "https://api.github.com/users/WillAyd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/WillAyd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/WillAyd/subscriptions",
      "organizations_url": "https://api.github.com/users/WillAyd/orgs",
      "repos_url": "https://api.github.com/users/WillAyd/repos",
      "events_url": "https://api.github.com/users/WillAyd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/WillAyd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-22T05:17:32Z",
    "updated_at": "2019-01-22T05:17:32Z",
    "author_association": "MEMBER",
    "body": "Check out our contributing guide as a first step:\r\n\r\nhttps://pandas.pydata.org/pandas-docs/stable/contributing.html#bug-reports-and-enhancement-requests"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/456275824",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-456275824",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 456275824,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NjI3NTgyNA==",
    "user": {
      "login": "PN12",
      "id": 46820227,
      "node_id": "MDQ6VXNlcjQ2ODIwMjI3",
      "avatar_url": "https://avatars0.githubusercontent.com/u/46820227?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/PN12",
      "html_url": "https://github.com/PN12",
      "followers_url": "https://api.github.com/users/PN12/followers",
      "following_url": "https://api.github.com/users/PN12/following{/other_user}",
      "gists_url": "https://api.github.com/users/PN12/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/PN12/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/PN12/subscriptions",
      "organizations_url": "https://api.github.com/users/PN12/orgs",
      "repos_url": "https://api.github.com/users/PN12/repos",
      "events_url": "https://api.github.com/users/PN12/events{/privacy}",
      "received_events_url": "https://api.github.com/users/PN12/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-22T05:29:08Z",
    "updated_at": "2019-01-22T05:29:08Z",
    "author_association": "NONE",
    "body": "@WillAyd -\r\n\r\nSorry, but the same information has already been shared above. \r\n\r\nThe same are mentioned as below - \r\n\r\n**1. Snippet of the issue -** \r\n`\r\nimport pandas as pd\r\ndf_hist_trans = pd.read_csv(r'C:\\Users\\Prachi\\Downloads\\all\\historical_transactions.csv')\r\n`\r\n\r\n**2. Full version string of pandas and its dependencies**\r\n**Code** \r\n`pd.show_versions()\r\n`\r\n\r\n**Output**\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.7.1.final.0\r\npython-bits: 64\r\nOS: Windows\r\nOS-release: 10\r\nmachine: AMD64\r\nprocessor: Intel64 Family 6 Model 158 Stepping 10, GenuineIntel\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en\r\nLOCALE: None.None\r\n\r\npandas: 0.23.4\r\npytest: 4.0.2\r\npip: 18.1\r\nsetuptools: 40.6.3\r\nCython: 0.29.2\r\nnumpy: 1.15.4\r\nscipy: 1.1.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 7.2.0\r\nsphinx: 1.8.2\r\npatsy: 0.5.1\r\ndateutil: 2.7.5\r\npytz: 2018.7\r\nblosc: None\r\nbottleneck: 1.2.1\r\ntables: 3.4.4\r\nnumexpr: 2.6.8\r\nfeather: None\r\nmatplotlib: 3.0.2\r\nopenpyxl: 2.5.12\r\nxlrd: 1.2.0\r\nxlwt: 1.3.0\r\nxlsxwriter: 1.1.2\r\nlxml: 4.2.5\r\nbs4: 4.6.3\r\nhtml5lib: 1.0.1\r\nsqlalchemy: 1.2.15\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: None\r\npandas_gbq: None\r\npandas_datareader: None\r\n\r\n**3. Explain why the current behavior is wrong/not desired and what you expect instead.**\r\n\r\nMemoryError issue is being faced while running the above snippet. Traceback of the same is as below (pasted from 1st comment above)\r\n\r\n************************\r\nMemoryError Traceback (most recent call last)\r\nin \r\n_----> 1 df_hist_trans = pd.read_csv(r'C:\\Users\\Prachi\\Downloads\\all\\historical_transactions.csv')\r\n\r\n~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py in parser_f(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\r\n676 skip_blank_lines=skip_blank_lines)\r\n677\r\n--> 678 return _read(filepath_or_buffer, kwds)\r\n679\r\n680 parser_f.name = name\r\n\r\n~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py in _read(filepath_or_buffer, kwds)\r\n444\r\n445 try:\r\n--> 446 data = parser.read(nrows)\r\n447 finally:\r\n448 parser.close()\r\n\r\n~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py in read(self, nrows)\r\n1034 raise ValueError('skipfooter not supported for iteration')\r\n1035\r\n-> 1036 ret = self._engine.read(nrows)\r\n1037\r\n1038 # May alter columns / col_dict\r\n\r\n~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py in read(self, nrows)\r\n1846 def read(self, nrows=None):\r\n1847 try:\r\n-> 1848 data = self._reader.read(nrows)\r\n1849 except StopIteration:\r\n1850 if self._first_chunk:\r\n\r\npandas_libs\\parsers.pyx in pandas._libs.parsers.TextReader.read()\r\n\r\npandas_libs\\parsers.pyx in pandas._libs.parsers.TextReader._read_low_memory()\r\n\r\npandas_libs\\parsers.pyx in pandas._libs.parsers.TextReader._read_rows()\r\n\r\npandas_libs\\parsers.pyx in pandas._libs.parsers.TextReader._convert_column_data()\r\n\r\npandas_libs\\parsers.pyx in pandas._libs.parsers.TextReader._convert_tokens()\r\n\r\npandas_libs\\parsers.pyx in pandas._libs.parsers.TextReader._convert_with_dtype()\r\n\r\npandas_libs\\parsers.pyx in pandas._libs.parsers._try_int64()\r\n\r\nMemoryError:_\r\n\r\n****************\r\n\r\n@WillAyd  - Please advise in case of any more needed information.\r\n\r\nMany Thanks."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/456384647",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-456384647",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 456384647,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NjM4NDY0Nw==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-22T12:37:30Z",
    "updated_at": "2019-01-22T12:38:11Z",
    "author_association": "CONTRIBUTOR",
    "body": "@PN12 A few suggestions\r\n\r\n1. That example isn't quite minimal :) See http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports for some advice. For example, I don't have a C drive on my computer :) If truly necessary, you can depend external file, but that is rarely necessary. You may be able to generate the data (possibly in batches) and write it to disk, before getting a memory error reading it in. I assume scikit-learn, matplotlib, seaboard, lightgbm, etc. aren't necessary either.\r\n2. Could you collect the requested information (minimal example, problem description, expected output, output of show_versions in a `<details>` tag) in the original post? You can edit it.\r\n3. Nitpick: Could you format your posts (https://guides.github.com/features/mastering-markdown)? It makes them easier to scan through.\r\n\r\nWe understand that it can take some time to put together a good, minimal example. But it's what lets us figure out the problem (if any) and a solution more quickly."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/476971577",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24836#issuecomment-476971577",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24836",
    "id": 476971577,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3Njk3MTU3Nw==",
    "user": {
      "login": "WillAyd",
      "id": 609873,
      "node_id": "MDQ6VXNlcjYwOTg3Mw==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/609873?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/WillAyd",
      "html_url": "https://github.com/WillAyd",
      "followers_url": "https://api.github.com/users/WillAyd/followers",
      "following_url": "https://api.github.com/users/WillAyd/following{/other_user}",
      "gists_url": "https://api.github.com/users/WillAyd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/WillAyd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/WillAyd/subscriptions",
      "organizations_url": "https://api.github.com/users/WillAyd/orgs",
      "repos_url": "https://api.github.com/users/WillAyd/repos",
      "events_url": "https://api.github.com/users/WillAyd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/WillAyd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-27T04:41:17Z",
    "updated_at": "2019-03-27T04:41:17Z",
    "author_association": "MEMBER",
    "body": "Closing due to age. If you can provide info as requested above feel free to reopen"
  }
]
