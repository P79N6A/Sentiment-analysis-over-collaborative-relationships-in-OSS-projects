[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/350555357",
    "html_url": "https://github.com/pandas-dev/pandas/issues/18692#issuecomment-350555357",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/18692",
    "id": 350555357,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDU1NTM1Nw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-10T15:18:15Z",
    "updated_at": "2017-12-10T15:18:15Z",
    "author_association": "CONTRIBUTOR",
    "body": "@gfyoung can you have a look"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/350601364",
    "html_url": "https://github.com/pandas-dev/pandas/issues/18692#issuecomment-350601364",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/18692",
    "id": 350601364,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDYwMTM2NA==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-11T01:34:57Z",
    "updated_at": "2017-12-11T01:35:18Z",
    "author_association": "MEMBER",
    "body": "@rgieseke : Thanks for reporting this!  Handling malformed rows is just not an easy question, and I agree here that indeed we should handle this case.\r\n\r\n#12900 was a design choice on our part to ensure that quoted lines got fully skipped, even if they had line-terminators within them.  In your case, because your quoted line never properly terminates, `read_csv` will skip over everything.\r\n\r\nSurprised to see that the Python engine is okay with this.  Line skipping behavior is hard to understand there because it's masked away in the Python language library itself.\r\n\r\nMy feeling is that we can add a second parameter called `parse_bad_lines` (which has been mentioned before in other issues) in which we can handle the behavior of #12900 but still allow for your example to work.  Adding parameters will become a lot more palatable once we remove a wave of deprecated ones."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/350675308",
    "html_url": "https://github.com/pandas-dev/pandas/issues/18692#issuecomment-350675308",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/18692",
    "id": 350675308,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDY3NTMwOA==",
    "user": {
      "login": "rgieseke",
      "id": 198537,
      "node_id": "MDQ6VXNlcjE5ODUzNw==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/198537?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rgieseke",
      "html_url": "https://github.com/rgieseke",
      "followers_url": "https://api.github.com/users/rgieseke/followers",
      "following_url": "https://api.github.com/users/rgieseke/following{/other_user}",
      "gists_url": "https://api.github.com/users/rgieseke/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rgieseke/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rgieseke/subscriptions",
      "organizations_url": "https://api.github.com/users/rgieseke/orgs",
      "repos_url": "https://api.github.com/users/rgieseke/repos",
      "events_url": "https://api.github.com/users/rgieseke/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rgieseke/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-11T09:55:29Z",
    "updated_at": "2017-12-11T09:55:29Z",
    "author_association": "CONTRIBUTOR",
    "body": "@gfyoung Thanks for the quick feedback!\r\n\r\nHere is a more real-world example from the data where I encountered the problem (simplified, this is Fortran namelist metadata plus whitespace separated columns), it's not really malformed, just having a space within the quotes. Again, with `engine=\"python\"` it works. And without the `delim_whitespace` and commas as separator there is also no problem.\r\n\r\n```python\r\nimport pandas as pd\r\nfrom io import StringIO\r\ndata = \"\"\"&THISFILE_SPECIFICATIONS\r\n THISFILE_UNITS=\"K \",\r\n /\r\n      YEARS     GLOBAL       \r\n      1765      0.00000000E+00\r\n\"\"\"\r\npd.read_csv(StringIO(data), skiprows=3, delim_whitespace=True)\r\n```\r\n\r\nIf there were newlines in the header to be skipped, wouldn't it be okay to treat them as newlines? If one has a weird header one wants to be skipped, one would need to check anyway if the first line is correctly identified.\r\n\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/350768637",
    "html_url": "https://github.com/pandas-dev/pandas/issues/18692#issuecomment-350768637",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/18692",
    "id": 350768637,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDc2ODYzNw==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-11T16:02:34Z",
    "updated_at": "2017-12-11T16:02:54Z",
    "author_association": "MEMBER",
    "body": "Indeed, this example is harder to explain away, since it isn't particularly malformed in this case...have a look at the CParser code to see where the discrepancy is arising.\r\n\r\n> If there were newlines in the header to be skipped, wouldn't it be okay to treat them as newlines? If one has a weird header one wants to be skipped, one would need to check anyway if the first line is correctly identified.\r\n\r\nNot sure I fully understand your question here."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/350770921",
    "html_url": "https://github.com/pandas-dev/pandas/issues/18692#issuecomment-350770921",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/18692",
    "id": 350770921,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDc3MDkyMQ==",
    "user": {
      "login": "rgieseke",
      "id": 198537,
      "node_id": "MDQ6VXNlcjE5ODUzNw==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/198537?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rgieseke",
      "html_url": "https://github.com/rgieseke",
      "followers_url": "https://api.github.com/users/rgieseke/followers",
      "following_url": "https://api.github.com/users/rgieseke/following{/other_user}",
      "gists_url": "https://api.github.com/users/rgieseke/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rgieseke/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rgieseke/subscriptions",
      "organizations_url": "https://api.github.com/users/rgieseke/orgs",
      "repos_url": "https://api.github.com/users/rgieseke/repos",
      "events_url": "https://api.github.com/users/rgieseke/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rgieseke/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-11T16:09:39Z",
    "updated_at": "2017-12-11T16:09:45Z",
    "author_association": "CONTRIBUTOR",
    "body": "> Not sure I fully understand your question here.\r\n\r\nSorry, that was hard to parse ... I hadn't thought of the usecase of actually wanting to skip a number of rows. I only ever use skiprows to get rid of meta information in header lines."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/350772234",
    "html_url": "https://github.com/pandas-dev/pandas/issues/18692#issuecomment-350772234",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/18692",
    "id": 350772234,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDc3MjIzNA==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-11T16:13:41Z",
    "updated_at": "2017-12-11T16:13:41Z",
    "author_association": "MEMBER",
    "body": "> Sorry, that was hard to parse ... I hadn't thought of the usecase of actually wanting to skip a number of rows. I only ever use skiprows to get rid of meta informationin header lines.\r\n\r\nAh, gotcha.  In any case, FWIW, if you remove the `skiprows` parameter, Python can still read the input, while the C engine still can't.  Thus, that definitely points to some kind of parsing issue."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/386212964",
    "html_url": "https://github.com/pandas-dev/pandas/issues/18692#issuecomment-386212964",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/18692",
    "id": 386212964,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM4NjIxMjk2NA==",
    "user": {
      "login": "cip",
      "id": 261897,
      "node_id": "MDQ6VXNlcjI2MTg5Nw==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/261897?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cip",
      "html_url": "https://github.com/cip",
      "followers_url": "https://api.github.com/users/cip/followers",
      "following_url": "https://api.github.com/users/cip/following{/other_user}",
      "gists_url": "https://api.github.com/users/cip/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cip/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cip/subscriptions",
      "organizations_url": "https://api.github.com/users/cip/orgs",
      "repos_url": "https://api.github.com/users/cip/repos",
      "events_url": "https://api.github.com/users/cip/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cip/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-05-03T07:33:20Z",
    "updated_at": "2018-05-03T07:33:20Z",
    "author_association": "NONE",
    "body": "I've experienced a similar issue when using skiprows to skip  \"corrupt\" lines in the csv files.\r\nIn this test case no exception is thrown, but some rows are just missing.\r\n\r\nTested with pandas 0.22.0 and 0.19.2.\r\n\r\nPerhaps adding an argument to disable parsing of quotes in skipped rows is an option to fix this?\r\nPersonally I'd prefer if this would be the default behaviour, and the argument can be used to enable parsing of quotes in skipped rows.\r\n\r\n## Example\r\n\r\n```python\r\nimport pandas as pd\r\nfrom io import StringIO\r\nimport csv\r\n```\r\n\r\n\r\n```python\r\npd.__version__\r\n```\r\n\r\n\r\n\r\n\r\n    '0.22.0'\r\n\r\n\r\n\r\n\r\n```python\r\ndata=\"\"\"1 2 3\r\na\"b \"\r\n4 5 6\r\n\"\"\" \r\n```\r\n\r\n\r\n```python\r\nprint(data)\r\n```\r\n\r\n    1 2 3\r\n    a\"b \"\r\n    4 5 6\r\n    \r\n\r\n\r\n\r\n```python\r\npd.read_csv(StringIO(data), header=None, delim_whitespace=True, skiprows=[1])\r\n```\r\n\r\n\r\n\r\n<div>\r\n\r\n<table border=\"1\" class=\"dataframe\">\r\n  <thead>\r\n    <tr style=\"text-align: right;\">\r\n      <th></th>\r\n      <th>0</th>\r\n      <th>1</th>\r\n      <th>2</th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <th>0</th>\r\n      <td>1</td>\r\n      <td>2</td>\r\n      <td>3</td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n</div>\r\n\r\n\r\n\r\n\r\n```python\r\npd.read_csv(StringIO(data), header=None, delim_whitespace=True, skiprows=[1], engine=\"python\")\r\n```\r\n\r\n\r\n\r\n\r\n<div>\r\n<table border=\"1\" class=\"dataframe\">\r\n  <thead>\r\n    <tr style=\"text-align: right;\">\r\n      <th></th>\r\n      <th>0</th>\r\n      <th>1</th>\r\n      <th>2</th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <th>0</th>\r\n      <td>1</td>\r\n      <td>2</td>\r\n      <td>3</td>\r\n    </tr>\r\n    <tr>\r\n      <th>1</th>\r\n      <td>4</td>\r\n      <td>5</td>\r\n      <td>6</td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n</div>\r\n\r\n\r\n\r\n\r\n```python\r\npd.read_csv(StringIO(data), header=None, delim_whitespace=True, skiprows=[1], quoting=csv.QUOTE_NONE)\r\n```\r\n\r\n\r\n\r\n\r\n<div>\r\n<table border=\"1\" class=\"dataframe\">\r\n  <thead>\r\n    <tr style=\"text-align: right;\">\r\n      <th></th>\r\n      <th>0</th>\r\n      <th>1</th>\r\n      <th>2</th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <th>0</th>\r\n      <td>1</td>\r\n      <td>2</td>\r\n      <td>3</td>\r\n    </tr>\r\n    <tr>\r\n      <th>1</th>\r\n      <td>4</td>\r\n      <td>5</td>\r\n      <td>6</td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n</div>\r\n\r\n"
  }
]
