[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/39562509",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6798#issuecomment-39562509",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6798",
    "id": 39562509,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NTYyNTA5",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-04T13:07:31Z",
    "updated_at": "2014-04-04T13:07:31Z",
    "author_association": "CONTRIBUTOR",
    "body": "give a try on the new sql support in master/0.14 (coming soon), see here: https://github.com/pydata/pandas/issues/6292\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/43359983",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6798#issuecomment-43359983",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6798",
    "id": 43359983,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzMzU5OTgz",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-05-16T17:50:33Z",
    "updated_at": "2014-05-16T17:50:33Z",
    "author_association": "CONTRIBUTOR",
    "body": "not sure this is necessary, @jorisvandenbossche ?\n\ncan always `convert_objects()` if needed (but in general the dtypes ar coerced properly)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/43596383",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6798#issuecomment-43596383",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6798",
    "id": 43596383,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTk2Mzgz",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-05-20T07:57:48Z",
    "updated_at": "2014-05-20T07:58:35Z",
    "author_association": "MEMBER",
    "body": "@Midnighter Can you give a concrete example case where you would like to use such a keyword.\n\nIf there is good use for it, we can consider to add I think, but be aware that you already have `coerce_floats` to convert all numeric-like strings to numerics, and `parse_dates` to parse datetime-like strings to datetimes. And that in general the types in the database (ints, reals, strings, etc) are already converted correctly to pandas types.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/43599487",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6798#issuecomment-43599487",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6798",
    "id": 43599487,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTk5NDg3",
    "user": {
      "login": "Midnighter",
      "id": 135653,
      "node_id": "MDQ6VXNlcjEzNTY1Mw==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/135653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Midnighter",
      "html_url": "https://github.com/Midnighter",
      "followers_url": "https://api.github.com/users/Midnighter/followers",
      "following_url": "https://api.github.com/users/Midnighter/following{/other_user}",
      "gists_url": "https://api.github.com/users/Midnighter/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Midnighter/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Midnighter/subscriptions",
      "organizations_url": "https://api.github.com/users/Midnighter/orgs",
      "repos_url": "https://api.github.com/users/Midnighter/repos",
      "events_url": "https://api.github.com/users/Midnighter/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Midnighter/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-05-20T08:34:19Z",
    "updated_at": "2014-05-20T08:34:19Z",
    "author_association": "NONE",
    "body": "@jreback I'm ashamed to admit that I didn't get around to trying out the new SQL support in master yet.\n\n@jorisvandenbossche My use case is a silly column that is of type string but actually only contains integers (or strings that represent integers I should say). So yes, it's not a big deal to convert them after the data frame is returned but I thought that adding the `dtype` argument would:\n1. Provide a clean interface when I want to mess with the data types manually (as in my situation).\n2. Mirror the `DataFrame` constructor.\n3. Avoid multiple conversion steps after column (array) creation.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/43619057",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6798#issuecomment-43619057",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6798",
    "id": 43619057,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNjE5MDU3",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-05-20T12:31:52Z",
    "updated_at": "2014-05-20T12:31:52Z",
    "author_association": "CONTRIBUTOR",
    "body": "@Midnighter \n\n1) you can check out `df.convert_objects(convert_numeric=True)` to do what you want; this is by definition a user initiated step; automatic conversion is for 'normal' cases; this is not.\n\n2) `dtype` in the DataFrame constructor is a single-dtype; not normally what you want; you are probably looking to specify a dict of colmumn->dtype.\n\n3) However, sql normally can provide good dtype hints (even better than `read_csv`). Dtype conversion always involves multiple steps (its actually more efficien that way as these are vectorized operations),\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/48196705",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6798#issuecomment-48196705",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6798",
    "id": 48196705,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ4MTk2NzA1",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-07-07T15:48:33Z",
    "updated_at": "2014-07-07T15:48:33Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jorisvandenbossche close?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/48205594",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6798#issuecomment-48205594",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6798",
    "id": 48205594,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ4MjA1NTk0",
    "user": {
      "login": "Midnighter",
      "id": 135653,
      "node_id": "MDQ6VXNlcjEzNTY1Mw==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/135653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Midnighter",
      "html_url": "https://github.com/Midnighter",
      "followers_url": "https://api.github.com/users/Midnighter/followers",
      "following_url": "https://api.github.com/users/Midnighter/following{/other_user}",
      "gists_url": "https://api.github.com/users/Midnighter/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Midnighter/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Midnighter/subscriptions",
      "organizations_url": "https://api.github.com/users/Midnighter/orgs",
      "repos_url": "https://api.github.com/users/Midnighter/repos",
      "events_url": "https://api.github.com/users/Midnighter/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Midnighter/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-07-07T16:55:21Z",
    "updated_at": "2014-07-07T16:55:21Z",
    "author_association": "NONE",
    "body": "1) That's really easy, thanks for the hint.\n\n2) I was sure that I did exactly that previously but I can't find the code any longer and can't seem to replicate it right now.\n\nIn general I'm very happy with the new SQL integration, great work!\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/327706800",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6798#issuecomment-327706800",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6798",
    "id": 327706800,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNzcwNjgwMA==",
    "user": {
      "login": "halfmoonhalf",
      "id": 10101515,
      "node_id": "MDQ6VXNlcjEwMTAxNTE1",
      "avatar_url": "https://avatars1.githubusercontent.com/u/10101515?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/halfmoonhalf",
      "html_url": "https://github.com/halfmoonhalf",
      "followers_url": "https://api.github.com/users/halfmoonhalf/followers",
      "following_url": "https://api.github.com/users/halfmoonhalf/following{/other_user}",
      "gists_url": "https://api.github.com/users/halfmoonhalf/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/halfmoonhalf/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/halfmoonhalf/subscriptions",
      "organizations_url": "https://api.github.com/users/halfmoonhalf/orgs",
      "repos_url": "https://api.github.com/users/halfmoonhalf/repos",
      "events_url": "https://api.github.com/users/halfmoonhalf/events{/privacy}",
      "received_events_url": "https://api.github.com/users/halfmoonhalf/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-09-07T07:02:41Z",
    "updated_at": "2017-09-07T07:02:41Z",
    "author_association": "NONE",
    "body": "say you have a MySQL table with tinyint column, when downloaded by pandas.read_sql_table(), the column's dtype is int64 not int8. This could be a case where a dtype argument for read_sql is useful. Am I right?\r\n\r\nsome details:\r\n\r\nin MySQL:\r\n  `status` tinyint(4) NOT NULL DEFAULT '0',    # <<--- tinyint\r\n\r\nin pandas:\r\n  df = pd.read_sql_table('xxx', engine)\r\n  print df.info()\r\n        ...\r\n        status        int64  # <<--- tinyint becomes int64\r\n        ...\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/335591498",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6798#issuecomment-335591498",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6798",
    "id": 335591498,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTU5MTQ5OA==",
    "user": {
      "login": "tobyjohnson",
      "id": 7631949,
      "node_id": "MDQ6VXNlcjc2MzE5NDk=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/7631949?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/tobyjohnson",
      "html_url": "https://github.com/tobyjohnson",
      "followers_url": "https://api.github.com/users/tobyjohnson/followers",
      "following_url": "https://api.github.com/users/tobyjohnson/following{/other_user}",
      "gists_url": "https://api.github.com/users/tobyjohnson/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/tobyjohnson/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/tobyjohnson/subscriptions",
      "organizations_url": "https://api.github.com/users/tobyjohnson/orgs",
      "repos_url": "https://api.github.com/users/tobyjohnson/repos",
      "events_url": "https://api.github.com/users/tobyjohnson/events{/privacy}",
      "received_events_url": "https://api.github.com/users/tobyjohnson/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-10T20:05:11Z",
    "updated_at": "2017-10-10T20:05:11Z",
    "author_association": "NONE",
    "body": "I have a compelling use case for this functionality.\r\n\r\nI have tables (in Impala, but I think same problem would arise in MySQL) with both columns of both integer and double type, all of which contain nulls.  I want to write a short python script that queries a table (the table name being a user provided argument) and writes the table contents to a flat file.  The intent is that the table schema might be unknown a priori to both the user and the script, so the script doesn't know the names of which columns are integer vs double.\r\n\r\nSo my code looks like:\r\n\r\nmydata = pd.read_sql('SELECT * FROM %s;' % sanitized_table_name, odbcConnection)\r\nmydata.to_csv(outputFile, sep = '|', index = False)\r\n\r\nBut this fails to do what I need because any columns in the SQL database that are actually integer, often contain nulls so get coerced to floats/doubles in the pandas dataframe.  Then when I call to_csv(), these get printed with spurious numeric precision (like \"123.0\").  This then confuses the downstream application (which is a reload into Impala) because they are not recognized as integer any more.\r\n\r\nI can't easily use the float_format argument when I call to_csv(), because my python script doesn't know which columns are meant to be integer and which columns are meant to be double.\r\n\r\nIf read_sql() took an argument like dtype=str, like read_csv() does, then my problem would be solved."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/348805735",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6798#issuecomment-348805735",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6798",
    "id": 348805735,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM0ODgwNTczNQ==",
    "user": {
      "login": "kodonnell",
      "id": 8204904,
      "node_id": "MDQ6VXNlcjgyMDQ5MDQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/8204904?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/kodonnell",
      "html_url": "https://github.com/kodonnell",
      "followers_url": "https://api.github.com/users/kodonnell/followers",
      "following_url": "https://api.github.com/users/kodonnell/following{/other_user}",
      "gists_url": "https://api.github.com/users/kodonnell/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/kodonnell/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/kodonnell/subscriptions",
      "organizations_url": "https://api.github.com/users/kodonnell/orgs",
      "repos_url": "https://api.github.com/users/kodonnell/repos",
      "events_url": "https://api.github.com/users/kodonnell/events{/privacy}",
      "received_events_url": "https://api.github.com/users/kodonnell/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-03T19:00:44Z",
    "updated_at": "2017-12-03T19:00:44Z",
    "author_association": "NONE",
    "body": "Seconding @halfmoonhalf - my use case involved hundreds of one-hot encoded columns (i.e. `0` or `1`), and it's a big memory burden to pull them in as int64s. If I remember rightly, there's a way to change such things in the cursor.\r\n\r\nWorkaround: iterated through in chunks, converting each chunk to correct dtype, then append, etc."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/348908123",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6798#issuecomment-348908123",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6798",
    "id": 348908123,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM0ODkwODEyMw==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-04T09:34:59Z",
    "updated_at": "2017-12-04T09:34:59Z",
    "author_association": "MEMBER",
    "body": "As I said elsewhere (https://github.com/pandas-dev/pandas/issues/13049#issuecomment-348192363), we would be happy to receive a contribution to make this better. (eg a `dtype` keyword for `read_sql`). \r\n\r\nBut also, this will not necessarily change memory problems, as this depends on the actual driver used, and pandas still gets the data from those drivers as python objects."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/348911137",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6798#issuecomment-348911137",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6798",
    "id": 348911137,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM0ODkxMTEzNw==",
    "user": {
      "login": "kodonnell",
      "id": 8204904,
      "node_id": "MDQ6VXNlcjgyMDQ5MDQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/8204904?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/kodonnell",
      "html_url": "https://github.com/kodonnell",
      "followers_url": "https://api.github.com/users/kodonnell/followers",
      "following_url": "https://api.github.com/users/kodonnell/following{/other_user}",
      "gists_url": "https://api.github.com/users/kodonnell/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/kodonnell/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/kodonnell/subscriptions",
      "organizations_url": "https://api.github.com/users/kodonnell/orgs",
      "repos_url": "https://api.github.com/users/kodonnell/repos",
      "events_url": "https://api.github.com/users/kodonnell/events{/privacy}",
      "received_events_url": "https://api.github.com/users/kodonnell/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-04T09:46:47Z",
    "updated_at": "2017-12-04T09:46:47Z",
    "author_association": "NONE",
    "body": "> But also, this will not necessarily change memory problems, as this depends on the actual driver used, and pandas still gets the data from those drivers as python objects.\r\n\r\nWith a naive implementation, yes. Though there are workarounds, e.g.\r\n\r\n- internally chunk, but convert each chunk to the correct type. Memory will only ever bloat by `1 / n_chunks` of what it would with a complete read\r\n- get more involved involved with drivers - e.g. you can specify the database type <-> python type mapping, or you could do some clever SQL `cast(blah as <dtype>)` sort of tricks. I wouldn't recommend this approach though, for maintenance etc.\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/458078744",
    "html_url": "https://github.com/pandas-dev/pandas/issues/6798#issuecomment-458078744",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/6798",
    "id": 458078744,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1ODA3ODc0NA==",
    "user": {
      "login": "konstantinmiller",
      "id": 2629945,
      "node_id": "MDQ6VXNlcjI2Mjk5NDU=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/2629945?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/konstantinmiller",
      "html_url": "https://github.com/konstantinmiller",
      "followers_url": "https://api.github.com/users/konstantinmiller/followers",
      "following_url": "https://api.github.com/users/konstantinmiller/following{/other_user}",
      "gists_url": "https://api.github.com/users/konstantinmiller/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/konstantinmiller/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/konstantinmiller/subscriptions",
      "organizations_url": "https://api.github.com/users/konstantinmiller/orgs",
      "repos_url": "https://api.github.com/users/konstantinmiller/repos",
      "events_url": "https://api.github.com/users/konstantinmiller/events{/privacy}",
      "received_events_url": "https://api.github.com/users/konstantinmiller/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-28T10:38:10Z",
    "updated_at": "2019-01-28T10:38:10Z",
    "author_association": "NONE",
    "body": "The problem that I have is that whenever integer columns that contains NULL's get converted to float you loose precision. However, simply adding a `dtype` parameter won't help here, as pandas can't represent NULL's in integer columns. However, if it would be possible to replace NULL's with some constant value before creating the `DataFrame`, and in addition specifying `dtype` would be cool :)\r\n\r\n[As a workaround it's of course also possible to `COALESCE` NULL's to a fixed constant.]"
  }
]
