[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/44483630",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7269#issuecomment-44483630",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7269",
    "id": 44483630,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NDgzNjMw",
    "user": {
      "login": "hayd",
      "id": 1931852,
      "node_id": "MDQ6VXNlcjE5MzE4NTI=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1931852?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hayd",
      "html_url": "https://github.com/hayd",
      "followers_url": "https://api.github.com/users/hayd/followers",
      "following_url": "https://api.github.com/users/hayd/following{/other_user}",
      "gists_url": "https://api.github.com/users/hayd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hayd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hayd/subscriptions",
      "organizations_url": "https://api.github.com/users/hayd/orgs",
      "repos_url": "https://api.github.com/users/hayd/repos",
      "events_url": "https://api.github.com/users/hayd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hayd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-05-29T01:04:09Z",
    "updated_at": "2014-05-29T01:04:09Z",
    "author_association": "CONTRIBUTOR",
    "body": "With %timeit I see extract being around twice as slow as match (and both match and extract are around the same times for multiple and single groups).\n\nCould you try with timeit and see if you can reproduce, the 150x one seems v. strange - I don't see that at all.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/48197480",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7269#issuecomment-48197480",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7269",
    "id": 48197480,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ4MTk3NDgw",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-07-07T15:54:02Z",
    "updated_at": "2014-07-07T15:54:02Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jhorowitz-coursera ok, will mark this an issue. pls investigate and see if you can find a reason/fix. thanks!\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/54741803",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7269#issuecomment-54741803",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7269",
    "id": 54741803,
    "node_id": "MDEyOklzc3VlQ29tbWVudDU0NzQxODAz",
    "user": {
      "login": "jtratner",
      "id": 1598379,
      "node_id": "MDQ6VXNlcjE1OTgzNzk=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1598379?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jtratner",
      "html_url": "https://github.com/jtratner",
      "followers_url": "https://api.github.com/users/jtratner/followers",
      "following_url": "https://api.github.com/users/jtratner/following{/other_user}",
      "gists_url": "https://api.github.com/users/jtratner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jtratner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jtratner/subscriptions",
      "organizations_url": "https://api.github.com/users/jtratner/orgs",
      "repos_url": "https://api.github.com/users/jtratner/repos",
      "events_url": "https://api.github.com/users/jtratner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jtratner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-09-07T09:24:21Z",
    "updated_at": "2014-09-07T09:32:05Z",
    "author_association": "CONTRIBUTOR",
    "body": "Okay, I took a look at this and played around with it.  I see ~150ms of difference between str.match and str.extract (and it's relatively consistent even with more tries). I'm also showing the timing for a small-ish change that closes the gap a little bit:\n\n``` python\nIn [20]: %timeit test.str.match(pattern2)\n10 loops, best of 3: 170 ms per loop\n\nIn [21]: %timeit test.str.extract(pattern2)\n10 loops, best of 3: 317 ms per loop\n\nIn [22]: %timeit -n try_except_str_extract2(test, pattern2)\n10 loops, best of 3: 265 ms per loop\n```\n\nAbout 30-60ms of difference is that `extract()` checks for string types, whereas `match()` uses `_na_wrap` instead (which boils down to a try/except vs. an isinstance check), so switching that gets you part of the way there (and I've submitted a PR to that effect).\n\nHowever, there's a really key difference between `match()` and `extract()`: match returns gibberish that you can't really use with other pandas functions (because tuples are considered a single object, rather than an array), whereas `extract()` gives you back an actual dataframe. The rest of the time lost is converting from tuple to list in the loop and there's not really a way around that.\n\n``` python\n>>> pattern2 = '.*some (.)(.).*'\n>>> test = pd.Series(['here is some sample text' for x in range(100000)])\n>>> test.str.match(pattern2)\n0     (s, a)\n1     (s, a)\n2     (s, a)\n3     (s, a)\n...\n99997    (s, a)\n99998    (s, a)\n99999    (s, a)\nLength: 100000, dtype: object\n>>> test.str.extract(pattern2)\n       0  1\n0      s  a\n1      s  a\n2      s  a\n3      s  a\n...   .. ..\n99997  s  a\n99998  s  a\n99999  s  a\n\n[100000 rows x 2 columns]\n```\n\nWhereas `DataFrame(test.str.match('.*some (.)(.).*'))` comes out as a single column of tuples - not very useful.\n\nThe current str.match behavior is very simple to copy out for yourself, it's essentially this:\n\n``` python\ndef match_text(ser, pattern):\n    regex = re.compile(pattern)\n    def f(x):\n        try:\n            m = regex.match(x)\n        except TypeError:\n            return np.nan\n        if m:\n            return m.groups()\n        else:\n            return  []\n    return ser._wrap_result(Series([f(val) for f in ser], index=ser.index))\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/54755892",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7269#issuecomment-54755892",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7269",
    "id": 54755892,
    "node_id": "MDEyOklzc3VlQ29tbWVudDU0NzU1ODky",
    "user": {
      "login": "jtratner",
      "id": 1598379,
      "node_id": "MDQ6VXNlcjE1OTgzNzk=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1598379?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jtratner",
      "html_url": "https://github.com/jtratner",
      "followers_url": "https://api.github.com/users/jtratner/followers",
      "following_url": "https://api.github.com/users/jtratner/following{/other_user}",
      "gists_url": "https://api.github.com/users/jtratner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jtratner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jtratner/subscriptions",
      "organizations_url": "https://api.github.com/users/jtratner/orgs",
      "repos_url": "https://api.github.com/users/jtratner/repos",
      "events_url": "https://api.github.com/users/jtratner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jtratner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-09-07T18:39:28Z",
    "updated_at": "2014-09-07T18:39:28Z",
    "author_association": "CONTRIBUTOR",
    "body": "I've played around with this quite a bit now.  What it really boils down to is that `extract()` adds another layer of type conversion in order to make the data more useful.  The only case where I see that deprecating `match()` over `extract()` is something like `myteststr.str.match(some_pattern).str.get(0)` and at that point the perf difference starts shrinking further because of the need to construct a new Series.\n\nI get a lot of variability when I profile this (e.g., the perf difference I saw with the `try/except` basically went away) and the majority of the time spent is in the regex library.\n\nOne thing that did come out of this: anchoring your text (i.e., using `'^'` at the start of your pattern) makes a very significant performance difference when not every row matches.  So if you're trying this out in production and seeing speed issues (and you want the behavior of `match()`) try adding a `^` to your pattern.\n\nFinally, `match()` isn't disappearing, it's just going to start returning `True` or `False` for each row, rather than an empty `[]` (no matches), `nan` (wrong type) or a `tuple` (found matches) for each row.\n"
  }
]
