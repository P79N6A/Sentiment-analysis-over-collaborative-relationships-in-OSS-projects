[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/260891224",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14669#issuecomment-260891224",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14669",
    "id": 260891224,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2MDg5MTIyNA==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-11-16T09:04:21Z",
    "updated_at": "2016-11-16T09:04:21Z",
    "author_association": "MEMBER",
    "body": "The `date` and `time` attributes return python `datetime.date` and `datetime.time` objects, while the other attributes return integers. This is certainly a reason that it is both slower and takes more memory.\n\nExample of memory usage (in MBs)\n\n```\nIn [144]: df.memory_usage(deep=True, index=False) / (1024**2)\nOut[144]: \ndata      0.668335\ntstamp    0.668335\ndtype: float64\n\nIn [145]: df['tstamp'].dt.date.memory_usage(deep=True, index=False) / (1024**2)\nOut[145]: 3.3416748046875\n\nIn [146]: df['tstamp'].dt.time.memory_usage(deep=True, index=False) / (1024**2)\nOut[146]: 4.010009765625\n\nIn [147]: df['tstamp'].dt.dayofyear.memory_usage(deep=True, index=False) / (1024**2)\nOut[147]: 0.6683349609375\n```\n\nSo you can see that the `datetime.date/time` objects take a lot more memory compared to the numpy integers or foats (up to almost 6 times as much memory). This easily explains the MemoryError you see since you only have 5 columns.\n\nSpeed-wise, the creation of the `datetime.date/time` objects is probably a reason for slowdown as well, although I am not sure all slowdown can be attributed to this. You are welcome to look into this.\n\nAnyway, if speed and memory is of concern, you better avoid `date` and `time` anyway, and you cannot perform vectorized operations anymore on those columns. Depending on your application, all information about the date and time is also available in the other attributes (day, month, hour, etc ..)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/260921268",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14669#issuecomment-260921268",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14669",
    "id": 260921268,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2MDkyMTI2OA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-11-16T11:20:28Z",
    "updated_at": "2016-11-16T11:20:28Z",
    "author_association": "CONTRIBUTOR",
    "body": "further to @jorisvandenbossche comments. One of the strengths of pandas is that data can be represented by a specific implementation with fast-path accessing for most operations, while retaining compat with python object if needed. This is true for datetime, timedelta, period, and category dtypes. (other dtypes map the interface directly to the implementation).\n\nWhat this means is that a user must be aware of the performance/memory tradeoffs when asking for python objects.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/261069038",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14669#issuecomment-261069038",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14669",
    "id": 261069038,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTA2OTAzOA==",
    "user": {
      "login": "dragonator4",
      "id": 8196363,
      "node_id": "MDQ6VXNlcjgxOTYzNjM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/8196363?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dragonator4",
      "html_url": "https://github.com/dragonator4",
      "followers_url": "https://api.github.com/users/dragonator4/followers",
      "following_url": "https://api.github.com/users/dragonator4/following{/other_user}",
      "gists_url": "https://api.github.com/users/dragonator4/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dragonator4/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dragonator4/subscriptions",
      "organizations_url": "https://api.github.com/users/dragonator4/orgs",
      "repos_url": "https://api.github.com/users/dragonator4/repos",
      "events_url": "https://api.github.com/users/dragonator4/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dragonator4/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-11-16T20:56:11Z",
    "updated_at": "2016-11-16T20:56:11Z",
    "author_association": "NONE",
    "body": "@jorisvandenbossche Then how is it that storing datetime together consumes just as much memory as storing the day of year? If datetime can be represented as ints, and floats, but still have a display format as YYYY-MM-DD HH:MM:SS, then similarly dates, if not also times, can be stored as ints and floats and displayed correctly.\n\n@jreback How much of an effort is it to build pandas equivalent for Python date and time types?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/261072107",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14669#issuecomment-261072107",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14669",
    "id": 261072107,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTA3MjEwNw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-11-16T21:07:53Z",
    "updated_at": "2016-11-16T21:07:53Z",
    "author_association": "CONTRIBUTOR",
    "body": "@dragonator4 you are missing the point. this already exists as `Timestamp` (which is a sub-class of datetime actually). It only instantiated when needed. If you are actually using `date` and `time` directly as python objects then you are doing it wrong. \n\n`Timestamp` is a performant replacement that is feature-full like `datetime.datetime` and performant like `np.datetime64`\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/261077912",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14669#issuecomment-261077912",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14669",
    "id": 261077912,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTA3NzkxMg==",
    "user": {
      "login": "dragonator4",
      "id": 8196363,
      "node_id": "MDQ6VXNlcjgxOTYzNjM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/8196363?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dragonator4",
      "html_url": "https://github.com/dragonator4",
      "followers_url": "https://api.github.com/users/dragonator4/followers",
      "following_url": "https://api.github.com/users/dragonator4/following{/other_user}",
      "gists_url": "https://api.github.com/users/dragonator4/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dragonator4/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dragonator4/subscriptions",
      "organizations_url": "https://api.github.com/users/dragonator4/orgs",
      "repos_url": "https://api.github.com/users/dragonator4/repos",
      "events_url": "https://api.github.com/users/dragonator4/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dragonator4/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-11-16T21:29:05Z",
    "updated_at": "2016-11-16T21:29:05Z",
    "author_association": "NONE",
    "body": "@jreback I have timestamped sensor data, and I need to group the data by day and sensor ID, and fit models on each group. Since the data spans more than a year, I need something robust to form the groups on. Date is perfect, but it has performance and memory drain, as we discussed. As a work around, I can form groups on year, and day of year. Doing so requires an extra step of recovering the date from year, and day of year. Can you recommend a better way?\n\nIdeally, I would like to do this:\n\n```\ndf['date'] = df['tstamp'].dt.date\nres = df.groupby(['sens_id', 'date']).apply(modeler)\n```\n\nNow, I would do this (for lack of something better):\n\n```\ndf['year'], df['doy'] = df['tstamp'].dt.year, df['tstamp'].dt.dayofyear\nres = df.groupby(['sens_id', 'year', 'doy']).apply(modeler)\n```\n\nSince the gap in performance is so huge, the latter is actually faster than the former, despite the extra computations. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/261080259",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14669#issuecomment-261080259",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14669",
    "id": 261080259,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTA4MDI1OQ==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-11-16T21:38:01Z",
    "updated_at": "2016-11-16T21:46:06Z",
    "author_association": "CONTRIBUTOR",
    "body": "@dragonator4 looks like you could round your `tstamp`. `df['date'] = df['tstamp'].dt.round('d')` and then group by that and sensor ID.\n\nIt'd be quite a bit of work to support `date` and `time`, and in many cases (like this) a suitably rounded datetime does the job.\n\nEDIT: mmm, you need to round down though. Pretty sure there's a way to do this. Yeah, `df['date'] = df['tstamp'].dt.floor('d')`\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/261083201",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14669#issuecomment-261083201",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14669",
    "id": 261083201,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTA4MzIwMQ==",
    "user": {
      "login": "dragonator4",
      "id": 8196363,
      "node_id": "MDQ6VXNlcjgxOTYzNjM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/8196363?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dragonator4",
      "html_url": "https://github.com/dragonator4",
      "followers_url": "https://api.github.com/users/dragonator4/followers",
      "following_url": "https://api.github.com/users/dragonator4/following{/other_user}",
      "gists_url": "https://api.github.com/users/dragonator4/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dragonator4/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dragonator4/subscriptions",
      "organizations_url": "https://api.github.com/users/dragonator4/orgs",
      "repos_url": "https://api.github.com/users/dragonator4/repos",
      "events_url": "https://api.github.com/users/dragonator4/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dragonator4/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-11-16T21:49:21Z",
    "updated_at": "2016-11-16T21:49:21Z",
    "author_association": "NONE",
    "body": "@TomAugspurger Thanks for that trick. I'll perhaps use `floor`. `round` may round to the next day if the time is after noon..?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/261083452",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14669#issuecomment-261083452",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14669",
    "id": 261083452,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTA4MzQ1Mg==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-11-16T21:50:28Z",
    "updated_at": "2016-11-16T21:50:28Z",
    "author_association": "MEMBER",
    "body": "There is also `normalize` to get only the date part (not sure about what would be better performance wise, normalize or floor, you can test):\n\n```\nIn [14]: s = pd.Series(pd.date_range('2012-01-01', freq='8h', periods=10))\n\nIn [15]: s\nOut[15]: \n0   2012-01-01 00:00:00\n1   2012-01-01 08:00:00\n2   2012-01-01 16:00:00\n3   2012-01-02 00:00:00\n4   2012-01-02 08:00:00\n5   2012-01-02 16:00:00\n6   2012-01-03 00:00:00\n7   2012-01-03 08:00:00\n8   2012-01-03 16:00:00\n9   2012-01-04 00:00:00\ndtype: datetime64[ns]\n\nIn [17]: s.dt.normalize()\nOut[17]: \n0   2012-01-01\n1   2012-01-01\n2   2012-01-01\n3   2012-01-02\n4   2012-01-02\n5   2012-01-02\n6   2012-01-03\n7   2012-01-03\n8   2012-01-03\n9   2012-01-04\ndtype: datetime64[ns]\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/261088992",
    "html_url": "https://github.com/pandas-dev/pandas/issues/14669#issuecomment-261088992",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/14669",
    "id": 261088992,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTA4ODk5Mg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-11-16T22:12:15Z",
    "updated_at": "2016-11-16T22:12:15Z",
    "author_association": "CONTRIBUTOR",
    "body": "I seriously doubt the _grouping_ part is actually slowing you down. For sure its the `.apply` which IS executed in python space.\n\nIn any event you can simply do\n\n`df.groupby(['sens_id',  pd.Grouper(key='date', freq='D')]).apply(modeler)`\n\nfor proper semantics or as @TomAugspurger  and @jorisvandenbossche suggest this is de-facto equivalent to rounding.\n"
  }
]
