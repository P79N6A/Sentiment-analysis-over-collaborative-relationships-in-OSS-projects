[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/22373864",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-22373864",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 22373864,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIyMzczODY0",
    "user": {
      "login": "jtratner",
      "id": 1598379,
      "node_id": "MDQ6VXNlcjE1OTgzNzk=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1598379?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jtratner",
      "html_url": "https://github.com/jtratner",
      "followers_url": "https://api.github.com/users/jtratner/followers",
      "following_url": "https://api.github.com/users/jtratner/following{/other_user}",
      "gists_url": "https://api.github.com/users/jtratner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jtratner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jtratner/subscriptions",
      "organizations_url": "https://api.github.com/users/jtratner/orgs",
      "repos_url": "https://api.github.com/users/jtratner/repos",
      "events_url": "https://api.github.com/users/jtratner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jtratner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-08-09T03:43:34Z",
    "updated_at": "2013-08-09T03:43:34Z",
    "author_association": "CONTRIBUTOR",
    "body": "I agree this is a frustrating issue (and if you get a big enough file, you can actually run out of memory entirely). I've had the thought in the back of my head that we should try to use [PyExcelerate](https://github.com/kz26/PyExcelerate) - which should be faster and use much less memory\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/22403995",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-22403995",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 22403995,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIyNDAzOTk1",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-08-09T15:58:38Z",
    "updated_at": "2013-08-09T15:58:38Z",
    "author_association": "CONTRIBUTOR",
    "body": "these use `xlwt` for writing, an option would be to use `openpyxl` for writing `xls` (its used by default for `.xlsx`), and using `optimize_write=True` in the Workbook constructor. I don't know why this is not used (maybe more functionaily exposes by `xlwt`?). \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/25273787",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-25273787",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 25273787,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI1MjczNzg3",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-09-27T20:14:21Z",
    "updated_at": "2013-09-27T20:14:21Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jtratner close this as a result of #4542 ?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/25278734",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-25278734",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 25278734,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI1Mjc4NzM0",
    "user": {
      "login": "jtratner",
      "id": 1598379,
      "node_id": "MDQ6VXNlcjE1OTgzNzk=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1598379?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jtratner",
      "html_url": "https://github.com/jtratner",
      "followers_url": "https://api.github.com/users/jtratner/followers",
      "following_url": "https://api.github.com/users/jtratner/following{/other_user}",
      "gists_url": "https://api.github.com/users/jtratner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jtratner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jtratner/subscriptions",
      "organizations_url": "https://api.github.com/users/jtratner/orgs",
      "repos_url": "https://api.github.com/users/jtratner/repos",
      "events_url": "https://api.github.com/users/jtratner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jtratner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-09-27T21:30:30Z",
    "updated_at": "2013-09-27T21:30:30Z",
    "author_association": "CONTRIBUTOR",
    "body": "Yes, xlsxwriter is likely faster (and may become even faster in the\nfuture). PyExcelerate may also be added. (cheers to @jmcnamara for this)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/25298490",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-25298490",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 25298490,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI1Mjk4NDkw",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-09-28T13:52:15Z",
    "updated_at": "2013-09-28T13:52:15Z",
    "author_association": "CONTRIBUTOR",
    "body": "closed by #4542\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/229472454",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-229472454",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 229472454,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIyOTQ3MjQ1NA==",
    "user": {
      "login": "brydavis",
      "id": 11343762,
      "node_id": "MDQ6VXNlcjExMzQzNzYy",
      "avatar_url": "https://avatars0.githubusercontent.com/u/11343762?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/brydavis",
      "html_url": "https://github.com/brydavis",
      "followers_url": "https://api.github.com/users/brydavis/followers",
      "following_url": "https://api.github.com/users/brydavis/following{/other_user}",
      "gists_url": "https://api.github.com/users/brydavis/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/brydavis/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/brydavis/subscriptions",
      "organizations_url": "https://api.github.com/users/brydavis/orgs",
      "repos_url": "https://api.github.com/users/brydavis/repos",
      "events_url": "https://api.github.com/users/brydavis/events{/privacy}",
      "received_events_url": "https://api.github.com/users/brydavis/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-06-29T20:06:54Z",
    "updated_at": "2016-06-29T20:06:54Z",
    "author_association": "NONE",
    "body": "Update, default writer for `df.to_excel(...)` still **super slow** for large data.\n\nFinally gave up and used `df.to_csv(...)`.\n\nWorked for my purposes.  Thanks!\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/289037284",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-289037284",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 289037284,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI4OTAzNzI4NA==",
    "user": {
      "login": "sancau",
      "id": 16306443,
      "node_id": "MDQ6VXNlcjE2MzA2NDQz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/16306443?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sancau",
      "html_url": "https://github.com/sancau",
      "followers_url": "https://api.github.com/users/sancau/followers",
      "following_url": "https://api.github.com/users/sancau/following{/other_user}",
      "gists_url": "https://api.github.com/users/sancau/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sancau/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sancau/subscriptions",
      "organizations_url": "https://api.github.com/users/sancau/orgs",
      "repos_url": "https://api.github.com/users/sancau/repos",
      "events_url": "https://api.github.com/users/sancau/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sancau/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-03-24T14:27:16Z",
    "updated_at": "2017-03-24T14:27:16Z",
    "author_association": "NONE",
    "body": "Using [PyExcelerate ](https://github.com/kz26/PyExcelerate) helps a lot when it comes to dumping lots of data. \r\n\r\nWith a DataFrame (120000, 120)  of real mixed data (not ones and zeros: )) it took 4 minutes to write down an  .xlsx\r\n\r\nAnother test I did was a (189121, 27)  DF that took only 2min 33s (.xlsx). Also tested Pandas to_excel() and it took 5min 23s. PyExcelerate was more then 2 times faster.\r\n\r\nI also noticed that it consumes much less memory during the process\r\n\r\nThough PyExcelerate might require some manual data preparation in some cases (NaNs NaTs and so on)\r\nPersonaly, I faced an error with a empty value in a datetime column and had to manualy fix that.\r\nAnyways if one needs a bulk excel dump PyExcelerate is a way to go. Cheers for its authors!\r\n\r\nFor trivial cases I use something like this and it works fine:\r\n\r\n```python\r\nfrom pyexcelerate import Workbook\r\n\r\ndef df_to_excel(df, path, sheet_name='Sheet 1'):\r\n    data = [df.columns.tolist(), ] + df.values.tolist()\r\n    wb = Workbook()\r\n    wb.new_sheet(sheet_name, data=data)\r\n    wb.save(path)\r\n```\r\n "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/289038901",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-289038901",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 289038901,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI4OTAzODkwMQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-03-24T14:32:33Z",
    "updated_at": "2017-03-24T14:32:33Z",
    "author_association": "CONTRIBUTOR",
    "body": "@sancau it you would like to add this to the supported engines would be fine (most of the work would be making sure dtypes are correct and round-trippable)."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317075767",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-317075767",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 317075767,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzA3NTc2Nw==",
    "user": {
      "login": "raffam",
      "id": 1469713,
      "node_id": "MDQ6VXNlcjE0Njk3MTM=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1469713?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/raffam",
      "html_url": "https://github.com/raffam",
      "followers_url": "https://api.github.com/users/raffam/followers",
      "following_url": "https://api.github.com/users/raffam/following{/other_user}",
      "gists_url": "https://api.github.com/users/raffam/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/raffam/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/raffam/subscriptions",
      "organizations_url": "https://api.github.com/users/raffam/orgs",
      "repos_url": "https://api.github.com/users/raffam/repos",
      "events_url": "https://api.github.com/users/raffam/events{/privacy}",
      "received_events_url": "https://api.github.com/users/raffam/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-21T18:20:27Z",
    "updated_at": "2017-07-21T18:20:27Z",
    "author_association": "NONE",
    "body": "Is there any update on this?\r\n`xls` does not support more than 255 columns, while saving in `xlsx` in pandas is **really** slow\r\nI tried using pyexcelerate, but that requires to copy the entire pandas DataFrame to a multi-dimension list in memory\r\nIs there any plan to support `pyexcelerate` natively, for example?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317095373",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-317095373",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 317095373,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzA5NTM3Mw==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-21T19:45:40Z",
    "updated_at": "2017-07-21T19:45:40Z",
    "author_association": "MEMBER",
    "body": "> Is there any update on this?\r\n\r\nUnfortunately, no AFAIK :cry: \r\n\r\n> Is there any plan to support pyexcelerate natively, for example?\r\n\r\nJudging from the comment from @jreback , we would certainly be happy with supporting it, but the PR needs to be done right for it to be incorporated.  If you would like to jumpstart that effort, go for it!"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317177336",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-317177336",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 317177336,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzE3NzMzNg==",
    "user": {
      "login": "raffam",
      "id": 1469713,
      "node_id": "MDQ6VXNlcjE0Njk3MTM=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1469713?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/raffam",
      "html_url": "https://github.com/raffam",
      "followers_url": "https://api.github.com/users/raffam/followers",
      "following_url": "https://api.github.com/users/raffam/following{/other_user}",
      "gists_url": "https://api.github.com/users/raffam/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/raffam/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/raffam/subscriptions",
      "organizations_url": "https://api.github.com/users/raffam/orgs",
      "repos_url": "https://api.github.com/users/raffam/repos",
      "events_url": "https://api.github.com/users/raffam/events{/privacy}",
      "received_events_url": "https://api.github.com/users/raffam/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-22T11:29:07Z",
    "updated_at": "2017-07-22T11:29:07Z",
    "author_association": "NONE",
    "body": "I wouldn't even know where to start :("
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317203455",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-317203455",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 317203455,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzIwMzQ1NQ==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-22T18:59:06Z",
    "updated_at": "2017-07-22T18:59:58Z",
    "author_association": "MEMBER",
    "body": "> Though PyExcelerate might require some manual data preparation in some cases (NaNs NaTs and so on) Personaly, I faced an error with a empty value in a datetime column and had to manualy fix that.\r\n\r\n@sancau @jreback : this makes me skeptical about performance because data preparation is very important for us to ensure round-trippability.  I think this might be why we've had issues implementing this."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317203565",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-317203565",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 317203565,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzIwMzU2NQ==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-22T19:00:34Z",
    "updated_at": "2017-07-22T19:00:34Z",
    "author_association": "MEMBER",
    "body": "I'll re-open for now, just so that people know we have this on our radar."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/317203744",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-317203744",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 317203744,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzIwMzc0NA==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-22T19:03:20Z",
    "updated_at": "2017-07-22T19:05:26Z",
    "author_association": "MEMBER",
    "body": "> I tried using pyexcelerate, but that requires to copy the entire pandas DataFrame to a multi-dimension list in memory Is there any plan to support pyexcelerate natively, for example?\r\n\r\nFor us to avoid the in-memory issue, you would need to be able to write with `pyexcerlate` in chunks.  As your Excel code is largely in Python, it would be otherwise difficult to avoid that problem.\r\n\r\n@raffam : do you know if such functionality is possible?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/321509496",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-321509496",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 321509496,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMTUwOTQ5Ng==",
    "user": {
      "login": "raffam",
      "id": 1469713,
      "node_id": "MDQ6VXNlcjE0Njk3MTM=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1469713?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/raffam",
      "html_url": "https://github.com/raffam",
      "followers_url": "https://api.github.com/users/raffam/followers",
      "following_url": "https://api.github.com/users/raffam/following{/other_user}",
      "gists_url": "https://api.github.com/users/raffam/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/raffam/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/raffam/subscriptions",
      "organizations_url": "https://api.github.com/users/raffam/orgs",
      "repos_url": "https://api.github.com/users/raffam/repos",
      "events_url": "https://api.github.com/users/raffam/events{/privacy}",
      "received_events_url": "https://api.github.com/users/raffam/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-10T10:07:17Z",
    "updated_at": "2017-08-10T10:08:30Z",
    "author_association": "NONE",
    "body": "@gfyoung I don't knkow. What do you mean exactly by \"writing in chunks\"? The way to write an xlsx file with pyexcelerate seems to be like this\r\n\r\n```\r\nfrom pyexcelerate import Workbook\r\n\r\ndata = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] # data is a 2D array\r\n\r\nwb = Workbook()\r\nwb.new_sheet(\"sheet name\", data=data)\r\nwb.save(\"output.xlsx\")\r\n\r\n```\r\nThis is more or less what I had done (I have switched to CSV since then). So I too converted the pandas Dataframe to a multi-dimensional array and passed that to pyexcelerate. I don't have deep knowledge of pandas' insight to assess if it would be possible to avoid that passage"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/321583398",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-321583398",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 321583398,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMTU4MzM5OA==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-10T15:19:16Z",
    "updated_at": "2017-08-10T15:19:16Z",
    "author_association": "MEMBER",
    "body": "@raffam : What I mean by that is that instead of writing the entire `DataFrame` (and having to make an entire copy of it in memory as you mentioned above), you would take *a portion of* the `DataFrame` on each iteration and write it to your Excel file."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/321611292",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-321611292",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 321611292,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMTYxMTI5Mg==",
    "user": {
      "login": "jmcnamara",
      "id": 94267,
      "node_id": "MDQ6VXNlcjk0MjY3",
      "avatar_url": "https://avatars3.githubusercontent.com/u/94267?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jmcnamara",
      "html_url": "https://github.com/jmcnamara",
      "followers_url": "https://api.github.com/users/jmcnamara/followers",
      "following_url": "https://api.github.com/users/jmcnamara/following{/other_user}",
      "gists_url": "https://api.github.com/users/jmcnamara/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jmcnamara/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jmcnamara/subscriptions",
      "organizations_url": "https://api.github.com/users/jmcnamara/orgs",
      "repos_url": "https://api.github.com/users/jmcnamara/repos",
      "events_url": "https://api.github.com/users/jmcnamara/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jmcnamara/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-10T16:57:02Z",
    "updated_at": "2017-08-10T16:57:02Z",
    "author_association": "CONTRIBUTOR",
    "body": "It is probably worth pointing out that according to the [benchmark ](https://github.com/kz26/PyExcelerate)in the pyexcelerate docs it is only 2x faster than XlsxWriter. Also openpyxl with lxml is probably as fast as xlsxwriter now.\r\n\r\nSo although pyexcelerate may be faster it isn't going to get the end user anywhere close to CSV speed due to the verbose nature of the xlsx format and the fact that it needs to be zipped.  Ever the C version of XlsxWriter ([libxlsxwriter](https://github.com/jmcnamara/libxlsxwriter)) is only about 10x faster than the Python version. \r\n\r\nSo it is questionable if any of this is worth the effort.\r\n\r\nIf the Pandas xlsx writer was restructured to write the data row by row then I might be able to optimise XlsxWriter up to the pyexcelerate speed. But again I'm not sure if it is worth the effort.\r\n\r\nFinal note, I've seen a 10x increase in speed running long XlsxWriter programs under pypy.\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/321685916",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-321685916",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 321685916,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMTY4NTkxNg==",
    "user": {
      "login": "raffam",
      "id": 1469713,
      "node_id": "MDQ6VXNlcjE0Njk3MTM=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1469713?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/raffam",
      "html_url": "https://github.com/raffam",
      "followers_url": "https://api.github.com/users/raffam/followers",
      "following_url": "https://api.github.com/users/raffam/following{/other_user}",
      "gists_url": "https://api.github.com/users/raffam/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/raffam/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/raffam/subscriptions",
      "organizations_url": "https://api.github.com/users/raffam/orgs",
      "repos_url": "https://api.github.com/users/raffam/repos",
      "events_url": "https://api.github.com/users/raffam/events{/privacy}",
      "received_events_url": "https://api.github.com/users/raffam/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-10T22:04:07Z",
    "updated_at": "2017-08-10T22:45:49Z",
    "author_association": "NONE",
    "body": "I have made a rapid testcase.\r\nI built two functions that save a pandas DataFrame to Excel using pyexcelerate. The first function iterates over rows, the second function iterates over columns\r\nThe test is run against 2 matrices: one with lots of rows, and the other one with lots of columns. \r\nIt's highly likely that my code can be optimized further. \r\nAnyway the results of the second implementation are consistent with what declared on pyexcelerate doc: approximately 2 times faster in any case.\r\n\r\nThe code was run under the Intel distribution of Python 3.5.2. Similar results are obtained under \"normal\" CPython 3.6.2\r\n\r\n```\r\nFRAME WITH LOTS OF ROWS\r\nto_excel took 2.97 secs\r\npyexcelerate1 took 1.94 secs\r\n34.68% faster than base time\r\npyexcelerate2 took 1.73 secs\r\n41.75% faster than base time\r\nFRAME WITH LOTS OF COLUMNS\r\nto_excel took 2.13 secs\r\npyexcelerate1 took 1.15 secs\r\n46.01% faster than base time\r\npyexcelerate2 took 1.06 secs\r\n50.23% faster than base time\r\n```\r\n\r\nHere is the code\r\n\r\n```\r\nfrom pyexcelerate import Workbook, Range\r\nimport pandas as pd\r\nimport timeit\r\nimport math\r\n\r\ndef toPandasExcel(file, frame):\r\n    start = timeit.default_timer()\r\n    frame.to_excel(file, index=False, header=False)\r\n    end = timeit.default_timer()\r\n    delta = round(end-start,2)\r\n    print(\"to_excel took \"+str(delta)+\" secs\")\r\n    return delta\r\n\r\n# Iterate over rows\r\ndef toExcelerate1(file, frame):\r\n    start = timeit.default_timer()\r\n    wb = Workbook()\r\n    ws = wb.new_sheet(\"test\")    \r\n    col_num = frame.shape[1]\r\n    row_num = 1\r\n    for row_tup in frame.itertuples(name=None, index=False):\r\n        ws.range((row_num,1), (row_num,col_num)).value = [[*row_tup]]\r\n        row_num += 1        \r\n    wb.save(file)\r\n    end = timeit.default_timer()\r\n    delta = round(end-start,2)\r\n    print(\"pyexcelerate1 took \"+str(delta)+\" secs\")\r\n    return delta\r\n\r\n# Iterate over columns\r\ndef toExcelerate2(file, frame):\r\n    start_time = timeit.default_timer()\r\n    wb = Workbook()\r\n    ws = wb.new_sheet(\"test\")    \r\n    row_num = frame.shape[0]    \r\n    col_num = 1\r\n    for col_name, col_series in frame.iteritems():\r\n        ws.range((1,col_num), (row_num,col_num)).value = [[x] for x in col_series]\r\n        col_num += 1        \r\n    wb.save(file)\r\n    end_time = timeit.default_timer()\r\n    delta = round(end_time-start_time,2)\r\n    print(\"pyexcelerate2 took \"+str(delta)+\" secs\")\r\n    return delta\r\n    \r\ndef perf(base, eps):\r\n    perc = ((base-eps)/base)*100\r\n    perc = round(perc, 2)\r\n    print(str(perc)+\"% faster than base time\")\r\n    \r\nprint(\"FRAME WITH LOTS OF ROWS\")\r\nsize = 50000\r\ndic = {'a':[50]*size, 'b':[1]*size, 'c':['hi']*size}\r\n#print(dic)\r\nframe_rows = pd.DataFrame(dic)\r\ndel dic\r\nbase = toPandasExcel(\"rows_pandas.xlsx\", frame_rows)\r\ne1 = toExcelerate1(\"rows_pyexcelerate1.xlsx\", frame_rows)\r\nperf(base,e1)\r\ne2 = toExcelerate2(\"rows_pyexcelerate2.xlsx\", frame_rows)\r\nperf(base,e2)\r\n\r\nprint(\"FRAME WITH LOTS OF COLUMNS\")\r\ndic = dict()\r\nfor x in range(10000):\r\n    dic.update({\"A\"+str(x):['c']*5})\r\nframe_cols = pd.DataFrame(dic)\r\ndel dic\r\nbase = toPandasExcel(\"cols_pandas.xlsx\", frame_cols)\r\ne1 = toExcelerate1(\"cols_pyexcelerate1.xlsx\", frame_cols)\r\nperf(base,e1)\r\ne2 = toExcelerate2(\"cols_pyexcelerate2.xlsx\", frame_cols)\r\nperf(base,e2)\r\n```\r\n \r\nEDIT: it was not a fair comparison since to_excel wrote indexes and headers. Now it is a fair comparison\r\nEDIT2: performance improvements"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/322026636",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-322026636",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 322026636,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjAyNjYzNg==",
    "user": {
      "login": "raffam",
      "id": 1469713,
      "node_id": "MDQ6VXNlcjE0Njk3MTM=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1469713?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/raffam",
      "html_url": "https://github.com/raffam",
      "followers_url": "https://api.github.com/users/raffam/followers",
      "following_url": "https://api.github.com/users/raffam/following{/other_user}",
      "gists_url": "https://api.github.com/users/raffam/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/raffam/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/raffam/subscriptions",
      "organizations_url": "https://api.github.com/users/raffam/orgs",
      "repos_url": "https://api.github.com/users/raffam/repos",
      "events_url": "https://api.github.com/users/raffam/events{/privacy}",
      "received_events_url": "https://api.github.com/users/raffam/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-13T07:25:04Z",
    "updated_at": "2017-08-13T07:25:04Z",
    "author_association": "NONE",
    "body": "@gfyoung would one of the 2 implementations be ok?\r\nI don't think is possible to actually \"write\" the Excel file in chunks, since as it is already been said, it needs to be compressed\r\nIt may be possible to \"build\" the precursor data structure in chunks, so you effectively has 2 copy of the dataframe in memory (one as pandas DataFrame, one as pyexcelerate Workbook) instead of three (pandas, pyexcelerate and the temporary 2-dimensional array you need if you build the pyexcelerate Workbook in one step)"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/322027823",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-322027823",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 322027823,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjAyNzgyMw==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-13T07:58:22Z",
    "updated_at": "2017-08-13T07:58:22Z",
    "author_association": "MEMBER",
    "body": "@raffam : Hmm...your timing results are encouraging but not convincing enough.  Can you try with even larger sizes (think millions ðŸ˜‰ ) ?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/322031413",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-322031413",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 322031413,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjAzMTQxMw==",
    "user": {
      "login": "raffam",
      "id": 1469713,
      "node_id": "MDQ6VXNlcjE0Njk3MTM=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1469713?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/raffam",
      "html_url": "https://github.com/raffam",
      "followers_url": "https://api.github.com/users/raffam/followers",
      "following_url": "https://api.github.com/users/raffam/following{/other_user}",
      "gists_url": "https://api.github.com/users/raffam/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/raffam/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/raffam/subscriptions",
      "organizations_url": "https://api.github.com/users/raffam/orgs",
      "repos_url": "https://api.github.com/users/raffam/repos",
      "events_url": "https://api.github.com/users/raffam/events{/privacy}",
      "received_events_url": "https://api.github.com/users/raffam/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-13T09:26:31Z",
    "updated_at": "2017-08-13T09:26:31Z",
    "author_association": "NONE",
    "body": "The [limits](https://support.office.com/en-us/article/Excel-specifications-and-limits-1672b34d-7043-467e-8e27-269d656771c3) are 1,048,576 rows by 16,384 columns"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/322035236",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-322035236",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 322035236,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjAzNTIzNg==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-13T11:00:45Z",
    "updated_at": "2017-08-13T11:00:45Z",
    "author_association": "MEMBER",
    "body": "@raffam : Right, so you can test with WAY MORE than 50,000 rows is my point."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/322719695",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-322719695",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 322719695,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjcxOTY5NQ==",
    "user": {
      "login": "raffam",
      "id": 1469713,
      "node_id": "MDQ6VXNlcjE0Njk3MTM=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1469713?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/raffam",
      "html_url": "https://github.com/raffam",
      "followers_url": "https://api.github.com/users/raffam/followers",
      "following_url": "https://api.github.com/users/raffam/following{/other_user}",
      "gists_url": "https://api.github.com/users/raffam/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/raffam/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/raffam/subscriptions",
      "organizations_url": "https://api.github.com/users/raffam/orgs",
      "repos_url": "https://api.github.com/users/raffam/repos",
      "events_url": "https://api.github.com/users/raffam/events{/privacy}",
      "received_events_url": "https://api.github.com/users/raffam/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-16T09:42:27Z",
    "updated_at": "2017-08-16T09:42:27Z",
    "author_association": "NONE",
    "body": "I understand, but unfortunately my PC stalls with very high size of the matrix :(\r\nHere is the code I have written in case someone wants to test it:\r\n\r\n```\r\nfrom pyexcelerate import Workbook, Range\r\nimport pandas as pd\r\nimport timeit\r\nimport math\r\nimport numpy as np\r\n\r\ndef toPandasExcel(file, frame):\r\n    start = timeit.default_timer()\r\n    frame.to_excel(file, index=False, header=False)\r\n    end = timeit.default_timer()\r\n    delta = round(end-start,2)\r\n    print(\"to_excel took \"+str(delta)+\" secs\")\r\n    return delta\r\n\r\n# Iterate over rows\r\ndef toExcelerate1(file, frame):\r\n    start = timeit.default_timer()\r\n    wb = Workbook()\r\n    ws = wb.new_sheet(\"test\")    \r\n    col_num = frame.shape[1]\r\n    row_num = 1\r\n    for row_tup in frame.itertuples(name=None, index=False):\r\n        ws.range((row_num,1), (row_num,col_num)).value = [[*row_tup]]\r\n        row_num += 1        \r\n    wb.save(file)\r\n    end = timeit.default_timer()\r\n    delta = round(end-start,2)\r\n    print(\"pyexcelerate1 took \"+str(delta)+\" secs\")\r\n    return delta\r\n\r\n# Iterate over columns\r\ndef toExcelerate2(file, frame):\r\n    start_time = timeit.default_timer()\r\n    wb = Workbook()\r\n    ws = wb.new_sheet(\"test\")    \r\n    row_num = frame.shape[0]    \r\n    col_num = 1\r\n    for col_name, col_series in frame.iteritems():\r\n        ws.range((1,col_num), (row_num,col_num)).value = list(map(lambda a:[a],col_series))\r\n        col_num += 1        \r\n    wb.save(file)\r\n    end_time = timeit.default_timer()\r\n    delta = round(end_time-start_time,2)\r\n    print(\"pyexcelerate2 took \"+str(delta)+\" secs\")\r\n    return delta\r\n    \r\n# Iterate over columns\r\ndef toExcelerate3(file, frame):\r\n    start_time = timeit.default_timer()\r\n    wb = Workbook()\r\n    ws = wb.new_sheet(\"test\")    \r\n    row_num = frame.shape[0]    \r\n    col_num = frame.shape[1]\r\n    ws.range((1,1), (row_num,col_num)).value = frame.values.tolist()\r\n    wb.save(file)\r\n    end_time = timeit.default_timer()\r\n    delta = round(end_time-start_time,2)\r\n    print(\"pyexcelerate3 took \"+str(delta)+\" secs\")\r\n    return delta\r\n    \r\ndef perf(base, eps):\r\n    perc = (base-eps)/base\r\n    print(\"{0:.2%} over base time\".format(perc))\r\n    \r\nprint(\"BUILDING DATAFRAME\")\r\nframe = pd.DataFrame()\r\nrows = int(math.pow(10,5))\r\ncols = 5000\r\ndic = dict()\r\nfor x in range(cols):\r\n    frame[str(x)] = pd.Series(np.random.randn(rows))\r\n\r\nprint(\"to_excel()\")\r\nbase = toPandasExcel(\"pandas.xlsx\", frame)\r\nprint(\"pyexcelerate1\")\r\ne1 = toExcelerate1(\"pyexcelerate1.xlsx\", frame)\r\nperf(base,e1)\r\nprint(\"pyexcelerate2\")\r\ne2 = toExcelerate2(\"pyexcelerate2.xlsx\", frame)\r\nperf(base,e2)\r\nprint(\"pyexcelerate3\")\r\ne3 = toExcelerate3(\"pyexcelerate3.xlsx\", frame)\r\nperf(base,e3)\r\n```\r\n    \r\n\r\n\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/322724235",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-322724235",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 322724235,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjcyNDIzNQ==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-16T10:02:11Z",
    "updated_at": "2017-08-16T10:02:11Z",
    "author_association": "MEMBER",
    "body": "@raffam : Thanks for this!  This will be very helpful."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/371784059",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-371784059",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 371784059,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM3MTc4NDA1OQ==",
    "user": {
      "login": "cryptotvync",
      "id": 35772357,
      "node_id": "MDQ6VXNlcjM1NzcyMzU3",
      "avatar_url": "https://avatars1.githubusercontent.com/u/35772357?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cryptotvync",
      "html_url": "https://github.com/cryptotvync",
      "followers_url": "https://api.github.com/users/cryptotvync/followers",
      "following_url": "https://api.github.com/users/cryptotvync/following{/other_user}",
      "gists_url": "https://api.github.com/users/cryptotvync/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cryptotvync/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cryptotvync/subscriptions",
      "organizations_url": "https://api.github.com/users/cryptotvync/orgs",
      "repos_url": "https://api.github.com/users/cryptotvync/repos",
      "events_url": "https://api.github.com/users/cryptotvync/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cryptotvync/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-03-09T11:09:59Z",
    "updated_at": "2018-03-09T11:09:59Z",
    "author_association": "NONE",
    "body": "Used toExcelerate3 function and defaults xlsx function to write dataframe 333243*34 to file. Results:\r\nto_excel (xlsx) default: 1360 seconds\r\ntoExcelerate3: 773 seconds"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/418496187",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-418496187",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 418496187,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxODQ5NjE4Nw==",
    "user": {
      "login": "mapa17",
      "id": 1401861,
      "node_id": "MDQ6VXNlcjE0MDE4NjE=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1401861?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mapa17",
      "html_url": "https://github.com/mapa17",
      "followers_url": "https://api.github.com/users/mapa17/followers",
      "following_url": "https://api.github.com/users/mapa17/following{/other_user}",
      "gists_url": "https://api.github.com/users/mapa17/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mapa17/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mapa17/subscriptions",
      "organizations_url": "https://api.github.com/users/mapa17/orgs",
      "repos_url": "https://api.github.com/users/mapa17/repos",
      "events_url": "https://api.github.com/users/mapa17/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mapa17/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-09-04T19:51:53Z",
    "updated_at": "2018-09-04T19:51:53Z",
    "author_association": "NONE",
    "body": "For who is interested, I created a simple helper function to write DataFrames to excel (including header s and Index) using pyexcelerate. ( https://gist.github.com/mapa17/bc04be36e447cab0746a0ec8903cc49f )\r\n\r\nI thought about adding a excel writer engine to pandas/pandas/io/excel.py but I am a bit worried looking through the other already implanted engines. They support all kind of fancy cell formatting. \r\n\r\nDo you think it would it be sufficient to provide a minimalistic excel writer engine using pyexcelerate, writing only unformatted excel files?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/418524004",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-418524004",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 418524004,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxODUyNDAwNA==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-09-04T21:28:14Z",
    "updated_at": "2018-09-04T21:28:32Z",
    "author_association": "MEMBER",
    "body": "Hmm...from a maintenance perspective, I think I would want to maintain fewer engines than multiple because of the compatibility issues down the road (e.g. maintaining consistency between a Python and C parser for CSV has quite difficult).\r\n\r\nI could potentially see this as a \"fast track,\" but it sounds a little corner case.  Thus, I'm -0.5 on this overall because I'm leaning towards this being more maintenance than useful for the broader audience.\r\n\r\ncc @jreback "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/432414640",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-432414640",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 432414640,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzMjQxNDY0MA==",
    "user": {
      "login": "Masterxilo",
      "id": 2378665,
      "node_id": "MDQ6VXNlcjIzNzg2NjU=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/2378665?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Masterxilo",
      "html_url": "https://github.com/Masterxilo",
      "followers_url": "https://api.github.com/users/Masterxilo/followers",
      "following_url": "https://api.github.com/users/Masterxilo/following{/other_user}",
      "gists_url": "https://api.github.com/users/Masterxilo/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Masterxilo/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Masterxilo/subscriptions",
      "organizations_url": "https://api.github.com/users/Masterxilo/orgs",
      "repos_url": "https://api.github.com/users/Masterxilo/repos",
      "events_url": "https://api.github.com/users/Masterxilo/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Masterxilo/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-23T20:51:04Z",
    "updated_at": "2018-10-23T20:51:04Z",
    "author_association": "NONE",
    "body": "This thing is indeed too slow, I'm not surprised that I find others thinking the same. 5 minutes for producing a 50 MB excel file is too much."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/463098086",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4517#issuecomment-463098086",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4517",
    "id": 463098086,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ2MzA5ODA4Ng==",
    "user": {
      "login": "WillAyd",
      "id": 609873,
      "node_id": "MDQ6VXNlcjYwOTg3Mw==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/609873?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/WillAyd",
      "html_url": "https://github.com/WillAyd",
      "followers_url": "https://api.github.com/users/WillAyd/followers",
      "following_url": "https://api.github.com/users/WillAyd/following{/other_user}",
      "gists_url": "https://api.github.com/users/WillAyd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/WillAyd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/WillAyd/subscriptions",
      "organizations_url": "https://api.github.com/users/WillAyd/orgs",
      "repos_url": "https://api.github.com/users/WillAyd/repos",
      "events_url": "https://api.github.com/users/WillAyd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/WillAyd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-02-13T08:03:13Z",
    "updated_at": "2019-02-13T08:03:13Z",
    "author_association": "MEMBER",
    "body": "Based off of conversation above I think we'll close this for now as its unclear if there's really anything to be gained here. If anyone disagrees feel free to reopen"
  }
]
