[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/238865546",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13956#issuecomment-238865546",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13956",
    "id": 238865546,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzODg2NTU0Ng==",
    "user": {
      "login": "rockg",
      "id": 3195015,
      "node_id": "MDQ6VXNlcjMxOTUwMTU=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/3195015?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rockg",
      "html_url": "https://github.com/rockg",
      "followers_url": "https://api.github.com/users/rockg/followers",
      "following_url": "https://api.github.com/users/rockg/following{/other_user}",
      "gists_url": "https://api.github.com/users/rockg/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rockg/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rockg/subscriptions",
      "organizations_url": "https://api.github.com/users/rockg/orgs",
      "repos_url": "https://api.github.com/users/rockg/repos",
      "events_url": "https://api.github.com/users/rockg/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rockg/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-10T13:25:51Z",
    "updated_at": "2016-08-10T13:25:51Z",
    "author_association": "CONTRIBUTOR",
    "body": "If this data getting sorted at any point by your code?  It seems to me that it should be presented in the below way as this how it came in sequentially and then localizing will work using `infer`.  I had a similar issue with some electricity pricing data and notified the data provider and they were able to fix in subsequent years.  If it's like the below, then it will work fine.\n\n```\n2015-10-25 01:30:00    14603.9\n2015-10-25 01:45:00    14559.7\n2015-10-25 02:00:00    14239.0\n2015-10-25 02:15:00    13914.5\n2015-10-25 02:30:00    14300.5\n2015-10-25 02:45:00    14162.2\n2015-10-25 02:00:00    14371.0\n2015-10-25 02:15:00    14427.2\n2015-10-25 02:30:00    14267.5\n2015-10-25 02:45:00    14148.5\n2015-10-25 03:00:00    14028.1\n2015-10-25 03:15:00    14083.1\n2015-10-25 03:30:00    14122.9\ndtype: float64\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/238868996",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13956#issuecomment-238868996",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13956",
    "id": 238868996,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzODg2ODk5Ng==",
    "user": {
      "login": "rockg",
      "id": 3195015,
      "node_id": "MDQ6VXNlcjMxOTUwMTU=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/3195015?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rockg",
      "html_url": "https://github.com/rockg",
      "followers_url": "https://api.github.com/users/rockg/followers",
      "following_url": "https://api.github.com/users/rockg/following{/other_user}",
      "gists_url": "https://api.github.com/users/rockg/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rockg/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rockg/subscriptions",
      "organizations_url": "https://api.github.com/users/rockg/orgs",
      "repos_url": "https://api.github.com/users/rockg/repos",
      "events_url": "https://api.github.com/users/rockg/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rockg/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-10T13:38:42Z",
    "updated_at": "2016-08-10T13:38:42Z",
    "author_association": "CONTRIBUTOR",
    "body": "I see from the original source that it is already sorted.  You'll have to do some manipulation to get the right ordering in order for localizing to work given the current code.  If you want to try and fix for cases like this I think that will be a useful addition.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/238918392",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13956#issuecomment-238918392",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13956",
    "id": 238918392,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzODkxODM5Mg==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-10T16:13:35Z",
    "updated_at": "2016-08-10T16:13:35Z",
    "author_association": "MEMBER",
    "body": "As @rockg noted, if your data is sorted by time correctly, it works. As an example with some manual sorting:\n\n```\nIn [19]: s2 = s.iloc[[0,1,2,4,6,8,3,5,7,9,10,11]]\n\nIn [20]: s2\nOut[20]: \n2015-10-25 01:30:00    14603.9\n2015-10-25 01:45:00    14559.7\n2015-10-25 02:00:00    14239.0\n2015-10-25 02:15:00    13914.5\n2015-10-25 02:30:00    14300.5\n2015-10-25 02:45:00    14162.2\n2015-10-25 02:00:00    14371.0\n2015-10-25 02:15:00    14427.2\n2015-10-25 02:30:00    14267.5\n2015-10-25 02:45:00    14148.5\n2015-10-25 03:00:00    14028.1\n2015-10-25 03:15:00    14083.1\ndtype: float64\n\nIn [21]: s2.tz_localize('Europe/Warsaw', ambiguous='infer')\nOut[21]: \n2015-10-25 01:30:00+02:00    14603.9\n2015-10-25 01:45:00+02:00    14559.7\n2015-10-25 02:00:00+02:00    14239.0\n2015-10-25 02:15:00+02:00    13914.5\n2015-10-25 02:30:00+02:00    14300.5\n2015-10-25 02:45:00+02:00    14162.2\n2015-10-25 02:00:00+01:00    14371.0\n2015-10-25 02:15:00+01:00    14427.2\n2015-10-25 02:30:00+01:00    14267.5\n2015-10-25 02:45:00+01:00    14148.5\n2015-10-25 03:00:00+01:00    14028.1\n2015-10-25 03:15:00+01:00    14083.1\ndtype: float64\n```\n\n>  If you want to try and fix for cases like this I think that will be a useful addition.\n\nAlthough I am not sure we should add something like this. When inferring dst, it seems sensible to me to ask the user that the timeseries is continuous? As data in such form (not sorted by 'real' time) seems more like an error in the data source. @rockg You think it is worth adding?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/238922194",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13956#issuecomment-238922194",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13956",
    "id": 238922194,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzODkyMjE5NA==",
    "user": {
      "login": "rockg",
      "id": 3195015,
      "node_id": "MDQ6VXNlcjMxOTUwMTU=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/3195015?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rockg",
      "html_url": "https://github.com/rockg",
      "followers_url": "https://api.github.com/users/rockg/followers",
      "following_url": "https://api.github.com/users/rockg/following{/other_user}",
      "gists_url": "https://api.github.com/users/rockg/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rockg/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rockg/subscriptions",
      "organizations_url": "https://api.github.com/users/rockg/orgs",
      "repos_url": "https://api.github.com/users/rockg/repos",
      "events_url": "https://api.github.com/users/rockg/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rockg/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-10T16:26:09Z",
    "updated_at": "2016-08-10T16:26:09Z",
    "author_association": "CONTRIBUTOR",
    "body": "I agree that it is sensible that it be continuous, but I've seen enough cases where it's sorted as in the original post and it's a difficult enough problem to work around that I don't see any harm in offering this as an additional inference.  You are right that it is most likely a problem in the original source, but going through the hoops of getting that source to change, while the right course of action, is probably not one that many will take.  It does require that the user understand the nature of the data and what assumptions we are making in our inference (i.e., that the second point of the duplicated time stamp is really the second hour), but I think having a warning or something of that nature is sufficient.  Alternately, providing a recipe or snippet to work-around this problem might be also be okay.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/239013264",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13956#issuecomment-239013264",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13956",
    "id": 239013264,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTAxMzI2NA==",
    "user": {
      "login": "liori",
      "id": 789385,
      "node_id": "MDQ6VXNlcjc4OTM4NQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/789385?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/liori",
      "html_url": "https://github.com/liori",
      "followers_url": "https://api.github.com/users/liori/followers",
      "following_url": "https://api.github.com/users/liori/following{/other_user}",
      "gists_url": "https://api.github.com/users/liori/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/liori/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/liori/subscriptions",
      "organizations_url": "https://api.github.com/users/liori/orgs",
      "repos_url": "https://api.github.com/users/liori/repos",
      "events_url": "https://api.github.com/users/liori/events{/privacy}",
      "received_events_url": "https://api.github.com/users/liori/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-10T21:40:07Z",
    "updated_at": "2016-08-11T02:28:18Z",
    "author_association": "NONE",
    "body": "Indeed, the page I linked sometimes returns data that looks like in-order-of-UTC, and sometimes in-order-of-numerical-values. Was surprised when after working with data before 2015 everything was working fine, and only started getting this problem in 2015.\n\nAlso, I did actually ask the source to provide data in UTC; so far no response (after four months now).\n\nCurrently I just fixed it by hardcoding a permutation using `.iloc` (the data is pretty much the only instance of this type), but I was thinking of a generic solution like:\n1. stable-sort the index by numerical values,\n2. assert that no date that can't conflict in the given time zone is only once, and no date that can conflict is only twice in the index,\n3. for each duplicate, assign the UTC-earlier timestamp to the first occurence, and UTC-later to the second.\n\nThis is O(nlogn) because of sorting, so will probably work slower than the current implementation (maybe start the above algorithm only when we detect the problem?). ~~However, it will preserve the result for the cases that the current implementation already handles.~~ (It won't if the timestamps don't match. Stupid me!)\n\nIf the above sounds ok, I'll try doing something towards an implementation.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/239023046",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13956#issuecomment-239023046",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13956",
    "id": 239023046,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTAyMzA0Ng==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-10T22:21:53Z",
    "updated_at": "2016-08-10T22:21:53Z",
    "author_association": "CONTRIBUTOR",
    "body": "The current code accepts a boolean for the `ambiguous` parameter. So you _could_ use this directly.\n\n```\nIn [8]: s.tz_localize('Europe/Warsaw',ambiguous=[False]*len(s))\nOut[8]: \n2015-10-25 01:30:00+02:00    14603.9\n2015-10-25 01:45:00+02:00    14559.7\n2015-10-25 02:00:00+01:00    14239.0\n2015-10-25 02:00:00+01:00    14371.0\n2015-10-25 02:15:00+01:00    13914.5\n2015-10-25 02:15:00+01:00    14427.2\n2015-10-25 02:30:00+01:00    14300.5\n2015-10-25 02:30:00+01:00    14267.5\n2015-10-25 02:45:00+01:00    14162.2\n2015-10-25 02:45:00+01:00    14148.5\n2015-10-25 03:00:00+01:00    14028.1\n2015-10-25 03:15:00+01:00    14083.1\n2015-10-25 03:30:00+01:00    14122.9\ndtype: float64\n\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/239059822",
    "html_url": "https://github.com/pandas-dev/pandas/issues/13956#issuecomment-239059822",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/13956",
    "id": 239059822,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTA1OTgyMg==",
    "user": {
      "login": "liori",
      "id": 789385,
      "node_id": "MDQ6VXNlcjc4OTM4NQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/789385?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/liori",
      "html_url": "https://github.com/liori",
      "followers_url": "https://api.github.com/users/liori/followers",
      "following_url": "https://api.github.com/users/liori/following{/other_user}",
      "gists_url": "https://api.github.com/users/liori/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/liori/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/liori/subscriptions",
      "organizations_url": "https://api.github.com/users/liori/orgs",
      "repos_url": "https://api.github.com/users/liori/repos",
      "events_url": "https://api.github.com/users/liori/events{/privacy}",
      "received_events_url": "https://api.github.com/users/liori/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-11T02:37:19Z",
    "updated_at": "2016-08-11T02:37:19Z",
    "author_association": "NONE",
    "body": "Indeed I can get the behavior from the expected output section in the ticket by:\n\n```\nIn [14]: s.tz_localize('Europe/Warsaw', ambiguous=[0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0]).sort_index()\nOut[14]: \n2015-10-25 01:30:00+02:00    14603.9\n2015-10-25 01:45:00+02:00    14559.7\n2015-10-25 02:00:00+02:00    14239.0\n2015-10-25 02:15:00+02:00    13914.5\n2015-10-25 02:30:00+02:00    14300.5\n2015-10-25 02:45:00+02:00    14162.2\n2015-10-25 02:00:00+01:00    14371.0\n2015-10-25 02:15:00+01:00    14427.2\n2015-10-25 02:30:00+01:00    14267.5\n2015-10-25 02:45:00+01:00    14148.5\n2015-10-25 03:00:00+01:00    14028.1\n2015-10-25 03:15:00+01:00    14083.1\n2015-10-25 03:30:00+01:00    14122.9\ndtype: float64\n```\n\nAlso, I realized that my above idea does not actually produce the same output as the current `ambiguous='infer'`. Will have to think about it.\n"
  }
]
