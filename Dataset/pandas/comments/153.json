[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/3125167",
    "html_url": "https://github.com/pandas-dev/pandas/issues/153#issuecomment-3125167",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/153",
    "id": 3125167,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjUxNjc=",
    "user": {
      "login": "wesm",
      "id": 329591,
      "node_id": "MDQ6VXNlcjMyOTU5MQ==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/329591?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/wesm",
      "html_url": "https://github.com/wesm",
      "followers_url": "https://api.github.com/users/wesm/followers",
      "following_url": "https://api.github.com/users/wesm/following{/other_user}",
      "gists_url": "https://api.github.com/users/wesm/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/wesm/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/wesm/subscriptions",
      "organizations_url": "https://api.github.com/users/wesm/orgs",
      "repos_url": "https://api.github.com/users/wesm/repos",
      "events_url": "https://api.github.com/users/wesm/events{/privacy}",
      "received_events_url": "https://api.github.com/users/wesm/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2011-12-13T16:22:26Z",
    "updated_at": "2011-12-13T16:22:26Z",
    "author_association": "MEMBER",
    "body": "use case from @andreas-h\n\n```\nI have a DataFrame with a 2d MultiIndex:\n\nlat = np.linspace(-88.75, 88.75, 72)\nlon = np.linspace(-178.75, 178.75, 144)\nlons, lats = np.meshgrid(lon, lat)\nMI = pandas.MultiIndex.from_tuples(zip(lons.ravel(), lats.ravel()),\nnames=['lon', 'lat'])\ntimeidx = pandas.DateRange(start=datetime.datetime(2009,1,1),\nend=datetime.datetime(2009,12,31), offset=pandas.datetools.MonthEnd())\nDF = pandas.DataFrame(index=timeidx, columns=MI)\n# somehow fill DF with data\n\nIs there a way to easily spatially downsample the data to a coarser\nGrid? (or do other statistics on subsets of DF)? I'm thinking\nsomething like this:\n\nlonedges = np.linspace(-180., 180., 73)\nlatedges = np.linspace(90., 90., 37)\nlons_new, lats_new = np.meshgrid(np.linspace(-177.5, 177.5, 36),\nnp.linspace(-90., 90., 18))\nlons_new, lats_new = lons_new.ravel(), lats_new.ravel()\nMI_new = pandas.MultiIndex.from_tuples(zip(lons_new, lats_new),\nnames=['lon', 'lat'])\nresults = pandas.DataFrame(index=timeidx, columns=MI_new)\n\nfor i in MI_new:\n   results[i] = DF.groupby('all points within lonedges, latedges\nwhich correspond to this ``i``').mean()\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/3159605",
    "html_url": "https://github.com/pandas-dev/pandas/issues/153#issuecomment-3159605",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/153",
    "id": 3159605,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTk2MDU=",
    "user": {
      "login": "andreas-h",
      "id": 358378,
      "node_id": "MDQ6VXNlcjM1ODM3OA==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/358378?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/andreas-h",
      "html_url": "https://github.com/andreas-h",
      "followers_url": "https://api.github.com/users/andreas-h/followers",
      "following_url": "https://api.github.com/users/andreas-h/following{/other_user}",
      "gists_url": "https://api.github.com/users/andreas-h/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/andreas-h/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/andreas-h/subscriptions",
      "organizations_url": "https://api.github.com/users/andreas-h/orgs",
      "repos_url": "https://api.github.com/users/andreas-h/repos",
      "events_url": "https://api.github.com/users/andreas-h/events{/privacy}",
      "received_events_url": "https://api.github.com/users/andreas-h/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2011-12-15T10:58:28Z",
    "updated_at": "2011-12-15T10:58:28Z",
    "author_association": "CONTRIBUTOR",
    "body": "Another use case would be the same as above, except that the tuples in the MultiArray do not represent a regular grid but just arbitrary lon/lat tuples of single measurement locations, for example.\nProbably doesn't change anything for the implementation, but I thought I'd just add it here.\n\nWhat I'm looking for is something like \n\n```\ndef DataFrame.grid(bins, method):\n    \"\"\"\n    bins : e.g. tuple of arrays; see the bins parameter of numpy.histogram2d\n\n    method : either 'mean' or 'std' or any function which will work on the data which will go into one new grid cell\n\n    returns a pandas.DataFrame with the columns being the same as the original DataFrame, and the index being a MultiIndex which has the centers of the bins as values\n    \"\"\"\n```\n\nI know a lot of this should be more general (e.g. index.ndim > 2), but this here would be all I need for now.\n\nAs for the averaging of the grid cells, I recently did something similar using numpy.histogram2d:\n\n```\ndef _histnd(lons, lats, lonbins, latbins, data=None):\n    if data == None:\n        summed = np.histogram2d(lons, lats, (lonbins, latbins))[0]\n    elif data.ndim == 1:\n        summed = np.histogram2d(lons, lats, (lonbins, latbins),\n                                weights=data)[0]\n    elif data.ndim == 2:\n        summed = np.empty(np.r_[data.shape[0], lonbins.shape[0] - 1,\n                                latbins.shape[0] - 1])\n        for i in xrange(summed.shape[0]):\n            summed[i] = np.histogram2d(lons, lats, (lonbins, latbins),\n                                       weights=data[i])[0]\n    else:\n        raise ValueError(\"constraint ``data.ndim in [1, 2]`` violated!\")\n\n    summed = ma.masked_invalid(summed)\n    return summed\n\n\ndef bin_data(data, lons, lats, lonbins, latbins, mask_zero=False,\n             calc_std=False):\n    \"\"\"\n    Bin data by longitude and latitude, using mean()\n\n    data : np.ndarray\n       The data to be binned, dimension (d, n)\n\n    lons : np.ndarray\n       the longitudes of the data points, dimension (n)\n\n    lats : np.ndarray\n       the latitudes of the data points, dimension (n)\n\n    lonbins : np.ndarray\n       the edges of the longitude bins\n\n    latbins : np.ndarray\n       the edges of the latitude bins\n\n    mask_zero : bool\n       if True, do not count data points with a value of 0. Defaults to False\n\n    calc_std : bool\n       if True, also calculate the standard deviation within each bin.\n\n    returns mean, std (if calc_std == True)\n\n\n    The idea to this function is taken from\n\n       http://stackoverflow.com/questions/6163334/\n\n    For calculating the stds on the grid, the formula was taken from\n\n       http://stackoverflow.com/questions/1174984/1175084#1175084\n\n    \"\"\"\n    summed = _histnd(lons, lats, lonbins, latbins, data)\n\n    count_weights = np.where(data != 0., 1, 0) if mask_zero else None\n    count = _histnd(lons, lats, lonbins, latbins, count_weights)\n    count = ma.masked_invalid(count)\n\n    # in the 3d data case, we need to set the count to the highest count of the\n    # appropriate lon/lat pair\n    if data.ndim == 2:\n        count = np.tile(count.max(axis=0).copy(), (count.shape[0], 1, 1))\n\n    if mask_zero:\n        summed = ma.masked_where(summed==0., summed)\n        count = ma.masked_where(count==0., count)\n\n    binned = summed / count\n\n    if calc_std:\n        if data.ndim == 3:\n            raise NotImplementedError(\"Calculation of std not implemented for \\\n3d data yet\")\n        sum_squares = np.histogram2d(lons, lats, (lonbins, latbins),\n                                     weights=data**2)[0]\n        return binned, np.sqrt((sum_squares / count) - (binned **2))\n    else:\n        return binned\n```\n"
  }
]
