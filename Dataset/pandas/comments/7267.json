[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/44449437",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7267#issuecomment-44449437",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7267",
    "id": 44449437,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NDQ5NDM3",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-05-28T18:53:57Z",
    "updated_at": "2014-05-28T18:54:33Z",
    "author_association": "CONTRIBUTOR",
    "body": "so this is defacto doing this:\n\nEssentially you are grouping by a Categorical give then time\n\n```\nIn [75]: def ct(x):\n   ....:     return x.hour*3600+x.minute*60+x.second\n   ....: \n\nIn [77]: pd.cut(map(ct,s.index.time),bins=[0] + map(ct,index.time))\nOut[77]: \n            NaN\n     (0, 41400]\n     (0, 41400]\n (41400, 54000]\n (54000, 79200]\n (54000, 79200]\nLevels (3): Index(['(0, 41400]', '(41400, 54000]', '(54000, 79200]'], dtype=object)\n\nIn [78]: s.groupby(pd.cut(map(ct,s.index.time),bins=[0] + map(ct,index.time))).sum()\nOut[78]: \n(0, 41400]        5\n(41400, 54000]    3\n(54000, 79200]    9\ndtype: int64\n```\n\nAnd if we had a properly constructed `TimeIndex` this would work nicely (ignore edge effects).\nrelated: https://github.com/pydata/pandas/issues/4023\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/44605197",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7267#issuecomment-44605197",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7267",
    "id": 44605197,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NjA1MTk3",
    "user": {
      "login": "shura-v",
      "id": 2202588,
      "node_id": "MDQ6VXNlcjIyMDI1ODg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/2202588?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shura-v",
      "html_url": "https://github.com/shura-v",
      "followers_url": "https://api.github.com/users/shura-v/followers",
      "following_url": "https://api.github.com/users/shura-v/following{/other_user}",
      "gists_url": "https://api.github.com/users/shura-v/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shura-v/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shura-v/subscriptions",
      "organizations_url": "https://api.github.com/users/shura-v/orgs",
      "repos_url": "https://api.github.com/users/shura-v/repos",
      "events_url": "https://api.github.com/users/shura-v/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shura-v/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-05-30T01:19:26Z",
    "updated_at": "2014-05-30T01:27:36Z",
    "author_association": "NONE",
    "body": "Series meant to be something like this:\n\n```\ns = Series({\n    datetime(2014, 1, 10, 0): 1,\n    datetime(2014, 1, 11, 10): 2,\n    datetime(2014, 1, 11, 11): 3,\n    datetime(2014, 1, 12, 12): 3,\n    datetime(2014, 1, 13, 1): 100,\n    datetime(2014, 1, 15, 16): 4,\n    datetime(2014, 1, 15, 22): 5\n})\n```\n\nBut I got the idea, thanks. Anyway, I think it would extremely useful feature that would _resample by index_ (with presence of 'closed', 'label' and 'how' arguments) using some high-level method.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/44683756",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7267#issuecomment-44683756",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7267",
    "id": 44683756,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NjgzNzU2",
    "user": {
      "login": "shura-v",
      "id": 2202588,
      "node_id": "MDQ6VXNlcjIyMDI1ODg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/2202588?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shura-v",
      "html_url": "https://github.com/shura-v",
      "followers_url": "https://api.github.com/users/shura-v/followers",
      "following_url": "https://api.github.com/users/shura-v/following{/other_user}",
      "gists_url": "https://api.github.com/users/shura-v/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shura-v/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shura-v/subscriptions",
      "organizations_url": "https://api.github.com/users/shura-v/orgs",
      "repos_url": "https://api.github.com/users/shura-v/repos",
      "events_url": "https://api.github.com/users/shura-v/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shura-v/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-05-30T18:28:52Z",
    "updated_at": "2014-05-30T18:53:37Z",
    "author_association": "NONE",
    "body": "Here is the solution I came up with, based on your suggestion.\nThink of _index_to_ as some random (predefined) DatetimeIndex:\n\n```\nindex_from = pd.date_range('2009-01-01', '2016-01-01', freq='T')\ns = pd.Series(np.arange(len(index_from)), index_from)\n\nindex_to = pd.date_range('2010-01-01', '2015-05-30', freq='H')\nbins = index_to.insert(0, datetime.fromtimestamp(0)).astype(np.long)\nlabels = pd.cut(s.index.astype(np.long), bins=bins).labels\n\nagg = s.groupby(labels).last().ix[0:]\npd.Series(agg.values, index_to)\n```\n\n---\n\n```\n2010-01-01 00:00:00    525600\n2010-01-01 01:00:00    525660\n2010-01-01 02:00:00    525720\n2010-01-01 03:00:00    525780\n2010-01-01 04:00:00    525840\n2010-01-01 05:00:00    525900\n2010-01-01 06:00:00    525960\n2010-01-01 07:00:00    526020\n2010-01-01 08:00:00    526080\n2010-01-01 09:00:00    526140\n2010-01-01 10:00:00    526200\n2010-01-01 11:00:00    526260\n2010-01-01 12:00:00    526320\n2010-01-01 13:00:00    526380\n2010-01-01 14:00:00    526440\n...\n2015-05-29 10:00:00    3368760\n2015-05-29 11:00:00    3368820\n2015-05-29 12:00:00    3368880\n2015-05-29 13:00:00    3368940\n2015-05-29 14:00:00    3369000\n2015-05-29 15:00:00    3369060\n2015-05-29 16:00:00    3369120\n2015-05-29 17:00:00    3369180\n2015-05-29 18:00:00    3369240\n2015-05-29 19:00:00    3369300\n2015-05-29 20:00:00    3369360\n2015-05-29 21:00:00    3369420\n2015-05-29 22:00:00    3369480\n2015-05-29 23:00:00    3369540\n2015-05-30 00:00:00    3369600\nFreq: H, Length: 47401\n```\n\nI think it's the same as `s.reindex(index_to, method='pad')`, but with ability to use any aggregate function instead of just picking last value.\n"
  }
]
