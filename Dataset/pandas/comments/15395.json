[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/279823702",
    "html_url": "https://github.com/pandas-dev/pandas/issues/15395#issuecomment-279823702",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/15395",
    "id": 279823702,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI3OTgyMzcwMg==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-02-14T20:19:51Z",
    "updated_at": "2017-02-14T20:19:51Z",
    "author_association": "MEMBER",
    "body": "@randomgambit The two ways actually do something different. \r\n\r\nIn the `reshaper(dataframe = test, frequency = '200 L')` case, you are grouping by 'groups' and 'day'. This means, I think, that it will do the `Timegrouper` for each value of 'groups'. Eg for groups 'A', this means a range from '2012-02-01' to '2012-03-11' with this frequency:\r\n\r\n```\r\nIn [5]: idx = pd.date_range('2012-02-01', '2012-03-11', freq='200L')\r\n\r\nIn [6]: len(idx)\r\nOut[6]: 16848001\r\n```\r\n\r\nSo this is a huge amount of groups that you create. Possibly the reason for that it takes so long (note, there may be a bug as well). \r\n\r\nIn the `test.groupby('day').apply(lambda x: reshaper(x,  frequency = '200 L'))`, you also group by 'day', therefore, you never get such large date ranges.\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/279834515",
    "html_url": "https://github.com/pandas-dev/pandas/issues/15395#issuecomment-279834515",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/15395",
    "id": 279834515,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI3OTgzNDUxNQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-02-14T21:01:23Z",
    "updated_at": "2017-02-14T21:01:23Z",
    "author_association": "CONTRIBUTOR",
    "body": "it looks like a bug, but since you are multiply grouping you MUST expand the groupands, IOW the number of groups x resampled intervals. So this is something like 16M x 2 groups, which is really really large.\r\n\r\n@randomgambit if you want to have a look, go for it. I would simply do\r\n\r\n``test.groupby('groups').resample('200L').value.sum()``\r\n\r\nSo I'll mark it, but it would be really helpful for someone (you!) to look into it."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/279834563",
    "html_url": "https://github.com/pandas-dev/pandas/issues/15395#issuecomment-279834563",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/15395",
    "id": 279834563,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI3OTgzNDU2Mw==",
    "user": {
      "login": "randomgambit",
      "id": 8282510,
      "node_id": "MDQ6VXNlcjgyODI1MTA=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/8282510?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/randomgambit",
      "html_url": "https://github.com/randomgambit",
      "followers_url": "https://api.github.com/users/randomgambit/followers",
      "following_url": "https://api.github.com/users/randomgambit/following{/other_user}",
      "gists_url": "https://api.github.com/users/randomgambit/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/randomgambit/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/randomgambit/subscriptions",
      "organizations_url": "https://api.github.com/users/randomgambit/orgs",
      "repos_url": "https://api.github.com/users/randomgambit/repos",
      "events_url": "https://api.github.com/users/randomgambit/events{/privacy}",
      "received_events_url": "https://api.github.com/users/randomgambit/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-02-14T21:01:37Z",
    "updated_at": "2017-02-14T21:04:59Z",
    "author_association": "NONE",
    "body": "@jreback @jorisvandenbossche (looping in Jeff who posted at the same time!) thanks for your answer!\r\n\r\nThat is interesting. I was convinced that `TimeGrouper` would act like some flooring datetime function so it would combine together timetamps falling in the same \"time bin\" as defined by the frequency. Very much like `floor_date` in R (https://rdrr.io/cran/lubridate/man/round_date.html)\r\n\r\nUnless I am mistaken here, there seem to be some inconsistency. Consider this alternative example\r\n\r\n```\r\nidx2=[pd.to_datetime('2012-02-01 14:00:00') , \r\n     pd.to_datetime('2012-02-02 14:00:00'),\r\n     pd.to_datetime('2012-02-04 14:00:00')]\r\n\r\ntest2=pd.DataFrame({'value':[1,2,3], 'groups' : ['A','B','A']},index=idx2)\r\n\r\ntest2\r\nOut[212]: \r\n                    groups  value\r\n2012-02-01 14:00:00      A      1\r\n2012-02-02 14:00:00      B      2\r\n2012-02-04 14:00:00      A      3\r\n```\r\n\r\nConsistent with that I am saying, \r\n\r\n`test2.groupby([pd.TimeGrouper('1 H')]).groups`\r\n\r\ngives \r\n\r\n```\r\ntest2.groupby([pd.TimeGrouper('1 H')]).groups\r\nOut[222]: \r\n{Timestamp('2012-02-01 14:00:00'): DatetimeIndex(['2012-02-01 14:00:00'], dtype='datetime64[ns]', freq=None),\r\n Timestamp('2012-02-02 14:00:00'): DatetimeIndex(['2012-02-02 14:00:00'], dtype='datetime64[ns]', freq=None),\r\n Timestamp('2012-02-04 14:00:00'): DatetimeIndex(['2012-02-04 14:00:00'], dtype='datetime64[ns]', freq=None)}\r\n\r\n```\r\n\r\nBUT, \r\n\r\n`test2.groupby(pd.TimeGrouper('1 H')).groups`\r\n\r\n[note the missing brackets]\r\ngives: \r\n\r\n```\r\ntest2.groupby(pd.TimeGrouper('1 H')).groups\r\nOut[223]: \r\n{Timestamp('2012-02-01 14:00:00', freq='H'): 1,\r\n Timestamp('2012-02-01 15:00:00', freq='H'): 1,\r\n Timestamp('2012-02-01 16:00:00', freq='H'): 1,\r\n Timestamp('2012-02-01 17:00:00', freq='H'): 1,\r\n Timestamp('2012-02-01 18:00:00', freq='H'): 1,\r\n Timestamp('2012-02-01 19:00:00', freq='H'): 1,\r\n Timestamp('2012-02-01 20:00:00', freq='H'): 1,\r\n Timestamp('2012-02-01 21:00:00', freq='H'): 1,\r\n Timestamp('2012-02-01 22:00:00', freq='H'): 1,\r\n Timestamp('2012-02-01 23:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 00:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 01:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 02:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 03:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 04:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 05:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 06:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 07:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 08:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 09:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 10:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 11:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 12:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 13:00:00', freq='H'): 1,\r\n Timestamp('2012-02-02 14:00:00', freq='H'): 2,\r\n Timestamp('2012-02-02 15:00:00', freq='H'): 2,\r\n Timestamp('2012-02-02 16:00:00', freq='H'): 2,\r\n Timestamp('2012-02-02 17:00:00', freq='H'): 2,\r\n Timestamp('2012-02-02 18:00:00', freq='H'): 2,\r\n Timestamp('2012-02-02 19:00:00', freq='H'): 2,\r\n Timestamp('2012-02-02 20:00:00', freq='H'): 2,\r\n Timestamp('2012-02-02 21:00:00', freq='H'): 2,\r\n Timestamp('2012-02-02 22:00:00', freq='H'): 2,\r\n Timestamp('2012-02-02 23:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 00:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 01:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 02:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 03:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 04:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 05:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 06:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 07:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 08:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 09:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 10:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 11:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 12:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 13:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 14:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 15:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 16:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 17:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 18:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 19:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 20:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 21:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 22:00:00', freq='H'): 2,\r\n Timestamp('2012-02-03 23:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 00:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 01:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 02:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 03:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 04:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 05:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 06:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 07:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 08:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 09:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 10:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 11:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 12:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 13:00:00', freq='H'): 2,\r\n Timestamp('2012-02-04 14:00:00', freq='H'): 3}\r\n```\r\n\r\nso what is `TimeGrouping` doing at the end of the day?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/279836767",
    "html_url": "https://github.com/pandas-dev/pandas/issues/15395#issuecomment-279836767",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/15395",
    "id": 279836767,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI3OTgzNjc2Nw==",
    "user": {
      "login": "randomgambit",
      "id": 8282510,
      "node_id": "MDQ6VXNlcjgyODI1MTA=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/8282510?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/randomgambit",
      "html_url": "https://github.com/randomgambit",
      "followers_url": "https://api.github.com/users/randomgambit/followers",
      "following_url": "https://api.github.com/users/randomgambit/following{/other_user}",
      "gists_url": "https://api.github.com/users/randomgambit/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/randomgambit/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/randomgambit/subscriptions",
      "organizations_url": "https://api.github.com/users/randomgambit/orgs",
      "repos_url": "https://api.github.com/users/randomgambit/repos",
      "events_url": "https://api.github.com/users/randomgambit/events{/privacy}",
      "received_events_url": "https://api.github.com/users/randomgambit/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-02-14T21:09:56Z",
    "updated_at": "2017-02-14T21:09:56Z",
    "author_association": "NONE",
    "body": "@jreback @jorisvandenbossche actually the small example above seems to suggest that this is a bug. Indeed, `groupby([pd_timegrouper , groups])` has the magic square brackets around ;-) what do you think?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/279837358",
    "html_url": "https://github.com/pandas-dev/pandas/issues/15395#issuecomment-279837358",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/15395",
    "id": 279837358,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI3OTgzNzM1OA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-02-14T21:12:13Z",
    "updated_at": "2017-02-14T21:12:13Z",
    "author_association": "CONTRIBUTOR",
    "body": "@randomgambit you need to step thru the code. its not the specification, but the actual group generation."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/279841687",
    "html_url": "https://github.com/pandas-dev/pandas/issues/15395#issuecomment-279841687",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/15395",
    "id": 279841687,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI3OTg0MTY4Nw==",
    "user": {
      "login": "randomgambit",
      "id": 8282510,
      "node_id": "MDQ6VXNlcjgyODI1MTA=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/8282510?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/randomgambit",
      "html_url": "https://github.com/randomgambit",
      "followers_url": "https://api.github.com/users/randomgambit/followers",
      "following_url": "https://api.github.com/users/randomgambit/following{/other_user}",
      "gists_url": "https://api.github.com/users/randomgambit/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/randomgambit/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/randomgambit/subscriptions",
      "organizations_url": "https://api.github.com/users/randomgambit/orgs",
      "repos_url": "https://api.github.com/users/randomgambit/repos",
      "events_url": "https://api.github.com/users/randomgambit/events{/privacy}",
      "received_events_url": "https://api.github.com/users/randomgambit/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-02-14T21:29:07Z",
    "updated_at": "2017-02-14T21:29:07Z",
    "author_association": "NONE",
    "body": "@jreback @jorisvandenbossche  I will try but I am afraid I am only good at finding bugs...\r\n\r\nJust to make sure and avoid any misunderstanding, you agree with me that the expected output of \r\n\r\n`reshaper(dataframe = test, frequency = '200 L')`\r\n\r\n\r\nshould be\r\n\r\n```\r\n\r\nOut[176]: \r\n                                 value       \r\n                                 mysum myfunc\r\nday                                          \r\n2012-02-01 A 2012-02-01 14:00:00     1     -1\r\n             2012-02-01 14:01:00     2     -2\r\n2012-03-05 A 2012-03-05 14:01:00     3     -3\r\n           B 2012-03-05 14:02:00     4     -4\r\n2012-03-10 A 2012-03-10 14:02:00     5     -5\r\n2012-03-11 A 2012-03-11 14:02:00     6     -6\r\n```\r\n\r\n?"
  }
]
