[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/410517651",
    "html_url": "https://github.com/pandas-dev/pandas/issues/22205#issuecomment-410517651",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22205",
    "id": 410517651,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDUxNzY1MQ==",
    "user": {
      "login": "realead",
      "id": 17513912,
      "node_id": "MDQ6VXNlcjE3NTEzOTEy",
      "avatar_url": "https://avatars2.githubusercontent.com/u/17513912?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/realead",
      "html_url": "https://github.com/realead",
      "followers_url": "https://api.github.com/users/realead/followers",
      "following_url": "https://api.github.com/users/realead/following{/other_user}",
      "gists_url": "https://api.github.com/users/realead/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/realead/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/realead/subscriptions",
      "organizations_url": "https://api.github.com/users/realead/orgs",
      "repos_url": "https://api.github.com/users/realead/repos",
      "events_url": "https://api.github.com/users/realead/events{/privacy}",
      "received_events_url": "https://api.github.com/users/realead/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-05T12:40:33Z",
    "updated_at": "2018-08-05T12:40:33Z",
    "author_association": "CONTRIBUTOR",
    "body": "The problem at core of this issue, is that pandas' `unique` and numpy's `unique` have different notions about nan's in the case of `float64`:\r\n\r\n```\r\n>>> pd.unique([np.nan, np.nan])\r\narray([ nan])\r\n>>> np.unique([np.nan, np.nan])\r\narray([ nan,  nan])\r\n```\r\n\r\nFor N>10^6, pandas' notion of unique is switched to numpy's notion of unique:\r\n\r\n```\r\n    f = lambda x, y: htable.ismember_object(x, values)\r\n    # GH16012\r\n    # Ensure np.in1d doesn't get object types or it *may* throw an exception\r\n    if len(comps) > 1000000 and not is_object_dtype(comps):\r\n          f = lambda x, y: np.in1d(x, y)\r\n```\r\n\r\n[Here the whole code](https://github.com/pandas-dev/pandas/blob/master/pandas/core/algorithms.py#L425)"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/410519409",
    "html_url": "https://github.com/pandas-dev/pandas/issues/22205#issuecomment-410519409",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22205",
    "id": 410519409,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDUxOTQwOQ==",
    "user": {
      "login": "realead",
      "id": 17513912,
      "node_id": "MDQ6VXNlcjE3NTEzOTEy",
      "avatar_url": "https://avatars2.githubusercontent.com/u/17513912?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/realead",
      "html_url": "https://github.com/realead",
      "followers_url": "https://api.github.com/users/realead/followers",
      "following_url": "https://api.github.com/users/realead/following{/other_user}",
      "gists_url": "https://api.github.com/users/realead/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/realead/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/realead/subscriptions",
      "organizations_url": "https://api.github.com/users/realead/orgs",
      "repos_url": "https://api.github.com/users/realead/repos",
      "events_url": "https://api.github.com/users/realead/events{/privacy}",
      "received_events_url": "https://api.github.com/users/realead/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-05T13:12:31Z",
    "updated_at": "2018-08-05T14:20:08Z",
    "author_association": "CONTRIBUTOR",
    "body": "It seems, as if `np.in1d` is used because it is faster. \r\n\r\nI don't  understand the [the 'in1d- algorithm](https://github.com/numpy/numpy/blob/23cb605d7f230ee2b00c0e7167256cf434731b16/numpy/lib/arraysetops.py#L434) good enough, to tell what is going on, but here are my benchmark and timings:\r\n```\r\nport pandas.core.algorithms as algos\r\nuses_pandas = np.arange(10**6)\r\nuses_numpy = np.arange(10**6+1)\r\nsmall = np.arange(2)\r\nsmall2 = np.arange(10)\r\nlarge = np.arange(10**7)\r\n%timeit algos.isin(uses_pandas, small)\r\n%timeit algos.isin(uses_numpy, small)\r\n%timeit algos.isin(uses_pandas, small2)\r\n%timeit algos.isin(uses_numpy, small2)\r\n%timeit algos.isin(uses_pandas, large)\r\n%timeit algos.isin(uses_numpy, large)\r\n```\r\n\r\nresults in\r\n```\r\n                pandas vs numpy\r\nsmall          4.4ms      2.4ms\r\nsmall2        5.5ms     10.9ms\r\nlarge          277 ms 699 ms\r\n```\r\nTo me it seems, as if for large inputs of look-up-values, the hash-map-approach could be the better one.\r\n\r\nActually, [there is an optimization](https://github.com/numpy/numpy/blob/23cb605d7f230ee2b00c0e7167256cf434731b16/numpy/lib/arraysetops.py#L510) if the size of the second array is very small:\r\n\r\n```\r\n    if len(ar2) < 10 * len(ar1) ** 0.145 or contains_object:\r\n        if invert:\r\n            mask = np.ones(len(ar1), dtype=bool)\r\n            for a in ar2:\r\n                mask &= (ar1 != a)\r\n        else:\r\n            mask = np.zeros(len(ar1), dtype=bool)\r\n            for a in ar2:\r\n                mask |= (ar1 == a)\r\n      return mask\r\n```\r\n\r\nwhich leads to `O(n*m)` behavior (n.m - sizes of input arrays)for small sizes `m` of the second array. This linear behavior can also be seen in the timing.\r\n\r\nThe running times of algorithms are\r\n\r\n pandas:    `O(n+m)` if look-up can be assumed to be `O(1)`\r\n np.in1d:    `O(n*log(n)+m*log(m) +(N+M)log(N+M))` if there are N/M unique elements in the arrays\r\n\r\nSo it looks like `np.in1d` is only faster if there are less than 5 elements in the second array."
  }
]
