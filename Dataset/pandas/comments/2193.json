[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/10211293",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-10211293",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 10211293,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEwMjExMjkz",
    "user": {
      "login": "ghost",
      "id": 10137,
      "node_id": "MDQ6VXNlcjEwMTM3",
      "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ghost",
      "html_url": "https://github.com/ghost",
      "followers_url": "https://api.github.com/users/ghost/followers",
      "following_url": "https://api.github.com/users/ghost/following{/other_user}",
      "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
      "organizations_url": "https://api.github.com/users/ghost/orgs",
      "repos_url": "https://api.github.com/users/ghost/repos",
      "events_url": "https://api.github.com/users/ghost/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ghost/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-11-09T00:33:01Z",
    "updated_at": "2012-11-09T00:33:01Z",
    "author_association": "NONE",
    "body": "To the best of my knowledge, DataFrames are not lazy. \n\nFor example, in the absence of an `index` arg to the df ctor,  `len(data)` is used to determine the size of the index.\nAssuming you'll need all the data in memory anyway, I don't see how having a row generator will provide a win\nfor you.\n\nIn theory, you might have been able to avoid having two copies of the data in memory at the \nsame time by having a generator of rows, but that's not naturally supported right now afaict.\nYou also can't fake it by [appending rows](http://stackoverflow.com/questions/10715965/add-one-row-in-a-pandas-dataframe) one at a time, because you end up copying the array \neach time.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12459950",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-12459950",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 12459950,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyNDU5OTUw",
    "user": {
      "login": "wesm",
      "id": 329591,
      "node_id": "MDQ6VXNlcjMyOTU5MQ==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/329591?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/wesm",
      "html_url": "https://github.com/wesm",
      "followers_url": "https://api.github.com/users/wesm/followers",
      "following_url": "https://api.github.com/users/wesm/following{/other_user}",
      "gists_url": "https://api.github.com/users/wesm/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/wesm/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/wesm/subscriptions",
      "organizations_url": "https://api.github.com/users/wesm/orgs",
      "repos_url": "https://api.github.com/users/wesm/repos",
      "events_url": "https://api.github.com/users/wesm/events{/privacy}",
      "received_events_url": "https://api.github.com/users/wesm/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-19T19:43:31Z",
    "updated_at": "2013-01-19T19:43:31Z",
    "author_association": "MEMBER",
    "body": "Could you please let me know what API you would want on this issue?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12979494",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-12979494",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 12979494,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyOTc5NDk0",
    "user": {
      "login": "ryanwitt",
      "id": 94631,
      "node_id": "MDQ6VXNlcjk0NjMx",
      "avatar_url": "https://avatars3.githubusercontent.com/u/94631?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ryanwitt",
      "html_url": "https://github.com/ryanwitt",
      "followers_url": "https://api.github.com/users/ryanwitt/followers",
      "following_url": "https://api.github.com/users/ryanwitt/following{/other_user}",
      "gists_url": "https://api.github.com/users/ryanwitt/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ryanwitt/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ryanwitt/subscriptions",
      "organizations_url": "https://api.github.com/users/ryanwitt/orgs",
      "repos_url": "https://api.github.com/users/ryanwitt/repos",
      "events_url": "https://api.github.com/users/ryanwitt/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ryanwitt/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-01T03:45:00Z",
    "updated_at": "2013-02-01T03:45:00Z",
    "author_association": "NONE",
    "body": "perhaps something like `DataFrame.from_records_lazy()`?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12986101",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-12986101",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 12986101,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyOTg2MTAx",
    "user": {
      "login": "dw",
      "id": 2315,
      "node_id": "MDQ6VXNlcjIzMTU=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/2315?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dw",
      "html_url": "https://github.com/dw",
      "followers_url": "https://api.github.com/users/dw/followers",
      "following_url": "https://api.github.com/users/dw/following{/other_user}",
      "gists_url": "https://api.github.com/users/dw/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dw/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dw/subscriptions",
      "organizations_url": "https://api.github.com/users/dw/orgs",
      "repos_url": "https://api.github.com/users/dw/repos",
      "events_url": "https://api.github.com/users/dw/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dw/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-01T09:06:48Z",
    "updated_at": "2013-02-01T09:06:48Z",
    "author_association": "NONE",
    "body": "Sorry for the late reply. :)\n\nIt seems the DataFrame constructor is already pretty heavily overloaded, however my initial desire would be for:\n\n```\n>>> pandas.DataFrame((x for x in range(0)))\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/Library/Python/2.7/site-packages/pandas/core/frame.py\", line 417, in __init__\n    raise PandasError('DataFrame constructor not properly called!')\npandas.core.common.PandasError: DataFrame constructor not properly called!\n```\n\nTo result in a valid frame. Looking at the code it seems possible to add (yet another) fall-through for this case, however ryanwitt's suggestion is probably saner, given that the more tests added to that constructor the more magical and unpredictable it'll become.\n\nThe other problem is how to check for an iterable sanely: options appear to be attempting `iter(obj)` (which would succeed for strings!) or `hasattr(obj, 'next')`. Again it's sounding like something that shouldn't be implicitly tested for in a constructor, so +1 for `from_records_lazy()` or perhaps just `from_iter()`.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/13544821",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-13544821",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 13544821,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzNTQ0ODIx",
    "user": {
      "login": "snth",
      "id": 652285,
      "node_id": "MDQ6VXNlcjY1MjI4NQ==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/652285?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/snth",
      "html_url": "https://github.com/snth",
      "followers_url": "https://api.github.com/users/snth/followers",
      "following_url": "https://api.github.com/users/snth/following{/other_user}",
      "gists_url": "https://api.github.com/users/snth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/snth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/snth/subscriptions",
      "organizations_url": "https://api.github.com/users/snth/orgs",
      "repos_url": "https://api.github.com/users/snth/repos",
      "events_url": "https://api.github.com/users/snth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/snth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-14T12:09:38Z",
    "updated_at": "2013-02-14T12:09:38Z",
    "author_association": "CONTRIBUTOR",
    "body": "+1 for `from_iter()`\n\nI think something like this would be nice to have. For example I have the following utility function which imitates expand.grid() in R:\n\n``` python\nimport itertools as it\nimport operator as op\nimport pandas as pd\n\ndef expand_grid(*args, **kwargs):\n    columns = []\n    lst = []\n    if args:\n        columns += xrange(len(args))\n        lst += args\n    if kwargs:\n        columns += kwargs.iterkeys()\n        lst += kwargs.itervalues()\n    return pd.DataFrame(list(it.product(*lst)), columns=columns)\n\nprint expand_grid([0,1], [1,2,3])\nprint expand_grid(a=[0,1], b=[1,2,3])\nprint expand_grid([0,1], b=[1,2,3])\n```\n\nIt would be nice if we didn't need the list() constructor in the last line of the function and could avoid creating a temporary copy of all the tuples.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/13545664",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-13545664",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 13545664,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzNTQ1NjY0",
    "user": {
      "login": "snth",
      "id": 652285,
      "node_id": "MDQ6VXNlcjY1MjI4NQ==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/652285?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/snth",
      "html_url": "https://github.com/snth",
      "followers_url": "https://api.github.com/users/snth/followers",
      "following_url": "https://api.github.com/users/snth/following{/other_user}",
      "gists_url": "https://api.github.com/users/snth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/snth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/snth/subscriptions",
      "organizations_url": "https://api.github.com/users/snth/orgs",
      "repos_url": "https://api.github.com/users/snth/repos",
      "events_url": "https://api.github.com/users/snth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/snth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-14T12:36:57Z",
    "updated_at": "2013-02-14T12:36:57Z",
    "author_association": "CONTRIBUTOR",
    "body": "Since in my case the total number of rows can be computed upfront, I tried to see if I could get it to work with some duck typing. Alas, I got stuck when it calls out to `pandas.lib`, here's what I had gotten to by then:\n\n``` python\ndef expand_grid3(*args, **kwargs):\n    columns = []\n    lst = []\n    if args:\n        columns += xrange(len(args))\n        lst += args\n    if kwargs:\n        columns += kwargs.iterkeys()\n        lst += kwargs.itervalues()\n    class _proditer(list):\n        def __init__(self, l):\n            self.N = reduce(op.mul, map(len, l), 1)\n            self.iter_ = it.product(*l)\n        def __iter__(self): return self\n        def next(self): return next(self.iter_)\n        def __len__(self): return self.N\n        def __getitem__(self, item):\n            if item==0:\n                value = next(self.iter_)\n                self.iter_ = it.chain(iter([value]), self.iter_)\n                return value\n            else:\n                raise NotImplementedError(\"item=={}\".format(item))\n    lst = _proditer(lst)\n    return pd.DataFrame.from_records(lst, index=range(len(lst)), columns=columns)\n```\n\nbut this fails with:\n\n``` python\nIn [3]: expand_grid3([0,1], [1,2,3])\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-3-f632bd646903> in <module>()\n----> 1 expand_grid3([0,1], [1,2,3])\n\n/home/tobias/code/dev/argon/scripts/expand_grid.py in expand_grid3(*args, **kwargs)\n     68                 raise NotImplementedError(\"item=={}\".format(item))\n     69     lst = _proditer(lst)\n---> 70     return pd.DataFrame.from_records(lst, index=range(len(lst)), columns=columns)\n     71 \n     72 print expand_grid3([0,1], [1,2,3])\n\n/home/tobias/code/envs/mac/local/lib/python2.7/site-packages/pandas-0.9.0-py2.7-linux-x86_64.egg/pandas/core/frame.pyc in from_records(cls, data, index, exclude, columns, names, coerce_float)\n    844         else:\n    845             sdict, columns = _to_sdict(data, columns,\n--> 846                                        coerce_float=coerce_float)\n    847 \n    848         if exclude is None:\n\n/home/tobias/code/envs/mac/local/lib/python2.7/site-packages/pandas-0.9.0-py2.7-linux-x86_64.egg/pandas/core/frame.pyc in _to_sdict(data, columns, coerce_float)\n   4958         return {}, columns\n   4959     if isinstance(data[0], (list, tuple)):\n-> 4960         return _list_to_sdict(data, columns, coerce_float=coerce_float)\n   4961     elif isinstance(data[0], dict):\n   4962         return _list_of_dict_to_sdict(data, columns, coerce_float=coerce_float)\n\n/home/tobias/code/envs/mac/local/lib/python2.7/site-packages/pandas-0.9.0-py2.7-linux-x86_64.egg/pandas/core/frame.pyc in _list_to_sdict(data, columns, coerce_float)\n   4971 def _list_to_sdict(data, columns, coerce_float=False):\n   4972     if len(data) > 0 and isinstance(data[0], tuple):\n-> 4973         content = list(lib.to_object_array_tuples(data).T)\n   4974     elif len(data) > 0:\n   4975         # list of lists\n\nTypeError: Argument 'rows' has incorrect type (expected list, got _proditer)\n\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/13570270",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-13570270",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 13570270,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzNTcwMjcw",
    "user": {
      "login": "ghost",
      "id": 10137,
      "node_id": "MDQ6VXNlcjEwMTM3",
      "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ghost",
      "html_url": "https://github.com/ghost",
      "followers_url": "https://api.github.com/users/ghost/followers",
      "following_url": "https://api.github.com/users/ghost/following{/other_user}",
      "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
      "organizations_url": "https://api.github.com/users/ghost/orgs",
      "repos_url": "https://api.github.com/users/ghost/repos",
      "events_url": "https://api.github.com/users/ghost/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ghost/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-14T18:23:34Z",
    "updated_at": "2013-02-14T18:23:34Z",
    "author_association": "NONE",
    "body": "The form `(x for x in xrange(10)` suggested by dw yields a generator,\nand accepting a  generator that yields fixed-length sequences seems \nlike the logical choice here:\n\n``` python\nIn [46]: def data_source():\n    ...:     for row_count in xrange(10):\n    ...:         yield np.random.rand(5)\n    ...: pd.DataFrame(list(data_source()))\n    ...: \nOut[46]: \n          0         1         2         3         4\n0  0.241975  0.336069  0.584298  0.990567  0.628024\n1  0.491197  0.153000  0.069927  0.923961  0.321994\n2  0.331411  0.135619  0.742957  0.917101  0.751598\n3  0.259744  0.566237  0.854419  0.478699  0.322557\n4  0.237514  0.725468  0.258899  0.106149  0.238813\n5  0.703378  0.905303  0.200714  0.492119  0.050031\n6  0.881858  0.199581  0.057018  0.855477  0.094684\n7  0.006712  0.081865  0.359633  0.758901  0.587118\n8  0.511695  0.788931  0.753998  0.159687  0.678947\n9  0.267654  0.840976  0.278592  0.051802  0.704802\n\nIn [47]: pd.DataFrame(data_source())\n---------------------------------------------------------------------------\nPandasError                               Traceback (most recent call last)\n<ipython-input-47-5667ec91c127> in <module>()\n----> 1 pd.DataFrame(data_source())\n\n/home/user1/src/pandas/pandas/core/frame.pyc in __init__(self, data, index, columns, dtype, copy)\n    445                                          copy=False)\n    446             else:\n--> 447                 raise PandasError('DataFrame constructor not properly called!')\n    448 \n    449         NDFrame.__init__(self, mgr)\n\nPandasError: DataFrame constructor not properly called!\n\nIn [48]: type(data_source())\nOut[48]: generator\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/30760439",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-30760439",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 30760439,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzYwNDM5",
    "user": {
      "login": "elyase",
      "id": 1175888,
      "node_id": "MDQ6VXNlcjExNzU4ODg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1175888?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/elyase",
      "html_url": "https://github.com/elyase",
      "followers_url": "https://api.github.com/users/elyase/followers",
      "following_url": "https://api.github.com/users/elyase/following{/other_user}",
      "gists_url": "https://api.github.com/users/elyase/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/elyase/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/elyase/subscriptions",
      "organizations_url": "https://api.github.com/users/elyase/orgs",
      "repos_url": "https://api.github.com/users/elyase/repos",
      "events_url": "https://api.github.com/users/elyase/events{/privacy}",
      "received_events_url": "https://api.github.com/users/elyase/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-12-17T15:33:25Z",
    "updated_at": "2013-12-17T15:33:25Z",
    "author_association": "NONE",
    "body": "+1, this would be nice to have, the API can be similar to numpy.fromiter where if you know the number of rows memory can can be preallocated. The main use would be to avoid having two copies of the same data in memory at the same time.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/30761514",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-30761514",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 30761514,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwNzYxNTE0",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-12-17T15:43:55Z",
    "updated_at": "2013-12-17T15:43:55Z",
    "author_association": "CONTRIBUTOR",
    "body": "you can't really preallocate this \n\ninstead you allocate chunks and fill, appending as needed\nthen take a view of the final memory\n\ncould be done but only necessary for really really large structures\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31302544",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-31302544",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 31302544,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzAyNTQ0",
    "user": {
      "login": "ghost",
      "id": 10137,
      "node_id": "MDQ6VXNlcjEwMTM3",
      "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ghost",
      "html_url": "https://github.com/ghost",
      "followers_url": "https://api.github.com/users/ghost/followers",
      "following_url": "https://api.github.com/users/ghost/following{/other_user}",
      "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
      "organizations_url": "https://api.github.com/users/ghost/orgs",
      "repos_url": "https://api.github.com/users/ghost/repos",
      "events_url": "https://api.github.com/users/ghost/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ghost/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-12-28T18:59:30Z",
    "updated_at": "2013-12-28T19:05:51Z",
    "author_association": "NONE",
    "body": "@jreback, this just came to mind and it seems like there's a possible memory win here after all.\nIf the number of records is known, and the dtypes are inferred from the first record, we can allocate\nthe numpy arrays, mutate them one `.next()` at a time. The dataframe ctor can then reuse the resulting\narrays to form the df without copying.\nPeak memory is then the numpy array + epsilon, rather then numpy array + full dataset as list of lists\nof python objects. That can be a significant diff given the mem overhead of a python object .\n\n0.14?\n\nhttps://github.com/pydata/pandas/issues/1794\nhttps://github.com/pydata/pandas/issues/2305\n\n[from_records](https://github.com/pydata/pandas/commit/4a6e6d297d882a5e0b2d4f9e9eb71b42cca2bee0#diff-1e79abbbdd150d4771b91ea60a4e1cc7R909) seems to be doing the wrong thing memory-wise as well . Am I missing something obvious?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31302711",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-31302711",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 31302711,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzAyNzEx",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-12-28T19:08:31Z",
    "updated_at": "2013-12-28T19:08:31Z",
    "author_association": "CONTRIBUTOR",
    "body": "yep not that hard\nyou would have to intercept the generator as a separate case in init\nthen ultimately just create an ndarray then. init_ndarray\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31302725",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-31302725",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 31302725,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzAyNzI1",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-12-28T19:09:46Z",
    "updated_at": "2013-12-28T19:09:46Z",
    "author_association": "CONTRIBUTOR",
    "body": "FYI could refactor from_records in any event to be more integrated into reg dataframe ctor\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31302754",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-31302754",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 31302754,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzAyNzU0",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-12-28T19:11:06Z",
    "updated_at": "2013-12-28T19:11:06Z",
    "author_association": "CONTRIBUTOR",
    "body": "somewhat related (if from_records is refactored), #4464\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32469580",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-32469580",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 32469580,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDY5NTgw",
    "user": {
      "login": "ghost",
      "id": 10137,
      "node_id": "MDQ6VXNlcjEwMTM3",
      "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ghost",
      "html_url": "https://github.com/ghost",
      "followers_url": "https://api.github.com/users/ghost/followers",
      "following_url": "https://api.github.com/users/ghost/following{/other_user}",
      "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
      "organizations_url": "https://api.github.com/users/ghost/orgs",
      "repos_url": "https://api.github.com/users/ghost/repos",
      "events_url": "https://api.github.com/users/ghost/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ghost/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-16T13:47:06Z",
    "updated_at": "2014-01-16T13:47:06Z",
    "author_association": "NONE",
    "body": "Comparing memory footprint in a roundabout way:\n\n```\nIn [2]: import pickle\n   ...: l=arange(1000000)\n   ...: pickle.dump(l,open(\"/tmp/py\",\"wb\"))\nIn [4]: np.save(open(\"/tmp/np\",\"wb\"),np.array(l))\nIn [5]: ll /tmp/np\n-rw-rw-r--. 1 user1 8000080 Jan 16 15:45 /tmp/np\nIn [6]: ll /tmp/py\n-rw-rw-r--. 1 user1 29340698 Jan 16 15:44 /tmp/py\n```\n\nso a roughly 4x reduction in footprint by not materializing fully in memory.\n@jreback, is that a valid measurement or did I miss something?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32469838",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-32469838",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 32469838,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDY5ODM4",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-16T13:50:16Z",
    "updated_at": "2014-01-16T13:50:16Z",
    "author_association": "CONTRIBUTOR",
    "body": "I don't know why you think that is a valid measurement. They are 2 different formats. npz is a specific binary format, where pickle is a text-ified binary repr\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32470428",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-32470428",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 32470428,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDcwNDI4",
    "user": {
      "login": "ghost",
      "id": 10137,
      "node_id": "MDQ6VXNlcjEwMTM3",
      "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ghost",
      "html_url": "https://github.com/ghost",
      "followers_url": "https://api.github.com/users/ghost/followers",
      "following_url": "https://api.github.com/users/ghost/following{/other_user}",
      "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
      "organizations_url": "https://api.github.com/users/ghost/orgs",
      "repos_url": "https://api.github.com/users/ghost/repos",
      "events_url": "https://api.github.com/users/ghost/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ghost/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-16T13:57:20Z",
    "updated_at": "2014-01-16T13:57:46Z",
    "author_association": "NONE",
    "body": "I was trying to measure the savings by eliminating the per-object overhead of python objects\nin favor of numpy arrays. np.save surely takes advantage of that to store things more compactly,\nillustrating the potential in-memory saving, pickle apperently does not.\n\nWill look around for a better way to measure in-memory python footprint.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32472763",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-32472763",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 32472763,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDcyNzYz",
    "user": {
      "login": "ghost",
      "id": 10137,
      "node_id": "MDQ6VXNlcjEwMTM3",
      "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ghost",
      "html_url": "https://github.com/ghost",
      "followers_url": "https://api.github.com/users/ghost/followers",
      "following_url": "https://api.github.com/users/ghost/following{/other_user}",
      "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
      "organizations_url": "https://api.github.com/users/ghost/orgs",
      "repos_url": "https://api.github.com/users/ghost/repos",
      "events_url": "https://api.github.com/users/ghost/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ghost/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-16T14:26:11Z",
    "updated_at": "2014-01-16T14:29:38Z",
    "author_association": "NONE",
    "body": "Second try:\n\n```\nIn [27]: from pympler.asizeof import asizeof\n    ...: asizeof([1,2],infer=True)-asizeof([2],infer=True)\nOut[27]: 32\n\nIn [29]: np.save(open(\"/tmp/np1\",\"wb\"),np.array([1,2]))\n    ...: np.save(open(\"/tmp/np2\",\"wb\"),np.array([1]))\n\nIn [30]: ll /tmp/np1\n-rw-rw-r--. 1 user1 96 Jan 16 16:22 /tmp/np1\n\nIn [31]: ll /tmp/np2\n-rw-rw-r--. 1 user1 88 Jan 16 16:22 /tmp/np2\n\nIn [32]: 96-88\nOut[32]: 8\n```\n\npython objects require 32 bytes to store an additional int64, numpy array require only 8 (64bits), a 4x difference.\n\nThat's an added bonus to the basic win of not having an extra copy of the data in memory during construction.\nnumpy arrays are way more efficient in storing the data in memory.\n\nIs _that_ a valid conclusion in your eyes?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32472764",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-32472764",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 32472764,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDcyNzY0",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-16T14:26:11Z",
    "updated_at": "2014-01-16T14:26:11Z",
    "author_association": "CONTRIBUTOR",
    "body": "did you try memory_profiler (use via %memit)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32472977",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-32472977",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 32472977,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDcyOTc3",
    "user": {
      "login": "ghost",
      "id": 10137,
      "node_id": "MDQ6VXNlcjEwMTM3",
      "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ghost",
      "html_url": "https://github.com/ghost",
      "followers_url": "https://api.github.com/users/ghost/followers",
      "following_url": "https://api.github.com/users/ghost/following{/other_user}",
      "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
      "organizations_url": "https://api.github.com/users/ghost/orgs",
      "repos_url": "https://api.github.com/users/ghost/repos",
      "events_url": "https://api.github.com/users/ghost/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ghost/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-16T14:29:00Z",
    "updated_at": "2014-01-16T14:29:00Z",
    "author_association": "NONE",
    "body": "It monitors overall process memory, I don't trust it for detailed measurement.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32473288",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-32473288",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 32473288,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDczMjg4",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-16T14:32:56Z",
    "updated_at": "2014-01-16T14:32:56Z",
    "author_association": "CONTRIBUTOR",
    "body": "oh I agree numpy arrays are more efficient, but the point is that they ARE starting as python objects, so not sure this makes much difference in practice as it should be chunked anyhow (THAT is how to save memory)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32473572",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-32473572",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 32473572,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDczNTcy",
    "user": {
      "login": "ghost",
      "id": 10137,
      "node_id": "MDQ6VXNlcjEwMTM3",
      "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ghost",
      "html_url": "https://github.com/ghost",
      "followers_url": "https://api.github.com/users/ghost/followers",
      "following_url": "https://api.github.com/users/ghost/following{/other_user}",
      "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
      "organizations_url": "https://api.github.com/users/ghost/orgs",
      "repos_url": "https://api.github.com/users/ghost/repos",
      "events_url": "https://api.github.com/users/ghost/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ghost/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-16T14:36:49Z",
    "updated_at": "2014-01-16T14:37:52Z",
    "author_association": "NONE",
    "body": "They are starting a python objects, but potentially only one row at a time. That's the iterator's business.\nIf that's the case, then peak mem usage will be (for this int64 case for example) O(x) instead of O(x+4x).\n\nIsn't that right?\n\nUpdate: mod the fact that O(x) = O(5x)... :) . far better constants is what I meant.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32473702",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-32473702",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 32473702,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDczNzAy",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-16T14:38:19Z",
    "updated_at": "2014-01-16T14:38:19Z",
    "author_association": "CONTRIBUTOR",
    "body": "I agree....I just think the soln is easier to simply chunk the stream into say x rows, then create frames and concatenate at the end, rather than handle this one row at a time. makes code much simpler with a guaranteed peak maxx mem usage.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32473902",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-32473902",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 32473902,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDczOTAy",
    "user": {
      "login": "ghost",
      "id": 10137,
      "node_id": "MDQ6VXNlcjEwMTM3",
      "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ghost",
      "html_url": "https://github.com/ghost",
      "followers_url": "https://api.github.com/users/ghost/followers",
      "following_url": "https://api.github.com/users/ghost/following{/other_user}",
      "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
      "organizations_url": "https://api.github.com/users/ghost/orgs",
      "repos_url": "https://api.github.com/users/ghost/repos",
      "events_url": "https://api.github.com/users/ghost/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ghost/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-16T14:40:43Z",
    "updated_at": "2014-01-16T15:11:15Z",
    "author_association": "NONE",
    "body": "Absolutely. I read your comments in the other thread and it's a losing battle to support larger dataset\nby reducing memory footprint. chunking is a much more general solution.\nThere's still reasonable cases where this would make a big difference for users, in eliminating the requirement\nto move to a more complex worklfow.\n\n5x reduction in max memory usage is worth doing I think. even if it won't solve everyone's not-small-data problems.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32474240",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-32474240",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 32474240,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDc0MjQw",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-16T14:44:25Z",
    "updated_at": "2014-01-16T14:44:25Z",
    "author_association": "CONTRIBUTOR",
    "body": "agreed....#5902 looks interesting. IMHO its going to be non-trivial to do it, but possible.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32481339",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-32481339",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 32481339,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDgxMzM5",
    "user": {
      "login": "ghost",
      "id": 10137,
      "node_id": "MDQ6VXNlcjEwMTM3",
      "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ghost",
      "html_url": "https://github.com/ghost",
      "followers_url": "https://api.github.com/users/ghost/followers",
      "following_url": "https://api.github.com/users/ghost/following{/other_user}",
      "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
      "organizations_url": "https://api.github.com/users/ghost/orgs",
      "repos_url": "https://api.github.com/users/ghost/repos",
      "events_url": "https://api.github.com/users/ghost/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ghost/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-16T15:54:48Z",
    "updated_at": "2014-01-16T15:54:57Z",
    "author_association": "NONE",
    "body": "yeah, though we discussed this recently before that and @elyase made a comment to the same\neffect a little before the idea occured to me.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/231516102",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2193#issuecomment-231516102",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2193",
    "id": 231516102,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzMTUxNjEwMg==",
    "user": {
      "login": "pkch",
      "id": 1593648,
      "node_id": "MDQ6VXNlcjE1OTM2NDg=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1593648?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pkch",
      "html_url": "https://github.com/pkch",
      "followers_url": "https://api.github.com/users/pkch/followers",
      "following_url": "https://api.github.com/users/pkch/following{/other_user}",
      "gists_url": "https://api.github.com/users/pkch/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pkch/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pkch/subscriptions",
      "organizations_url": "https://api.github.com/users/pkch/orgs",
      "repos_url": "https://api.github.com/users/pkch/repos",
      "events_url": "https://api.github.com/users/pkch/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pkch/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-09T05:15:57Z",
    "updated_at": "2016-07-09T05:19:51Z",
    "author_association": "NONE",
    "body": "What's the rational of DataFrame() accepting a generator as an input but not an iterator? It converts generator to a list anyway, so why not do the same with an iterator? (Note I'm not talking about performance, just convenience.)\n\n```\ndef gen():\n    for i in range(5):\n        yield {'a': 1, 'b': 10}\npd.DataFrame(gen(), columns=['a', 'b']) # ok\npd.DataFrame(itertools.islice(gen(), 2), columns=['a', 'b']) # TypeError: data argument can't be an iterator \n\n```\n"
  }
]
