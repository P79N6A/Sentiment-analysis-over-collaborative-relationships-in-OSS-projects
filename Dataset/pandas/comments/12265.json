[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/181809005",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12265#issuecomment-181809005",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12265",
    "id": 181809005,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4MTgwOTAwNQ==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-09T10:37:47Z",
    "updated_at": "2016-02-09T10:37:47Z",
    "author_association": "MEMBER",
    "body": "> Maybe my expectations were wrong?\n\nPossibly. `chunksize` is in any case a somewhat misleading keyword:\n1. Using `chunksize` does not necessarily fetches the data from the database into python in chunks. By default it will fetch all data into memory at once, and only returns the data in chunks (so the conversion to a dataframe happens in chunks). Generally, this is a limitation of the database drivers.  \n   See also https://github.com/pydata/pandas/issues/10693. In fact, pandas could try to set the appropriate `execution_options`, but until then you can set this yourself for the engine you provide to `read_sql` (but this works only using `psycopg2`).\n2. Python does not necessarily free all memory that is not used anymore to the OS, so it will also depend on how you measured the memory usage (as you will probably know since you tried the garbage collector)\n\nSide note, there may be better ways for database migration. Eg teh author of SQLAlchemy has also a database migration tool: https://pypi.python.org/pypi/alembic\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/181811745",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12265#issuecomment-181811745",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12265",
    "id": 181811745,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4MTgxMTc0NQ==",
    "user": {
      "login": "klonuo",
      "id": 361447,
      "node_id": "MDQ6VXNlcjM2MTQ0Nw==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/361447?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/klonuo",
      "html_url": "https://github.com/klonuo",
      "followers_url": "https://api.github.com/users/klonuo/followers",
      "following_url": "https://api.github.com/users/klonuo/following{/other_user}",
      "gists_url": "https://api.github.com/users/klonuo/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/klonuo/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/klonuo/subscriptions",
      "organizations_url": "https://api.github.com/users/klonuo/orgs",
      "repos_url": "https://api.github.com/users/klonuo/repos",
      "events_url": "https://api.github.com/users/klonuo/events{/privacy}",
      "received_events_url": "https://api.github.com/users/klonuo/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-09T10:47:25Z",
    "updated_at": "2016-02-09T10:47:25Z",
    "author_association": "CONTRIBUTOR",
    "body": "Thanks for your prompt reply. \nSo I've been mislead with chunksize... I remember I was using it in the past, but perhaps understood it wrong, and used it with tables that fits in memory...\n\nPG is also an option for me instead MSSQL, but I'll try alembic first.\n\nCheers\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/181818257",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12265#issuecomment-181818257",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12265",
    "id": 181818257,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4MTgxODI1Nw==",
    "user": {
      "login": "klonuo",
      "id": 361447,
      "node_id": "MDQ6VXNlcjM2MTQ0Nw==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/361447?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/klonuo",
      "html_url": "https://github.com/klonuo",
      "followers_url": "https://api.github.com/users/klonuo/followers",
      "following_url": "https://api.github.com/users/klonuo/following{/other_user}",
      "gists_url": "https://api.github.com/users/klonuo/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/klonuo/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/klonuo/subscriptions",
      "organizations_url": "https://api.github.com/users/klonuo/orgs",
      "repos_url": "https://api.github.com/users/klonuo/repos",
      "events_url": "https://api.github.com/users/klonuo/events{/privacy}",
      "received_events_url": "https://api.github.com/users/klonuo/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-09T11:07:43Z",
    "updated_at": "2016-02-09T11:07:43Z",
    "author_association": "CONTRIBUTOR",
    "body": "PG example parameters for this example would be very nice ;)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/181838631",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12265#issuecomment-181838631",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12265",
    "id": 181838631,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4MTgzODYzMQ==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-09T12:07:00Z",
    "updated_at": "2016-02-09T12:07:00Z",
    "author_association": "MEMBER",
    "body": "In principle, I think it should be something like this:\n\n```\nengine = create_engine(\"...\", execution_options=dict(stream_results=True))\n\nfor table in pd.read_sql_query('SELECT * FROM %s' % table_name, engine, chunksize=100000):\n    ...\n```\n\nBut, I never tested this myself. Would be interesting to hear experiences with it.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/181852641",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12265#issuecomment-181852641",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12265",
    "id": 181852641,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4MTg1MjY0MQ==",
    "user": {
      "login": "klonuo",
      "id": 361447,
      "node_id": "MDQ6VXNlcjM2MTQ0Nw==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/361447?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/klonuo",
      "html_url": "https://github.com/klonuo",
      "followers_url": "https://api.github.com/users/klonuo/followers",
      "following_url": "https://api.github.com/users/klonuo/following{/other_user}",
      "gists_url": "https://api.github.com/users/klonuo/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/klonuo/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/klonuo/subscriptions",
      "organizations_url": "https://api.github.com/users/klonuo/orgs",
      "repos_url": "https://api.github.com/users/klonuo/repos",
      "events_url": "https://api.github.com/users/klonuo/events{/privacy}",
      "received_events_url": "https://api.github.com/users/klonuo/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-09T12:53:16Z",
    "updated_at": "2016-02-09T12:53:16Z",
    "author_association": "CONTRIBUTOR",
    "body": "Thanks Joris, you seem like a really nice person\n\nunfortunately your snippet seems like not enough:\n\n``` python\nimport pandas as pd\nfrom sqlalchemy import create_engine\n\nmy_engine = create_engine(\"mysql+pymysql://root:pass@localhost/gen\")\npg_engine = create_engine('postgresql://postgres:postgres@localhost:5432/gen',\n                          execution_options=dict(stream_results=True))\n\nfor table_name in tables.keys():\n    for table in pd.read_sql('SELECT * FROM %s' % table_name, \n                             my_engine, \n                             chunksize=10000):\n\n        table.to_sql(name=table_name, con=pg_engine, if_exists='append')\n```\n\nI mean this is just for reference. It would be nice if we could migrate data in chunks to PG just by using pandas.\n\nAnyway I'm reading alembic and I will put here simple script if it's simple as in pandas :)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/181865128",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12265#issuecomment-181865128",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12265",
    "id": 181865128,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4MTg2NTEyOA==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-09T13:29:29Z",
    "updated_at": "2016-02-09T13:29:29Z",
    "author_association": "MEMBER",
    "body": "Ah, but note that the `execution_option` of `stream_results` is for _fetching_ the data. You are fetching the data from MySQL, which does not support this, and so the above will still fetch all data at once into memory, so it is normal you do not see any difference.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/183790765",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12265#issuecomment-183790765",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12265",
    "id": 183790765,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4Mzc5MDc2NQ==",
    "user": {
      "login": "klonuo",
      "id": 361447,
      "node_id": "MDQ6VXNlcjM2MTQ0Nw==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/361447?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/klonuo",
      "html_url": "https://github.com/klonuo",
      "followers_url": "https://api.github.com/users/klonuo/followers",
      "following_url": "https://api.github.com/users/klonuo/following{/other_user}",
      "gists_url": "https://api.github.com/users/klonuo/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/klonuo/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/klonuo/subscriptions",
      "organizations_url": "https://api.github.com/users/klonuo/orgs",
      "repos_url": "https://api.github.com/users/klonuo/repos",
      "events_url": "https://api.github.com/users/klonuo/events{/privacy}",
      "received_events_url": "https://api.github.com/users/klonuo/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-14T01:40:21Z",
    "updated_at": "2016-02-14T05:20:17Z",
    "author_association": "CONTRIBUTOR",
    "body": "Several days later, for reference...\n\nAlembic was too complicated for my concentration. I tried FME and Navicat apps, and while later didn't manage to make migration through \"Data transfer\" for all tables, former migrated successfully, but although MySQL tables were encoded in UTF-8 it didn't use `nvarchar` data type for SQL Server, so I got records with garbage characters. On top of it no index was preserved.\n\nSo I used Python (^_^):\n\n``` python\n#!/usr/bin/env python3\n\nimport pandas as pd\nfrom sqlalchemy import create_engine\n\nmy_engine = create_engine(\"mysql+pymysql://root:pass@localhost/gen?charset=utf8\")\nms_engine = create_engine('mssql+pyodbc://localhost/gen?driver=SQL Server')\n\nchunksize = 10000\nfor table_name in ['topics', 'fiction', 'compact']:\n\n    row_count = int(pd.read_sql('SELECT COUNT(*) FROM {table_name}'.format(\n        table_name=table_name), my_engine).values)\n\n    for i in range(int(row_count / chunksize) + 1):\n        query = 'SELECT * FROM {table_name} LIMIT {offset}, {chunksize}'.format(\n            table_name=table_name, offset=i * chunksize, chunksize=chunksize)\n\n        pd.read_sql_query(query, con=my_engine).to_sql(\n            name=table_name, con=ms_engine, if_exists='append', index=False)\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/231867862",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12265#issuecomment-231867862",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12265",
    "id": 231867862,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzMTg2Nzg2Mg==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-07-11T21:16:44Z",
    "updated_at": "2016-07-11T21:16:44Z",
    "author_association": "MEMBER",
    "body": "@tfurmston I notice you removed your comment. But, it was a very useful comment, so if you want, feel free to add it again.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/292196187",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12265#issuecomment-292196187",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12265",
    "id": 292196187,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjE5NjE4Nw==",
    "user": {
      "login": "robertdavidwest",
      "id": 2637612,
      "node_id": "MDQ6VXNlcjI2Mzc2MTI=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/2637612?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/robertdavidwest",
      "html_url": "https://github.com/robertdavidwest",
      "followers_url": "https://api.github.com/users/robertdavidwest/followers",
      "following_url": "https://api.github.com/users/robertdavidwest/following{/other_user}",
      "gists_url": "https://api.github.com/users/robertdavidwest/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/robertdavidwest/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/robertdavidwest/subscriptions",
      "organizations_url": "https://api.github.com/users/robertdavidwest/orgs",
      "repos_url": "https://api.github.com/users/robertdavidwest/repos",
      "events_url": "https://api.github.com/users/robertdavidwest/events{/privacy}",
      "received_events_url": "https://api.github.com/users/robertdavidwest/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-04-06T14:42:20Z",
    "updated_at": "2017-04-06T14:42:20Z",
    "author_association": "CONTRIBUTOR",
    "body": "Thank you @klonuo, I'm using your solution for myself. \r\n\r\nQuestion. What if the sqlalchemy engine had another boolean option whereby if selected with chunksize this simple loop with limits is done in the background? Curious what other would think. Or is it better to be as explicit, as @klonuo's solution? "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/311623701",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12265#issuecomment-311623701",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12265",
    "id": 311623701,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMTYyMzcwMQ==",
    "user": {
      "login": "alfonsomhc",
      "id": 3679615,
      "node_id": "MDQ6VXNlcjM2Nzk2MTU=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/3679615?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/alfonsomhc",
      "html_url": "https://github.com/alfonsomhc",
      "followers_url": "https://api.github.com/users/alfonsomhc/followers",
      "following_url": "https://api.github.com/users/alfonsomhc/following{/other_user}",
      "gists_url": "https://api.github.com/users/alfonsomhc/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/alfonsomhc/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/alfonsomhc/subscriptions",
      "organizations_url": "https://api.github.com/users/alfonsomhc/orgs",
      "repos_url": "https://api.github.com/users/alfonsomhc/repos",
      "events_url": "https://api.github.com/users/alfonsomhc/events{/privacy}",
      "received_events_url": "https://api.github.com/users/alfonsomhc/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-28T10:42:09Z",
    "updated_at": "2017-06-28T10:55:14Z",
    "author_association": "CONTRIBUTOR",
    "body": "I see that server side cursors are supported in sqlalchemy now (New in version 1.1.4):\r\nhttp://docs.sqlalchemy.org/en/latest/dialects/mysql.html#server-side-cursors\r\n\r\nI have verified that \r\n```\r\nengine = create_engine('mysql+pymysql://user:password@domain/database', server_side_cursors=True)\r\nresult = engine.execute(sql_query)\r\nresult.fetchone()\r\n```\r\nreturns a row inmediately (i.e. the client doesn't read the complete table in memory). This should be useful to allow read_sql to read in chunks and avoid memory problems. Passing the parameter chunk to fetchmany: \r\n`result.fetchmany(chunk) `\r\nshould do the trick?\r\n"
  }
]
