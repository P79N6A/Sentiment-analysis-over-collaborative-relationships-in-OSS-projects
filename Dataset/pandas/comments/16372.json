[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/301931802",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16372#issuecomment-301931802",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16372",
    "id": 301931802,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwMTkzMTgwMg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-05-16T22:17:59Z",
    "updated_at": "2017-05-16T22:17:59Z",
    "author_association": "CONTRIBUTOR",
    "body": "cc @mrocklin\r\n\r\n@TomAugspurger @jorisvandenbossche \r\n\r\nfrom a practical perspective I don't think this makes a whole lot of difference, but should fix to be correct."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/302011196",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16372#issuecomment-302011196",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16372",
    "id": 302011196,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwMjAxMTE5Ng==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-05-17T07:39:08Z",
    "updated_at": "2017-05-17T07:39:17Z",
    "author_association": "MEMBER",
    "body": "What alternative do you think off to hash upon? Hash the timezone separately and combine the hashes?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/302070276",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16372#issuecomment-302070276",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16372",
    "id": 302070276,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwMjA3MDI3Ng==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-05-17T12:08:19Z",
    "updated_at": "2017-05-17T12:08:19Z",
    "author_association": "CONTRIBUTOR",
    "body": "I think you could do something like this.\r\n```\r\nIn [1]: df = pd.DataFrame({'tz': pd.date_range('20130101', periods=3, tz='UTC').tz_convert('US/Eastern'),\r\n   ...: 'utc': pd.date_range('20130101', periods=3, tz='UTC'),\r\n   ...: 'naive': pd.date_range('20130101', periods=3)})\r\n\r\nIn [2]: df\r\nOut[2]: \r\n       naive                        tz                       utc\r\n0 2013-01-01 2012-12-31 19:00:00-05:00 2013-01-01 00:00:00+00:00\r\n1 2013-01-02 2013-01-01 19:00:00-05:00 2013-01-02 00:00:00+00:00\r\n2 2013-01-03 2013-01-02 19:00:00-05:00 2013-01-03 00:00:00+00:00\r\n\r\nIn [3]: from pandas.util import hash_pandas_object\r\n\r\nIn [6]: hash_pandas_object(pd.DataFrame({'tz':df['tz'],'zone':df['tz'].dt.tz}), index=False)\r\nOut[6]: \r\n0    11960632900184590671\r\n1    17909201100930397932\r\n2      244240496600445005\r\ndtype: uint64\r\n\r\nIn [7]: hash_pandas_object(pd.DataFrame({'utc':df['tz'],'zone':df['utc'].dt.tz}), index=False)\r\nOut[7]: \r\n0     557885042773898185\r\n1    1996380570925580138\r\n2    5435501107539799243\r\ndtype: uint64\r\n\r\nIn [8]: hash_pandas_object(pd.DataFrame({'naivec':df['naive']}), index=False)\r\nOut[8]: \r\n0    14376405836841727586\r\n1     1052390041072582175\r\n2    12596642793234779168\r\ndtype: uint64\r\n```\r\n\r\nIOW, hash the tz as an additional column and combine (which is what we do with a ``DataFrame`` with ``index=False``).\r\n\r\nThis would break backward compat for tz-aware, but (and maybe should document this more), that this is version-to-version hashing, it is not (necessarily) designed to be backward compat."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/428545609",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16372#issuecomment-428545609",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16372",
    "id": 428545609,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyODU0NTYwOQ==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-10T12:03:25Z",
    "updated_at": "2018-10-10T12:03:25Z",
    "author_association": "CONTRIBUTOR",
    "body": "I suppose it depends on what people are using the hashing for. Suppose I have hashed values `a` and a pandas object `x`.\r\n\r\n1. `hash_pandas_object(x) == a`, then `x` *may* be the same as the object that originally hashed to `a`\r\n2. `hash_pandas_ojbect(x) != a`, then `x` *is not* the same as the object that originally hashed to `a`.\r\n\r\nTo me, the most common use case is likely storing hashed values somewhere and wanting to answer \"are these new values the same as what I have hashed?\", so a stronger form of 1. (*is the same* instead of *may be the same*).\r\n\r\nSo I think it's on pandas to either mix the dtype information into the hash somehow,  or provide guidance that you should store the original dtype along with the hashed values.\r\n\r\n> IOW, hash the tz as an additional column and combine (which is what we do with a DataFrame with index=False).\r\n\r\nHashing an extra column seems wasteful. I'd rather have some kind of stable map of each type and do a bit-shift on each type after hashing.\r\n\r\n```\r\ntype_map = {\r\n    int: 0,\r\n    float: 1,\r\n    ...\r\n}\r\n\r\nh = hash_array(obj.values, encoding, hash_key,\r\n               categorize).astype('uint64', copy=False)\r\nh >>= type_map[obj.dtype]\r\n```\r\n\r\nBuilding that type map is tricky (impossible?), because of parameterize types, 3rd party extension types...\r\n\r\n> version-to-version hashing, it is not (necessarily) designed to be backward compat.\r\n\r\nWe should explicitly state that hashing can change between versions. Maintaining that seems like it would be a nightmare."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/428943608",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16372#issuecomment-428943608",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16372",
    "id": 428943608,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyODk0MzYwOA==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-11T12:53:25Z",
    "updated_at": "2018-10-11T12:53:25Z",
    "author_association": "MEMBER",
    "body": "> To me, the most common use case is likely storing hashed values somewhere and wanting to answer \"are these new values the same as what I have hashed?\", so a stronger form of 1. (is the same instead of may be the same).\r\n\r\nYes, I agree with that (that is eg what joblib uses hashing for)\r\n\r\n> Building that type map is tricky (impossible?), because of parameterize types, 3rd party extension types...\r\n\r\nI am not familiar with how hash values are calculated. But would it be possible to somehow combine the hash of the dtype with the hash of the values?"
  }
]
