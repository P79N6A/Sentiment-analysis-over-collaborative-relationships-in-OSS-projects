[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/45187409",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7347#issuecomment-45187409",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7347",
    "id": 45187409,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1MTg3NDA5",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-06-05T07:08:22Z",
    "updated_at": "2014-08-13T09:58:09Z",
    "author_association": "MEMBER",
    "body": "This is coming from a SO question: http://stackoverflow.com/questions/24007762/python-pandas-using-to-sql-with-large-data-frames\n\nWith postgresql I never personally encountered this issue (even with more records), but if it is a problem, then we should solve it!\n\nFor the API, `to_csv` has also this functionality with the keyword `chunksize` (and read_csv and read_hdf to read), so best to take the same keyword. \nThe implementation of `to_csv` is here: https://github.com/pydata/pandas/blob/master/pandas/core/format.py#L1401, and for `to_sql`, your approach above is OK I think, but it can happen at a lower level, namely inside the `insert` function (https://github.com/pydata/pandas/blob/master/pandas/io/sql.py#L579).\n\nIf you want to work on this, certainly do! \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/52551434",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7347#issuecomment-52551434",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7347",
    "id": 52551434,
    "node_id": "MDEyOklzc3VlQ29tbWVudDUyNTUxNDM0",
    "user": {
      "login": "artemyk",
      "id": 833768,
      "node_id": "MDQ6VXNlcjgzMzc2OA==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/833768?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/artemyk",
      "html_url": "https://github.com/artemyk",
      "followers_url": "https://api.github.com/users/artemyk/followers",
      "following_url": "https://api.github.com/users/artemyk/following{/other_user}",
      "gists_url": "https://api.github.com/users/artemyk/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/artemyk/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/artemyk/subscriptions",
      "organizations_url": "https://api.github.com/users/artemyk/orgs",
      "repos_url": "https://api.github.com/users/artemyk/repos",
      "events_url": "https://api.github.com/users/artemyk/events{/privacy}",
      "received_events_url": "https://api.github.com/users/artemyk/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-08-18T20:38:06Z",
    "updated_at": "2014-08-18T20:38:06Z",
    "author_association": "CONTRIBUTOR",
    "body": "I created an initial pull request trying to address this issue.\n"
  }
]
