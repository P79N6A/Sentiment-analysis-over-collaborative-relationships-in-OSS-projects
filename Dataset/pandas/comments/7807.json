[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/49532333",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7807#issuecomment-49532333",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7807",
    "id": 49532333,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ5NTMyMzMz",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-07-19T23:31:28Z",
    "updated_at": "2014-07-19T23:31:28Z",
    "author_association": "CONTRIBUTOR",
    "body": "you can already do this\njust give it a pre allocated frame in the beginning\n\nbut more  to the point\n\nwhy would you want to do this? it's pretty inefficient \n\nyou are much better off creating smaller frames and then concating every once in a while if u really need a big frame\n\nor simply write the data as you generate it to disk (via an hdf table) then query / read as needed (you can do this into a memory buffer as well if u really want)\n\nbut again comes back to the point - what are you doing (aside from appending data)? eg what queries / ops are you doing and why do u think this idiom is useful?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/49532466",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7807#issuecomment-49532466",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7807",
    "id": 49532466,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ5NTMyNDY2",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-07-19T23:37:47Z",
    "updated_at": "2014-07-19T23:37:47Z",
    "author_association": "CONTRIBUTOR",
    "body": "the way to do this is to have a chunked underlying representation of the frame\n\nI would not subclass directly but use dispatching I think\n\nmost operations would then simply concat the used chunks (which is pretty efficient)\nthis would make appending quite cheap as well\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/49534618",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7807#issuecomment-49534618",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7807",
    "id": 49534618,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ5NTM0NjE4",
    "user": {
      "login": "cjermain",
      "id": 4521567,
      "node_id": "MDQ6VXNlcjQ1MjE1Njc=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/4521567?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cjermain",
      "html_url": "https://github.com/cjermain",
      "followers_url": "https://api.github.com/users/cjermain/followers",
      "following_url": "https://api.github.com/users/cjermain/following{/other_user}",
      "gists_url": "https://api.github.com/users/cjermain/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cjermain/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cjermain/subscriptions",
      "organizations_url": "https://api.github.com/users/cjermain/orgs",
      "repos_url": "https://api.github.com/users/cjermain/repos",
      "events_url": "https://api.github.com/users/cjermain/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cjermain/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-07-20T01:45:03Z",
    "updated_at": "2014-07-20T01:45:03Z",
    "author_association": "NONE",
    "body": "Thanks for the suggestions! Since all my data is constantly being appended to a file, I changed my design to read directly from the file. Any time the data is referenced, it is updated from the file using chunks and concatenate as shown in the docs, only loading the new rows using skiprows. You are right, pandas already had it covered.\n"
  }
]
