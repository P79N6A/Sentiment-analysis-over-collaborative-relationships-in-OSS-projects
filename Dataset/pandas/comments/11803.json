[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/163309768",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11803#issuecomment-163309768",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11803",
    "id": 163309768,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE2MzMwOTc2OA==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-12-09T16:13:31Z",
    "updated_at": "2015-12-09T16:13:31Z",
    "author_association": "CONTRIBUTOR",
    "body": "@educhana is your text data suitable for Categorization (few distinct values relative to the number of rows)? That would be a relatively easy way to cut down the peak memory usage.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/163542618",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11803#issuecomment-163542618",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11803",
    "id": 163542618,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE2MzU0MjYxOA==",
    "user": {
      "login": "educhana",
      "id": 3425,
      "node_id": "MDQ6VXNlcjM0MjU=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/3425?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/educhana",
      "html_url": "https://github.com/educhana",
      "followers_url": "https://api.github.com/users/educhana/followers",
      "following_url": "https://api.github.com/users/educhana/following{/other_user}",
      "gists_url": "https://api.github.com/users/educhana/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/educhana/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/educhana/subscriptions",
      "organizations_url": "https://api.github.com/users/educhana/orgs",
      "repos_url": "https://api.github.com/users/educhana/repos",
      "events_url": "https://api.github.com/users/educhana/events{/privacy}",
      "received_events_url": "https://api.github.com/users/educhana/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-12-10T09:22:13Z",
    "updated_at": "2015-12-10T09:23:07Z",
    "author_association": "NONE",
    "body": "Thanks,\n\nThis is interesting, but not really applicable in this case, that contains colums like client_id, product_id with many possible values. \n\nAnyway, I was talking about the general case. Pandas is using too much memory than it should and has performance problems managing csv files that are loaded in R -for example-  with no problem at all.\n\nedit: typo\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/163591891",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11803#issuecomment-163591891",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11803",
    "id": 163591891,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE2MzU5MTg5MQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-12-10T12:06:19Z",
    "updated_at": "2015-12-10T12:06:19Z",
    "author_association": "CONTRIBUTOR",
    "body": "@educhana \n\npandas is quite good on the memory vs speed tradeoff vs most other parsers and R in particular. Most good parses uses 2x of the incoming memory; yes it can be worked around, but its quite expensive to do this (the tradeoff vs speed). \n\nIf you are actually hitting a peak memory issue, then you need to either chunk read, use [dask](https://dask.readthedocs.org/) for OOC operations that auto-chunk, convert to a different (binary format), or select columns. All of these have tradeoffs as well. \n\nFurthermore the pandas model is to return a new copy of data when operations are performed, you will almost always needs > 2x your data to have a reasonable system for analysis; even then if you are bumping the memory limits, you can have to be very very careful about garbage collection and such.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/163591957",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11803#issuecomment-163591957",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11803",
    "id": 163591957,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE2MzU5MTk1Nw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-12-10T12:06:50Z",
    "updated_at": "2015-12-10T12:06:50Z",
    "author_association": "CONTRIBUTOR",
    "body": "closing as this is a well known idea/issue.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/163645515",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11803#issuecomment-163645515",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11803",
    "id": 163645515,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE2MzY0NTUxNQ==",
    "user": {
      "login": "educhana",
      "id": 3425,
      "node_id": "MDQ6VXNlcjM0MjU=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/3425?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/educhana",
      "html_url": "https://github.com/educhana",
      "followers_url": "https://api.github.com/users/educhana/followers",
      "following_url": "https://api.github.com/users/educhana/following{/other_user}",
      "gists_url": "https://api.github.com/users/educhana/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/educhana/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/educhana/subscriptions",
      "organizations_url": "https://api.github.com/users/educhana/orgs",
      "repos_url": "https://api.github.com/users/educhana/repos",
      "events_url": "https://api.github.com/users/educhana/events{/privacy}",
      "received_events_url": "https://api.github.com/users/educhana/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-12-10T14:46:40Z",
    "updated_at": "2015-12-10T14:46:40Z",
    "author_association": "NONE",
    "body": "Thanks for the clarification,\n\nI agree with you. Sooner or later you'll reach the memory limit and the reasoning about needing 2x is right.\n"
  }
]
