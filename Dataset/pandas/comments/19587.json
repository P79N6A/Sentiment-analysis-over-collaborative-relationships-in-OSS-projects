[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/363965117",
    "html_url": "https://github.com/pandas-dev/pandas/issues/19587#issuecomment-363965117",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/19587",
    "id": 363965117,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2Mzk2NTExNw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-08T00:52:53Z",
    "updated_at": "2018-02-08T00:52:53Z",
    "author_association": "CONTRIBUTOR",
    "body": "not sure what you are trying to show here.\r\n\r\n```\r\nIn [18]: %timeit sd_series.take([l1 for l1 in sd_series.index.levels[0]])\r\n87.1 us +- 887 ns per loop (mean +- std. dev. of 7 runs, 10000 loops each)\r\n\r\nIn [19]: %timeit [(l1, DataFrame(list(group))) for l1, group in groupby(sd_series.items(), lambda it: it[0][0])]\r\n30.4 ms +- 400 us per loop (mean +- std. dev. of 7 runs, 10 loops each)\r\n```\r\n\r\nso your indexing doesn't actually do anything but a split, which you accomplish in many ways. this is what ``groupby`` actually does (its even worse, its just returning an iterator so its really not doing anything).\r\n\r\nSo you are comparing indexing & construction vs a split. In a completely non-idiomatic way.\r\n\r\n[18] is idiomatic for pandas."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/364100698",
    "html_url": "https://github.com/pandas-dev/pandas/issues/19587#issuecomment-364100698",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/19587",
    "id": 364100698,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDEwMDY5OA==",
    "user": {
      "login": "fcolas",
      "id": 502086,
      "node_id": "MDQ6VXNlcjUwMjA4Ng==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/502086?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/fcolas",
      "html_url": "https://github.com/fcolas",
      "followers_url": "https://api.github.com/users/fcolas/followers",
      "following_url": "https://api.github.com/users/fcolas/following{/other_user}",
      "gists_url": "https://api.github.com/users/fcolas/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/fcolas/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/fcolas/subscriptions",
      "organizations_url": "https://api.github.com/users/fcolas/orgs",
      "repos_url": "https://api.github.com/users/fcolas/repos",
      "events_url": "https://api.github.com/users/fcolas/events{/privacy}",
      "received_events_url": "https://api.github.com/users/fcolas/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-08T12:44:07Z",
    "updated_at": "2018-02-08T12:44:07Z",
    "author_association": "NONE",
    "body": "Thank you for your answer.\r\nI actually want a split and I might not have found the idiomatic way. More precisely, I have some data that I sometimes want to iterate over by group of first level and sometimes simply over all values. These iterations yield non-pandas objects consumed by some outside code. (Of course I also do some `pandas` processing on this data).\r\nA more precise look at what I'm doing here:\r\n```python\r\nIn [103]: MyClass = collections.namedtuple('MyClass', list('Labcde'))\r\n\r\nIn [104]: sd_series = pd.Series(range(1000, 1500), index=pd.MultiIndex.from_product([range(100,200), list('abcde')]))\r\n\r\nIn [105]: def f_loc():\r\n     ...:     for l1 in sd_series.index.levels[0]:\r\n     ...:         _ = MyClass(l1, **sd_series.loc[l1])\r\n     ...: \r\n\r\nIn [106]: def f_iloc():\r\n     ...:     for i, l1 in enumerate(sd_series.index.levels[0]):\r\n     ...:         _ = MyClass(l1, *sd_series.iloc[5*i:5*(i+1)])\r\n     ...: \r\n\r\nIn [107]: def f_pd_groupby():\r\n     ...:     for l1, group in sd_series.groupby(level=0):\r\n     ...:         _ = MyClass(l1, **{n: v for (_, n), v in group.items()})\r\n     ...: \r\n\r\nIn [108]: def f_groupby():\r\n     ...:     for l1, group in groupby(sd_series.items(), lambda it: it[0][0]):\r\n     ...:         _ = MyClass(l1, **{n: v for (_, n), v in group})\r\n     ...: \r\n\r\nIn [109]: def f_take():\r\n     ...:     for i, l1 in enumerate(sd_series.index.levels[0]):\r\n     ...:         _ = MyClass(l1, **{n: v for (_, n), v in sd_series.take(range(5*i, 5*(i+1))).items()})\r\n     ...: \r\n\r\nIn [110]: %timeit f_loc()\r\n10 loops, best of 3: 38.7 ms per loop\r\n\r\nIn [111]: %timeit f_iloc()\r\n100 loops, best of 3: 11 ms per loop\r\n\r\nIn [112]: %timeit f_pd_groupby()\r\n10 loops, best of 3: 23.7 ms per loop\r\n\r\nIn [113]: %timeit f_groupby()\r\n1000 loops, best of 3: 252 Âµs per loop\r\n\r\nIn [114]: %timeit f_take()\r\n10 loops, best of 3: 25.4 ms per loop\r\n```\r\n\r\nBut Indeed things change if I want to have a `pd.Series` (disregarding differences in index):\r\n```python\r\nIn [139]: def g_loc():\r\n     ...:     for l1 in sd_series.index.levels[0]:\r\n     ...:         _ = sd_series.loc[l1]\r\n     ...: \r\n\r\nIn [140]: def g_iloc():\r\n     ...:     for i, l1 in enumerate(sd_series.index.levels[0]):\r\n     ...:         _ = sd_series.iloc[5*i:5*(i+1)]\r\n     ...: \r\n\r\nIn [141]: def g_pd_groupby():\r\n     ...:     for _, group in sd_series.groupby(level=0):\r\n     ...:         _ = group\r\n     ...: \r\n\r\nIn [142]: def g_groupby():\r\n     ...:     for l1, group in groupby(sd_series.items(), lambda it: it[0][0]):\r\n     ...:         keys, values = zip(*group)\r\n     ...:         _ = pd.Series(values, index=keys)\r\n     ...: \r\n\r\nIn [143]: def g_take():\r\n     ...:     for i, l1 in enumerate(sd_series.index.levels[0]):\r\n     ...:         _ = sd_series.take(range(5*i, 5*(i+1)))\r\n     ...: \r\n\r\nIn [144]: def g_xs():\r\n     ...:     for l1 in sd_series.index.levels[0]:\r\n     ...:         _ = sd_series.xs(l1, level=0)\r\n     ...: \r\n\r\nIn [145]: %timeit g_loc()\r\n10 loops, best of 3: 30.4 ms per loop\r\n\r\nIn [146]: %timeit g_iloc()\r\n%100 loops, best of 3: 8.72 ms per loop\r\n\r\nIn [147]: %timeit g_pd_groupby()\r\n100 loops, best of 3: 8.05 ms per loop\r\n\r\nIn [148]: %timeit g_groupby()\r\n100 loops, best of 3: 13.6 ms per loop\r\n\r\nIn [149]: %timeit g_take()\r\n100 loops, best of 3: 9.56 ms per loop\r\n\r\nIn [150]: %timeit g_xs()\r\n10 loops, best of 3: 27.1 ms per loop\r\n```\r\nWhat is unclear to me is:\r\n- why do `loc` and `xs` take this long (3x compared to `pd.groupby`)?\r\n- what takes time in creating a `pd.Series`?\r\n- is there a more idiomatic way to iterate over `Series` by group?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/364678372",
    "html_url": "https://github.com/pandas-dev/pandas/issues/19587#issuecomment-364678372",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/19587",
    "id": 364678372,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDY3ODM3Mg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-10T18:25:54Z",
    "updated_at": "2018-02-10T18:25:54Z",
    "author_association": "CONTRIBUTOR",
    "body": "your sample size is very small. You are turning tuples into a Series. this involves a copy to underyling storage. I suppose there could be more info in a performance section. But I do recall several issues / nice explanations on SO. "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/364678406",
    "html_url": "https://github.com/pandas-dev/pandas/issues/19587#issuecomment-364678406",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/19587",
    "id": 364678406,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2NDY3ODQwNg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-10T18:26:19Z",
    "updated_at": "2018-02-10T18:26:19Z",
    "author_association": "CONTRIBUTOR",
    "body": "If you want to contribute docs would be fine."
  }
]
