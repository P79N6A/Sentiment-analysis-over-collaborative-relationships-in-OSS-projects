[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/434115171",
    "html_url": "https://github.com/pandas-dev/pandas/issues/23412#issuecomment-434115171",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/23412",
    "id": 434115171,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNDExNTE3MQ==",
    "user": {
      "login": "WillAyd",
      "id": 609873,
      "node_id": "MDQ6VXNlcjYwOTg3Mw==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/609873?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/WillAyd",
      "html_url": "https://github.com/WillAyd",
      "followers_url": "https://api.github.com/users/WillAyd/followers",
      "following_url": "https://api.github.com/users/WillAyd/following{/other_user}",
      "gists_url": "https://api.github.com/users/WillAyd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/WillAyd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/WillAyd/subscriptions",
      "organizations_url": "https://api.github.com/users/WillAyd/orgs",
      "repos_url": "https://api.github.com/users/WillAyd/repos",
      "events_url": "https://api.github.com/users/WillAyd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/WillAyd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-29T23:14:48Z",
    "updated_at": "2018-10-29T23:14:48Z",
    "author_association": "MEMBER",
    "body": "Do you have a way of figuring out how long individual benchmarks are running? IIRC there is a `setup_cache` method which may make sense to use in place of the normal `setup` if it yields the same info yet saves  on unnecessary setup time with some benchmarks"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/434512123",
    "html_url": "https://github.com/pandas-dev/pandas/issues/23412#issuecomment-434512123",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/23412",
    "id": 434512123,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNDUxMjEyMw==",
    "user": {
      "login": "jbrockmendel",
      "id": 8078968,
      "node_id": "MDQ6VXNlcjgwNzg5Njg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/8078968?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jbrockmendel",
      "html_url": "https://github.com/jbrockmendel",
      "followers_url": "https://api.github.com/users/jbrockmendel/followers",
      "following_url": "https://api.github.com/users/jbrockmendel/following{/other_user}",
      "gists_url": "https://api.github.com/users/jbrockmendel/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jbrockmendel/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jbrockmendel/subscriptions",
      "organizations_url": "https://api.github.com/users/jbrockmendel/orgs",
      "repos_url": "https://api.github.com/users/jbrockmendel/repos",
      "events_url": "https://api.github.com/users/jbrockmendel/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jbrockmendel/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-30T23:49:33Z",
    "updated_at": "2018-10-30T23:49:33Z",
    "author_association": "MEMBER",
    "body": "@h-vetinari what you've written matches my experience.\r\n\r\n@WillAyd my understanding (grain of salt) of `setup_cache` is that it is helpful when the `setup` method is expensive, but still involves I/O+unpickling, so doesn't save much in cases with fairly cheap setup (which I think most of ours are, but I haven't measured).\r\n\r\nMost of our benchmarks are both fairly fast non-stateful.  i.e. if there were an option to only run `setup` once (like `setup_class` in tests) instead of before each call of `time_foo`, we would cut a lot of runtime.  (... I think)\r\n\r\nAnother intuition I have no evidence for: `asv` makes a _ton_ of `subprocess.Popen` calls, with child process writing results to a file (json IIRC) and parent process reading those results.  This may be related to the fact that asv bends over backwards to ensure major backward-compatibility; not totally sure on this one.  I think a lot of that subprocess overhead is not necessary for our use cases.\r\n\r\nFor the noise, the idea I've pitched to the asv folks is to interleave the benchmarks instead of running all-benchmarks-for-commit-A followed by all-benchmarks-for-commit B.  IIRC they said that would require a pretty serious re-working of asv in order to implement.\r\n\r\nOne piece of bright-side: there has been some discussion within asv (I haven't checked on it for a while, no idea how it went) about an option to aggregate results across runs.  So if I run `asv continuous ...` K times, eventually it should get a large enough sample size to give meaningful results."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/435078740",
    "html_url": "https://github.com/pandas-dev/pandas/issues/23412#issuecomment-435078740",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/23412",
    "id": 435078740,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTA3ODc0MA==",
    "user": {
      "login": "pv",
      "id": 35046,
      "node_id": "MDQ6VXNlcjM1MDQ2",
      "avatar_url": "https://avatars1.githubusercontent.com/u/35046?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pv",
      "html_url": "https://github.com/pv",
      "followers_url": "https://api.github.com/users/pv/followers",
      "following_url": "https://api.github.com/users/pv/following{/other_user}",
      "gists_url": "https://api.github.com/users/pv/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pv/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pv/subscriptions",
      "organizations_url": "https://api.github.com/users/pv/orgs",
      "repos_url": "https://api.github.com/users/pv/repos",
      "events_url": "https://api.github.com/users/pv/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pv/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-01T15:30:11Z",
    "updated_at": "2018-11-01T16:21:56Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jbrockmendel: the interleaved benchmarks were already implemented in 0.3, ditto for the option for aggregating results."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/435107701",
    "html_url": "https://github.com/pandas-dev/pandas/issues/23412#issuecomment-435107701",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/23412",
    "id": 435107701,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTEwNzcwMQ==",
    "user": {
      "login": "pv",
      "id": 35046,
      "node_id": "MDQ6VXNlcjM1MDQ2",
      "avatar_url": "https://avatars1.githubusercontent.com/u/35046?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pv",
      "html_url": "https://github.com/pv",
      "followers_url": "https://api.github.com/users/pv/followers",
      "following_url": "https://api.github.com/users/pv/following{/other_user}",
      "gists_url": "https://api.github.com/users/pv/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pv/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pv/subscriptions",
      "organizations_url": "https://api.github.com/users/pv/orgs",
      "repos_url": "https://api.github.com/users/pv/repos",
      "events_url": "https://api.github.com/users/pv/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pv/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-01T16:54:46Z",
    "updated_at": "2018-11-01T19:01:03Z",
    "author_association": "CONTRIBUTOR",
    "body": "On a laptops I'd recommend to at least pin the CPU frequency/performance settings to get stable results https://asv.readthedocs.io/en/stable/tuning.html#tuning-machines-for-benchmarking  (and on linux disable thermald which also tunes the frequencies on the fly).\r\n\r\nHow much collecting statistics across multiple runs helps depends on how large the CPU frequency fluctuations are. The default setting for asv is to collect statistics over k=2 reruns of the whole suite (and of course multiple samples on each single benchmark, but here they are strongly correlated). Suppose e.g. that you have probability p chance for each benchmark to be run with \"slow\" CPU frequency, otherwise with \"fast\" frequency. Pandas has N=2618 benchmarks (counting parameterized separately), and suppose the suite is interleaved k times. Then Pr[each benchmark sampled with \"fast\" CPU frequency] = (1 - p^k)^N. For k=2, N=2618 and e.g. p=0.05 this is ~0; for k=5 (`asv run -a processes=5`) >0.99 -- reality may be worse as the CPU state is probably not uncorrelated between benchmarks.\r\n\r\nThe choices are that either the benchmark run takes a long time (i.e. not asv default settings), or the system is configured to produce stable timings.\r\n\r\nOn linux, the forkserver mode pushes benchmarks overheads to <~50msec, so most time is taken by running the user code, on Windows you have bigger overhead as `import pandas` is quite slow. The default settings take repeat counts such that about ~1 sec total is spent per each timing benchmark. \r\n\r\nPandas has 2618 benchmarks (counting parameter combinations), so theoretically it should take 45min, maybe double that on Windows. This doesn't count time taken by setup methods, and pandas probably maybe has several slow ones, and benchmarks that have runtime in several seconds.\r\n\r\nFinding slow setup() routines: https://gist.github.com/pv/9f51381ec8a488c34920749d0f00c43e\r\n\r\nPandas also seems to set `sample_time = 0.2` for all benchmarks --- that's twice the default, so benchmarking takes twice longer (for the bare benchmarking part). I'm not really convinced increasing this option from the default will improve the accuracy of the results."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/436521871",
    "html_url": "https://github.com/pandas-dev/pandas/issues/23412#issuecomment-436521871",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/23412",
    "id": 436521871,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNjUyMTg3MQ==",
    "user": {
      "login": "WillAyd",
      "id": 609873,
      "node_id": "MDQ6VXNlcjYwOTg3Mw==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/609873?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/WillAyd",
      "html_url": "https://github.com/WillAyd",
      "followers_url": "https://api.github.com/users/WillAyd/followers",
      "following_url": "https://api.github.com/users/WillAyd/following{/other_user}",
      "gists_url": "https://api.github.com/users/WillAyd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/WillAyd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/WillAyd/subscriptions",
      "organizations_url": "https://api.github.com/users/WillAyd/orgs",
      "repos_url": "https://api.github.com/users/WillAyd/repos",
      "events_url": "https://api.github.com/users/WillAyd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/WillAyd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-07T06:48:16Z",
    "updated_at": "2018-11-07T06:48:16Z",
    "author_association": "MEMBER",
    "body": "Here's the output of @pv 's script if anyone was curious\r\n\r\n[asv_setup_times.txt](https://github.com/pandas-dev/pandas/files/2556305/asv_setup_times.txt)\r\n"
  }
]
