[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/13161217",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-13161217",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 13161217,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMTYxMjE3",
    "user": {
      "login": "wesm",
      "id": 329591,
      "node_id": "MDQ6VXNlcjMyOTU5MQ==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/329591?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/wesm",
      "html_url": "https://github.com/wesm",
      "followers_url": "https://api.github.com/users/wesm/followers",
      "following_url": "https://api.github.com/users/wesm/following{/other_user}",
      "gists_url": "https://api.github.com/users/wesm/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/wesm/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/wesm/subscriptions",
      "organizations_url": "https://api.github.com/users/wesm/orgs",
      "repos_url": "https://api.github.com/users/wesm/repos",
      "events_url": "https://api.github.com/users/wesm/events{/privacy}",
      "received_events_url": "https://api.github.com/users/wesm/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-06T00:49:29Z",
    "updated_at": "2013-02-06T00:49:29Z",
    "author_association": "MEMBER",
    "body": "It actually wouldn't because new arrays still have to be allocated and the data copied over\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/13161361",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-13161361",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 13161361,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMTYxMzYx",
    "user": {
      "login": "darindillon",
      "id": 2766856,
      "node_id": "MDQ6VXNlcjI3NjY4NTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/2766856?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/darindillon",
      "html_url": "https://github.com/darindillon",
      "followers_url": "https://api.github.com/users/darindillon/followers",
      "following_url": "https://api.github.com/users/darindillon/following{/other_user}",
      "gists_url": "https://api.github.com/users/darindillon/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/darindillon/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/darindillon/subscriptions",
      "organizations_url": "https://api.github.com/users/darindillon/orgs",
      "repos_url": "https://api.github.com/users/darindillon/repos",
      "events_url": "https://api.github.com/users/darindillon/events{/privacy}",
      "received_events_url": "https://api.github.com/users/darindillon/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-06T00:54:19Z",
    "updated_at": "2013-02-06T00:54:19Z",
    "author_association": "NONE",
    "body": "Hmm, interesting. Well, it would be convenient to have the parameter anyway, just to simplify code (even if there's no performance boost)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/13162056",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-13162056",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 13162056,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMTYyMDU2",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-06T01:17:26Z",
    "updated_at": "2013-02-06T01:17:26Z",
    "author_association": "CONTRIBUTOR",
    "body": "i often append to really big tables on disk (using HDFStore)\n\nhttp://pandas.pydata.org/pandas-docs/stable/io.html#storing-in-table-format\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/17638677",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-17638677",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 17638677,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjM4Njc3",
    "user": {
      "login": "knowitnothing",
      "id": 4287880,
      "node_id": "MDQ6VXNlcjQyODc4ODA=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/4287880?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/knowitnothing",
      "html_url": "https://github.com/knowitnothing",
      "followers_url": "https://api.github.com/users/knowitnothing/followers",
      "following_url": "https://api.github.com/users/knowitnothing/following{/other_user}",
      "gists_url": "https://api.github.com/users/knowitnothing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/knowitnothing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/knowitnothing/subscriptions",
      "organizations_url": "https://api.github.com/users/knowitnothing/orgs",
      "repos_url": "https://api.github.com/users/knowitnothing/repos",
      "events_url": "https://api.github.com/users/knowitnothing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/knowitnothing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-05-08T22:42:31Z",
    "updated_at": "2013-05-08T22:42:31Z",
    "author_association": "NONE",
    "body": "Isn't it possible to pre-alloc a larger-than-initially-needed DataFrame (possibly via a parameter) and make short appends efficient ? It would be nice to combine that with resizes that go beyond the imediate needs, reducing reallocations. This should be all obvious, and since I never touched Pandas code I guess there is some impeding reason for not doing that ?\n\nThe case I'm thinking about is that of data coming in real-time, and then one appends a DataFrame with a single entry to a larger one.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/17639954",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-17639954",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 17639954,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjM5OTU0",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-05-08T23:13:36Z",
    "updated_at": "2013-05-08T23:13:36Z",
    "author_association": "CONTRIBUTOR",
    "body": "can you give an example of how you are using this (and include some parameters that would 'simulate' what you are doing?)\n\nas an aside, a way of possibly mitigate this is to create new frames every so often (depends on your frequency of updates), then concat them together in one fell swoop (so you are appending to only a very small frame)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/17640361",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-17640361",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 17640361,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjQwMzYx",
    "user": {
      "login": "knowitnothing",
      "id": 4287880,
      "node_id": "MDQ6VXNlcjQyODc4ODA=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/4287880?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/knowitnothing",
      "html_url": "https://github.com/knowitnothing",
      "followers_url": "https://api.github.com/users/knowitnothing/followers",
      "following_url": "https://api.github.com/users/knowitnothing/following{/other_user}",
      "gists_url": "https://api.github.com/users/knowitnothing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/knowitnothing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/knowitnothing/subscriptions",
      "organizations_url": "https://api.github.com/users/knowitnothing/orgs",
      "repos_url": "https://api.github.com/users/knowitnothing/repos",
      "events_url": "https://api.github.com/users/knowitnothing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/knowitnothing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-05-08T23:23:41Z",
    "updated_at": "2013-05-08T23:23:41Z",
    "author_association": "NONE",
    "body": "I'm not using Pandas for that case I mentioned, but I'm considering it. I guess by \"an example\" you mean an extended version of that last phrase I included in the previous comment ?\n\nSo here is the extended example: the program receives live data from a given exchange. Let us restrict that to \"trade\" data, i.e. if a sell order or a buy order is filled in a given a exchange, the program receives a message telling that a buy/sell order was filled at a given price and a given volume. There might be additional details, but they are irrelevant here. So, suppose this exchange is just starting and the first trade on it just happened. Create a DataFrame for it. Now a new trade happened, append the just received to the earlier DataFrame. And so on. It is very interesting to use Pandas to resample this DataFrame up-to-the-last update so we can apply different analysis on it, in real time. It is also very interesting that the DataFrame can be stored in HDF5, while not a Pandas feature, it provides an easy way to do so. It might be the case that appending data to HDF5 is fast enough for this situation, and Pandas can retrieve the appended-DataFrame from the storage fast enough too. I have no benchmark data for this, by the way.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/17642789",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-17642789",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 17642789,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjQyNzg5",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-05-09T00:32:31Z",
    "updated_at": "2013-05-09T00:32:31Z",
    "author_association": "CONTRIBUTOR",
    "body": "appending to HDF5 will be very easy to do here, to save a record of what you are doing, and you will be able to read from that HDF5 (in the same process and sequentially), e.g. you write, then read, and do your processing.\n\nDoing this in separate processes is problematic; there is no 'locking' of the HDF5 file per se.\n\nThis is still allocating memory for the entire read back\n\nThere is nothing conceptually wrong with appending to an existing frame, it has to allocate new memory, but unless you are dealing with REALLY big frames, this shouldn't be a problem\n\n```\nIn [1]: df = DataFrame(randn(100000,2),columns=list('AB'))\n\nIn [2]: df2 = DataFrame(randn(10,2),columns=list('AB'))\n\nIn [3]: %timeit df.append(df2)\n1000 loops, best of 3: 431 us per loop\n```\n\nI suspect your bottleneck will not be this at all, but the actual operations you want to do on the frame\n\n```\nIn [7]: df3 = df.append(df2)\n\nIn [8]: %timeit df3.mean()\n100 loops, best of 3: 3.04 ms per loop\n```\n\nWrite your program and profile it\n\nmy favorite saying: **premature optimization is the root of all evil**\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/17643760",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-17643760",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 17643760,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjQzNzYw",
    "user": {
      "login": "knowitnothing",
      "id": 4287880,
      "node_id": "MDQ6VXNlcjQyODc4ODA=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/4287880?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/knowitnothing",
      "html_url": "https://github.com/knowitnothing",
      "followers_url": "https://api.github.com/users/knowitnothing/followers",
      "following_url": "https://api.github.com/users/knowitnothing/following{/other_user}",
      "gists_url": "https://api.github.com/users/knowitnothing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/knowitnothing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/knowitnothing/subscriptions",
      "organizations_url": "https://api.github.com/users/knowitnothing/orgs",
      "repos_url": "https://api.github.com/users/knowitnothing/repos",
      "events_url": "https://api.github.com/users/knowitnothing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/knowitnothing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-05-09T01:01:42Z",
    "updated_at": "2013-05-09T01:01:42Z",
    "author_association": "NONE",
    "body": "The dataframes can get big, but I guess it depends on what you mean by big. I have this data stored in another format taking ~5 million rows right now, \"importing\" it to a DataFrame is a one-time-heavy process but that is fine. I'm worried about reallocing 5 mil + 1, 5 mil + 1 + 1, for each append.\n\nIf the implementation takes O(n) for something that could be amortized to O(1) then this could become a bottleneck (or maybe already is for some given application, which then moved on to something else).\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/17643874",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-17643874",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 17643874,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjQzODc0",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-05-09T01:05:30Z",
    "updated_at": "2013-05-09T01:05:30Z",
    "author_association": "CONTRIBUTOR",
    "body": "your are much better off doing a marginal calculation anyhow\n\nif u are adding 1 point to 5m then it doesn't affect the stats of the  5m\nso I would just calc the stats u need, write it to hdf for storage and later retrieval and do your calc \nshould be much more efficient\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/17643954",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-17643954",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 17643954,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjQzOTU0",
    "user": {
      "login": "knowitnothing",
      "id": 4287880,
      "node_id": "MDQ6VXNlcjQyODc4ODA=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/4287880?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/knowitnothing",
      "html_url": "https://github.com/knowitnothing",
      "followers_url": "https://api.github.com/users/knowitnothing/followers",
      "following_url": "https://api.github.com/users/knowitnothing/following{/other_user}",
      "gists_url": "https://api.github.com/users/knowitnothing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/knowitnothing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/knowitnothing/subscriptions",
      "organizations_url": "https://api.github.com/users/knowitnothing/orgs",
      "repos_url": "https://api.github.com/users/knowitnothing/repos",
      "events_url": "https://api.github.com/users/knowitnothing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/knowitnothing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-05-09T01:09:10Z",
    "updated_at": "2013-05-09T01:09:35Z",
    "author_association": "NONE",
    "body": "Thus my earlier point: \"... It might be the case that appending data to HDF5 is fast enough for this situation ...\". I would actually continuously store new data in HDF5 by appending to what I currently have. And then I would use a subset of this stored DataFrame to do the analysis.\n\nThe possible advantage of not using HDF5 is that it we could guarantee that all the data is in memory, otherwise we have to trust on HDF5 being good/fast enough.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/17644076",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-17644076",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 17644076,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjQ0MDc2",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-05-09T01:13:00Z",
    "updated_at": "2013-05-09T01:13:00Z",
    "author_association": "CONTRIBUTOR",
    "body": "Here's a way to preallocate\ncreate the frame bigger than you need (e.g. the existing + the expected)\n\nfill in rows, increment your indexer (realloc if you run out of space)\ncalc your function that selects <= the indexer \nrepeat\n\n```\nIn [7]: df = DataFrame(index=range(5),columns=list('AB'))\n\nIn [8]: df.iloc[0] = Series(dict(A = 10, B = 5))\n\nIn [9]: df.iloc[1] = Series(dict(A = 11, B = 6))\n\nIn [10]: def f(x,indexer):\n   ....:     return x.iloc[0:indexer]*2\n   ....: \n\nIn [11]: f(df,2)\nOut[11]: \n    A   B\n0  20  10\n1  22  12\n\nIn [12]: df.iloc[2] = Series(dict(A = 12, B = 7))\n\nIn [13]: f(df,3)\nOut[13]: \n    A   B\n0  20  10\n1  22  12\n2  24  14\n\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/17644110",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-17644110",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 17644110,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjQ0MTEw",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-05-09T01:14:20Z",
    "updated_at": "2013-05-09T01:14:20Z",
    "author_association": "CONTRIBUTOR",
    "body": "you can do a combination of all of these approaches, you know your data and your workflow best\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/17644207",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-17644207",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 17644207,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjQ0MjA3",
    "user": {
      "login": "knowitnothing",
      "id": 4287880,
      "node_id": "MDQ6VXNlcjQyODc4ODA=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/4287880?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/knowitnothing",
      "html_url": "https://github.com/knowitnothing",
      "followers_url": "https://api.github.com/users/knowitnothing/followers",
      "following_url": "https://api.github.com/users/knowitnothing/following{/other_user}",
      "gists_url": "https://api.github.com/users/knowitnothing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/knowitnothing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/knowitnothing/subscriptions",
      "organizations_url": "https://api.github.com/users/knowitnothing/orgs",
      "repos_url": "https://api.github.com/users/knowitnothing/repos",
      "events_url": "https://api.github.com/users/knowitnothing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/knowitnothing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-05-09T01:17:53Z",
    "updated_at": "2013-05-09T01:21:58Z",
    "author_association": "NONE",
    "body": "The problem with your prealloc example is that you know the index values, I don't know them beforehand. Can you set index to NaN and later modify it without incurring more than constant time ? Thinking about this.. I guess I could use timestamp_{i-1} + 1 nanosecond for the prealloc. But I would still need to update the index when inserting actual data. Is that possible ? It would mostly solve the initial suggestion.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/17644431",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-17644431",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 17644431,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjQ0NDMx",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-05-09T01:24:25Z",
    "updated_at": "2013-05-09T01:24:25Z",
    "author_association": "CONTRIBUTOR",
    "body": "use the index like I did, add your 'index' as another column (which can be nan, then fill in as u fill the rows), then \n\nfunc(df.iloc[0:indexer].set_index('my_index'))\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/17644465",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-17644465",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 17644465,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjQ0NDY1",
    "user": {
      "login": "knowitnothing",
      "id": 4287880,
      "node_id": "MDQ6VXNlcjQyODc4ODA=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/4287880?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/knowitnothing",
      "html_url": "https://github.com/knowitnothing",
      "followers_url": "https://api.github.com/users/knowitnothing/followers",
      "following_url": "https://api.github.com/users/knowitnothing/following{/other_user}",
      "gists_url": "https://api.github.com/users/knowitnothing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/knowitnothing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/knowitnothing/subscriptions",
      "organizations_url": "https://api.github.com/users/knowitnothing/orgs",
      "repos_url": "https://api.github.com/users/knowitnothing/repos",
      "events_url": "https://api.github.com/users/knowitnothing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/knowitnothing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-05-09T01:25:42Z",
    "updated_at": "2013-05-09T01:25:42Z",
    "author_association": "NONE",
    "body": "I will properly evaluate these suggestions, thank you :)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/17644980",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-17644980",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 17644980,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjQ0OTgw",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-05-09T01:46:32Z",
    "updated_at": "2013-05-09T01:46:32Z",
    "author_association": "CONTRIBUTOR",
    "body": "good luck\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/226516338",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-226516338",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 226516338,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIyNjUxNjMzOA==",
    "user": {
      "login": "markfink",
      "id": 33456,
      "node_id": "MDQ6VXNlcjMzNDU2",
      "avatar_url": "https://avatars0.githubusercontent.com/u/33456?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markfink",
      "html_url": "https://github.com/markfink",
      "followers_url": "https://api.github.com/users/markfink/followers",
      "following_url": "https://api.github.com/users/markfink/following{/other_user}",
      "gists_url": "https://api.github.com/users/markfink/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markfink/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markfink/subscriptions",
      "organizations_url": "https://api.github.com/users/markfink/orgs",
      "repos_url": "https://api.github.com/users/markfink/repos",
      "events_url": "https://api.github.com/users/markfink/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markfink/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-06-16T15:13:56Z",
    "updated_at": "2016-06-16T15:13:56Z",
    "author_association": "NONE",
    "body": "hey \"premature optimization is the root of all evil\"! Awesome quote! Strange that this issue is closed and I get \"TypeError: append() got an unexpected keyword argument 'inplace'\".\nI know with scientists all variables are usually global. But if you attempt to do a proper software design (using methods and arguments) and you want to append to a dataframe in a callback somewhere this breaks the design. Back to evil global variables again!\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/442866030",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-442866030",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 442866030,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0Mjg2NjAzMA==",
    "user": {
      "login": "vincent-yao27",
      "id": 28707665,
      "node_id": "MDQ6VXNlcjI4NzA3NjY1",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28707665?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vincent-yao27",
      "html_url": "https://github.com/vincent-yao27",
      "followers_url": "https://api.github.com/users/vincent-yao27/followers",
      "following_url": "https://api.github.com/users/vincent-yao27/following{/other_user}",
      "gists_url": "https://api.github.com/users/vincent-yao27/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vincent-yao27/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vincent-yao27/subscriptions",
      "organizations_url": "https://api.github.com/users/vincent-yao27/orgs",
      "repos_url": "https://api.github.com/users/vincent-yao27/repos",
      "events_url": "https://api.github.com/users/vincent-yao27/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vincent-yao27/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-29T15:04:43Z",
    "updated_at": "2018-11-29T15:04:43Z",
    "author_association": "NONE",
    "body": "@jreback A `inplace` parameter for `append()` is really needed in `for..in` loops.\r\n```py\r\nfor df in df_list:\r\n  df = df.append(...) # no effects on df_list\r\n```\r\nIn the case above, there are still counter-intuitive workarounds like\r\n```py\r\nfor idx in range(len(df_list)):\r\n  df_list[idx] = df_list[idx].append(...)\r\n```\r\nHowever, in some case, it just doesn't work.\r\n```py\r\nA_df_list, B_df_list = ...\r\ndf_list = A_df_list + B_df_list\r\nfor idx in range(len(df_list)):\r\n  df_list[idx] = df_list[idx].append(...)\r\n  # no effects on A_df_list and B_df_list\r\n```"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/450079894",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2801#issuecomment-450079894",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2801",
    "id": 450079894,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1MDA3OTg5NA==",
    "user": {
      "login": "NumesSanguis",
      "id": 8008618,
      "node_id": "MDQ6VXNlcjgwMDg2MTg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/8008618?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/NumesSanguis",
      "html_url": "https://github.com/NumesSanguis",
      "followers_url": "https://api.github.com/users/NumesSanguis/followers",
      "following_url": "https://api.github.com/users/NumesSanguis/following{/other_user}",
      "gists_url": "https://api.github.com/users/NumesSanguis/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/NumesSanguis/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/NumesSanguis/subscriptions",
      "organizations_url": "https://api.github.com/users/NumesSanguis/orgs",
      "repos_url": "https://api.github.com/users/NumesSanguis/repos",
      "events_url": "https://api.github.com/users/NumesSanguis/events{/privacy}",
      "received_events_url": "https://api.github.com/users/NumesSanguis/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-27T05:46:59Z",
    "updated_at": "2018-12-27T05:53:53Z",
    "author_association": "NONE",
    "body": "@jreback , I agree with @vincent-yao27 . An `inplace=True` parameter would be useful in for loops when you deal with multiple dataframes.\r\nIt is even more useful when you have e.g. a function that takes series to append to a dataframe:\r\n\r\n    def add_ds_to_df(df, ds):\r\n        df = df.append(ds, ignore_index=True)\r\n        return df  # unnecessary need to return dataframe\r\n\r\nWith `inplace`:\r\n\r\n    def add_ds_to_df(df, ds):\r\n        df.append(ds, ignore_index=True, inplace=True)"
  }
]
