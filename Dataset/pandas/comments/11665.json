[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/159690915",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-159690915",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 159690915,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE1OTY5MDkxNQ==",
    "user": {
      "login": "stevenmanton",
      "id": 3666725,
      "node_id": "MDQ6VXNlcjM2NjY3MjU=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/3666725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/stevenmanton",
      "html_url": "https://github.com/stevenmanton",
      "followers_url": "https://api.github.com/users/stevenmanton/followers",
      "following_url": "https://api.github.com/users/stevenmanton/following{/other_user}",
      "gists_url": "https://api.github.com/users/stevenmanton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/stevenmanton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/stevenmanton/subscriptions",
      "organizations_url": "https://api.github.com/users/stevenmanton/orgs",
      "repos_url": "https://api.github.com/users/stevenmanton/repos",
      "events_url": "https://api.github.com/users/stevenmanton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/stevenmanton/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-11-25T18:10:48Z",
    "updated_at": "2015-11-25T18:10:48Z",
    "author_association": "NONE",
    "body": "I recently stumbled across the exact same optimization. Converting 5 million strings to `datetime`'s takes 2 seconds instead of 10 minutes:\n\n``` python\npd.to_datetime(df['date'])  # takes 10 minutes\ndf['date'].map({k: pd.to_datetime(k) for k in df['date'].unique()})  # takes 2 seconds\n```\n\nIt seems like the caching/optimization strategy should live with `to_datetime` (or `_to_datetime`) and not necessarily with `read_csv`, which calls `to_datetime` internally anyway. Perhaps `to_datetime` could internally use the above unique-then-map strategy when it detects an array as input. It might also be possible, though probably more complicated, to cache values in `parse_datetime_string` in `tslib.pyx`.\n\nIt even seems as though you might want this optimization on by default. The only real overhead is the call to `unique`, which will make things slower if there aren't many duplicate strings. However, when there _are_ duplicate strings, which I imagine is a very common case, the optimized code is hundreds of times faster.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/159692679",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-159692679",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 159692679,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE1OTY5MjY3OQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-11-25T18:18:59Z",
    "updated_at": "2015-11-25T18:18:59Z",
    "author_association": "CONTRIBUTOR",
    "body": "@stevenmanton yes this could be implemented internally in `to_datetime`, but I think you need a keyword there to avoid recursively calling yourself (and to catch all of the cases), as well as to avoid doing this on a single timestamp conversion.\n\nnot saying this needs to be a kw to `read_csv` as already have enough!\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/159692788",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-159692788",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 159692788,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE1OTY5Mjc4OA==",
    "user": {
      "login": "stevenmanton",
      "id": 3666725,
      "node_id": "MDQ6VXNlcjM2NjY3MjU=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/3666725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/stevenmanton",
      "html_url": "https://github.com/stevenmanton",
      "followers_url": "https://api.github.com/users/stevenmanton/followers",
      "following_url": "https://api.github.com/users/stevenmanton/following{/other_user}",
      "gists_url": "https://api.github.com/users/stevenmanton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/stevenmanton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/stevenmanton/subscriptions",
      "organizations_url": "https://api.github.com/users/stevenmanton/orgs",
      "repos_url": "https://api.github.com/users/stevenmanton/repos",
      "events_url": "https://api.github.com/users/stevenmanton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/stevenmanton/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-11-25T18:19:33Z",
    "updated_at": "2015-11-25T18:19:33Z",
    "author_association": "NONE",
    "body": "Note that the above method is also about 10x faster than using `infer_datetime_format=True`:\n\n``` python\npd.to_datetime(df['date'], infer_datetime_format=True)  # takes 25 seconds\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/159693319",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-159693319",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 159693319,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE1OTY5MzMxOQ==",
    "user": {
      "login": "stevenmanton",
      "id": 3666725,
      "node_id": "MDQ6VXNlcjM2NjY3MjU=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/3666725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/stevenmanton",
      "html_url": "https://github.com/stevenmanton",
      "followers_url": "https://api.github.com/users/stevenmanton/followers",
      "following_url": "https://api.github.com/users/stevenmanton/following{/other_user}",
      "gists_url": "https://api.github.com/users/stevenmanton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/stevenmanton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/stevenmanton/subscriptions",
      "organizations_url": "https://api.github.com/users/stevenmanton/orgs",
      "repos_url": "https://api.github.com/users/stevenmanton/repos",
      "events_url": "https://api.github.com/users/stevenmanton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/stevenmanton/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-11-25T18:21:56Z",
    "updated_at": "2015-11-25T18:21:56Z",
    "author_association": "NONE",
    "body": "How about a simple recursive wrapper?\n\n``` python\ndef to_datetime(s, cache=True, **kwargs):\n    if cache:\n        return s.map({k: to_datetime(k, cache=False, **kwargs) for k in s.unique()})\n    else:\n        return pd.to_datetime(s, cache=False, **kwargs)\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/159693794",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-159693794",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 159693794,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE1OTY5Mzc5NA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-11-25T18:24:11Z",
    "updated_at": "2015-11-25T18:24:11Z",
    "author_association": "CONTRIBUTOR",
    "body": "you _could_ do this _inside_ `to_datetime`, which calls `_to_datetime`\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/159693911",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-159693911",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 159693911,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE1OTY5MzkxMQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-11-25T18:24:45Z",
    "updated_at": "2015-11-25T18:24:45Z",
    "author_association": "CONTRIBUTOR",
    "body": "note `infer_datetime_format` could ALSO be used with this (as this fixed the parsing issue of when you have non-ISO separators).\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/159695227",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-159695227",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 159695227,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE1OTY5NTIyNw==",
    "user": {
      "login": "stevenmanton",
      "id": 3666725,
      "node_id": "MDQ6VXNlcjM2NjY3MjU=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/3666725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/stevenmanton",
      "html_url": "https://github.com/stevenmanton",
      "followers_url": "https://api.github.com/users/stevenmanton/followers",
      "following_url": "https://api.github.com/users/stevenmanton/following{/other_user}",
      "gists_url": "https://api.github.com/users/stevenmanton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/stevenmanton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/stevenmanton/subscriptions",
      "organizations_url": "https://api.github.com/users/stevenmanton/orgs",
      "repos_url": "https://api.github.com/users/stevenmanton/repos",
      "events_url": "https://api.github.com/users/stevenmanton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/stevenmanton/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-11-25T18:30:51Z",
    "updated_at": "2015-11-25T18:30:51Z",
    "author_association": "NONE",
    "body": "It looks like some of the parser tools call `_to_datetime` so I wonder if the optimization would have to be inside that function, not just in `to_datetime`?\n\nNot sure what you mean by using the `infer_datetime_format` in conjunction with the optimization. You mean this?\n\n``` python\ndef to_datetime(s, **kwargs):\n    return s.map({k: pd.to_datetime(k, **kwargs) for k in s.unique()})\n```\n\n![image](https://cloud.githubusercontent.com/assets/3666725/11405883/89b4ee76-935f-11e5-9449-ab0eac1f0eb8.png)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/159695979",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-159695979",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 159695979,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE1OTY5NTk3OQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-11-25T18:34:14Z",
    "updated_at": "2015-11-25T18:34:44Z",
    "author_association": "CONTRIBUTOR",
    "body": "@stevenmanton it could be in either place\n\nwhat I mean is you prob want `cache=True` as the default, and people can still pass `infer_datetime_format` if they want (to be honest this _should_ prob default to `True` as well, but that's a separate issue), which helps when you have non-ISO formats but limited uniques, its orthogonal to `cache`\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/174345202",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-174345202",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 174345202,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NDM0NTIwMg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-01-24T21:58:51Z",
    "updated_at": "2016-01-24T21:58:51Z",
    "author_association": "CONTRIBUTOR",
    "body": "@stevenmanton want to do a PR for this?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/177264933",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-177264933",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 177264933,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NzI2NDkzMw==",
    "user": {
      "login": "stevenmanton",
      "id": 3666725,
      "node_id": "MDQ6VXNlcjM2NjY3MjU=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/3666725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/stevenmanton",
      "html_url": "https://github.com/stevenmanton",
      "followers_url": "https://api.github.com/users/stevenmanton/followers",
      "following_url": "https://api.github.com/users/stevenmanton/following{/other_user}",
      "gists_url": "https://api.github.com/users/stevenmanton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/stevenmanton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/stevenmanton/subscriptions",
      "organizations_url": "https://api.github.com/users/stevenmanton/orgs",
      "repos_url": "https://api.github.com/users/stevenmanton/repos",
      "events_url": "https://api.github.com/users/stevenmanton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/stevenmanton/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-01-30T18:07:55Z",
    "updated_at": "2016-01-30T18:07:55Z",
    "author_association": "NONE",
    "body": "@jreback I just got back from vacation, but I'll take a look and try to PR something.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/177269332",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-177269332",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 177269332,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3NzI2OTMzMg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-01-30T18:41:44Z",
    "updated_at": "2016-01-30T18:41:44Z",
    "author_association": "CONTRIBUTOR",
    "body": "great this would be a nice perf enhancement!\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/178297805",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-178297805",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 178297805,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE3ODI5NzgwNQ==",
    "user": {
      "login": "stevenmanton",
      "id": 3666725,
      "node_id": "MDQ6VXNlcjM2NjY3MjU=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/3666725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/stevenmanton",
      "html_url": "https://github.com/stevenmanton",
      "followers_url": "https://api.github.com/users/stevenmanton/followers",
      "following_url": "https://api.github.com/users/stevenmanton/following{/other_user}",
      "gists_url": "https://api.github.com/users/stevenmanton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/stevenmanton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/stevenmanton/subscriptions",
      "organizations_url": "https://api.github.com/users/stevenmanton/orgs",
      "repos_url": "https://api.github.com/users/stevenmanton/repos",
      "events_url": "https://api.github.com/users/stevenmanton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/stevenmanton/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-02T01:33:33Z",
    "updated_at": "2016-02-02T01:33:33Z",
    "author_association": "NONE",
    "body": "I took a stab at this but after a couple hours of looking through the code I'm not sure the best way to proceed. The small changes I made are [failing](https://travis-ci.org/stevenmanton/pandas) for a number of reasons. It seems like a lot of complexity is due to the number of inputs and outputs (tuple, list, string, Series, Index, etc.) accepted by the to_datetime function.\n\nAny thoughts on a better approach?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/183456739",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-183456739",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 183456739,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4MzQ1NjczOQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-12T19:22:44Z",
    "updated_at": "2016-02-12T19:22:44Z",
    "author_association": "CONTRIBUTOR",
    "body": "@stevenmanton the way to do this is to add a kw arg to `to_datetime`.\n\nthen [here](https://github.com/pydata/pandas/blob/master/pandas/tseries/tools.py#L277)\nuse that routine I have above (but call `_to_datetime(....)`; only do this if the kw is True & its a list-like and has a reasonable length, maybe > 100.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/198622519",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-198622519",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 198622519,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE5ODYyMjUxOQ==",
    "user": {
      "login": "GeorgieBanks",
      "id": 17939356,
      "node_id": "MDQ6VXNlcjE3OTM5MzU2",
      "avatar_url": "https://avatars2.githubusercontent.com/u/17939356?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/GeorgieBanks",
      "html_url": "https://github.com/GeorgieBanks",
      "followers_url": "https://api.github.com/users/GeorgieBanks/followers",
      "following_url": "https://api.github.com/users/GeorgieBanks/following{/other_user}",
      "gists_url": "https://api.github.com/users/GeorgieBanks/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/GeorgieBanks/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/GeorgieBanks/subscriptions",
      "organizations_url": "https://api.github.com/users/GeorgieBanks/orgs",
      "repos_url": "https://api.github.com/users/GeorgieBanks/repos",
      "events_url": "https://api.github.com/users/GeorgieBanks/events{/privacy}",
      "received_events_url": "https://api.github.com/users/GeorgieBanks/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-03-19T02:49:06Z",
    "updated_at": "2016-03-19T02:49:18Z",
    "author_association": "NONE",
    "body": "@charles-cooper suggested this feature 8 months earlier in #9594, but was rejected by @jreback. Just to give credit where it's due. \n\nI'm :+1: for this.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/198625901",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-198625901",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 198625901,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE5ODYyNTkwMQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-03-19T03:17:23Z",
    "updated_at": "2016-03-19T03:17:23Z",
    "author_association": "CONTRIBUTOR",
    "body": "@GeorgieBanks \n\nthe suggested feature was not parsing the uniques in a vectorized way and broadcasting, rather memoizarion of repeated inefficient calls\n\nto be honest I don't care about the credit - I was quite clear on that other issue why it was closed\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/303196238",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-303196238",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 303196238,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwMzE5NjIzOA==",
    "user": {
      "login": "DGrady",
      "id": 392172,
      "node_id": "MDQ6VXNlcjM5MjE3Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/392172?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/DGrady",
      "html_url": "https://github.com/DGrady",
      "followers_url": "https://api.github.com/users/DGrady/followers",
      "following_url": "https://api.github.com/users/DGrady/following{/other_user}",
      "gists_url": "https://api.github.com/users/DGrady/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/DGrady/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/DGrady/subscriptions",
      "organizations_url": "https://api.github.com/users/DGrady/orgs",
      "repos_url": "https://api.github.com/users/DGrady/repos",
      "events_url": "https://api.github.com/users/DGrady/events{/privacy}",
      "received_events_url": "https://api.github.com/users/DGrady/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-05-22T19:26:05Z",
    "updated_at": "2017-05-22T19:26:05Z",
    "author_association": "CONTRIBUTOR",
    "body": "Is there still interest in getting this optimization working? When it was originally reported, it looks like it was giving at 5x or better speed up. I'm testing again and seeing pretty consistently a 2x, at best, speed up even for very large series. I am willing to tackle it but wanted to check on the status first, since it appears that it's going to make the `to_datetime` interface a bit more complicated and may give only a modest performance boost at this point.\r\n\r\n```\r\n% ipython\r\nPython 3.6.1 |Anaconda custom (x86_64)| (default, May 11 2017, 13:04:09)\r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 6.0.0 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: import pandas as pd\r\n\r\nIn [2]: def parser(x):\r\n   ...:     uniques = pd.Series(pd.unique(x))\r\n   ...:     d = pd.to_datetime(uniques)\r\n   ...:     d.index = uniques\r\n   ...:     return pd.Series(x).map(d).values\r\n   ...:\r\n\r\nIn [3]: pd.DataFrame({'A' : ['20130101 00:00:00'] * 10 ** 4}).to_csv('test.csv', index=True)\r\n\r\nIn [4]: %timeit pd.read_csv('test.csv', index_col=0, parse_dates=['A'])\r\n10.1 ms ± 96.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\r\n\r\nIn [5]: %timeit pd.read_csv('test.csv', index_col=0, parse_dates=['A'], date_parser=parser)\r\n6.69 ms ± 104 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\r\n\r\nIn [6]: pd.DataFrame({'A' : ['20130101 00:00:00'] * 10 ** 5}).to_csv('test.csv', index=True)\r\n\r\nIn [7]: %timeit pd.read_csv('test.csv', index_col=0, parse_dates=['A'])\r\n90.2 ms ± 1.33 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\r\n\r\nIn [8]: %timeit pd.read_csv('test.csv', index_col=0, parse_dates=['A'], date_parser=parser)\r\n51 ms ± 546 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\r\n\r\nIn [9]: pd.DataFrame({'A' : ['20130101 00:00:00'] * 10 ** 6}).to_csv('test.csv', index=True)\r\n\r\nIn [10]: %timeit pd.read_csv('test.csv', index_col=0, parse_dates=['A'])\r\n876 ms ± 6.79 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\r\n\r\nIn [11]: %timeit pd.read_csv('test.csv', index_col=0, parse_dates=['A'], date_parser=parser)\r\n508 ms ± 6.49 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\r\n\r\nIn [12]: pd.DataFrame({'A' : ['20130101 00:00:00'] * 10 ** 7}).to_csv('test.csv', index=True)\r\n\r\nIn [13]: %timeit pd.read_csv('test.csv', index_col=0, parse_dates=['A'])\r\n/Users/dgrady/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:395: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\r\n  mask |= (ar1 == a)\r\n8.5 s ± 554 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\r\n\r\nIn [14]: %timeit pd.read_csv('test.csv', index_col=0, parse_dates=['A'], date_parser=parser)\r\n/Users/dgrady/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:395: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\r\n  mask |= (ar1 == a)\r\n4.46 s ± 56.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\r\n```"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/303230071",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-303230071",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 303230071,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwMzIzMDA3MQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-05-22T21:52:23Z",
    "updated_at": "2017-05-22T21:53:53Z",
    "author_association": "CONTRIBUTOR",
    "body": "oh i think we should always do this\r\nwe could add an option to turn it off i suppose\r\n\r\nbasically if you have say at least 1000 elements or less you can not do it otherwise it's always worth it (yes there is a degenerate case with a really long u issue series but detecting that is often not worth it)\r\n\r\nu can impelement then we an test a couple or of cases and see \r\n\r\nfyi we do something similar in pandas.core.util.hashing\r\nwith the categorize kw (it's simpler there to just hash the uniques there)\r\nso a similar approach would be good"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/303278883",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11665#issuecomment-303278883",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11665",
    "id": 303278883,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwMzI3ODg4Mw==",
    "user": {
      "login": "DGrady",
      "id": 392172,
      "node_id": "MDQ6VXNlcjM5MjE3Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/392172?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/DGrady",
      "html_url": "https://github.com/DGrady",
      "followers_url": "https://api.github.com/users/DGrady/followers",
      "following_url": "https://api.github.com/users/DGrady/following{/other_user}",
      "gists_url": "https://api.github.com/users/DGrady/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/DGrady/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/DGrady/subscriptions",
      "organizations_url": "https://api.github.com/users/DGrady/orgs",
      "repos_url": "https://api.github.com/users/DGrady/repos",
      "events_url": "https://api.github.com/users/DGrady/events{/privacy}",
      "received_events_url": "https://api.github.com/users/DGrady/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-05-23T03:15:31Z",
    "updated_at": "2017-05-23T03:15:31Z",
    "author_association": "CONTRIBUTOR",
    "body": "Okay; will dive in to it tomorrow."
  }
]
