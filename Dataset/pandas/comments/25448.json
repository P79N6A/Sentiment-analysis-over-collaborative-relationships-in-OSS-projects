[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/467738017",
    "html_url": "https://github.com/pandas-dev/pandas/issues/25448#issuecomment-467738017",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/25448",
    "id": 467738017,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ2NzczODAxNw==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-02-27T06:15:12Z",
    "updated_at": "2019-02-27T06:15:12Z",
    "author_association": "MEMBER",
    "body": "Interesting proposal...couldn't you use our `converters` parameter though to deserialize the string yourself when calling `read_csv`?\r\n\r\nLikewise, when serializing, you could do a transform on the column before calling `to_csv`."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/467766537",
    "html_url": "https://github.com/pandas-dev/pandas/issues/25448#issuecomment-467766537",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/25448",
    "id": 467766537,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ2Nzc2NjUzNw==",
    "user": {
      "login": "teto",
      "id": 886074,
      "node_id": "MDQ6VXNlcjg4NjA3NA==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/886074?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/teto",
      "html_url": "https://github.com/teto",
      "followers_url": "https://api.github.com/users/teto/followers",
      "following_url": "https://api.github.com/users/teto/following{/other_user}",
      "gists_url": "https://api.github.com/users/teto/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/teto/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/teto/subscriptions",
      "organizations_url": "https://api.github.com/users/teto/orgs",
      "repos_url": "https://api.github.com/users/teto/repos",
      "events_url": "https://api.github.com/users/teto/events{/privacy}",
      "received_events_url": "https://api.github.com/users/teto/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-02-27T08:17:31Z",
    "updated_at": "2019-02-27T08:17:31Z",
    "author_association": "NONE",
    "body": "I have a not so simple cycle of serializing/deserializing different types of dataframes with many fields so complexity quickly increases. It would be nice to have this tackled automatically. \r\n\r\nI tried using a converter` read_csv( converters= {\"tcpdest\": _convert_role;}` with\r\n```\r\ndef _convert_role(x):\r\n    return ConnectionRoles(x)\r\n```\r\nbut then I lose the dtype for the column as pandas warns it will use only the converter.\r\n```\r\ntcpdest             float64\r\n```\r\nand this is bad.\r\nWouldn't it be possible to properly rebuild enum values when codes in the CategoricalDType categories belong to an enum ? \r\nWith an IntEnum, my 1st example works a bit better, yet values are numpy.int64 when I would expect enum instances. Thus my checks fail:\r\n   ` assert isinstance(destination, ConnectionRoles), \"destination is %r\" % destination`.\r\n\r\nIf you tell me where to look at I can even have a try myself. I tried having a look but the logic seems pretty complex between real_values, inferred ones etc...\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/473080839",
    "html_url": "https://github.com/pandas-dev/pandas/issues/25448#issuecomment-473080839",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/25448",
    "id": 473080839,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3MzA4MDgzOQ==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-14T21:56:42Z",
    "updated_at": "2019-03-14T21:56:42Z",
    "author_association": "MEMBER",
    "body": "@teto : Sorry for taking so long to respond here.  Could you provide a complete code sample for what you're describing?  That would be very helpful!\r\n\r\nAlso, if you are interested, you can search for `parsers.pyx` on GitHub, and that will take you to the file where we handle the converters for `read_csv`."
  }
]
