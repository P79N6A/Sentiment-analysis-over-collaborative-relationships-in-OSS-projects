[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/132163226",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10843#issuecomment-132163226",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10843",
    "id": 132163226,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMjE2MzIyNg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-08-18T10:37:54Z",
    "updated_at": "2015-08-18T10:38:53Z",
    "author_association": "CONTRIBUTOR",
    "body": "well 90% of this comes from the calculation for whether this index it unique. So this is actually just a matter of a couple of function calls.\n\nNot sure how this actually matters in reality though. If you are relying on extreme performance for selecting columns which inherently is an iterative process then use a dict of ndarrays. \n\nThe data are kept in blocks of ndarray's so it is convenient to cache particular column access.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/132171811",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10843#issuecomment-132171811",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10843",
    "id": 132171811,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMjE3MTgxMQ==",
    "user": {
      "login": "Suor",
      "id": 284103,
      "node_id": "MDQ6VXNlcjI4NDEwMw==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/284103?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Suor",
      "html_url": "https://github.com/Suor",
      "followers_url": "https://api.github.com/users/Suor/followers",
      "following_url": "https://api.github.com/users/Suor/following{/other_user}",
      "gists_url": "https://api.github.com/users/Suor/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Suor/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Suor/subscriptions",
      "organizations_url": "https://api.github.com/users/Suor/orgs",
      "repos_url": "https://api.github.com/users/Suor/repos",
      "events_url": "https://api.github.com/users/Suor/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Suor/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-08-18T10:59:41Z",
    "updated_at": "2015-08-18T10:59:41Z",
    "author_association": "NONE",
    "body": "I can't see where index is checked for uniquiness. Most of the time is spent in `NDFrame._get_item_cache()`:\n\n```\nIn [4]: timeit df._get_item_cache('a'); df._item_cache = {}\n10000 loops, best of 3: 73.3 µs per loop\n\nIn [5]: timeit df['a']; df._item_cache = {}\n10000 loops, best of 3: 77.2 µs per loop\n```\n\nAnd here are line profiling of it:\n\n```\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n  1079                                               @profile\n  1080                                               def _get_item_cache(self, item):\n  1081                                                   \"\"\" return the cached item, item represents a label indexer \"\"\"\n  1082     82222        49337      0.6      0.9          cache = self._item_cache\n  1083     82222        51398      0.6      1.0          res = cache.get(item)\n  1084     82222        30061      0.4      0.6          if res is None:\n  1085     82222      2304416     28.0     42.8              values = self._data.get(item)\n  1086     82222      2079673     25.3     38.6              res = self._box_item_values(item, values)\n  1087     82222        60641      0.7      1.1              cache[item] = res\n  1088     82222       576752      7.0     10.7              res._set_as_cached(item, self)\n  1089                                           \n  1090                                                       # for a chain\n  1091     82222       195010      2.4      3.6              res.is_copy = self.is_copy\n  1092     82222        33936      0.4      0.6          return res\n```\n\nSignificant time is spent in boxing values here and in `BlockManager.iget()`:\n\n```\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n  2872                                               @profile\n  2873                                               def iget(self, i, fastpath=True):\n  2874                                                   \"\"\"\n  2875                                                   Return the data as a SingleBlockManager if fastpath=True and possible\n  2876                                           \n  2877                                                   Otherwise return as a ndarray\n  2878                                           \n  2879                                                   \"\"\"\n  2880                                           \n  2881     41111        61730      1.5      6.9          block = self.blocks[self._blknos[i]]\n  2882     41111        79573      1.9      8.8          values = block.iget(self._blklocs[i])\n  2883     41111        37949      0.9      4.2          if not fastpath or block.is_sparse or values.ndim != 1:\n  2884                                                       return values\n  2885                                           \n  2886                                                   # fastpath shortcut for select a single-dim from a 2-dim BM\n  2887     41111        22861      0.6      2.5          return SingleBlockManager([ block.make_block_same_class(values,\n  2888     41111        34554      0.8      3.8                                                                  placement=slice(0, len(values)),\n  2889     41111        17342      0.4      1.9                                                                  ndim=1,\n  2890     41111       382364      9.3     42.5                                                                  fastpath=True) ],\n  2891     41111       263750      6.4     29.3                                    self.axes[1])\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/132173559",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10843#issuecomment-132173559",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10843",
    "id": 132173559,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMjE3MzU1OQ==",
    "user": {
      "login": "Suor",
      "id": 284103,
      "node_id": "MDQ6VXNlcjI4NDEwMw==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/284103?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Suor",
      "html_url": "https://github.com/Suor",
      "followers_url": "https://api.github.com/users/Suor/followers",
      "following_url": "https://api.github.com/users/Suor/following{/other_user}",
      "gists_url": "https://api.github.com/users/Suor/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Suor/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Suor/subscriptions",
      "organizations_url": "https://api.github.com/users/Suor/orgs",
      "repos_url": "https://api.github.com/users/Suor/repos",
      "events_url": "https://api.github.com/users/Suor/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Suor/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-08-18T11:08:30Z",
    "updated_at": "2015-08-18T11:08:30Z",
    "author_association": "NONE",
    "body": "Extracting underlying values is significant for optimization. You/researcher write nice code with pandas, but you should be able to fall back to numpy for faster operations. E.g. look how `get_TE_se()` is implemented [here](https://github.com/idrdex/star-django/blob/0614efc754753d8ddd6f0431e832d3751fa4feab/analysis/analysis.py#L461).\n\nHere is it's line profiling:\n\n```\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n   506                                               @staticmethod\n   507                                               @profile\n   508                                               def get_TE_se(gene_stats):\n   509                                                   # Convert to numpy arrays for speed\n   510        50         5496    109.9     21.0          caseSigma = gene_stats['caseDataSigma'].values\n   511        50         5295    105.9     20.2          caseCount = gene_stats['caseDataCount'].values\n   512        50         5096    101.9     19.4          controlSigma = gene_stats['controlDataSigma'].values\n   513        50         4900     98.0     18.7          controlCount = gene_stats['controlDataCount'].values\n   514                                           \n   515                                                   # MD method\n   516        50          854     17.1      3.3          na = np.sqrt(caseSigma ** 2 / caseCount + controlSigma ** 2 / controlCount)\n   517                                           \n   518                                                   # Studies with non-positive variance get zero weight in meta-analysis\n   519       983          573      0.6      2.2          for i in range(len(na)):\n   520       933         1019      1.1      3.9              if caseSigma[i] <= 0 or controlSigma[i] <= 0:\n   521                                                           na[i] = float('nan')\n   522                                           \n   523        50         2970     59.4     11.3          return pd.Series(na, index=gene_stats.index)\n```\n\nColumn access is too slow.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/132173927",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10843#issuecomment-132173927",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10843",
    "id": 132173927,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMjE3MzkyNw==",
    "user": {
      "login": "Suor",
      "id": 284103,
      "node_id": "MDQ6VXNlcjI4NDEwMw==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/284103?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Suor",
      "html_url": "https://github.com/Suor",
      "followers_url": "https://api.github.com/users/Suor/followers",
      "following_url": "https://api.github.com/users/Suor/following{/other_user}",
      "gists_url": "https://api.github.com/users/Suor/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Suor/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Suor/subscriptions",
      "organizations_url": "https://api.github.com/users/Suor/orgs",
      "repos_url": "https://api.github.com/users/Suor/repos",
      "events_url": "https://api.github.com/users/Suor/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Suor/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-08-18T11:10:59Z",
    "updated_at": "2015-08-18T11:10:59Z",
    "author_association": "NONE",
    "body": "Maybe I need to make this into feature request? Something like `df.get_column_values('a')`. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/132183207",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10843#issuecomment-132183207",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10843",
    "id": 132183207,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMjE4MzIwNw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-08-18T11:42:02Z",
    "updated_at": "2015-08-18T11:42:02Z",
    "author_association": "CONTRIBUTOR",
    "body": "@Suor always glad to profile things. But you have to make sure it works with the current tests suite. The optimizations you are talking about are so tiny I can't imagine that any real use case would benefit. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/132185393",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10843#issuecomment-132185393",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10843",
    "id": 132185393,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMjE4NTM5Mw==",
    "user": {
      "login": "Suor",
      "id": 284103,
      "node_id": "MDQ6VXNlcjI4NDEwMw==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/284103?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Suor",
      "html_url": "https://github.com/Suor",
      "followers_url": "https://api.github.com/users/Suor/followers",
      "following_url": "https://api.github.com/users/Suor/following{/other_user}",
      "gists_url": "https://api.github.com/users/Suor/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Suor/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Suor/subscriptions",
      "organizations_url": "https://api.github.com/users/Suor/orgs",
      "repos_url": "https://api.github.com/users/Suor/repos",
      "events_url": "https://api.github.com/users/Suor/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Suor/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-08-18T11:52:32Z",
    "updated_at": "2015-08-18T11:52:32Z",
    "author_association": "NONE",
    "body": "I presented my use case. I can add that I am processing large amount dataframes resulted from `.groupby()` call. By switching to numpy arrays I already made it 2.5x faster. And this optimization could make function above 4x faster again.\n\nMaybe if you process small amount of large dataframes then this is insignificant, but here it's decisive.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/248024505",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10843#issuecomment-248024505",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10843",
    "id": 248024505,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI0ODAyNDUwNQ==",
    "user": {
      "login": "frol",
      "id": 304265,
      "node_id": "MDQ6VXNlcjMwNDI2NQ==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/304265?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/frol",
      "html_url": "https://github.com/frol",
      "followers_url": "https://api.github.com/users/frol/followers",
      "following_url": "https://api.github.com/users/frol/following{/other_user}",
      "gists_url": "https://api.github.com/users/frol/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/frol/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/frol/subscriptions",
      "organizations_url": "https://api.github.com/users/frol/orgs",
      "repos_url": "https://api.github.com/users/frol/repos",
      "events_url": "https://api.github.com/users/frol/events{/privacy}",
      "received_events_url": "https://api.github.com/users/frol/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-09-19T15:21:17Z",
    "updated_at": "2016-09-19T15:21:17Z",
    "author_association": "NONE",
    "body": "I hit this issue as well. This so-called \"tiny\" thing makes 35% overhead on my use-case! I use Dask, which operates on top of Pandas DataFrames, so accessing columns in `groupby` multiplying by thousands of dataframes (Dask chunks) gets me to 35% overhead! Using the suggested `get_col_values` function speeded up my code from 60 minutes to 39 minutes!\n\n@Suor Thank you so much!!!\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/405857814",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10843#issuecomment-405857814",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10843",
    "id": 405857814,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwNTg1NzgxNA==",
    "user": {
      "login": "0phoff",
      "id": 11853089,
      "node_id": "MDQ6VXNlcjExODUzMDg5",
      "avatar_url": "https://avatars3.githubusercontent.com/u/11853089?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/0phoff",
      "html_url": "https://github.com/0phoff",
      "followers_url": "https://api.github.com/users/0phoff/followers",
      "following_url": "https://api.github.com/users/0phoff/following{/other_user}",
      "gists_url": "https://api.github.com/users/0phoff/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/0phoff/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/0phoff/subscriptions",
      "organizations_url": "https://api.github.com/users/0phoff/orgs",
      "repos_url": "https://api.github.com/users/0phoff/repos",
      "events_url": "https://api.github.com/users/0phoff/events{/privacy}",
      "received_events_url": "https://api.github.com/users/0phoff/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-07-18T08:46:53Z",
    "updated_at": "2018-07-18T09:07:48Z",
    "author_association": "NONE",
    "body": "Sorry to bump this old thread, but I was wondering whether there is a chance this would ever come to pandas? I am doing lots of computations on data with ``groupby().apply()`` and I have sped up the function quite a bit by accessing the raw numpy arrays where possible.  \r\nAfter profiling, I noticed that a considerable amount of time was spent getting those arrays, which is how I stumbled on this thread. Using @Suor's function, I was able to get a 2x speedup (30sec -> 14sec), so this again proves that it can be useful to have this function.\r\n\r\nIf I understand anything from this issue, it is that the biggest bottleneck comes from trying to cache the data for future hits? If that is the case, maybe we could implement a ``.values_`` property that returns the numpy array witouth caching or checking the cache for the data?  \r\nI am not well aware how pandas works behind the scenes, but to me it sounds useful to have a function returning numpy arrays without caching. Whenever I would want a numpy array, I probably want to perform some heavy computations that return a different value, so caching makes no sense in those situations? (eg. in a ``groupby().apply()`` situation) Then again, this might be something different as I have no clue how pandas works.\r\n\r\nI am just another user that would benefit from such a function being implemented."
  }
]
