[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/141842247",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11084#issuecomment-141842247",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11084",
    "id": 141842247,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0MTg0MjI0Nw==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-09-20T22:41:30Z",
    "updated_at": "2015-09-20T22:41:30Z",
    "author_association": "MEMBER",
    "body": "@sinhrks I was looking at the time series plotting slowdown (`time_plot_timeseries_period`, there is a ca 5 times slowdown in timeseries plotting since 0.16.2)\n\nIt is related to some of the Period changes, namely that `freq` is no longer a string but a DateOffset object. \nIf you profile `df.plot()`, most of the time is cause by `to_offset`. At a certain point (in converter.py:convert), a object dtyped array of Period objects is converted back to a PeriodIndex:\n\n```\nIn [1]: values = pd.period_range('1/1/1975', periods=2000).astype(object).values\n\nIn [2]: values\nOut[2]:\narray([Period('1975-01-01', 'D'), Period('1975-01-02', 'D'),\n       Period('1975-01-03', 'D'), ..., Period('1980-06-20', 'D'),\n       Period('1980-06-21', 'D'), Period('1980-06-22', 'D')], dtype=object)\n\nIn [3]: %timeit pd.PeriodIndex(values, freq='D')\n100 loops, best of 3: 1.86 ms per loop\n```\n\nAbove is with 0.16.2, on master this gives me 109 ms instead of 1.86 ms. Reason for the slowdown is that PeriodIndex._from_arraylike will try to extract the freq from each object, and checks if the freq is equal to the given freq. Previously this was a string equality check, now a DateOffset/string equality check.\n\nNow, looking for a possible fix, this commit: https://github.com/jorisvandenbossche/pandas/commit/55ecbf0f4b0c1126f45fd738245e12d7c1139b75 (making it compare strings again) does solve the perf issue for a big part. But I was wondering, do you know a better approach? \nMaybe we could prevent this step (array of Period objects -> PeriodIndex) altogether in the plotting code? (although this is initially called from \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/141848746",
    "html_url": "https://github.com/pandas-dev/pandas/issues/11084#issuecomment-141848746",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/11084",
    "id": 141848746,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0MTg0ODc0Ng==",
    "user": {
      "login": "sinhrks",
      "id": 1696302,
      "node_id": "MDQ6VXNlcjE2OTYzMDI=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1696302?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sinhrks",
      "html_url": "https://github.com/sinhrks",
      "followers_url": "https://api.github.com/users/sinhrks/followers",
      "following_url": "https://api.github.com/users/sinhrks/following{/other_user}",
      "gists_url": "https://api.github.com/users/sinhrks/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sinhrks/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sinhrks/subscriptions",
      "organizations_url": "https://api.github.com/users/sinhrks/orgs",
      "repos_url": "https://api.github.com/users/sinhrks/repos",
      "events_url": "https://api.github.com/users/sinhrks/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sinhrks/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-09-21T00:13:45Z",
    "updated_at": "2015-09-21T00:13:45Z",
    "author_association": "MEMBER",
    "body": "Thanks for catching this. In addition to your ideas, caching str -> freq mapping in `to_offset` may work. This is already done in `get_offset`, and I _think_ the same cache can be used.\n\nLet me look into this.\n"
  }
]
