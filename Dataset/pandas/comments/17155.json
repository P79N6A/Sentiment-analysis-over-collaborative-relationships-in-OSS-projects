[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/319702773",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17155#issuecomment-319702773",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17155",
    "id": 319702773,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxOTcwMjc3Mw==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-02T15:11:52Z",
    "updated_at": "2017-08-02T15:11:52Z",
    "author_association": "MEMBER",
    "body": "I suspect the problem is that we aren't stopping the parsing for the C engine when we passing `nrows`.  I think we try to respect it in some cases, but those are likely insufficient it seems.\r\n\r\nAs for the Python parser, that does bewilder me a bit.  We are wrapping Python's `csv` reader class in most cases, so I suspect something is going with the interaction that causes it output the \"weird\" results that you are seeing.\r\n\r\nPR to investigate and patch is welcome!"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/391828914",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17155#issuecomment-391828914",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17155",
    "id": 391828914,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5MTgyODkxNA==",
    "user": {
      "login": "ewquon",
      "id": 18267059,
      "node_id": "MDQ6VXNlcjE4MjY3MDU5",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18267059?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ewquon",
      "html_url": "https://github.com/ewquon",
      "followers_url": "https://api.github.com/users/ewquon/followers",
      "following_url": "https://api.github.com/users/ewquon/following{/other_user}",
      "gists_url": "https://api.github.com/users/ewquon/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ewquon/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ewquon/subscriptions",
      "organizations_url": "https://api.github.com/users/ewquon/orgs",
      "repos_url": "https://api.github.com/users/ewquon/repos",
      "events_url": "https://api.github.com/users/ewquon/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ewquon/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-05-24T19:18:40Z",
    "updated_at": "2018-05-24T19:18:40Z",
    "author_association": "NONE",
    "body": "Can confirm this problem still exists with version 0.21"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/394180505",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17155#issuecomment-394180505",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17155",
    "id": 394180505,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NDE4MDUwNQ==",
    "user": {
      "login": "akaihola",
      "id": 13725,
      "node_id": "MDQ6VXNlcjEzNzI1",
      "avatar_url": "https://avatars3.githubusercontent.com/u/13725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/akaihola",
      "html_url": "https://github.com/akaihola",
      "followers_url": "https://api.github.com/users/akaihola/followers",
      "following_url": "https://api.github.com/users/akaihola/following{/other_user}",
      "gists_url": "https://api.github.com/users/akaihola/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/akaihola/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/akaihola/subscriptions",
      "organizations_url": "https://api.github.com/users/akaihola/orgs",
      "repos_url": "https://api.github.com/users/akaihola/repos",
      "events_url": "https://api.github.com/users/akaihola/events{/privacy}",
      "received_events_url": "https://api.github.com/users/akaihola/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-03T18:13:06Z",
    "updated_at": "2018-06-03T18:13:06Z",
    "author_association": "CONTRIBUTOR",
    "body": "Can confirm this problem also still exists as of master branch on May 31, 2018:\r\n\r\n    commit 4274b840e64374a39a0285c2174968588753ec35\r\n    Date:   Thu May 31 19:14:33 2018 -0500\r\n\r\nOutput for all the tests in the original description are identical to the examples above."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/394181212",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17155#issuecomment-394181212",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17155",
    "id": 394181212,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NDE4MTIxMg==",
    "user": {
      "login": "akaihola",
      "id": 13725,
      "node_id": "MDQ6VXNlcjEzNzI1",
      "avatar_url": "https://avatars3.githubusercontent.com/u/13725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/akaihola",
      "html_url": "https://github.com/akaihola",
      "followers_url": "https://api.github.com/users/akaihola/followers",
      "following_url": "https://api.github.com/users/akaihola/following{/other_user}",
      "gists_url": "https://api.github.com/users/akaihola/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/akaihola/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/akaihola/subscriptions",
      "organizations_url": "https://api.github.com/users/akaihola/orgs",
      "repos_url": "https://api.github.com/users/akaihola/repos",
      "events_url": "https://api.github.com/users/akaihola/events{/privacy}",
      "received_events_url": "https://api.github.com/users/akaihola/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-03T18:24:38Z",
    "updated_at": "2018-06-03T18:24:38Z",
    "author_association": "CONTRIBUTOR",
    "body": "Interestingly, the behavior changes slightly for a CSV file which has headers:\r\n```python\r\n%%file example_with_header.csv\r\nA,B\r\n1,2\r\n3,4\r\n5,6\r\n7,8\r\n9,10\r\n11,12\r\n```\r\n```python\r\nwith open('example_with_header.csv') as f:\r\n    data = pd.read_csv(f, nrows=1, engine='python')\r\n    print(f.readline())\r\n    print(f.readline())\r\n    print(data)\r\n```\r\n```\r\n5,6\r\n\r\n7,8\r\n\r\n   A  B\r\n0  1  2\r\n```\r\nSo the Python CSV parser skips one line less compared to a headerless file."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/394184984",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17155#issuecomment-394184984",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17155",
    "id": 394184984,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NDE4NDk4NA==",
    "user": {
      "login": "akaihola",
      "id": 13725,
      "node_id": "MDQ6VXNlcjEzNzI1",
      "avatar_url": "https://avatars3.githubusercontent.com/u/13725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/akaihola",
      "html_url": "https://github.com/akaihola",
      "followers_url": "https://api.github.com/users/akaihola/followers",
      "following_url": "https://api.github.com/users/akaihola/following{/other_user}",
      "gists_url": "https://api.github.com/users/akaihola/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/akaihola/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/akaihola/subscriptions",
      "organizations_url": "https://api.github.com/users/akaihola/orgs",
      "repos_url": "https://api.github.com/users/akaihola/repos",
      "events_url": "https://api.github.com/users/akaihola/events{/privacy}",
      "received_events_url": "https://api.github.com/users/akaihola/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-03T19:23:37Z",
    "updated_at": "2018-06-03T19:23:37Z",
    "author_association": "CONTRIBUTOR",
    "body": "I looked into the Python CSV parser by debugging how `example_with_header.csv` is parsed. I followed how the read pointer advances by calling `.tell()` for the file handle in the debugger.\r\n\r\nIn `PythonParser.__init__()`,\r\n- the call to `self._infer_columns()` consumes the header row\r\n- the call to `self._get_index_name()` consumes and buffers the first and second data rows, regardless of `nrows`\r\n- actual reading of data is done by concatenating the buffer with further lines read from the stream\r\n\r\nBefore the block which calls `self._get_index_name()`, there is this comment:\r\n```python\r\n        # needs to be cleaned/refactored\r\n        # multiple date column thing turning into a real spaghetti factory\r\n```\r\nThis is what `PythonParser._get_index_name()` advertises itself to be about:\r\n```\r\n        Try several cases to get lines:\r\n\r\n        0) There are headers on row 0 and row 1 and their\r\n        total summed lengths equals the length of the next line.\r\n        Treat row 0 as columns and row 1 as indices\r\n        1) Look for implicit index: there are more columns\r\n        on row 1 than row 0. If this is true, assume that row\r\n        1 lists index columns and row 0 lists normal columns.\r\n        2) Get index from the columns if it was listed.\r\n```\r\nThis may be related to [Index columns and trailing delimiters](https://pandas.pydata.org/pandas-docs/stable/io.html#index-columns-and-trailing-delimiters) (link to Pandas IO Tools documentation)."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/394185211",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17155#issuecomment-394185211",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17155",
    "id": 394185211,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NDE4NTIxMQ==",
    "user": {
      "login": "akaihola",
      "id": 13725,
      "node_id": "MDQ6VXNlcjEzNzI1",
      "avatar_url": "https://avatars3.githubusercontent.com/u/13725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/akaihola",
      "html_url": "https://github.com/akaihola",
      "followers_url": "https://api.github.com/users/akaihola/followers",
      "following_url": "https://api.github.com/users/akaihola/following{/other_user}",
      "gists_url": "https://api.github.com/users/akaihola/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/akaihola/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/akaihola/subscriptions",
      "organizations_url": "https://api.github.com/users/akaihola/orgs",
      "repos_url": "https://api.github.com/users/akaihola/repos",
      "events_url": "https://api.github.com/users/akaihola/events{/privacy}",
      "received_events_url": "https://api.github.com/users/akaihola/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-03T19:27:31Z",
    "updated_at": "2018-06-03T19:27:31Z",
    "author_association": "CONTRIBUTOR",
    "body": "Also @mcocdawc, I don't believe #2071 is related, since it's about the C engine CSV parser failing on a file handle which has already been partially iterated over.\r\n\r\nSpecifically, @wesm comments:\r\n>The underlying problem is that the new parser relies on being able to call read on the file handle you pass. however, after iterating, this causes:\r\n>```\r\n>ValueError: Mixing iteration and read methods would lose data \r\n>```"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/394495401",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17155#issuecomment-394495401",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17155",
    "id": 394495401,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NDQ5NTQwMQ==",
    "user": {
      "login": "akaihola",
      "id": 13725,
      "node_id": "MDQ6VXNlcjEzNzI1",
      "avatar_url": "https://avatars3.githubusercontent.com/u/13725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/akaihola",
      "html_url": "https://github.com/akaihola",
      "followers_url": "https://api.github.com/users/akaihola/followers",
      "following_url": "https://api.github.com/users/akaihola/following{/other_user}",
      "gists_url": "https://api.github.com/users/akaihola/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/akaihola/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/akaihola/subscriptions",
      "organizations_url": "https://api.github.com/users/akaihola/orgs",
      "repos_url": "https://api.github.com/users/akaihola/repos",
      "events_url": "https://api.github.com/users/akaihola/events{/privacy}",
      "received_events_url": "https://api.github.com/users/akaihola/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-04T20:52:35Z",
    "updated_at": "2018-06-04T20:52:35Z",
    "author_association": "CONTRIBUTOR",
    "body": "01bd5a2 adds a test case which shows the behavior when parsing text files and using the `nrows=` option. The position of the input stream after parsing using the `nrows=` option is different between the C and Python parse engines. Also visible is the fact that the Python parse engine consumes at least two rows even if `nrows=1`.\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/396029223",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17155#issuecomment-396029223",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17155",
    "id": 396029223,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NjAyOTIyMw==",
    "user": {
      "login": "akaihola",
      "id": 13725,
      "node_id": "MDQ6VXNlcjEzNzI1",
      "avatar_url": "https://avatars3.githubusercontent.com/u/13725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/akaihola",
      "html_url": "https://github.com/akaihola",
      "followers_url": "https://api.github.com/users/akaihola/followers",
      "following_url": "https://api.github.com/users/akaihola/following{/other_user}",
      "gists_url": "https://api.github.com/users/akaihola/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/akaihola/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/akaihola/subscriptions",
      "organizations_url": "https://api.github.com/users/akaihola/orgs",
      "repos_url": "https://api.github.com/users/akaihola/repos",
      "events_url": "https://api.github.com/users/akaihola/events{/privacy}",
      "received_events_url": "https://api.github.com/users/akaihola/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-10T07:59:01Z",
    "updated_at": "2018-06-10T08:06:56Z",
    "author_association": "CONTRIBUTOR",
    "body": "The C parser engine seems to read data in 256 kibibyte blocks, and doesn't seek back to actual data end even if `nrows` stops parsing early:\r\n```python\r\nimport pandas as pd\r\nimport os\r\n\r\ncsv_path = 'pandas/tests/io/sas/data/DEMO_G.csv'\r\n\r\ncsv_size_kib = os.path.getsize(csv_path) / 1024.\r\nprint(f'{csv_size_kib} KiB in {csv_path}')\r\n\r\nwith open(csv_path) as f:\r\n    df = pd.read_csv(f, nrows=1)\r\n    csv_pos_after_read = f.tell() / 1024.\r\n    print(f'{csv_pos_after_read} KiB read from {csv_path}')\r\n\r\nprint(f'{df.shape} is the shape of data read from {csv_path}')\r\n```\r\n```\r\n1303.5673828125 KiB in pandas/tests/io/sas/data/DEMO_G.csv\r\n256.0 KiB read from pandas/tests/io/sas/data/DEMO_G.csv\r\n(1, 48) is the shape of data read from pandas/tests/io/sas/data/DEMO_G.csv\r\n```\r\n\r\nThe 256 KiB chunk size is hard-coded. See:\r\n- [parsers.pyx:266](/pandas-dev/pandas/blob/9d61ab5aae0dd4ca3f805275c6a8ebcaeef77d64/pandas/_libs/parsers.pyx#L266)\r\n- [parsers.pyx:317](/pandas-dev/pandas/blob/9d61ab5aae0dd4ca3f805275c6a8ebcaeef77d64/pandas/_libs/parsers.pyx#L317)\r\n- [parsers.pyx:371](/pandas-dev/pandas/blob/9d61ab5aae0dd4ca3f805275c6a8ebcaeef77d64/pandas/_libs/parsers.pyx#L371)"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/396029926",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17155#issuecomment-396029926",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17155",
    "id": 396029926,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NjAyOTkyNg==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-10T08:10:06Z",
    "updated_at": "2018-06-10T08:10:06Z",
    "author_association": "MEMBER",
    "body": "@akaihola : Thanks for this investigation!  If you're able to put all of this analysis together into a PR, that would be great!"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/396030618",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17155#issuecomment-396030618",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17155",
    "id": 396030618,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NjAzMDYxOA==",
    "user": {
      "login": "akaihola",
      "id": 13725,
      "node_id": "MDQ6VXNlcjEzNzI1",
      "avatar_url": "https://avatars3.githubusercontent.com/u/13725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/akaihola",
      "html_url": "https://github.com/akaihola",
      "followers_url": "https://api.github.com/users/akaihola/followers",
      "following_url": "https://api.github.com/users/akaihola/following{/other_user}",
      "gists_url": "https://api.github.com/users/akaihola/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/akaihola/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/akaihola/subscriptions",
      "organizations_url": "https://api.github.com/users/akaihola/orgs",
      "repos_url": "https://api.github.com/users/akaihola/repos",
      "events_url": "https://api.github.com/users/akaihola/events{/privacy}",
      "received_events_url": "https://api.github.com/users/akaihola/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-10T08:21:10Z",
    "updated_at": "2018-06-10T08:21:10Z",
    "author_association": "CONTRIBUTOR",
    "body": "I'm trying to think of solutions on the C parser side. Without knowing all the details of the parser, I wonder if the following would work:\r\n- for seekable streams (typically files):\r\n  - read in 256 KiB chunks as before to keep the performance\r\n  - when parsing, keep count of how many bytes have been consumed\r\n  - if parsing stops early (e.g. due to `nrows`), seek back to the correct position\r\n- for non-seekable streams (e.g. HTTP responses):\r\n  - read in 1 byte chunks\r\n\r\n@gfyoung is this feasible at all? Do you think there would be a significant performance penalty from reading in one-byte chunks?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/396030898",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17155#issuecomment-396030898",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17155",
    "id": 396030898,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NjAzMDg5OA==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-10T08:24:48Z",
    "updated_at": "2018-06-10T08:24:48Z",
    "author_association": "MEMBER",
    "body": "I like the files proposition, but I'm a little wary of the HTTP responses proposal.  That being said, I can't argue with hard numbers.  Give it a shot and if possible, benchmark it."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/396035449",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17155#issuecomment-396035449",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17155",
    "id": 396035449,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NjAzNTQ0OQ==",
    "user": {
      "login": "akaihola",
      "id": 13725,
      "node_id": "MDQ6VXNlcjEzNzI1",
      "avatar_url": "https://avatars3.githubusercontent.com/u/13725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/akaihola",
      "html_url": "https://github.com/akaihola",
      "followers_url": "https://api.github.com/users/akaihola/followers",
      "following_url": "https://api.github.com/users/akaihola/following{/other_user}",
      "gists_url": "https://api.github.com/users/akaihola/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/akaihola/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/akaihola/subscriptions",
      "organizations_url": "https://api.github.com/users/akaihola/orgs",
      "repos_url": "https://api.github.com/users/akaihola/repos",
      "events_url": "https://api.github.com/users/akaihola/events{/privacy}",
      "received_events_url": "https://api.github.com/users/akaihola/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-10T09:46:50Z",
    "updated_at": "2018-06-25T18:45:27Z",
    "author_association": "CONTRIBUTOR",
    "body": "Pandas' support for the \"index columns in header\" CSV format leads to this tricky example:\r\n![two-header-rows](https://user-images.githubusercontent.com/13725/41200173-48b915bc-6ca8-11e8-95cc-f09943800166.png)\r\nThe parser correctly detects that the first two rows have fewer columns than the third. Based on this, it assumes that\r\n- the second row indicates the names of the leading index columns (`state`, `year`)\r\n- the first row indicates the names of the trailing data columns (`population`, `under18`)\r\n\r\nThe catch here is that there are as many index columns as data columns (`2 + 2 = 4`). For that reason, it's not possible to avoid reading three rows before being able to decide whether the second row contains index column names or actual data.\r\n\r\nThus, it won't even be possible to make `nrows=1` always behave \"correctly\", i.e. only consume only one row of data after headers, unless yet another new option is added to explicitly define whether a multi-row header is present.\r\n\r\n(`nrows=0` is an even more pathological case of course)\r\n\r\n**Edit:** ...unless of course the index column detection logic is allowed to correct itself after the fact while parsing the first actual data row. But that would need a major overhaul of the parser code base, and would certainly complicate it considerably.\r\n\r\n----\r\n\r\n**C parser support and documentation:** Interestingly, the \"index columns in header\" feature isn't supported at all in the C parser â€“ so actually there's more opportunity for fixing `nrows=1` there as long as this feature is kept out.\r\n\r\nAlso, I don't think the feature is actually documented on the [IO Tools](https://pandas.pydata.org/pandas-docs/stable/io.html) page nor in [read_csv()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) API documentation.\r\n\r\n----\r\n\r\n**Note about docstring:** Somehow the docstring for[ _get_index_name()](https://github.com/pandas-dev/pandas/blob/9d61ab5aae0dd4ca3f805275c6a8ebcaeef77d64/pandas/io/parsers.py#L2800) confuses me. The explanation for \"case 1\" is either confusing or plain wrong:\r\n>Try several cases to get lines:\r\n>\r\n>0) There are headers on row 0 and row 1 and their total summed lengths equals the length of the next line. Treat row 0 as columns and row 1 as indices\r\n>1) Look for implicit index: there are more columns on row 1 than row 0. If this is true, assume that **row 1 lists index columns and row 0 lists normal columns**.\r\n>2) Get index from the columns if it was listed.\r\n\r\nThe bolded part should in my opinion say *\"row 0 lists normal columns, and additional leading columns in data are treated as index columns\"*.\r\n\r\n----\r\n\r\nAnyway, thanks @gfyoung for your comments. I'll continue working on this on spare time, and I'll try to come up with PRs for at least some of the discussed issues."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/396054185",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17155#issuecomment-396054185",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17155",
    "id": 396054185,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NjA1NDE4NQ==",
    "user": {
      "login": "akaihola",
      "id": 13725,
      "node_id": "MDQ6VXNlcjEzNzI1",
      "avatar_url": "https://avatars3.githubusercontent.com/u/13725?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/akaihola",
      "html_url": "https://github.com/akaihola",
      "followers_url": "https://api.github.com/users/akaihola/followers",
      "following_url": "https://api.github.com/users/akaihola/following{/other_user}",
      "gists_url": "https://api.github.com/users/akaihola/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/akaihola/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/akaihola/subscriptions",
      "organizations_url": "https://api.github.com/users/akaihola/orgs",
      "repos_url": "https://api.github.com/users/akaihola/repos",
      "events_url": "https://api.github.com/users/akaihola/events{/privacy}",
      "received_events_url": "https://api.github.com/users/akaihola/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-10T14:38:52Z",
    "updated_at": "2018-06-10T14:38:52Z",
    "author_association": "CONTRIBUTOR",
    "body": "I can see two alternatives for a new `pd.read_csv()` / `pandas.io.parsers.PythonParser` option which could prevent unintended consumption of more than `nrows` data rows:\r\n- `row_index_header={None|False|True}`\r\n  - `None`: current behavior (the default)\r\n    - might consume more than `nrows` data rows\r\n  - `False`: don't expect row index definitions in the header\r\n    - always interpret first row after column header as data\r\n    - prevents consuming more than `nrows` data rows\r\n  - `True`: expect row index definitions in the header\r\n    - always intrepret first row after column header as row index definitions\r\n    - prevents consuming more than `nrows` data rows\r\n- `allow_lookahead={False|True}`\r\n  - `True`: current behavior (the default)\r\n    - might consume more than `nrows` data rows\r\n  - `False`: disallow row index definitions in the header\r\n    - interpret first row after column header as data\r\n    - prevents consuming more than `nrows` data rows"
  }
]
