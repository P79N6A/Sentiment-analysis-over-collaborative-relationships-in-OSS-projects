[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/51135543",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7935#issuecomment-51135543",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7935",
    "id": 51135543,
    "node_id": "MDEyOklzc3VlQ29tbWVudDUxMTM1NTQz",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-08-05T00:23:58Z",
    "updated_at": "2014-08-05T00:23:58Z",
    "author_association": "CONTRIBUTOR",
    "body": "cc @bashtage\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/51135676",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7935#issuecomment-51135676",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7935",
    "id": 51135676,
    "node_id": "MDEyOklzc3VlQ29tbWVudDUxMTM1Njc2",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-08-05T00:26:28Z",
    "updated_at": "2014-08-05T00:26:28Z",
    "author_association": "CONTRIBUTOR",
    "body": "should be called names for compat with other readers\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/51213170",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7935#issuecomment-51213170",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7935",
    "id": 51213170,
    "node_id": "MDEyOklzc3VlQ29tbWVudDUxMjEzMTcw",
    "user": {
      "login": "bashtage",
      "id": 5585221,
      "node_id": "MDQ6VXNlcjU1ODUyMjE=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5585221?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bashtage",
      "html_url": "https://github.com/bashtage",
      "followers_url": "https://api.github.com/users/bashtage/followers",
      "following_url": "https://api.github.com/users/bashtage/following{/other_user}",
      "gists_url": "https://api.github.com/users/bashtage/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bashtage/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bashtage/subscriptions",
      "organizations_url": "https://api.github.com/users/bashtage/orgs",
      "repos_url": "https://api.github.com/users/bashtage/repos",
      "events_url": "https://api.github.com/users/bashtage/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bashtage/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-08-05T15:24:14Z",
    "updated_at": "2014-08-05T15:24:14Z",
    "author_association": "CONTRIBUTOR",
    "body": "This will be very difficult since dta files are stored in binary as rows and the reader sequentially reads each row, parses the binary and keeps the data.  A `names` input would realistically only be able to drop columns once all data had been imported, and so would not be incredibly useful, since this can be trivially done from any `DataFrame`.  \n\nRewriting the reader to skip columns would be a substantial undertaking, imo.  This said, there may be one way to do it that wouldn't be too onerous, but I won't have any time for a while.\n\nAs a workaround I would recommend doing a once and for all conversion from a DTA to a more native pandas format (e.g. hdf) and then not worrying about it.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/52762338",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7935#issuecomment-52762338",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7935",
    "id": 52762338,
    "node_id": "MDEyOklzc3VlQ29tbWVudDUyNzYyMzM4",
    "user": {
      "login": "bashtage",
      "id": 5585221,
      "node_id": "MDQ6VXNlcjU1ODUyMjE=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5585221?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bashtage",
      "html_url": "https://github.com/bashtage",
      "followers_url": "https://api.github.com/users/bashtage/followers",
      "following_url": "https://api.github.com/users/bashtage/following{/other_user}",
      "gists_url": "https://api.github.com/users/bashtage/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bashtage/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bashtage/subscriptions",
      "organizations_url": "https://api.github.com/users/bashtage/orgs",
      "repos_url": "https://api.github.com/users/bashtage/repos",
      "events_url": "https://api.github.com/users/bashtage/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bashtage/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-08-20T11:17:54Z",
    "updated_at": "2014-08-20T11:17:54Z",
    "author_association": "CONTRIBUTOR",
    "body": "@sanguineturtle \n\nRecent changes to master allow 100,000 observations with 5 variables to be read in around 0.05 seconds. Hopefully this performance means reading select columns is not really a performance issue any more.  See #8073 for benchmarks.\n\n@jreback \n\nThis probably isn't remotely possible with the modifications I made to the reader since it uses `np.frombuffer` for performance.  However, the performance improvements are large enough that this isn't an issue except possibly in memory constrained situations.  Moreover, reading only a subset of columns to minimize memory impact would probably be so slow (relative to master) that it wouldn't be be useful in situations where the dataset was very big.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/52762973",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7935#issuecomment-52762973",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7935",
    "id": 52762973,
    "node_id": "MDEyOklzc3VlQ29tbWVudDUyNzYyOTcz",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-08-20T11:26:16Z",
    "updated_at": "2014-08-20T11:26:16Z",
    "author_association": "CONTRIBUTOR",
    "body": "yep in fact in hdf you read entire rows with every column and then just reindex at the end \nbut good for now\nthanks!\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/52857405",
    "html_url": "https://github.com/pandas-dev/pandas/issues/7935#issuecomment-52857405",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/7935",
    "id": 52857405,
    "node_id": "MDEyOklzc3VlQ29tbWVudDUyODU3NDA1",
    "user": {
      "login": "sanguineturtle",
      "id": 3282792,
      "node_id": "MDQ6VXNlcjMyODI3OTI=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/3282792?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sanguineturtle",
      "html_url": "https://github.com/sanguineturtle",
      "followers_url": "https://api.github.com/users/sanguineturtle/followers",
      "following_url": "https://api.github.com/users/sanguineturtle/following{/other_user}",
      "gists_url": "https://api.github.com/users/sanguineturtle/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sanguineturtle/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sanguineturtle/subscriptions",
      "organizations_url": "https://api.github.com/users/sanguineturtle/orgs",
      "repos_url": "https://api.github.com/users/sanguineturtle/repos",
      "events_url": "https://api.github.com/users/sanguineturtle/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sanguineturtle/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-08-20T23:01:27Z",
    "updated_at": "2014-08-20T23:01:27Z",
    "author_association": "CONTRIBUTOR",
    "body": "@bashtage This is great news. Thanks for letting me know. My dataset has ~27 million observations with 8 variables. The main reason I was looking for column selection is that 4 are redundant identifiers. As you have suggested I looked into `HDF` files and have written a conversion method (for the class) and moved the source to using `HDF` files (via pandas) with year keys which has proven to have very fast retrieval. I am still learning about `HDF` but it's in built compression delivers some pretty amazing results on file size etc. \n"
  }
]
