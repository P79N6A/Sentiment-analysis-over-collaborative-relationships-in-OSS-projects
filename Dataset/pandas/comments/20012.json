[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/371467252",
    "html_url": "https://github.com/pandas-dev/pandas/issues/20012#issuecomment-371467252",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/20012",
    "id": 371467252,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM3MTQ2NzI1Mg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-03-08T11:59:24Z",
    "updated_at": "2018-03-08T11:59:24Z",
    "author_association": "CONTRIBUTOR",
    "body": "what would a centered value actually do here? is this actually useful?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/371495799",
    "html_url": "https://github.com/pandas-dev/pandas/issues/20012#issuecomment-371495799",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/20012",
    "id": 371495799,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM3MTQ5NTc5OQ==",
    "user": {
      "login": "weber-s",
      "id": 25247745,
      "node_id": "MDQ6VXNlcjI1MjQ3NzQ1",
      "avatar_url": "https://avatars1.githubusercontent.com/u/25247745?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/weber-s",
      "html_url": "https://github.com/weber-s",
      "followers_url": "https://api.github.com/users/weber-s/followers",
      "following_url": "https://api.github.com/users/weber-s/following{/other_user}",
      "gists_url": "https://api.github.com/users/weber-s/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/weber-s/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/weber-s/subscriptions",
      "organizations_url": "https://api.github.com/users/weber-s/orgs",
      "repos_url": "https://api.github.com/users/weber-s/repos",
      "events_url": "https://api.github.com/users/weber-s/events{/privacy}",
      "received_events_url": "https://api.github.com/users/weber-s/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-03-08T14:05:20Z",
    "updated_at": "2018-03-08T14:10:20Z",
    "author_association": "NONE",
    "body": "**My usecase:**\r\n\r\nI work with time series acquired by a field sampler.  The sampling rate is approximately evenly spaced, with some variation (instrument failure, etc). The signal may be noisy so I want to apply a rolling mean in order to see the general tendency.\r\n\r\nDoing a average based on the number of point is not a good idea as they can represent a variable time interval. Then, I want the rolling mean account for, let's say, the past 2.5 days to the next 2.5 days.  \r\n\r\nOne solution may be to do a rolling mean without centering and then shift it, but it only work with regularly space data. See for instance the following DataFrame with/without the \"2010-01-07\" day: \r\n\r\n```python\r\nIn[89]: idx = pd.date_range(start=\"2010-01-01\", end=\"2010-01-10\", fred=\"1D\")\r\nIn[90]: df = pd.DataFrame(index=idx, data=[1,1,1,2,2,2,3,3,3,4])\r\nIn[91]: df\r\nOut[91]:\r\n            0\r\n2010-01-01  1\r\n2010-01-02  1\r\n2010-01-03  1\r\n2010-01-04  2\r\n2010-01-05  2\r\n2010-01-06  2\r\n2010-01-07  3\r\n2010-01-08  3\r\n2010-01-09  3\r\n2010-01-10  4\r\nIn [92]: df.rolling(window=5, center=True).mean()\r\nOut[92]: \r\n              0\r\n2010-01-01  NaN\r\n2010-01-02  NaN\r\n2010-01-03  1.4\r\n2010-01-04  1.6\r\n2010-01-05  2.0\r\n2010-01-06  2.4\r\n2010-01-07  2.6\r\n2010-01-08  3.0\r\n2010-01-09  NaN\r\n2010-01-10  NaN\r\n\r\nIn [93]: df.rolling(window=\"5D\", center=False).mean()\r\nOut[93]: \r\n               0\r\n2010-01-01  1.00\r\n2010-01-02  1.00\r\n2010-01-03  1.00\r\n2010-01-04  1.25\r\n2010-01-05  1.40\r\n2010-01-06  1.60\r\n2010-01-07  2.00\r\n2010-01-08  2.40\r\n2010-01-09  2.60\r\n2010-01-10  3.00\r\nIn [94]: # The rolling mean centered with number of sample works great\r\nIn [95]: # The rolling mean with date window does something ok. I just don't want the first 5 values\r\nIn [96]: # but I just need a shift, I can handle that\r\nIn [97]: # Now, let's remove the 2010-01-07, which is something I have in my dataset\r\nIn [98]: dfdrop = df.loc[idx.delete(6)]\r\nIn [99]: dfdrop\r\nOut[99]: \r\n            0\r\n2010-01-01  1\r\n2010-01-02  1\r\n2010-01-03  1\r\n2010-01-04  2\r\n2010-01-05  2\r\n2010-01-06  2\r\n2010-01-08  3\r\n2010-01-09  3\r\n2010-01-10  4\r\nIn [100]: dfdrop.rolling(window=5, center=True).mean()\r\nOut[100]: \r\n              0\r\n2010-01-01  NaN\r\n2010-01-02  NaN\r\n2010-01-03  1.4\r\n2010-01-04  1.6\r\n2010-01-05  2.0\r\n2010-01-06  2.4\r\n2010-01-08  2.8\r\n2010-01-09  NaN\r\n2010-01-10  NaN\r\nIn [101]: dfdrop.rolling(window=\"5D\", center=False).mean()\r\nOut[101]: \r\n               0\r\n2010-01-01  1.00\r\n2010-01-02  1.00\r\n2010-01-03  1.00\r\n2010-01-04  1.25\r\n2010-01-05  1.40\r\n2010-01-06  1.60\r\n2010-01-08  2.25\r\n2010-01-09  2.50\r\n2010-01-10  3.00\r\nIn [102]: # And the shift trick is no longer an option...\r\n```\r\n\r\nTo my point of view, I would expect for each date of my dataset a mean that takes into account the value of the 2.5 days before and after the current date. \r\nI would like to have something like:\r\n\r\n```python\r\nIn [101]: dfdrop.rolling(window=\"5D\", center=True).mean()\r\nOut[101]: \r\n               0\r\n2010-01-01  NaN\r\n2010-01-02  NaN\r\n2010-01-03  1.40 #mean(1,1,1,2,2)\r\n2010-01-04  1.60 #mean(1,1,2,2,2)\r\n2010-01-05  1.75 #mean(1,2,2,2) \r\n2010-01-06  2.25 #mean(2,2,2,3)\r\n2010-01-08  3.00 #mean(2,3,3,4)\r\n2010-01-09  NaN \r\n2010-01-10  NaN\r\n\r\n```\r\n\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/371995874",
    "html_url": "https://github.com/pandas-dev/pandas/issues/20012#issuecomment-371995874",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/20012",
    "id": 371995874,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM3MTk5NTg3NA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-03-10T02:35:08Z",
    "updated_at": "2018-03-10T02:35:08Z",
    "author_association": "CONTRIBUTOR",
    "body": "with time series data, being quite explicit about shifting in time is quite important. The centering is pretty ad-hoc in its implementation, so this would require quite a bit of effort for little gain. If you want to try a PR would be ok."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/411116134",
    "html_url": "https://github.com/pandas-dev/pandas/issues/20012#issuecomment-411116134",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/20012",
    "id": 411116134,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMTExNjEzNA==",
    "user": {
      "login": "bsolomon1124",
      "id": 25164676,
      "node_id": "MDQ6VXNlcjI1MTY0Njc2",
      "avatar_url": "https://avatars1.githubusercontent.com/u/25164676?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bsolomon1124",
      "html_url": "https://github.com/bsolomon1124",
      "followers_url": "https://api.github.com/users/bsolomon1124/followers",
      "following_url": "https://api.github.com/users/bsolomon1124/following{/other_user}",
      "gists_url": "https://api.github.com/users/bsolomon1124/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bsolomon1124/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bsolomon1124/subscriptions",
      "organizations_url": "https://api.github.com/users/bsolomon1124/orgs",
      "repos_url": "https://api.github.com/users/bsolomon1124/repos",
      "events_url": "https://api.github.com/users/bsolomon1124/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bsolomon1124/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-07T16:21:16Z",
    "updated_at": "2018-08-07T16:29:10Z",
    "author_association": "NONE",
    "body": "I have also run across a use case for this.  Essentially, it would be used for computing a rolling statistic for \"n periods before and after\" each observation on a rolling basis.\r\n\r\nNote that this trick will **not** work if the data is of staggered frequency, i.e. if the data is minute-frequency but there are missing minutes:\r\n\r\n```python\r\ndata.rolling(window='15D', closed='left').statistic().shift(-1296000/2, freq='min')\r\n```\r\n\r\nA barebones implementation might look something like this.  (Please excuse my Cython.)\r\n\r\n```python\r\nfrom cython cimport Py_ssize_t\r\n\r\nimport numpy as np\r\ncimport numpy as cnp\r\nfrom numpy cimport ndarray, double_t, int64_t\r\ncnp.import_array()\r\n\r\n\r\ncpdef ndarray rolling_centered_offset(ndarray[double_t, ndim=1] data,\r\n                                      ndarray[int64_t, ndim=1] index,\r\n                                      int64_t td,\r\n                                      f):\r\n    \"\"\"Rolling function with a time-based offset & centered window.\r\n\r\n    Parameters\r\n    ----------\r\n    data: 1D ndarray of floats\r\n        Array for which function will be computed.\r\n    index: 1D ndarray of date-ints\r\n        Dates that align with the data where windows are computed.\r\n        If you have a Pandas DatetimeIndex, use `index.asi8`\r\n    td: numpy.timedelta64\r\n        The offset in either direction, in the same precision as `index`.\r\n        If you have a datetime64[ns] Pandas Index as i8 and a timedelta of\r\n        pd.Timedelta('15D'), you would need to pass\r\n        `np.timedelta64(15, 'D') / np.timedelta64(1, 'ns')`\r\n    f:\r\n        The function/callable statistic, i.e. np.nanmean\r\n\r\n    Returns\r\n    -------\r\n    out: ndarray\r\n    \"\"\"\r\n\r\n    cdef:\r\n        Py_ssize_t i, j, k, n\r\n        ndarray[double_t] out\r\n        ndarray[int64_t] starts, ends\r\n\r\n    n = data.shape[0]\r\n    out = np.empty(n, dtype=float)\r\n\r\n    starts = index.searchsorted(index - td)\r\n    ends = index.searchsorted(index + td)\r\n\r\n    for i, (j, k) in enumerate(zip(starts, ends)):\r\n        out[i] = f(data[j:k])\r\n\r\n    return out\r\n```\r\n\r\nExample:\r\n\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nnp.random.seed(444)\r\nsize = 1938\r\n\r\ndef random_dates(start, end, n):\r\n    # Thanks https://stackoverflow.com/a/50668285/7954504\r\n    start_u = start.value//10**9\r\n    end_u = end.value//10**9\r\n    return pd.DatetimeIndex((10**9*np.random.randint(start_u, end_u, n)).view('M8[ns]'))\r\n\r\nstart = pd.Timestamp('2014-05-16 13:53:50+0000', tz='UTC')\r\nend = pd.Timestamp('2018-07-31 10:40:47+0000', tz='UTC')\r\n\r\nmock = pd.Series(np.random.randint(0, 10, size=size),\r\n                 index=random_dates(start, end, n=size)).sort_index()\r\n\r\nfrom rolling import rolling_centered_offset\r\n\r\ntd = 1296000000000000\r\n\r\nrolling_centered_offset(data=mock.values.astype(float), index=mock.index.asi8, td=td, f=np.nanmean)\r\narray([4.75  , 4.75  , 4.7143, 4.4348, 4.2917, 4.2143, 4.2143, 4.069 ,\r\n       4.069 , 4.2812, ..., 4.6667, 4.6897, 4.875 , 5.0435, 5.0435,\r\n       4.8636, 5.05  , 5.    , 5.    , 4.8889])\r\n```\r\n\r\nOne other note about actually reindexing: that is probably a dangerous route as it blows up RAM pretty easily."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/440647546",
    "html_url": "https://github.com/pandas-dev/pandas/issues/20012#issuecomment-440647546",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/20012",
    "id": 440647546,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MDY0NzU0Ng==",
    "user": {
      "login": "scootty1",
      "id": 38665102,
      "node_id": "MDQ6VXNlcjM4NjY1MTAy",
      "avatar_url": "https://avatars0.githubusercontent.com/u/38665102?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/scootty1",
      "html_url": "https://github.com/scootty1",
      "followers_url": "https://api.github.com/users/scootty1/followers",
      "following_url": "https://api.github.com/users/scootty1/following{/other_user}",
      "gists_url": "https://api.github.com/users/scootty1/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/scootty1/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/scootty1/subscriptions",
      "organizations_url": "https://api.github.com/users/scootty1/orgs",
      "repos_url": "https://api.github.com/users/scootty1/repos",
      "events_url": "https://api.github.com/users/scootty1/events{/privacy}",
      "received_events_url": "https://api.github.com/users/scootty1/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-21T12:35:31Z",
    "updated_at": "2018-11-21T14:09:21Z",
    "author_association": "NONE",
    "body": "@jreback I can also state that having a centered representation is really useful and important for time series analysis. I can only say that for the field of engineering it is frequently used (and you usually think in terms of a centered rolling window when using rolling windows...), resulting in two cases:\r\n- Case 1: most people don't really know what they are *really* doing with their data, thus they just use the rolling window and **expect** that it is centered.\r\n- Case 2: those who do know what they are doing, will have shift the data which is quite cumbersome, especially with unevenly spaced time series.\r\n\r\nJust one example: If you want to calculate the average power output as a rolling statistic over window='1d', it is not straight-forward when the value for the day (from 00:00:00 to 23:59:59) is set to 23:59:59\r\n\r\nCurrently shifting (and resampling for unevenly spaced time series) is the only possibility.\r\n\r\nEdit: Another important point: When resampling with `min_periods < window`, the last values of the rolling data will be lost when shifting, since non-centered rolling will set the values of the last window to the last index, even though there is still more data than min_periods. This can't be an intentional behavious, since it is a loss of information.\r\nThe only workaround for this is using a rolling window by replacing the datetime index with an integer index. But this makes it impossible to use rolling with a window-length which is **not** a multiple of the frequency."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/459132598",
    "html_url": "https://github.com/pandas-dev/pandas/issues/20012#issuecomment-459132598",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/20012",
    "id": 459132598,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1OTEzMjU5OA==",
    "user": {
      "login": "parsons-kyle-89",
      "id": 31140928,
      "node_id": "MDQ6VXNlcjMxMTQwOTI4",
      "avatar_url": "https://avatars3.githubusercontent.com/u/31140928?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/parsons-kyle-89",
      "html_url": "https://github.com/parsons-kyle-89",
      "followers_url": "https://api.github.com/users/parsons-kyle-89/followers",
      "following_url": "https://api.github.com/users/parsons-kyle-89/following{/other_user}",
      "gists_url": "https://api.github.com/users/parsons-kyle-89/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/parsons-kyle-89/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/parsons-kyle-89/subscriptions",
      "organizations_url": "https://api.github.com/users/parsons-kyle-89/orgs",
      "repos_url": "https://api.github.com/users/parsons-kyle-89/repos",
      "events_url": "https://api.github.com/users/parsons-kyle-89/events{/privacy}",
      "received_events_url": "https://api.github.com/users/parsons-kyle-89/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-30T22:18:43Z",
    "updated_at": "2019-01-30T22:18:43Z",
    "author_association": "NONE",
    "body": "I'm taking a look into this right now.  My thought was that in the cython [libwindow](https://github.com/pandas-dev/pandas/blob/master/pandas/_libs/window.pyx), the `roll_<func>` functions should be modified to take `left_win` and `right_win` arguments (instead of the current `win` argument).  These numbers would be computed by the [`_offset`](https://github.com/pandas-dev/pandas/blob/4bf3a0e11d2e98afc9ee76dbe54a667410d0220e/pandas/core/window.py#L2563) function.  As a bonus, this would allow most of the `if center` statements to be removed in [window.py](https://github.com/pandas-dev/pandas/blob/master/pandas/core/window.py).\r\n\r\nIn the cython code, each of the roll functions would pass `left_win` and `right_win` on to [`get_window_indexer`](https://github.com/pandas-dev/pandas/blob/515b0fa77e788c7fc15c9966e502ee99585fed39/pandas/_libs/window.pyx#L299) which would them pass them on to each of the `WindowIndexer` subclasses.  The implementation for the static window indexers would be trivial.  The implementation for the variable window indexer wouldn't be too much harder (and would basically just mirror the code that's already there for the left endpoint).  \r\n\r\nDoes anyone have any thoughts on this strategy?  On one hand it seems inefficient to have to change the function signatures of each of the cython roll functions individually, but it's not clear to me if there's a slicker way to do that.  "
  }
]
