[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/64932169",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-64932169",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 64932169,
    "node_id": "MDEyOklzc3VlQ29tbWVudDY0OTMyMTY5",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-11-28T22:26:57Z",
    "updated_at": "2014-11-28T22:26:57Z",
    "author_association": "CONTRIBUTOR",
    "body": "well how about a pseudo code example with inputs and outputs from a sample frame would be useful\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/64955748",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-64955748",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 64955748,
    "node_id": "MDEyOklzc3VlQ29tbWVudDY0OTU1NzQ4",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-11-29T15:49:17Z",
    "updated_at": "2014-11-29T15:49:30Z",
    "author_association": "CONTRIBUTOR",
    "body": "@chrish42, an example would be great.\n\nFYI scikit-learn has the [OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) class which fits into their pipeline.\n\nSomething like this should work?\n\n``` python\nimport pandas as pd\nfrom sklearn.pipeline import TransformerMixin\n\nclass DummyEncoder(TransformerMixin):\n\n    def __init__(self, columns=None):\n\n        self.columns = columns\n\n    def transform(self, X, y=None, **kwargs):\n\n        return pd.get_dummies(X, columns=self.columns)\n\n    def fit(self, X, y=None, **kwargs):\n\n        return self\n```\n\nGiving\n\n```\nIn [15]: df\nOut[15]: \n   A  B  C\n0  1  a  a\n1  2  b  a\n\nIn [16]: DummyEncoder().transform(df)\nOut[16]: \n   A  B_a  B_b  C_a\n0  1    1    0    1\n1  2    0    1    1\n```\n\nBe careful with the ordering of the columns.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/68929083",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-68929083",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 68929083,
    "node_id": "MDEyOklzc3VlQ29tbWVudDY4OTI5MDgz",
    "user": {
      "login": "chrish42",
      "id": 632858,
      "node_id": "MDQ6VXNlcjYzMjg1OA==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/632858?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/chrish42",
      "html_url": "https://github.com/chrish42",
      "followers_url": "https://api.github.com/users/chrish42/followers",
      "following_url": "https://api.github.com/users/chrish42/following{/other_user}",
      "gists_url": "https://api.github.com/users/chrish42/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/chrish42/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/chrish42/subscriptions",
      "organizations_url": "https://api.github.com/users/chrish42/orgs",
      "repos_url": "https://api.github.com/users/chrish42/repos",
      "events_url": "https://api.github.com/users/chrish42/events{/privacy}",
      "received_events_url": "https://api.github.com/users/chrish42/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-01-06T20:35:02Z",
    "updated_at": "2015-01-06T20:35:02Z",
    "author_association": "CONTRIBUTOR",
    "body": "@TomAugspurger, actually the compatibility with the sklearn processing pipeline itself is not the part that interests me. What I would like is the ability to save the transformation done by get_dummes() to a dataset, and then apply said transformation as is (creating the exact same columns), even if the second dataset has a subset of the values of the first one in some column, etc. That's actually what I meant by \"usable in a train/test framework\". Is this explanation clearer? (I can add an example someone thinks that's still needed.)\n\nI'm aware of the `OneHotEncoder` class in sklearn, but it has other limitations.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/145486273",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-145486273",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 145486273,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NTQ4NjI3Mw==",
    "user": {
      "login": "davidbp",
      "id": 4223580,
      "node_id": "MDQ6VXNlcjQyMjM1ODA=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/4223580?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/davidbp",
      "html_url": "https://github.com/davidbp",
      "followers_url": "https://api.github.com/users/davidbp/followers",
      "following_url": "https://api.github.com/users/davidbp/following{/other_user}",
      "gists_url": "https://api.github.com/users/davidbp/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/davidbp/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/davidbp/subscriptions",
      "organizations_url": "https://api.github.com/users/davidbp/orgs",
      "repos_url": "https://api.github.com/users/davidbp/repos",
      "events_url": "https://api.github.com/users/davidbp/events{/privacy}",
      "received_events_url": "https://api.github.com/users/davidbp/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-05T10:07:43Z",
    "updated_at": "2015-10-05T10:20:11Z",
    "author_association": "NONE",
    "body": "I stumbled upton the same problem as @chrish42 and I found get_dummies giving me some headache.\n\n#### Example of the limitations of the current get dummies\n\nLet us assume we work with data from the following df_train DataFrame\n\n``` .python\ndf_train = pandas.DataFrame({\"car\":[\"seat\",\"bmw\"], \"color\":[\"red\",\"green\"]})\npandas.get_dummies(df_train )\n\n   car_bmw  car_seat  color_green  color_red\n0        0         1            0          1\n1        1         0            1          0\n```\n\nThen we are provided with\n\n``` .python\ndf_test = pandas.DataFrame({\"car\":[\"seat\",\"mercedes\"], \"color\":[\"red\",\"green\"]})\npandas.get_dummies(df_test )\n\n         car_mercedes  car_seat  color_green  color_red\n0             0         1            0          1\n1             1         0            1          0\n```\n\nSince I have never observed a \"mercedes\" value for variable \"car\" in  df_train I would like to be able to get the following one hot encoding:\n\n``` .python\n           car_bmw  car_seat  color_green  color_red\n0             0         1            0          1\n1             0         0            1          0\n```\n\nWhere the column car_mercedes actually never appears.\n\nThis could be solved by allowing get_dummies to receive an input dictionary stating the accepted values that we allow for each column.  \n\nReturning to the previous example, we could give as input to get_dummies the following dict of sets\n\n``` .python\naccepted_values_per_column = {'car': {'bmw', 'seat'}, 'color': {'green', 'red'}}\n```\n\nand we would expect get_dummies to return\n\n``` .python\nget_dummies(df_test, accepted_values_per_column = accepted_values_per_column) \n\n           car_bmw  car_seat  color_green  color_red\n0             0         1            0          1\n1             0         0            1          0\n```\n\nand expect get_dummies(df_test) to return what already returns.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/145490689",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-145490689",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 145490689,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NTQ5MDY4OQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-05T10:34:22Z",
    "updated_at": "2015-10-05T10:34:22Z",
    "author_association": "CONTRIBUTOR",
    "body": "You simply need make your variables `Categorical` if you want to specified _possibly_ unobserved variables. This can be done at creation time or afterwards, see the [docs](http://pandas.pydata.org/pandas-docs/stable/categorical.html)\n\n```\nIn [5]: df_train = pd.DataFrame({\"car\":Series([\"seat\",\"bmw\"]).astype('category',categories=['seat','bmw','mercedes']),\"color\":[\"red\",\"green\"]})\n\nIn [6]: df_train\nOut[6]: \n    car  color\n0  seat    red\n1   bmw  green\n\nIn [7]: pd.get_dummies(df_train )\nOut[7]: \n   car_seat  car_bmw  car_mercedes  color_green  color_red\n0         1        0             0            0          1\n1         0        1             0            1          0\n```\n\nThe original question is not well specified, so closing.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/145504396",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-145504396",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 145504396,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE0NTUwNDM5Ng==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-05T11:50:59Z",
    "updated_at": "2015-10-05T11:50:59Z",
    "author_association": "CONTRIBUTOR",
    "body": "And when you're going the other way, from the encoding to back to Categorical you'll use Categorical.from_codes. \n\nOne more bit of unsolicited advice. If you care at all about accurate estimates of the coefficients on the categoricals, drop one of the encoded columns or else you'll have multicolinearity with the intercept (if you have one). \n\n> On Oct 5, 2015, at 05:34, Jeff Reback notifications@github.com wrote:\n> \n> You simply need make your variables Categorical if you want to specified possibly unobserved variables. This can be done at creation time or afterwards, see the docs\n> \n> In [5]: df_train = pd.DataFrame({\"car\":Series([\"seat\",\"bmw\"]).astype('category',categories=['seat','bmw','mercedes']),\"color\":[\"red\",\"green\"]})\n> \n> In [6]: df_train\n> Out[6]: \n>     car  color\n> 0  seat    red\n> 1   bmw  green\n> \n> In [7]: pd.get_dummies(df_train )\n> Out[7]: \n>    car_seat  car_bmw  car_mercedes  color_green  color_red\n> 0         1        0             0            0          1\n> 1         0        1             0            1          0\n> The original question is not well specified, so closing.\n> \n> —\n> Reply to this email directly or view it on GitHub.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/272327310",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-272327310",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 272327310,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI3MjMyNzMxMA==",
    "user": {
      "login": "aileronajay",
      "id": 4158294,
      "node_id": "MDQ6VXNlcjQxNTgyOTQ=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/4158294?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/aileronajay",
      "html_url": "https://github.com/aileronajay",
      "followers_url": "https://api.github.com/users/aileronajay/followers",
      "following_url": "https://api.github.com/users/aileronajay/following{/other_user}",
      "gists_url": "https://api.github.com/users/aileronajay/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/aileronajay/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/aileronajay/subscriptions",
      "organizations_url": "https://api.github.com/users/aileronajay/orgs",
      "repos_url": "https://api.github.com/users/aileronajay/repos",
      "events_url": "https://api.github.com/users/aileronajay/events{/privacy}",
      "received_events_url": "https://api.github.com/users/aileronajay/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-01-13T00:30:56Z",
    "updated_at": "2017-01-13T00:43:08Z",
    "author_association": "CONTRIBUTOR",
    "body": "@TomAugspurger  @jreback I think i have run into the same problem lately and i would like to state an example\r\n\r\ntrain_a = pd.DataFrame({\"IsBadBuy\":[0,1,0], \"Make\":['Toyota', 'Mazda','BMW']})\r\n\r\n\r\nIsBadBuy\tMake_BMW\tMake_Mazda\tMake_Toyota\r\n0\t0\t0\t0\t1\r\n1\t1\t0\t1\t0\r\n2\t0\t1\t0\t0\r\n\r\n\r\ntest_a = pd.DataFrame({\"Make\":['Toyota','BMW']})\r\nprint pd.get_dummies(test_a,columns=['Make'])\r\n\r\n   Make_BMW  Make_Toyota\r\n0         0            1\r\n1         1            0\r\n\r\nHere ideally the Make_Mazda column should be preserved as the ML algorithm would expect the same number of features and the values that we get in the test will be a subset of that in train. \r\n\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/272339635",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-272339635",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 272339635,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI3MjMzOTYzNQ==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-01-13T01:51:12Z",
    "updated_at": "2017-01-13T01:51:12Z",
    "author_association": "CONTRIBUTOR",
    "body": "Use a Categorical. That will expand to the correct number of columns. I gave a talk about this if you're interested https://m.youtube.com/watch?v=KLPtEBokqQ0\n\n\n\t\t_____________________________\nFrom: Ajay Saxena <notifications@github.com>\nSent: Thursday, January 12, 2017 18:31\nSubject: Re: [pandas-dev/pandas] Wishlist: make get_dummies() usable for train / test framework (#8918)\nTo: pandas-dev/pandas <pandas@noreply.github.com>\nCc: Tom Augspurger <thomas-augspurger@uiowa.edu>, Mention <mention@noreply.github.com>\n\n\n\n\n@jreback I think i have run into the same problem lately and i would like to state an example\n\ntrain_a = pd.DataFrame({\"IsBadBuy\":[0,1,0], \"Make\":['Toyota', 'Mazda','BMW']})\n\nIsBadBuy\tMake_BMW\tMake_Mazda\tMake_Toyota\n0\t0\t0\t0\t1\n1\t1\t0\t1\t0\n2\t0\t1\t0\t0\n\ntest_a = pd.DataFrame({\"Make\":['Toyota','BMW']})\nprint pd.get_dummies(test_a,columns=['Make'])\n\nMake_BMW  Make_Toyota\n0         0            1\n1         1            0\n\nHere ideally the Make_Mazda column should be preserved as the ML algorithm would expect the same number of features and the values that we get in the test will be a subset of that in train.\n\n—\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.    \n\n\n\t"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/272340501",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-272340501",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 272340501,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI3MjM0MDUwMQ==",
    "user": {
      "login": "aileronajay",
      "id": 4158294,
      "node_id": "MDQ6VXNlcjQxNTgyOTQ=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/4158294?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/aileronajay",
      "html_url": "https://github.com/aileronajay",
      "followers_url": "https://api.github.com/users/aileronajay/followers",
      "following_url": "https://api.github.com/users/aileronajay/following{/other_user}",
      "gists_url": "https://api.github.com/users/aileronajay/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/aileronajay/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/aileronajay/subscriptions",
      "organizations_url": "https://api.github.com/users/aileronajay/orgs",
      "repos_url": "https://api.github.com/users/aileronajay/repos",
      "events_url": "https://api.github.com/users/aileronajay/events{/privacy}",
      "received_events_url": "https://api.github.com/users/aileronajay/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-01-13T01:57:26Z",
    "updated_at": "2017-01-13T01:57:26Z",
    "author_association": "CONTRIBUTOR",
    "body": "Thanks @TomAugspurger "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/300638388",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-300638388",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 300638388,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDYzODM4OA==",
    "user": {
      "login": "brifordwylie",
      "id": 4806709,
      "node_id": "MDQ6VXNlcjQ4MDY3MDk=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/4806709?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/brifordwylie",
      "html_url": "https://github.com/brifordwylie",
      "followers_url": "https://api.github.com/users/brifordwylie/followers",
      "following_url": "https://api.github.com/users/brifordwylie/following{/other_user}",
      "gists_url": "https://api.github.com/users/brifordwylie/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/brifordwylie/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/brifordwylie/subscriptions",
      "organizations_url": "https://api.github.com/users/brifordwylie/orgs",
      "repos_url": "https://api.github.com/users/brifordwylie/repos",
      "events_url": "https://api.github.com/users/brifordwylie/events{/privacy}",
      "received_events_url": "https://api.github.com/users/brifordwylie/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-05-10T23:13:44Z",
    "updated_at": "2017-05-11T19:42:58Z",
    "author_association": "NONE",
    "body": "The PyData Chicago 2016 talk given by @TomAugspurger was really well done. He did a fantastic job of illustrating all the reasons why this issue/request should not be closed. IMHO either his class DummyEncoder or some reasonable equivalent should be included in Pandas proper. Yes I can go to his github and copy/emulate his class but it would be much nicer to just have it supported within the library. "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/300766743",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-300766743",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 300766743,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDc2Njc0Mw==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-05-11T11:53:05Z",
    "updated_at": "2017-05-11T11:53:05Z",
    "author_association": "CONTRIBUTOR",
    "body": "I think there's a need for a library that goes early in the data-modeling\npipeline and works well with pandas and scikit-learn.\nBut pandas doesn't depend on scikit-learn and vice-versa. I think there's\nroom for another library built on top of both.\n\nOn Wed, May 10, 2017 at 6:13 PM, Brian Wylie <notifications@github.com>\nwrote:\n\n> The PyData Chicago 2016 talk given by @TomAugspurger\n> <https://github.com/TomAugspurger> was really well done. He did a\n> fantastic job of illustrating all the reasons why this issue/request should\n> not be closed. IMHO either his class DummyEncoder or some reasonable\n> equivalent should be included in Pandas proper. Yes I can go to his github\n> and copy/emulate his class but it would be much nicer to just have it\n> supported within the library.\n>\n> BTW I think @TomAugspurger <https://github.com/TomAugspurger> might be my\n> new favorite PyData guru. I'm going to hunt down everything he's\n> done/working on and try to absorb it.. not in a creepy/stalking way.. you\n> know just in a normal way that's not creepy at all. :)\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pandas-dev/pandas/issues/8918#issuecomment-300638388>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABQHIpTqgHSE7iFVF9Pp4_YoKB9DPLcEks5r4kSrgaJpZM4DB6Hb>\n> .\n>\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/337348671",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-337348671",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 337348671,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNzM0ODY3MQ==",
    "user": {
      "login": "joeddav",
      "id": 9353833,
      "node_id": "MDQ6VXNlcjkzNTM4MzM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9353833?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/joeddav",
      "html_url": "https://github.com/joeddav",
      "followers_url": "https://api.github.com/users/joeddav/followers",
      "following_url": "https://api.github.com/users/joeddav/following{/other_user}",
      "gists_url": "https://api.github.com/users/joeddav/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/joeddav/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/joeddav/subscriptions",
      "organizations_url": "https://api.github.com/users/joeddav/orgs",
      "repos_url": "https://api.github.com/users/joeddav/repos",
      "events_url": "https://api.github.com/users/joeddav/events{/privacy}",
      "received_events_url": "https://api.github.com/users/joeddav/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-17T19:46:50Z",
    "updated_at": "2017-10-17T19:46:50Z",
    "author_association": "NONE",
    "body": "Here's a little solution some of us worked on that may be helpful for some here. Dummy variables with fit/transform capabilities.\r\n\r\nhttps://github.com/joeddav/get_smarties\r\n\r\nFeedback and contributions would be helpful!"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/341217086",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-341217086",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 341217086,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM0MTIxNzA4Ng==",
    "user": {
      "login": "Aylr",
      "id": 928247,
      "node_id": "MDQ6VXNlcjkyODI0Nw==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/928247?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Aylr",
      "html_url": "https://github.com/Aylr",
      "followers_url": "https://api.github.com/users/Aylr/followers",
      "following_url": "https://api.github.com/users/Aylr/following{/other_user}",
      "gists_url": "https://api.github.com/users/Aylr/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Aylr/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Aylr/subscriptions",
      "organizations_url": "https://api.github.com/users/Aylr/orgs",
      "repos_url": "https://api.github.com/users/Aylr/repos",
      "events_url": "https://api.github.com/users/Aylr/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Aylr/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-11-01T19:42:43Z",
    "updated_at": "2017-11-01T19:42:43Z",
    "author_association": "NONE",
    "body": "This appears related to #14017"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/351819507",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-351819507",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 351819507,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MTgxOTUwNw==",
    "user": {
      "login": "yashu-seth",
      "id": 14197921,
      "node_id": "MDQ6VXNlcjE0MTk3OTIx",
      "avatar_url": "https://avatars1.githubusercontent.com/u/14197921?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/yashu-seth",
      "html_url": "https://github.com/yashu-seth",
      "followers_url": "https://api.github.com/users/yashu-seth/followers",
      "following_url": "https://api.github.com/users/yashu-seth/following{/other_user}",
      "gists_url": "https://api.github.com/users/yashu-seth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/yashu-seth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/yashu-seth/subscriptions",
      "organizations_url": "https://api.github.com/users/yashu-seth/orgs",
      "repos_url": "https://api.github.com/users/yashu-seth/repos",
      "events_url": "https://api.github.com/users/yashu-seth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/yashu-seth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-14T19:58:52Z",
    "updated_at": "2017-12-14T19:59:06Z",
    "author_association": "NONE",
    "body": "I have created a solution that may be helpful exactly in this problem. One Hot Encoding categorical variable in a train test framework. It can also handle cases when the dataset is too large to fit in the machine memory.\r\n\r\n[https://github.com/yashu-seth/dummyPy](https://github.com/yashu-seth/dummyPy)\r\n\r\nYou can also find a small tutorial on this [here](https://yashuseth.wordpress.com/2017/12/14/how-to-one-hot-encode-categorical-variables-of-a-large-dataset-in-python/).\r\n\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/351820755",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-351820755",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 351820755,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MTgyMDc1NQ==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-14T20:03:56Z",
    "updated_at": "2017-12-14T20:03:56Z",
    "author_association": "CONTRIBUTOR",
    "body": "People subscribed to this may be interested in dask-ml's implementation\r\n\r\n- http://dask-ml.readthedocs.io/en/latest/preprocessing.html#additional-tranformers\r\n- http://dask-ml.readthedocs.io/en/latest/modules/generated/dask_ml.preprocessing.Categorizer.html#dask_ml.preprocessing.Categorizer\r\n- http://dask-ml.readthedocs.io/en/latest/modules/generated/dask_ml.preprocessing.DummyEncoder.html#dask_ml.preprocessing.DummyEncoder"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/357054677",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8918#issuecomment-357054677",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8918",
    "id": 357054677,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1NzA1NDY3Nw==",
    "user": {
      "login": "md733406",
      "id": 35312359,
      "node_id": "MDQ6VXNlcjM1MzEyMzU5",
      "avatar_url": "https://avatars0.githubusercontent.com/u/35312359?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/md733406",
      "html_url": "https://github.com/md733406",
      "followers_url": "https://api.github.com/users/md733406/followers",
      "following_url": "https://api.github.com/users/md733406/following{/other_user}",
      "gists_url": "https://api.github.com/users/md733406/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/md733406/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/md733406/subscriptions",
      "organizations_url": "https://api.github.com/users/md733406/orgs",
      "repos_url": "https://api.github.com/users/md733406/repos",
      "events_url": "https://api.github.com/users/md733406/events{/privacy}",
      "received_events_url": "https://api.github.com/users/md733406/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-01-11T20:40:55Z",
    "updated_at": "2018-01-11T20:41:22Z",
    "author_association": "NONE",
    "body": "@TomAugspurger  This Code doesn't work. When I go to transform my production single record data it only gives me the one hot encoded column for the single value that is present.\r\nWhat am I missing?\r\n\r\nimport pyodbc\r\nimport pickle\r\nfrom sklearn.linear_model import LogisticRegression\r\nfrom sklearn.linear_model import LinearRegression\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom sklearn.pipeline import TransformerMixin\r\nfrom sklearn.pipeline import make_pipeline\r\n\r\n\r\n\r\nclass DummyEncoder(TransformerMixin):\r\n    def fit(self, X, y=None):\r\n        self.index_ = X.index\r\n        self.columns_ = X.columns\r\n        self.cat_columns_ = X.select_dtypes(include=['category']).columns\r\n        self.non_cat_columns_ = X.columns.drop(self.cat_columns_)\r\n        \r\n        self.cat_map_ = {col: X[col].cat for col in self.cat_columns_}\r\n        \r\n        left = len(self.non_cat_columns_)\r\n        self.cat_blocks_ = {}\r\n        for col in self.cat_columns_:\r\n            right = left + len(X[col].cat.categories)\r\n            self.cat_blocks_[col], left = slice(left, right), right\r\n        return self\r\n\r\n    def transform(self, X, y=None):\r\n        return np.asarray(pd.get_dummies(X))\r\n    \r\n    def inverse_transform(self, X):\r\n        non_cat = pd.DataFrame(X[:, :len(self.non_Cat_columns_)],\r\n                                 columns=self.non_cat_columns_)\r\n        cats = []\r\n        for col, cat in self.cat_map_.items():\r\n            slice_ = self.cat_blocks_[col]\r\n            codes = X[:, slice_].argmax(1)\r\n            series = pd.Series(pd.Categorical.from_codes(\r\n                    codes, cat.categories, ordered=cat.ordered\r\n            ), name=col)\r\n            cats.append(series)\r\n        df = pd.concat([non_cat] + cats, axis=1)[self.columns_]\r\n        return df\r\n        \r\n#import data from SQL to pandas Dataframe\r\ncnxn = pyodbc.connect('DRIVER={SQL Server};SERVER={XXXXX};DATABASE={ML_Learn_Taxi};UID={XXXX};PWD={XXXX}')\r\nsql =\"\"\" \\\r\nSELECT top 1 CONVERT(int, [order_key]) order_key \\\r\n      ,CONVERT(int, [service_date_key]) service_date_key \\\r\n      ,[order_source_desc] \\\r\n      ,1 as 'return_flag' \\\r\n  FROM [ML_Return_Customer].[dbo].[return_customers_test_set] \\\r\n  WHERE [order_source_desc]='Online' \\\r\nUNION \\\r\nSELECT top 2 CONVERT(int, [order_key]) \\\r\n      ,CONVERT( int, [service_date_key]) \\\r\n      ,[order_source_desc] \\\r\n      ,2 \\\r\n  FROM [ML_Return_Customer].[dbo].[return_customers_test_set] \\\r\n  WHERE [order_source_desc]='Inbound Call' \\\r\n  UNION \\\r\n  SELECT top 1 CONVERT(int, [order_key]) \\\r\n      ,CONVERT(int, [service_date_key]) \\\r\n      ,[order_source_desc] \\\r\n      ,1 \\\r\n  FROM [ML_Return_Customer].[dbo].[return_customers_test_set] \\\r\n  WHERE [order_source_desc]='Outbound Call'\r\n\"\"\"\r\n\r\nprod_sql =\"\"\" \\\r\nSELECT top 1 CONVERT(int, [order_key]) order_key \\\r\n      ,CONVERT(int, [service_date_key]) service_date_key \\\r\n      ,[order_source_desc] \\\r\n      ,1 as 'return_flag' \\\r\n  FROM [ML_Return_Customer].[dbo].[return_customers_test_set] \\\r\n  WHERE [order_source_desc]='Online'\r\n\"\"\"\r\n\r\nInputDataSet = pd.read_sql(sql, cnxn)\r\nProdDataSet =  pd.read_sql(prod_sql, cnxn)\r\n\r\nprint(\"*************** Data ******************\")\r\nprint(InputDataSet)   \r\n\r\n\r\nprint(\"******** Category Columns Info ***********\")\r\ncolumns = ['order_source_desc']\r\nInputDataSet[columns] = InputDataSet[columns].apply(lambda x: x.astype('category'))\r\n\r\nInputDataSet.info()\r\n\r\nprint(\"******** Linear Regression ***********\")\r\n\r\nX = InputDataSet.drop('return_flag', axis=1)\r\ny = InputDataSet['return_flag']\r\n\r\nA = ProdDataSet.drop('return_flag', axis=1)\r\nB = ProdDataSet['return_flag']\r\n\r\nenc = DummyEncoder()\r\nenc.fit(X)\r\n#rain = enc.transform(X)\r\nProd = enc.transform(A)\r\n\r\nprint(Prod)\r\n\r\nOUTPUT: *************** Data ******************\r\n   order_key  service_date_key order_source_desc  return_flag\r\n0   10087937          20151214            Online            1\r\n1   10088174          20151201      Inbound Call            2\r\n2   10088553          20151217      Inbound Call            2\r\n3     663478          20160806     Outbound Call            1\r\n******** Category Columns Info ***********\r\n<class 'pandas.core.frame.DataFrame'>\r\nRangeIndex: 4 entries, 0 to 3\r\nData columns (total 4 columns):\r\norder_key            4 non-null int64\r\nservice_date_key     4 non-null int64\r\norder_source_desc    4 non-null category\r\nreturn_flag          4 non-null int64\r\ndtypes: category(1), int64(3)\r\nmemory usage: 284.0 bytes\r\n******** Linear Regression ***********\r\n[[10087937 20151214        1]]\r\n"
  }
]
