[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/22042771",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-22042771",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 22042771,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIyMDQyNzcx",
    "user": {
      "login": "cpcloud",
      "id": 417981,
      "node_id": "MDQ6VXNlcjQxNzk4MQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/417981?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cpcloud",
      "html_url": "https://github.com/cpcloud",
      "followers_url": "https://api.github.com/users/cpcloud/followers",
      "following_url": "https://api.github.com/users/cpcloud/following{/other_user}",
      "gists_url": "https://api.github.com/users/cpcloud/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cpcloud/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cpcloud/subscriptions",
      "organizations_url": "https://api.github.com/users/cpcloud/orgs",
      "repos_url": "https://api.github.com/users/cpcloud/repos",
      "events_url": "https://api.github.com/users/cpcloud/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cpcloud/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-08-02T23:21:07Z",
    "updated_at": "2013-08-02T23:23:17Z",
    "author_association": "MEMBER",
    "body": "what does the running time of syncing of indices depend on other than possibly the obvious `len(index)`?\n\n:+1: sounds interesting\n\ni also think should default to `Table` format, but that's not really back compat...I just find table much more useful\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/22043142",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-22043142",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 22043142,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIyMDQzMTQy",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-08-02T23:29:03Z",
    "updated_at": "2013-08-02T23:29:03Z",
    "author_association": "CONTRIBUTOR",
    "body": "when I say syncing indices I really mean its an append operation is a function of the number of columns\n\ne.g.\n\n`DataFrame(randn(100,100))`\n will have to traverse 100 columns and append its 100 rows to each\n\nwhile `DataFrame(randn(100,10))` will have to traverse 10 columns to append its 100 rows\n\nin `Table` format these would take the same amount of work\n\nselection is the same principle (subject of course to the number of columns actually selected. That is the big benefit here, you could have a wide table, but only select a few columns at a time quickly)\n\nAdding a column needs a compare of the index column of the table with the index of the new column (for integrity checking), as everything is indexed by the row number.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/22069909",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-22069909",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 22069909,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIyMDY5OTA5",
    "user": {
      "login": "dragoljub",
      "id": 2701562,
      "node_id": "MDQ6VXNlcjI3MDE1NjI=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/2701562?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dragoljub",
      "html_url": "https://github.com/dragoljub",
      "followers_url": "https://api.github.com/users/dragoljub/followers",
      "following_url": "https://api.github.com/users/dragoljub/following{/other_user}",
      "gists_url": "https://api.github.com/users/dragoljub/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dragoljub/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dragoljub/subscriptions",
      "organizations_url": "https://api.github.com/users/dragoljub/orgs",
      "repos_url": "https://api.github.com/users/dragoljub/repos",
      "events_url": "https://api.github.com/users/dragoljub/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dragoljub/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-08-04T10:57:48Z",
    "updated_at": "2013-08-04T10:57:48Z",
    "author_association": "NONE",
    "body": "I like this idea. In many cases such as feature selection you really only want a few columns out if many but across all rows.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/28850651",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-28850651",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 28850651,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODUwNjUx",
    "user": {
      "login": "CarstVaartjes",
      "id": 2722815,
      "node_id": "MDQ6VXNlcjI3MjI4MTU=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/2722815?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CarstVaartjes",
      "html_url": "https://github.com/CarstVaartjes",
      "followers_url": "https://api.github.com/users/CarstVaartjes/followers",
      "following_url": "https://api.github.com/users/CarstVaartjes/following{/other_user}",
      "gists_url": "https://api.github.com/users/CarstVaartjes/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CarstVaartjes/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CarstVaartjes/subscriptions",
      "organizations_url": "https://api.github.com/users/CarstVaartjes/orgs",
      "repos_url": "https://api.github.com/users/CarstVaartjes/repos",
      "events_url": "https://api.github.com/users/CarstVaartjes/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CarstVaartjes/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-11-19T23:42:55Z",
    "updated_at": "2013-11-19T23:42:55Z",
    "author_association": "NONE",
    "body": "Hi, it sounds like a great idea, I would love to understand better how the pandas - hdf5 works and this triggers some questions around how this it would work: \n- First it would create an array based on the and/or result from the rowindex of each column in the query index, right?\n- Would that impact the current \"data_columns\" usage? (is every column then automatically usable in a where clause? not that that is a good idea without an index of course)\n- It would narrow down its search parameters by using the existing row limitation from the previous results in the next column filter lookup? i.e. if you have (column_x='a' | column_y ='b') you only have to check where column_y = b in the rowids you have . But that might not matter if the index first gives back all the results of 'b' anyway before you can look for the common denominator?\n- If it does matter, does it have any smart selection where it would first use the column that has the highest chance of limiting the data greatly (i.e. use a score on the distribution of the column values in the table to estimate how likely it is that we will limit as much data as soon as possible already)\n- Then after creating the array with rowindex, it would use that to retrieve each selected column from column_list would go \"sub_table\" by \"sub_table\" selecting the rows\n\nIf these are all stupid questions / all these are already implemented and the separate columns would use that automatically, I apologize, I just never really found any explanation of how pandas & hdf5 indices work outside from a functional perspective. \nI will look at the source code in the coming weeks to estimate if I could be of any help here (would be good practice for my cython skills too I guess)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/28853156",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-28853156",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 28853156,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODUzMTU2",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-11-20T00:25:14Z",
    "updated_at": "2013-11-20T00:25:14Z",
    "author_association": "CONTRIBUTOR",
    "body": "There are basically 2 approaches here:\n- (1) Use PyTables to store each column of a DataFrame separately (as an array), as well as the index, all under a single node (where each column is a separate node). Kind of like the `append_to_multiple` approach.\n- (2) Use `CTable` (see the ref above), which is by the same original author as PyTables, but stores in i a directly on disk (compressed).\n\nThe wave of the future is the `CTable` like approach (e.g. Blaze and @wesm new creation 'badger').\n\nIn a row-oriented table (the current Table storage mechanism), the query is delegated to `numexpr` which figures out which row coordinates are selected, then they are selected. \n\nIn approach (1), this would have to change as the query would have to be evaluated for the columns, then `anded` (it would be quite performant as usually the number of querands is much less than the number of columns in the table). That's the main reason in fact to use a column-oriented approach. Oftentimes you only need a small subset of columns back, while currently (in a row-oriented table), you get the entire row.\n\nApproach (2) will again delegate the `CTable` mechanism (which uses `numexpr` under the hood), so would be pretty transparent.\n\nSo I think that a simple implementation of (1) would be straightforward. (2) offers the possibily of allowing transparent frames (kind of like memmap for numpy arrays).\n\nI don't think this would actually need any API change, you could just specify `format='column'` instead of `format=`table'` and handle it internally. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/28853818",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-28853818",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 28853818,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODUzODE4",
    "user": {
      "login": "CarstVaartjes",
      "id": 2722815,
      "node_id": "MDQ6VXNlcjI3MjI4MTU=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/2722815?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/CarstVaartjes",
      "html_url": "https://github.com/CarstVaartjes",
      "followers_url": "https://api.github.com/users/CarstVaartjes/followers",
      "following_url": "https://api.github.com/users/CarstVaartjes/following{/other_user}",
      "gists_url": "https://api.github.com/users/CarstVaartjes/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/CarstVaartjes/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/CarstVaartjes/subscriptions",
      "organizations_url": "https://api.github.com/users/CarstVaartjes/orgs",
      "repos_url": "https://api.github.com/users/CarstVaartjes/repos",
      "events_url": "https://api.github.com/users/CarstVaartjes/events{/privacy}",
      "received_events_url": "https://api.github.com/users/CarstVaartjes/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-11-20T00:37:19Z",
    "updated_at": "2013-11-20T00:37:19Z",
    "author_association": "NONE",
    "body": "Thanks! I will experiment with approach 2 as it's also really a good learning experience for me. I guess it would also be nice to have optional stuff like pre-aggregation in a select performed inside ctable before loading the end result into pandas. \nMe experimenting here should not stop anyone else to jump on this too if they have time & urge. I'm estimating that this will take me quite a bit of time (2-3 months to be honest) as I'm swamped in my normal work + will have a learning curve.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/28853942",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-28853942",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 28853942,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODUzOTQy",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-11-20T00:39:55Z",
    "updated_at": "2013-11-20T00:39:55Z",
    "author_association": "CONTRIBUTOR",
    "body": "@CarstVaartjes that would be gr8!. lmk of any questions/issues.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/40317100",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-40317100",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 40317100,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzE3MTAw",
    "user": {
      "login": "hussainsultan",
      "id": 3936122,
      "node_id": "MDQ6VXNlcjM5MzYxMjI=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/3936122?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hussainsultan",
      "html_url": "https://github.com/hussainsultan",
      "followers_url": "https://api.github.com/users/hussainsultan/followers",
      "following_url": "https://api.github.com/users/hussainsultan/following{/other_user}",
      "gists_url": "https://api.github.com/users/hussainsultan/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hussainsultan/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hussainsultan/subscriptions",
      "organizations_url": "https://api.github.com/users/hussainsultan/orgs",
      "repos_url": "https://api.github.com/users/hussainsultan/repos",
      "events_url": "https://api.github.com/users/hussainsultan/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hussainsultan/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-13T19:31:23Z",
    "updated_at": "2014-04-13T19:31:23Z",
    "author_association": "NONE",
    "body": "@jreback I know this hasn't been active much but i wanted to run by my approach to this problem and see if i can get some feedback. I am trying to prototype how something like option 1 will work. I am using pandas HDFStore machinery to write each column as an array (writes will also be faster) with index as a separate group, where columns are sharded by number of rows (should be calculated somehow). This results in each store having a separate group for each column and within each group there are row partitioned columns (1 :N).\n\n```\n<class 'pandas.io.pytables.HDFStore'>\nFile path: column_store.h5\n/f0/__0__             frame        (shape->[100000,1])\n/f0/__1__             frame        (shape->[100000,1])\n/f0/__2__             frame        (shape->[100000,1])\n/f0/__3__             frame        (shape->[100000,1])\n```\n\nHere is the prototype code:\n\n``` python\nfrom collections import OrderedDict\nimport pandas as pd\nimport tables as tb\nimport numpy as np\n\n#dataframe to store as columnar HDF\ndf = pd.DataFrame(np.random.randn(1000000,100))\n\nwith pd.get_store('column_store.h5',complib='blosc',complevel=6) as store:\n    k=100000 #arbitrary right now for column sizees to be stored\n    i=0\n    total=len(df.index)\n    _cols =OrderedDict()\n    for each in df.columns:\n        gen=(pd.DataFrame(df[each])[pos:pos + k] for pos in xrange(0, total, k))\n\n        _chunks =OrderedDict()\n\n        for i,chunk in enumerate(gen): \n\n            _chunks['f'+ str(each)+'/'+'__{0}__'.format(i)]=chunk.index\n            store['f'+ str(each)+'/'+'__{0}__'.format(i)]=chunk\n\n        _cols['f'+ str(each)]=_chunks\n\nCPU times: user 30.6 s, sys: 717 ms, total: 31.4 s\nWall time: 32.6 s\n```\n\nThere is some metadata here that i am saving in the dictionary _cols preserving the order of the columns and column chunks. This metadata can actually help in only reading the columns where a particular  condition is already met once the new index is already calculated. Obviously there needs to be a better way to calcuclate the where conditions better and also for the case of appends the dataframe could be reindexed the same way using the metadata. I think it can also be stored in the pytables attributes.\n\nAnd this can be read back with where conditions: naive example, with where on the first column >2:\n\n``` python\n%%time\nwith pd.get_store('column_store.h5') as store:\n    l=[]\n    rows=[]\n    for each in _cols:\n        if each =='f0':\n            for i in _cols[each]:\n                a = store[i]\n\n                rows.append(a[a>2].dropna().index)\n\n    for i,each in enumerate(_cols):\n        df_container=[]\n        for k,val in enumerate(_cols[each].keys()):\n            df_container.append(store[val][store[val].index.isin(rows[k])])\n\n        l.append(pd.concat(df_container))\n    result=pd.concat(l,axis=1)\n\nCPU times: user 18.6 s, sys: 359 ms, total: 19 s\nWall time: 19 s\n```\n\nThis approach reads in the column for where conditions and applies the returned index on all subsequent columns. \n\nThe reason i am chunking the columns here is because fixed array format can only be read in full and its better for the memory to read chunk by chunk.\n\nIs this a reasonable approach to the approach that you have proposed in Pytables option? Please let me know if you have any questions or concerns.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/40317489",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-40317489",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 40317489,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzE3NDg5",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-13T19:45:04Z",
    "updated_at": "2014-04-13T19:45:04Z",
    "author_association": "CONTRIBUTOR",
    "body": "why would you chunk the columns at all?\njust store each column as a separate group under a master group \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/40319012",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-40319012",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 40319012,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzE5MDEy",
    "user": {
      "login": "hussainsultan",
      "id": 3936122,
      "node_id": "MDQ6VXNlcjM5MzYxMjI=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/3936122?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hussainsultan",
      "html_url": "https://github.com/hussainsultan",
      "followers_url": "https://api.github.com/users/hussainsultan/followers",
      "following_url": "https://api.github.com/users/hussainsultan/following{/other_user}",
      "gists_url": "https://api.github.com/users/hussainsultan/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hussainsultan/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hussainsultan/subscriptions",
      "organizations_url": "https://api.github.com/users/hussainsultan/orgs",
      "repos_url": "https://api.github.com/users/hussainsultan/repos",
      "events_url": "https://api.github.com/users/hussainsultan/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hussainsultan/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-13T20:38:35Z",
    "updated_at": "2014-04-13T20:38:35Z",
    "author_association": "NONE",
    "body": "There are some other benefits for column chunking here:\n\n<ul>\n<li>Allows for chunk by chunk reading of a table without ever reading in the whole column and better search/filtering (e.g. once the index is calculated for the conditions in a where clause, reading the meta information could provide a mapping on which column chunks to read in ( my intuition is that it should be faster). </li>\n<li>the data is naturally chunked for optimal behavior in distributed storage. Providing a format that is already ‘sharded’ by default represents a big advantage for allowing spreading .h5 files among different nodes.</li></ul>\n\nThese maybe out of scope for this enhancement. If so, i can go ahead and implement a version something without the chunking option. Please let me know.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/40319915",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-40319915",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 40319915,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzE5OTE1",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-13T21:09:42Z",
    "updated_at": "2014-04-13T21:10:22Z",
    "author_association": "CONTRIBUTOR",
    "body": "well chunking is already supported in using a low level pytables mechanism. so that is not necessary at all.\n\nas far as sharding goes - I am not sure that makes sense at all - in practice hdf5 is performant because of the locality of data\ndistributing local data defeats the purpose in its entirety\n\ni would like to see what kind or use case that you have in mind for a columnar store and benchmark vs a standard row store\n\nit's easy to implement a simple columnar store - bug an efficient one for specific use cases may not be so trivial\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/40319989",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-40319989",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 40319989,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzE5OTg5",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-13T21:12:02Z",
    "updated_at": "2014-04-13T21:12:02Z",
    "author_association": "CONTRIBUTOR",
    "body": "all that said\n\n simple implementation as a demonstration / experimental is certainly welcome\n\nstart simple\n\nneeds a good amount of testing as well\n\nI think it's simple to hijack the format kw and just allow 'ctable' \n\nthen should be transparent to the user\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/40321503",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-40321503",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 40321503,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzIxNTAz",
    "user": {
      "login": "hussainsultan",
      "id": 3936122,
      "node_id": "MDQ6VXNlcjM5MzYxMjI=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/3936122?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hussainsultan",
      "html_url": "https://github.com/hussainsultan",
      "followers_url": "https://api.github.com/users/hussainsultan/followers",
      "following_url": "https://api.github.com/users/hussainsultan/following{/other_user}",
      "gists_url": "https://api.github.com/users/hussainsultan/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hussainsultan/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hussainsultan/subscriptions",
      "organizations_url": "https://api.github.com/users/hussainsultan/orgs",
      "repos_url": "https://api.github.com/users/hussainsultan/repos",
      "events_url": "https://api.github.com/users/hussainsultan/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hussainsultan/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-13T22:06:56Z",
    "updated_at": "2014-04-13T22:06:56Z",
    "author_association": "NONE",
    "body": "Thanks. My use case at the end of the day is to do out-of-core group by reading in certain columns and computing sum/counts on other columns based on the indices for grouped var.\nThis maybe my lack of understanding of HDF5/Pytables, but from what i understood the array format can only be read-in in its entirety and are not enlargeable. is there  a way to read in an array using pytables chunk by chunk? Also,how would you append new data onto a column. \n\nThe reason i was proposing a chunked column was that i could easily append new data in a new chunk with refactoring, if needed. I understand your point about data locality and sharding, that makes sense, it wont be as performant.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/40321634",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-40321634",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 40321634,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzIxNjM0",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-13T22:12:22Z",
    "updated_at": "2014-04-13T22:12:22Z",
    "author_association": "CONTRIBUTOR",
    "body": "http://pandas.pydata.org/pandas-docs/stable/io.html#hdf5-pytables\n\nyou are talking about the fixed format; much more power in the table format however \nwhich is queryable and appendable\n\nI would only implement a ctable which is a table stored in sub groups\n\nthis is conceptually equivalent to doing append_to_multiple and select_from_multiple with each column as a separate table\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/40322509",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-40322509",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 40322509,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzIyNTA5",
    "user": {
      "login": "hussainsultan",
      "id": 3936122,
      "node_id": "MDQ6VXNlcjM5MzYxMjI=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/3936122?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hussainsultan",
      "html_url": "https://github.com/hussainsultan",
      "followers_url": "https://api.github.com/users/hussainsultan/followers",
      "following_url": "https://api.github.com/users/hussainsultan/following{/other_user}",
      "gists_url": "https://api.github.com/users/hussainsultan/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hussainsultan/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hussainsultan/subscriptions",
      "organizations_url": "https://api.github.com/users/hussainsultan/orgs",
      "repos_url": "https://api.github.com/users/hussainsultan/repos",
      "events_url": "https://api.github.com/users/hussainsultan/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hussainsultan/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-13T22:44:08Z",
    "updated_at": "2014-04-13T22:44:08Z",
    "author_association": "NONE",
    "body": "that will be extremely slow to write.\n\nhere are quick tests\"\n\n``` python\ndef write_column_store(name,df,f):\n    pd.set_option('io.hdf.default_format',f)\n    with pd.get_store(name,complib='blosc',complevel=6) as store:   \n\n        for each in df.columns:\n                store['f'+ str(each)]=pd.DataFrame(df[each])\n```\n\n``` python\n#fixed format\n%time write_column_store('column_fixed.h5',df,'fixed')\nCPU times: user 7.67 s, sys: 676 ms, total: 8.34 s\nWall time: 9.64 s\n```\n\n``` python\n#table\n%time write_column_store('column_table.h5',df,'table')\nCPU times: user 1min 1s, sys: 6.51 s, total: 1min 8s\nWall time: 1min 2s\n```\n\n``` python\n\n%%time \n#row oriented table\nstore = pd.HDFStore('table1.h5')\nstore.append('data',df,format='table',complib='blosc',complevel=6)\nstore.close()\n\nCPU times: user 8.62 s, sys: 3.9 s, total: 12.5 s\nWall time: 9.95 s\n```\n\nI am reading over the pytables docs and there is an EArray format(http://www.pytables.org/docs/manual-1.3.3/x4072.html), i dont think it supports chunking or searching, but its at least append able. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/40323549",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-40323549",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 40323549,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzIzNTQ5",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-13T23:25:50Z",
    "updated_at": "2014-04-13T23:25:50Z",
    "author_association": "CONTRIBUTOR",
    "body": "that is a very naive impl because\nyou are writing an index column for each column and your are indexing each table\n\nyou don't need to do either\nexcept you prob do need to index the data_columns\n\nnormally you only specify as many data columns as you need\n\ndon't reinvent the wheel \n\nunderstand the wheel \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/40323867",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-40323867",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 40323867,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzIzODY3",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-13T23:39:44Z",
    "updated_at": "2014-04-13T23:39:44Z",
    "author_association": "CONTRIBUTOR",
    "body": "also you would not normally compress as you write - very inefficient that way\n\nsee this discussion : \nhttp://stackoverflow.com/questions/22934996/pandas-pytables-append-performance-and-increase-in-file-size\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/40324481",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-40324481",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 40324481,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzI0NDgx",
    "user": {
      "login": "hussainsultan",
      "id": 3936122,
      "node_id": "MDQ6VXNlcjM5MzYxMjI=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/3936122?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hussainsultan",
      "html_url": "https://github.com/hussainsultan",
      "followers_url": "https://api.github.com/users/hussainsultan/followers",
      "following_url": "https://api.github.com/users/hussainsultan/following{/other_user}",
      "gists_url": "https://api.github.com/users/hussainsultan/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hussainsultan/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hussainsultan/subscriptions",
      "organizations_url": "https://api.github.com/users/hussainsultan/orgs",
      "repos_url": "https://api.github.com/users/hussainsultan/repos",
      "events_url": "https://api.github.com/users/hussainsultan/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hussainsultan/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-14T00:06:49Z",
    "updated_at": "2014-04-14T00:06:49Z",
    "author_association": "NONE",
    "body": "Sorry, i did not think about indexes and data_columns. Thanks. Write times are much better now with all columns specified as data_columns. \n\n``` python\ndef write_column_table(name,df,f):\n    pd.set_option('io.hdf.default_format',f)\n    with pd.get_store(name,complib='blosc',complevel=6) as store:   \n        for each in df.columns:\n                store.append('f'+str(each),pd.DataFrame(df[each]),format=f,index=False,data_columns=str(each))\n%time write_column_store('column_table11.h5',df,'table')\n\nCPU times: user 15.1 s, sys: 3.26 s, total: 18.4 s\nWall time: 13 s\n```\n\nThis makes much more sense now. thanks.I will go ahead and play around this with append_to_multiple and select_from_multiple approaches. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/40324597",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-40324597",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 40324597,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzI0NTk3",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-04-14T00:11:53Z",
    "updated_at": "2014-04-14T00:11:53Z",
    "author_association": "CONTRIBUTOR",
    "body": "ok great\n\nFYI\n\nnormally u don't create more data columns that u need\nbut in this case everything effectively is a data column anyhow\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/238616584",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-238616584",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 238616584,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzODYxNjU4NA==",
    "user": {
      "login": "jzwinck",
      "id": 1216791,
      "node_id": "MDQ6VXNlcjEyMTY3OTE=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/1216791?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jzwinck",
      "html_url": "https://github.com/jzwinck",
      "followers_url": "https://api.github.com/users/jzwinck/followers",
      "following_url": "https://api.github.com/users/jzwinck/following{/other_user}",
      "gists_url": "https://api.github.com/users/jzwinck/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jzwinck/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jzwinck/subscriptions",
      "organizations_url": "https://api.github.com/users/jzwinck/orgs",
      "repos_url": "https://api.github.com/users/jzwinck/repos",
      "events_url": "https://api.github.com/users/jzwinck/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jzwinck/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-09T16:52:41Z",
    "updated_at": "2016-08-09T16:52:41Z",
    "author_association": "CONTRIBUTOR",
    "body": "I would find this very useful as well--specifically \"Option 1\" above, which is to simply store the DataFrame index and each column as named, separate HDF5 DataSets under a master node.\n\nThe reason I like Option 1 is that it's more compatible with other systems which may want to read the data (just as `format='table', data_columns=True` is now).  More elaborate approaches may offer benefits to Pandas-only users, but others like me want to be able to easily read the data using existing tools outside of Pandas too.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/397659698",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-397659698",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 397659698,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NzY1OTY5OA==",
    "user": {
      "login": "nmusolino",
      "id": 3150861,
      "node_id": "MDQ6VXNlcjMxNTA4NjE=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/3150861?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/nmusolino",
      "html_url": "https://github.com/nmusolino",
      "followers_url": "https://api.github.com/users/nmusolino/followers",
      "following_url": "https://api.github.com/users/nmusolino/following{/other_user}",
      "gists_url": "https://api.github.com/users/nmusolino/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/nmusolino/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/nmusolino/subscriptions",
      "organizations_url": "https://api.github.com/users/nmusolino/orgs",
      "repos_url": "https://api.github.com/users/nmusolino/repos",
      "events_url": "https://api.github.com/users/nmusolino/events{/privacy}",
      "received_events_url": "https://api.github.com/users/nmusolino/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-15T15:35:57Z",
    "updated_at": "2018-06-15T15:35:57Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jreback, could I ask, is this feature still desired today?  Some new column-oriented storage capabilities have been introduced in pandas (Parquet, Feather/PyArrow) since this issue was opened.\r\n\r\nI ask because I had some interest in working on this.\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/397669677",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4454#issuecomment-397669677",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4454",
    "id": 397669677,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NzY2OTY3Nw==",
    "user": {
      "login": "dragoljub",
      "id": 2701562,
      "node_id": "MDQ6VXNlcjI3MDE1NjI=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/2701562?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dragoljub",
      "html_url": "https://github.com/dragoljub",
      "followers_url": "https://api.github.com/users/dragoljub/followers",
      "following_url": "https://api.github.com/users/dragoljub/following{/other_user}",
      "gists_url": "https://api.github.com/users/dragoljub/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dragoljub/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dragoljub/subscriptions",
      "organizations_url": "https://api.github.com/users/dragoljub/orgs",
      "repos_url": "https://api.github.com/users/dragoljub/repos",
      "events_url": "https://api.github.com/users/dragoljub/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dragoljub/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-15T16:12:37Z",
    "updated_at": "2018-06-15T16:12:37Z",
    "author_association": "NONE",
    "body": "The other option here is to allow users to specify the write order for existing hdf5 table blocks and compression chunk size/shape. Last I checkd it’s currently using the default row-major with hdf5 determining block shape. It was storing and compressing chunks of rows and not columns by default. "
  }
]
