[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/10427553",
    "html_url": "https://github.com/pandas-dev/pandas/pull/2264#issuecomment-10427553",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2264",
    "id": 10427553,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEwNDI3NTUz",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-11-15T22:01:34Z",
    "updated_at": "2012-11-15T22:01:34Z",
    "author_association": "CONTRIBUTOR",
    "body": "@thisch ..thanks...that is fixed.....let me know if anything else is unclear.....this functionality has mostly been in pandas for a while, but undoced....so you can try it out \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/10469944",
    "html_url": "https://github.com/pandas-dev/pandas/pull/2264#issuecomment-10469944",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2264",
    "id": 10469944,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEwNDY5OTQ0",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-11-17T03:11:11Z",
    "updated_at": "2012-11-17T03:11:11Z",
    "author_association": "CONTRIBUTOR",
    "body": "@wesm I have also some preliminary work on speeding up table writes (with panels), currently takes about 9.5s for 1M rows (e.g. a 6 x 1000 x 1000 panel); made code a lot simpler and using cython..down to about 6s; about 1/2 of overhead is from pytables actually writing it, other from creating a list of tuples (which is then turned into a recarray by pytables) - prob will be able to PR this next week\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/10469979",
    "html_url": "https://github.com/pandas-dev/pandas/pull/2264#issuecomment-10469979",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2264",
    "id": 10469979,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEwNDY5OTc5",
    "user": {
      "login": "wesm",
      "id": 329591,
      "node_id": "MDQ6VXNlcjMyOTU5MQ==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/329591?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/wesm",
      "html_url": "https://github.com/wesm",
      "followers_url": "https://api.github.com/users/wesm/followers",
      "following_url": "https://api.github.com/users/wesm/following{/other_user}",
      "gists_url": "https://api.github.com/users/wesm/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/wesm/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/wesm/subscriptions",
      "organizations_url": "https://api.github.com/users/wesm/orgs",
      "repos_url": "https://api.github.com/users/wesm/repos",
      "events_url": "https://api.github.com/users/wesm/events{/privacy}",
      "received_events_url": "https://api.github.com/users/wesm/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-11-17T03:16:15Z",
    "updated_at": "2012-11-17T03:16:15Z",
    "author_association": "MEMBER",
    "body": "I think you can write whole blocks of data instead of going row by row and go much faster? @John-Colvin has worked on this I think\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/10470087",
    "html_url": "https://github.com/pandas-dev/pandas/pull/2264#issuecomment-10470087",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2264",
    "id": 10470087,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEwNDcwMDg3",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-11-17T03:28:54Z",
    "updated_at": "2012-11-17T03:31:52Z",
    "author_association": "CONTRIBUTOR",
    "body": "I had some discussions with John (waiting for some sample timings)\n\nbut I think there r really 2 cases here\n\n1) if u want a searchable table u could write it in one shot (say blocks of columns) - selecting is a bit tricky as u have to compute the values indices (eg select from major and minor then compute the offsets for the values) - could be done - but this becomes a fixed table - u cannot easily append (and have the ability to search) -\n\n2) the current approach, while slower in writing allows searching and appending\n\nso I suppose some use cases might prefer having faster writing and still have a searching ability \n\nI prefer to write my tables in small batches, but need to preserve searching (and reading is quite fast anyhow)\n\nI suppose If there is enough interest could support both approaches\n\nOn Nov 16, 2012, at 10:16 PM, Wes McKinney notifications@github.com wrote:\n\n> I think you can write whole blocks of data instead of going row by row and go much faster? @John-Colvin has worked on this I think\n> \n> â€”\n> Reply to this email directly or view it on GitHub.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/10681719",
    "html_url": "https://github.com/pandas-dev/pandas/pull/2264#issuecomment-10681719",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2264",
    "id": 10681719,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEwNjgxNzE5",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-11-24T18:09:04Z",
    "updated_at": "2012-11-24T18:09:04Z",
    "author_association": "CONTRIBUTOR",
    "body": "closing this - going to put in a new PR soon that is a bit cleaner\n"
  }
]
