[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/21273472",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-21273472",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 21273472,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMjczNDcy",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-07-19T19:56:34Z",
    "updated_at": "2013-07-19T19:56:34Z",
    "author_association": "CONTRIBUTOR",
    "body": "what exactly are you trying to accomplish?\n\nthe first groupby is very odd to do\n\nas is passing a reduction function of `pd.Series.tolist` which is technically not a reduction function at all\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/21304550",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-21304550",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 21304550,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzA0NTUw",
    "user": {
      "login": "jtratner",
      "id": 1598379,
      "node_id": "MDQ6VXNlcjE1OTgzNzk=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1598379?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jtratner",
      "html_url": "https://github.com/jtratner",
      "followers_url": "https://api.github.com/users/jtratner/followers",
      "following_url": "https://api.github.com/users/jtratner/following{/other_user}",
      "gists_url": "https://api.github.com/users/jtratner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jtratner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jtratner/subscriptions",
      "organizations_url": "https://api.github.com/users/jtratner/orgs",
      "repos_url": "https://api.github.com/users/jtratner/repos",
      "events_url": "https://api.github.com/users/jtratner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jtratner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-07-21T03:32:32Z",
    "updated_at": "2013-07-21T03:32:32Z",
    "author_association": "CONTRIBUTOR",
    "body": "not sure the first case ought to work either...\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/21330713",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-21330713",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 21330713,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzMwNzEz",
    "user": {
      "login": "frlnx",
      "id": 1025478,
      "node_id": "MDQ6VXNlcjEwMjU0Nzg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1025478?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/frlnx",
      "html_url": "https://github.com/frlnx",
      "followers_url": "https://api.github.com/users/frlnx/followers",
      "following_url": "https://api.github.com/users/frlnx/following{/other_user}",
      "gists_url": "https://api.github.com/users/frlnx/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/frlnx/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/frlnx/subscriptions",
      "organizations_url": "https://api.github.com/users/frlnx/orgs",
      "repos_url": "https://api.github.com/users/frlnx/repos",
      "events_url": "https://api.github.com/users/frlnx/events{/privacy}",
      "received_events_url": "https://api.github.com/users/frlnx/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-07-22T08:28:55Z",
    "updated_at": "2013-07-22T09:15:58Z",
    "author_association": "NONE",
    "body": "A simplified example would be this:\nI use it to compare KPIs of single rows to their peers. The peers being determined by the group key. I compare the KPIs to the averages / means of the KPIs of each group. It's an efficient way of doing it since I do not want to keep the original dataset in memory. This example is only for two levels. The superset and the entry compared. I actually do this on four levels, which makes it a whole lot messier, and the tolist helps strip the complexitivity down.\nIf I could not do tolist as an aggregator (which in my experience is quite common practice, lots of SQL variants have support for it) I would have to keep both the original dataset and the grouped dataset and then access the original by index.\nNeedless to say that would eat my memory in no-time, and my intuition tells me it would be slower, I could perform some tests and publish if necessary.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/21338339",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-21338339",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 21338339,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzM4MzM5",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-07-22T11:32:40Z",
    "updated_at": "2013-07-22T11:32:40Z",
    "author_association": "CONTRIBUTOR",
    "body": "how does using `tolist` save you any data? its the same data just in a list and comparisons are then hard\n\nI think you can one of these:\n- `df.groupby(keys).apply(lambda x: x._get_numeric_data().abs()sum())` or another function that effectively _hashes_ a row together\n- `df.groupby(['gk','gk2']).agg(lambda x: tuple(x.tolist()))` will do what you want with the multi-indexes (or single index); as a tuple it is inferred as a reduction\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/21342654",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-21342654",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 21342654,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzQyNjU0",
    "user": {
      "login": "frlnx",
      "id": 1025478,
      "node_id": "MDQ6VXNlcjEwMjU0Nzg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1025478?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/frlnx",
      "html_url": "https://github.com/frlnx",
      "followers_url": "https://api.github.com/users/frlnx/followers",
      "following_url": "https://api.github.com/users/frlnx/following{/other_user}",
      "gists_url": "https://api.github.com/users/frlnx/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/frlnx/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/frlnx/subscriptions",
      "organizations_url": "https://api.github.com/users/frlnx/orgs",
      "repos_url": "https://api.github.com/users/frlnx/repos",
      "events_url": "https://api.github.com/users/frlnx/events{/privacy}",
      "received_events_url": "https://api.github.com/users/frlnx/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-07-22T13:11:58Z",
    "updated_at": "2013-07-22T13:11:58Z",
    "author_association": "NONE",
    "body": "Well, if wrapping the list in a tuple is an acceptable solution, removing the check for the list from the source should also be, since it really does not add any functionality or help.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/21343002",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-21343002",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 21343002,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzQzMDAy",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-07-22T13:18:16Z",
    "updated_at": "2013-07-22T13:18:16Z",
    "author_association": "CONTRIBUTOR",
    "body": "ok....will think about it....\n\nbut still I am curious, how `tolist` actually reduces? it doesn't change the amount of data you have all, so your argument about not keeping data in memory is fallacious\n\nhere's another though, why don't you `hash` the result? you want to compare it to other items right? (to see if they are the same)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/21343477",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-21343477",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 21343477,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzQzNDc3",
    "user": {
      "login": "frlnx",
      "id": 1025478,
      "node_id": "MDQ6VXNlcjEwMjU0Nzg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1025478?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/frlnx",
      "html_url": "https://github.com/frlnx",
      "followers_url": "https://api.github.com/users/frlnx/followers",
      "following_url": "https://api.github.com/users/frlnx/following{/other_user}",
      "gists_url": "https://api.github.com/users/frlnx/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/frlnx/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/frlnx/subscriptions",
      "organizations_url": "https://api.github.com/users/frlnx/orgs",
      "repos_url": "https://api.github.com/users/frlnx/repos",
      "events_url": "https://api.github.com/users/frlnx/events{/privacy}",
      "received_events_url": "https://api.github.com/users/frlnx/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-07-22T13:26:28Z",
    "updated_at": "2013-07-22T13:26:28Z",
    "author_association": "NONE",
    "body": "I want to compare, yes, but I need to know if the median KPIs of the group are greater or smaller than the same KPIs of each entry which makes up the group. It is not a question of equal or not.\n\nThe original dataframe contains a lot more than just the columns I keep with the tolist \"reduction\". I could delete the other columns, but the columns coming out of our API keeps changing independent of my work, so a whitelist approach is really the only way. I can of course make a whitelist approach in other ways, but this is a very simple way of getting what I need.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/21343839",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-21343839",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 21343839,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzQzODM5",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-07-22T13:31:36Z",
    "updated_at": "2013-07-22T13:31:36Z",
    "author_association": "CONTRIBUTOR",
    "body": "ok...if it works for you\n\nwhy can't you do the actualy compare in the agg/applied function itself?\n\n```\ndef f(x):\n     if (x.median()>=other_data).all()\n            return x.median()\n     return nan\n\ndf.groupby(keys).apply(f)\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/21344108",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-21344108",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 21344108,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzQ0MTA4",
    "user": {
      "login": "frlnx",
      "id": 1025478,
      "node_id": "MDQ6VXNlcjEwMjU0Nzg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1025478?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/frlnx",
      "html_url": "https://github.com/frlnx",
      "followers_url": "https://api.github.com/users/frlnx/followers",
      "following_url": "https://api.github.com/users/frlnx/following{/other_user}",
      "gists_url": "https://api.github.com/users/frlnx/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/frlnx/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/frlnx/subscriptions",
      "organizations_url": "https://api.github.com/users/frlnx/orgs",
      "repos_url": "https://api.github.com/users/frlnx/repos",
      "events_url": "https://api.github.com/users/frlnx/events{/privacy}",
      "received_events_url": "https://api.github.com/users/frlnx/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-07-22T13:36:04Z",
    "updated_at": "2013-07-22T13:36:04Z",
    "author_association": "NONE",
    "body": "That may be a nice way of doing it.\nI still need the lists outputted to different files for validation though.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/21344165",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-21344165",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 21344165,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzQ0MTY1",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-07-22T13:37:14Z",
    "updated_at": "2013-07-22T13:37:14Z",
    "author_association": "CONTRIBUTOR",
    "body": "np...just trying to help...will keep this open in any event..thanks for the report\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/21344356",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-21344356",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 21344356,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzQ0MzU2",
    "user": {
      "login": "frlnx",
      "id": 1025478,
      "node_id": "MDQ6VXNlcjEwMjU0Nzg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1025478?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/frlnx",
      "html_url": "https://github.com/frlnx",
      "followers_url": "https://api.github.com/users/frlnx/followers",
      "following_url": "https://api.github.com/users/frlnx/following{/other_user}",
      "gists_url": "https://api.github.com/users/frlnx/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/frlnx/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/frlnx/subscriptions",
      "organizations_url": "https://api.github.com/users/frlnx/orgs",
      "repos_url": "https://api.github.com/users/frlnx/repos",
      "events_url": "https://api.github.com/users/frlnx/events{/privacy}",
      "received_events_url": "https://api.github.com/users/frlnx/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-07-22T13:40:16Z",
    "updated_at": "2013-07-22T13:40:16Z",
    "author_association": "NONE",
    "body": "I will be able to proceed with a mix of the workarounds you provided, thanks!\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/21461709",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-21461709",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 21461709,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxNDYxNzA5",
    "user": {
      "login": "jtratner",
      "id": 1598379,
      "node_id": "MDQ6VXNlcjE1OTgzNzk=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1598379?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jtratner",
      "html_url": "https://github.com/jtratner",
      "followers_url": "https://api.github.com/users/jtratner/followers",
      "following_url": "https://api.github.com/users/jtratner/following{/other_user}",
      "gists_url": "https://api.github.com/users/jtratner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jtratner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jtratner/subscriptions",
      "organizations_url": "https://api.github.com/users/jtratner/orgs",
      "repos_url": "https://api.github.com/users/jtratner/repos",
      "events_url": "https://api.github.com/users/jtratner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jtratner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-07-24T03:36:42Z",
    "updated_at": "2013-07-24T03:36:42Z",
    "author_association": "CONTRIBUTOR",
    "body": "@frinx you'd think that removing the check for list would be just fine, but there are some quirks with how groupby is handled in pandas, so it's not straightforward to just remove it. :-/ You can see #3805 for a start on this.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/150326845",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-150326845",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 150326845,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE1MDMyNjg0NQ==",
    "user": {
      "login": "florianverhein",
      "id": 4240669,
      "node_id": "MDQ6VXNlcjQyNDA2Njk=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/4240669?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/florianverhein",
      "html_url": "https://github.com/florianverhein",
      "followers_url": "https://api.github.com/users/florianverhein/followers",
      "following_url": "https://api.github.com/users/florianverhein/following{/other_user}",
      "gists_url": "https://api.github.com/users/florianverhein/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/florianverhein/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/florianverhein/subscriptions",
      "organizations_url": "https://api.github.com/users/florianverhein/orgs",
      "repos_url": "https://api.github.com/users/florianverhein/repos",
      "events_url": "https://api.github.com/users/florianverhein/events{/privacy}",
      "received_events_url": "https://api.github.com/users/florianverhein/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-10-22T19:15:21Z",
    "updated_at": "2015-10-22T19:18:57Z",
    "author_association": "NONE",
    "body": "Just ran into this too. Rather than being forced to collect the unique values in a column into a string, I would have liked them to be collected into a list (e.g. for use later). \n\nreduce in python is really a fold left, and there's absolutely nothing wrong with a fold left returning a collection. e.g. the identity reduction for a list `s` is `reduce(lambda x,y: x+[y],s,[])`, which fails in `pd.agg`.\n\n'reducing' the quantity of data is not a requirement of reduce, functionally speaking (that argument also fails considering that `str` works in `pd.agg`). \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/227621312",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-227621312",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 227621312,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzYyMTMxMg==",
    "user": {
      "login": "nbateshaus",
      "id": 3975356,
      "node_id": "MDQ6VXNlcjM5NzUzNTY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/3975356?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/nbateshaus",
      "html_url": "https://github.com/nbateshaus",
      "followers_url": "https://api.github.com/users/nbateshaus/followers",
      "following_url": "https://api.github.com/users/nbateshaus/following{/other_user}",
      "gists_url": "https://api.github.com/users/nbateshaus/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/nbateshaus/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/nbateshaus/subscriptions",
      "organizations_url": "https://api.github.com/users/nbateshaus/orgs",
      "repos_url": "https://api.github.com/users/nbateshaus/repos",
      "events_url": "https://api.github.com/users/nbateshaus/events{/privacy}",
      "received_events_url": "https://api.github.com/users/nbateshaus/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-06-22T01:46:12Z",
    "updated_at": "2016-06-22T01:46:12Z",
    "author_association": "NONE",
    "body": "I run into this working with shredded (EAV) data. Often, there are multiple values for a single column. Take data representing authors on articles:\n\n```\nrecordId,attributeName,value\n1,title,\"Map-Reduce Extensions and Recursive Queries\"\n1,author,\"Foto N. Afrati\"\n1,author,\"Vinayak Borkar\"\n1,author,\"Michael Carey\"\n1,author,\"Neoklis Polyzotis\"\n1,author,\"Jeffrey D. Ullman\"\n```\n\nThis data is coming from a 3rd party, and I'd like to fix it so I can work with it. I want to create a 3-level index of ['recordId', 'attributeName', 'instance'] with a single column for the values. The way to create 'instance' is to:\n1. `eav.set_index(['recordId', 'attributeName'], inplace=True)` to promote recordId and attributeName to indexes; then\n2. `s=eav.groupby(level=['recordId', 'attributeName']).agg(pd.Series.tolist)` to aggregate into to a Series of lists of values, then \n3. use `t=pd.DataFrame(s.tolist(), s.index)` to split into columns with numeric labels, then\n4. use `t.stack()` to create the 3rd level index.\n\nSadly, this doesn't work because `_aggregate_series_pure_python(self, obj, func)` has an explicit exclusion for the case when the aggregator returns a list for the first group.\n\nMany other data processing platforms have recognized the utility of aggregating into lists: PostgreSQL has `array_agg`; Spark has `collect_list()`; MySQL has `group_concat`; etc.\n\nThe exclusion is even less sensical when you consider that many methods such as `Series.str.split()` will create columns of lists, but the exclusion in `_aggregate_series_pure_python(self, obj, func)` prevents creation of list values when grouping.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/227627974",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-227627974",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 227627974,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzYyNzk3NA==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-06-22T02:39:04Z",
    "updated_at": "2016-06-22T02:39:04Z",
    "author_association": "CONTRIBUTOR",
    "body": "@nbateshaus what's your desired output there? Is it\n\n``` python\nIn [12]: df['instance'] = df.groupby(['recordId', 'attributeName']).value.cumcount()\n\nIn [13]: df.set_index(['recordId', 'attributeName', 'instance'])\nOut[13]:\n                                                                       value\nrecordId attributeName instance\n1        title         0         Map-Reduce Extensions and Recursive Queries\n         author        0                                      Foto N. Afrati\n                       1                                      Vinayak Borkar\n                       2                                       Michael Carey\n                       3                                   Neoklis Polyzotis\n                       4                                   Jeffrey D. Ullman\n\n```\n\nI know that nested data is important, but the building-blocks aren't in place for pandas to support it well at the moment.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/227736642",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-227736642",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 227736642,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzczNjY0Mg==",
    "user": {
      "login": "nbateshaus",
      "id": 3975356,
      "node_id": "MDQ6VXNlcjM5NzUzNTY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/3975356?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/nbateshaus",
      "html_url": "https://github.com/nbateshaus",
      "followers_url": "https://api.github.com/users/nbateshaus/followers",
      "following_url": "https://api.github.com/users/nbateshaus/following{/other_user}",
      "gists_url": "https://api.github.com/users/nbateshaus/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/nbateshaus/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/nbateshaus/subscriptions",
      "organizations_url": "https://api.github.com/users/nbateshaus/orgs",
      "repos_url": "https://api.github.com/users/nbateshaus/repos",
      "events_url": "https://api.github.com/users/nbateshaus/events{/privacy}",
      "received_events_url": "https://api.github.com/users/nbateshaus/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-06-22T13:04:53Z",
    "updated_at": "2016-06-22T13:04:53Z",
    "author_association": "NONE",
    "body": "Yes, that's the output I want. Assuming I sort by ['e','a'] first, this is probably faster, too. It is still very convenient to be able to create list values.\n\nLooking at the history of this restriction, it looks like it was accidentally introduced by a transcription error in f3c0a081e2cfc8e073f8461cac5c242d0e4219d0 - at the time, it was an assertion, and it went from\n\n```\nassert(not (isinstance(res, list) and len(res) == len(self.dummy)))\n```\n\nwhere, as far as I can tell, `dummy` is uninitialized, to\n\n```\nassert(not isinstance(res, list))\n```\n\nThe original assertion was added without comment in 71e9046c52246535d4db1f350e82c3a84d748f88, in response to #612 \"Pure python multi-key groupby can't handle non-numeric results\". Which reveals another oddity: groupby().agg(pd.Series.tolist) works fine for single-key groupings; it only fails for multi-key groupings.\n\n```\n>>> eav.groupby(['attributeName']).agg(pd.Series.tolist)\n                      recordId  \\\nattributeName                    \nauthor         [1, 1, 1, 1, 1]   \ntitle                      [1]   \n\n                                                           value  \nattributeName                                                     \nauthor         [Foto N. Afrati, Vinayak Borkar, Michael Carey...  \ntitle              [Map-Reduce Extensions and Recursive Queries]  \n>>> eav.groupby(['recordId', 'attributeName']).agg(pd.Series.tolist)\nTraceback (most recent call last):\n  File \"/Users/nik/anaconda/envs/python3/lib/python3.5/site-packages/pandas/core/groupby.py\", line 1863, in agg_series\n    return self._aggregate_series_fast(obj, func)\n  File \"/Users/nik/anaconda/envs/python3/lib/python3.5/site-packages/pandas/core/groupby.py\", line 1868, in _aggregate_series_fast\n    func = self._is_builtin_func(func)\nAttributeError: 'BaseGrouper' object has no attribute '_is_builtin_func'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/Users/nik/anaconda/envs/python3/lib/python3.5/site-packages/pandas/core/groupby.py\", line 3597, in aggregate\n    return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n  File \"/Users/nik/anaconda/envs/python3/lib/python3.5/site-packages/pandas/core/groupby.py\", line 3122, in aggregate\n    return self._python_agg_general(arg, *args, **kwargs)\n  File \"/Users/nik/anaconda/envs/python3/lib/python3.5/site-packages/pandas/core/groupby.py\", line 777, in _python_agg_general\n    result, counts = self.grouper.agg_series(obj, f)\n  File \"/Users/nik/anaconda/envs/python3/lib/python3.5/site-packages/pandas/core/groupby.py\", line 1865, in agg_series\n    return self._aggregate_series_pure_python(obj, func)\n  File \"/Users/nik/anaconda/envs/python3/lib/python3.5/site-packages/pandas/core/groupby.py\", line 1899, in _aggregate_series_pure_python\n    raise ValueError('Function does not reduce')\nValueError: Function does not reduce\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/390121391",
    "html_url": "https://github.com/pandas-dev/pandas/issues/4293#issuecomment-390121391",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/4293",
    "id": 390121391,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5MDEyMTM5MQ==",
    "user": {
      "login": "toobaz",
      "id": 1224492,
      "node_id": "MDQ6VXNlcjEyMjQ0OTI=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1224492?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/toobaz",
      "html_url": "https://github.com/toobaz",
      "followers_url": "https://api.github.com/users/toobaz/followers",
      "following_url": "https://api.github.com/users/toobaz/following{/other_user}",
      "gists_url": "https://api.github.com/users/toobaz/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/toobaz/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/toobaz/subscriptions",
      "organizations_url": "https://api.github.com/users/toobaz/orgs",
      "repos_url": "https://api.github.com/users/toobaz/repos",
      "events_url": "https://api.github.com/users/toobaz/events{/privacy}",
      "received_events_url": "https://api.github.com/users/toobaz/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-05-18T07:33:23Z",
    "updated_at": "2018-05-18T07:33:23Z",
    "author_association": "MEMBER",
    "body": "The example by @frinx seems to now work fine, _and_ @bobhaffner [said](https://github.com/pandas-dev/pandas/pull/18354#issuecomment-346960868) that #18354 \"might\" close this. So assuming this is solved. @nbateshaus please feel free to provide a reproducible example if this is still an issue."
  }
]
