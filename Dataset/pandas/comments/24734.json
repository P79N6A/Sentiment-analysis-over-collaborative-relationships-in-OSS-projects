[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/453666944",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24734#issuecomment-453666944",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24734",
    "id": 453666944,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1MzY2Njk0NA==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-11T21:45:31Z",
    "updated_at": "2019-01-11T21:45:31Z",
    "author_association": "MEMBER",
    "body": "@HarveySummers : Thanks for reporting this!  Do you mind doing two things here:\r\n\r\n* Uploading CSV and XLSX versions of the data?  As it stands, reading this issue is VERY long ðŸ™‚ \r\n\r\nFor CSV, just upload as a `.txt` file.  XLSX is natively [supported](https://help.github.com/articles/file-attachments-on-issues-and-pull-requests/).\r\n\r\n* Could you explain the error / issue that you're running into when you try to read either file?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/453851440",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24734#issuecomment-453851440",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24734",
    "id": 453851440,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1Mzg1MTQ0MA==",
    "user": {
      "login": "HarveySummers",
      "id": 24304778,
      "node_id": "MDQ6VXNlcjI0MzA0Nzc4",
      "avatar_url": "https://avatars3.githubusercontent.com/u/24304778?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/HarveySummers",
      "html_url": "https://github.com/HarveySummers",
      "followers_url": "https://api.github.com/users/HarveySummers/followers",
      "following_url": "https://api.github.com/users/HarveySummers/following{/other_user}",
      "gists_url": "https://api.github.com/users/HarveySummers/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/HarveySummers/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/HarveySummers/subscriptions",
      "organizations_url": "https://api.github.com/users/HarveySummers/orgs",
      "repos_url": "https://api.github.com/users/HarveySummers/repos",
      "events_url": "https://api.github.com/users/HarveySummers/events{/privacy}",
      "received_events_url": "https://api.github.com/users/HarveySummers/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-13T17:58:41Z",
    "updated_at": "2019-01-13T18:03:23Z",
    "author_association": "NONE",
    "body": "Done.  There are no error messages, even when error_bad_lines set to true.  \r\n\r\nAs crazy as it sounds, it seems like its just not reading the file. And I can't explain why. I open the file in Notepad++ and there is 5063 lines, no spurious characters and no iso code issues.; same for Excel. \r\n\r\nIt fails in both read_excel (xlxs) and read_table (csv) with both the 'c' and 'python' engines consistently at 3121 lines.  No errors, warnings, or physic communications. \r\n\r\nI'm truly bifflesnickered on this. "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/453863003",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24734#issuecomment-453863003",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24734",
    "id": 453863003,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1Mzg2MzAwMw==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-13T20:32:00Z",
    "updated_at": "2019-01-13T20:32:19Z",
    "author_association": "MEMBER",
    "body": "@HarveySummers : Thanks for doing this!  This might sound a little strange, but can you confirm that every single line in your CSV has data?  Here's why:\r\n\r\n~~~python\r\nfrom pandas import read_csv\r\nfilename = \"gex-globalexplorer-ML_df.csv.txt\"\r\n\r\nfor skip_blank_lines in [True, False]:\r\n    print(\"Skip Blank Lines:\", skip_blank_lines)\r\n    df = read_csv(filename, skip_blank_lines=skip_blank_lines)\r\n\r\n    print(\"Row count:\", len(df))\r\n    print(\"Unique values:\", df[df.columns[0]].unique(), \"\\n\")\r\n~~~\r\n\r\nThis outputs:\r\n\r\n~~~\r\nSkip Blank Lines: True\r\nRow count: 3121\r\nUnique values: ['Retain' 'Revoke']\r\n\r\nSkip Blank Lines: False\r\nRow count: 5062\r\nUnique values: ['Retain' nan 'Revoke']\r\n~~~\r\n\r\nNote that one row from your file is allocated to the header, hence the maximum number of rows in your `DataFrame` can be 5062.  However, as you can see, `pandas` believes that you have empty data in approximately 2000 of your lines."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/454090748",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24734#issuecomment-454090748",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24734",
    "id": 454090748,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NDA5MDc0OA==",
    "user": {
      "login": "WillAyd",
      "id": 609873,
      "node_id": "MDQ6VXNlcjYwOTg3Mw==",
      "avatar_url": "https://avatars0.githubusercontent.com/u/609873?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/WillAyd",
      "html_url": "https://github.com/WillAyd",
      "followers_url": "https://api.github.com/users/WillAyd/followers",
      "following_url": "https://api.github.com/users/WillAyd/following{/other_user}",
      "gists_url": "https://api.github.com/users/WillAyd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/WillAyd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/WillAyd/subscriptions",
      "organizations_url": "https://api.github.com/users/WillAyd/orgs",
      "repos_url": "https://api.github.com/users/WillAyd/repos",
      "events_url": "https://api.github.com/users/WillAyd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/WillAyd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-14T17:30:50Z",
    "updated_at": "2019-01-14T17:30:50Z",
    "author_association": "MEMBER",
    "body": "I believe @gfyoung has pointed out the answer here in that you are most likely looking for `skip_blank_lines=False` based off of your input files and comments.\r\n\r\nIf that's not the case feel free to reopen"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/454103047",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24734#issuecomment-454103047",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24734",
    "id": 454103047,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NDEwMzA0Nw==",
    "user": {
      "login": "HarveySummers",
      "id": 24304778,
      "node_id": "MDQ6VXNlcjI0MzA0Nzc4",
      "avatar_url": "https://avatars3.githubusercontent.com/u/24304778?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/HarveySummers",
      "html_url": "https://github.com/HarveySummers",
      "followers_url": "https://api.github.com/users/HarveySummers/followers",
      "following_url": "https://api.github.com/users/HarveySummers/following{/other_user}",
      "gists_url": "https://api.github.com/users/HarveySummers/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/HarveySummers/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/HarveySummers/subscriptions",
      "organizations_url": "https://api.github.com/users/HarveySummers/orgs",
      "repos_url": "https://api.github.com/users/HarveySummers/repos",
      "events_url": "https://api.github.com/users/HarveySummers/events{/privacy}",
      "received_events_url": "https://api.github.com/users/HarveySummers/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-14T18:06:47Z",
    "updated_at": "2019-01-14T18:06:47Z",
    "author_association": "NONE",
    "body": "@gfyoung Yes, this solved the problem.  Thanks for the help.\r\n\r\nI want to dig deeper on this to find out how many blank lined pandas will encounter before deciding that its the end of the file.  Odd that I've never encountered this problem in the 5 years I've been working with pandas and large data files.  Once I figure it out I'll post my findings for others to learn from.\r\n\r\nMany thanks for the help and to the entire team for pandas in its support. You folks rock."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/454152087",
    "html_url": "https://github.com/pandas-dev/pandas/issues/24734#issuecomment-454152087",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/24734",
    "id": 454152087,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ1NDE1MjA4Nw==",
    "user": {
      "login": "gfyoung",
      "id": 9273653,
      "node_id": "MDQ6VXNlcjkyNzM2NTM=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/9273653?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gfyoung",
      "html_url": "https://github.com/gfyoung",
      "followers_url": "https://api.github.com/users/gfyoung/followers",
      "following_url": "https://api.github.com/users/gfyoung/following{/other_user}",
      "gists_url": "https://api.github.com/users/gfyoung/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gfyoung/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gfyoung/subscriptions",
      "organizations_url": "https://api.github.com/users/gfyoung/orgs",
      "repos_url": "https://api.github.com/users/gfyoung/repos",
      "events_url": "https://api.github.com/users/gfyoung/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gfyoung/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-01-14T20:36:10Z",
    "updated_at": "2019-01-14T20:36:30Z",
    "author_association": "MEMBER",
    "body": "> I want to dig deeper on this to find out how many blank lined pandas will encounter before deciding that its the end of the file.\r\n\r\n@HarveySummers : What's actually happening is that `pandas` is reading your entire file, but for any line that it finds to be blank, it's not returning it in the final result.\r\n\r\nHence, that's why I had suggested you double check that every line in your data file has data."
  }
]
