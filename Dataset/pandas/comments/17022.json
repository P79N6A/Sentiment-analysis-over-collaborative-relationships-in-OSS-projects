[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/316428037",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17022#issuecomment-316428037",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17022",
    "id": 316428037,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjQyODAzNw==",
    "user": {
      "login": "chris-b1",
      "id": 1924092,
      "node_id": "MDQ6VXNlcjE5MjQwOTI=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1924092?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/chris-b1",
      "html_url": "https://github.com/chris-b1",
      "followers_url": "https://api.github.com/users/chris-b1/followers",
      "following_url": "https://api.github.com/users/chris-b1/following{/other_user}",
      "gists_url": "https://api.github.com/users/chris-b1/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/chris-b1/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/chris-b1/subscriptions",
      "organizations_url": "https://api.github.com/users/chris-b1/orgs",
      "repos_url": "https://api.github.com/users/chris-b1/repos",
      "events_url": "https://api.github.com/users/chris-b1/events{/privacy}",
      "received_events_url": "https://api.github.com/users/chris-b1/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-19T15:41:22Z",
    "updated_at": "2017-07-19T15:41:22Z",
    "author_association": "CONTRIBUTOR",
    "body": "In prepping the data to write, it looks like we take a copy, so at least 2x the frame size is needed in memory.  _Might_ be a way to avoid that and/or write the data in chunks, would definitely welcome any improvements if you want to have a look.\r\nhttps://github.com/pandas-dev/pandas/blob/dd1852d59e51e28c2f9b589eefa1916ef5d9bdc9/pandas/io/stata.py#L2086\r\n\r\ncc @bashtage "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/316452227",
    "html_url": "https://github.com/pandas-dev/pandas/issues/17022#issuecomment-316452227",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/17022",
    "id": 316452227,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjQ1MjIyNw==",
    "user": {
      "login": "bashtage",
      "id": 5585221,
      "node_id": "MDQ6VXNlcjU1ODUyMjE=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5585221?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bashtage",
      "html_url": "https://github.com/bashtage",
      "followers_url": "https://api.github.com/users/bashtage/followers",
      "following_url": "https://api.github.com/users/bashtage/following{/other_user}",
      "gists_url": "https://api.github.com/users/bashtage/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bashtage/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bashtage/subscriptions",
      "organizations_url": "https://api.github.com/users/bashtage/orgs",
      "repos_url": "https://api.github.com/users/bashtage/repos",
      "events_url": "https://api.github.com/users/bashtage/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bashtage/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-19T17:03:55Z",
    "updated_at": "2017-07-19T17:03:55Z",
    "author_association": "CONTRIBUTOR",
    "body": "IMO there are too many places where data format changes are needed to remove this copy operation.  This isn't really a `to_stata` problem so much as a data set is too big for the memory on the machine being used. "
  }
]
