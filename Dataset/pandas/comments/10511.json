[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/118566263",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-118566263",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 118566263,
    "node_id": "MDEyOklzc3VlQ29tbWVudDExODU2NjI2Mw==",
    "user": {
      "login": "shoyer",
      "id": 1217238,
      "node_id": "MDQ6VXNlcjEyMTcyMzg=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shoyer",
      "html_url": "https://github.com/shoyer",
      "followers_url": "https://api.github.com/users/shoyer/followers",
      "following_url": "https://api.github.com/users/shoyer/following{/other_user}",
      "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions",
      "organizations_url": "https://api.github.com/users/shoyer/orgs",
      "repos_url": "https://api.github.com/users/shoyer/repos",
      "events_url": "https://api.github.com/users/shoyer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shoyer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-07-05T00:25:40Z",
    "updated_at": "2015-07-05T00:25:40Z",
    "author_association": "MEMBER",
    "body": "How do you create these data frames with nested lists? My sense is that there is almost always a better way.\n\nI'm reluctant to expand the dataframe API for new methods unless they are broadly useful -- this is a large part of why we added the `.pipe` method.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/118584051",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-118584051",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 118584051,
    "node_id": "MDEyOklzc3VlQ29tbWVudDExODU4NDA1MQ==",
    "user": {
      "login": "dov",
      "id": 338235,
      "node_id": "MDQ6VXNlcjMzODIzNQ==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/338235?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dov",
      "html_url": "https://github.com/dov",
      "followers_url": "https://api.github.com/users/dov/followers",
      "following_url": "https://api.github.com/users/dov/following{/other_user}",
      "gists_url": "https://api.github.com/users/dov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dov/subscriptions",
      "organizations_url": "https://api.github.com/users/dov/orgs",
      "repos_url": "https://api.github.com/users/dov/repos",
      "events_url": "https://api.github.com/users/dov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-07-05T05:59:06Z",
    "updated_at": "2015-07-05T05:59:06Z",
    "author_association": "NONE",
    "body": "My use case is the use of a dataframe through various part of an experiment, containing planning, execution, data collection and analysis. At the planning stage when building the initial data frame I still don't know what one of the columns -- containing \"perpendicular\" (data independent from all the other columns) data will contain. Once I know it, I want to insert the new data. I.e. I want to go from:\n\n```\n     A \nC                      \n10  11\n20  22\n```\n\nto:\n         A  B\n    C  \n    10  11  0\n    10  11  1\n    10  11  2\n    10  11  3\n    10  11  4\n    20  22  0\n    20  22  1\n    20  22  2\n\nWith the unlistify() function this is trivial:\n\n``` python\ndf['B'] = [range(5),range(3)]\ndf = df.unlistify('B')\n```\n\nBut perhaps there is a different simple way that I have missed?\n\nI don't see how the `pipe()` method is relevant as it seems that it is just syntactic sugar for doing right-hand chaining of operators instead of left-hand function calls. I agree that it can be used together with my listify() and unlistify() implementations. If my proposal is not accepted, I will certainly use my implemtations, with or without pipe.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/118588498",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-118588498",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 118588498,
    "node_id": "MDEyOklzc3VlQ29tbWVudDExODU4ODQ5OA==",
    "user": {
      "login": "shoyer",
      "id": 1217238,
      "node_id": "MDQ6VXNlcjEyMTcyMzg=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shoyer",
      "html_url": "https://github.com/shoyer",
      "followers_url": "https://api.github.com/users/shoyer/followers",
      "following_url": "https://api.github.com/users/shoyer/following{/other_user}",
      "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions",
      "organizations_url": "https://api.github.com/users/shoyer/orgs",
      "repos_url": "https://api.github.com/users/shoyer/repos",
      "events_url": "https://api.github.com/users/shoyer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shoyer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-07-05T06:54:51Z",
    "updated_at": "2015-07-05T06:54:51Z",
    "author_association": "MEMBER",
    "body": "Maybe you could show an example of how you make the dataframe? Presumably you're not reading it in from CSV. I guess my thought is that you might be able to easily create the \"unlisted\" dataframe in the first place.\n\nPipe is indeed a side point here. Mostly I mentioned it to point out that we are trying to put other libraries on equal footings to what we put in pandas proper.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/118589071",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-118589071",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 118589071,
    "node_id": "MDEyOklzc3VlQ29tbWVudDExODU4OTA3MQ==",
    "user": {
      "login": "shoyer",
      "id": 1217238,
      "node_id": "MDQ6VXNlcjEyMTcyMzg=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shoyer",
      "html_url": "https://github.com/shoyer",
      "followers_url": "https://api.github.com/users/shoyer/followers",
      "following_url": "https://api.github.com/users/shoyer/following{/other_user}",
      "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions",
      "organizations_url": "https://api.github.com/users/shoyer/orgs",
      "repos_url": "https://api.github.com/users/shoyer/repos",
      "events_url": "https://api.github.com/users/shoyer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shoyer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-07-05T07:05:34Z",
    "updated_at": "2015-07-05T07:05:34Z",
    "author_association": "MEMBER",
    "body": "For example, suppose the number of items in the lists depends on the other columns, e.g., suppose `df['c'] = [list(range(a, b)) for a, b in zip(df.a, df.b)]`. It might seem natural to use unlistify in this context. But you might just as easily write `df = pd.concat([pd.DataFrame({'a': a, 'b': b, 'c': list(range(a, b))}) for a, b in zip(df.a, df.b)]`.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/118592257",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-118592257",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 118592257,
    "node_id": "MDEyOklzc3VlQ29tbWVudDExODU5MjI1Nw==",
    "user": {
      "login": "dov",
      "id": 338235,
      "node_id": "MDQ6VXNlcjMzODIzNQ==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/338235?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dov",
      "html_url": "https://github.com/dov",
      "followers_url": "https://api.github.com/users/dov/followers",
      "following_url": "https://api.github.com/users/dov/following{/other_user}",
      "gists_url": "https://api.github.com/users/dov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dov/subscriptions",
      "organizations_url": "https://api.github.com/users/dov/orgs",
      "repos_url": "https://api.github.com/users/dov/repos",
      "events_url": "https://api.github.com/users/dov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-07-05T07:39:37Z",
    "updated_at": "2015-07-05T07:39:37Z",
    "author_association": "NONE",
    "body": "Thanks for the `pd.concat()` example. It is indeed simpler than my use of `groupby()`. But still if e.g. df has 10 columns before adding a new column, the use of pd.concat() becomes quite cumbersome. \n\nIn any case, I think it is a legitimate use case to start off with a a few dimensions and then unlisting new dimensions to add additional complexity. I don't think it is justified to force the user to declare all dimenions in advance. Initially I thought of adding a function to `MultiIndex.add_factor()` that would allow adding a new factor (like adding a new dimension to MultiIndex.from_product()). But I think the `unlistify()` concept is more general.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/118635763",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-118635763",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 118635763,
    "node_id": "MDEyOklzc3VlQ29tbWVudDExODYzNTc2Mw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-07-05T16:14:21Z",
    "updated_at": "2015-07-05T16:14:21Z",
    "author_association": "CONTRIBUTOR",
    "body": "@dov you are just using a much less-efficient form of multi-index. You lose all performance and indexing with the list/unlistify. Mainly the mixed-list structures force you to be in `object` dtype. Further I am not sure that the list-structure actually allows you to do any operations easily. Everything first requires conversions, again leading to less that desirable performance / storage characteristics.\n\nCompare to a regular multi-index\n\n```\nIn [24]: df.reset_index().set_index(['C','B'])\nOut[24]: \n       A\nC  B    \n10 0  11\n   1  11\n   2  11\n   3  11\n   4  11\n20 0  22\n   1  22\n   2  22\n\nIn [28]: df2 = df.reset_index().set_index(['C','B'])\n\nIn [29]: df2.loc[10]\nOut[29]: \n    A\nB    \n0  11\n1  11\n2  11\n3  11\n4  11\n\nIn [30]: df2.dtypes\nOut[30]: \nA    int64\ndtype: object\n\nIn [31]: df2.index\nOut[31]: \nMultiIndex(levels=[[10, 20], [0, 1, 2, 3, 4]],\n           labels=[[0, 0, 0, 0, 0, 1, 1, 1], [0, 1, 2, 3, 4, 0, 1, 2]],\n           names=[u'C', u'B'])\n\n\n```\n\nNot sure why one would prefer a non-native structure that would have not any advantages (and several key disadvantages) over the multi-index structure.\n\nMaybe you could shed some light on why you are not using a multi-index structure.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/118649304",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-118649304",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 118649304,
    "node_id": "MDEyOklzc3VlQ29tbWVudDExODY0OTMwNA==",
    "user": {
      "login": "dov",
      "id": 338235,
      "node_id": "MDQ6VXNlcjMzODIzNQ==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/338235?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dov",
      "html_url": "https://github.com/dov",
      "followers_url": "https://api.github.com/users/dov/followers",
      "following_url": "https://api.github.com/users/dov/following{/other_user}",
      "gists_url": "https://api.github.com/users/dov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dov/subscriptions",
      "organizations_url": "https://api.github.com/users/dov/orgs",
      "repos_url": "https://api.github.com/users/dov/repos",
      "events_url": "https://api.github.com/users/dov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-07-05T18:36:23Z",
    "updated_at": "2015-07-05T18:36:23Z",
    "author_association": "NONE",
    "body": "I think the difference is that I see the DataFrame as something evolving in which you don't see the whole picture at the time of its construction. I will try to give an example. Let's say that you have an xy-table with a camera pictures of a plate filled with micro organisms. The field of view is much smaller than the plate. The goal is to image processing and classification of the micro organisms in the images.\n\nHere are the steps that needs to be carried out:\n1. Create a plan containing x,y coordinates of where to snapshot the images. These may be stored in two columns of a dataframe.\n2. Take the images. The references to the images  may be stored in a third column of the dataframe in 1.\n3. Do image detection. Each image generates a list of microorganisms with properties such as size x,y position etc. Each organism's properties should be stored on a separate line in a dataframe. \n\nOf course the dataframe in 3 could be created with references back to the image dataframe of 1. But it may make more sense to expand the dataframe in 1 to make room for the detected image property.\n\nIn this sense the dataframe is like a logbook for the experiment. It grows and possibly contracts as the experiment progresses.\n\nThis is my goal. The idea of the unlistify() function was just a means of doing this. shoyer showed me the same functionality can be achieved through `pd.concat()`. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/118780713",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-118780713",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 118780713,
    "node_id": "MDEyOklzc3VlQ29tbWVudDExODc4MDcxMw==",
    "user": {
      "login": "shoyer",
      "id": 1217238,
      "node_id": "MDQ6VXNlcjEyMTcyMzg=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shoyer",
      "html_url": "https://github.com/shoyer",
      "followers_url": "https://api.github.com/users/shoyer/followers",
      "following_url": "https://api.github.com/users/shoyer/following{/other_user}",
      "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions",
      "organizations_url": "https://api.github.com/users/shoyer/orgs",
      "repos_url": "https://api.github.com/users/shoyer/repos",
      "events_url": "https://api.github.com/users/shoyer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shoyer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-07-06T09:10:02Z",
    "updated_at": "2015-07-06T09:10:13Z",
    "author_association": "MEMBER",
    "body": "> Of course the dataframe in 3 could be created with references back to the image dataframe of 1. But it may make more sense to expand the dataframe in 1 to make room for the detected image property.\n\nI think the idiomatic way to do such an operation in pandas would be to use [Database-style DataFrame joining/merging](http://pandas.pydata.org/pandas-docs/version/0.16.2/merging.html#database-style-dataframe-joining-merging).\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/213477348",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-213477348",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 213477348,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzQ3NzM0OA==",
    "user": {
      "login": "libbkmz",
      "id": 1144960,
      "node_id": "MDQ6VXNlcjExNDQ5NjA=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1144960?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/libbkmz",
      "html_url": "https://github.com/libbkmz",
      "followers_url": "https://api.github.com/users/libbkmz/followers",
      "following_url": "https://api.github.com/users/libbkmz/following{/other_user}",
      "gists_url": "https://api.github.com/users/libbkmz/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/libbkmz/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/libbkmz/subscriptions",
      "organizations_url": "https://api.github.com/users/libbkmz/orgs",
      "repos_url": "https://api.github.com/users/libbkmz/repos",
      "events_url": "https://api.github.com/users/libbkmz/events{/privacy}",
      "received_events_url": "https://api.github.com/users/libbkmz/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-04-22T15:34:39Z",
    "updated_at": "2016-04-22T15:34:39Z",
    "author_association": "NONE",
    "body": "I'll save it here for better search for this issue.\n\nThis SO answer explain how to do this thing really easily.\nhttp://stackoverflow.com/questions/27263805/pandas-when-cell-contents-are-lists-create-a-row-for-each-element-in-the-list\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/213486418",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-213486418",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 213486418,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzQ4NjQxOA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-04-22T15:53:01Z",
    "updated_at": "2016-04-22T15:53:01Z",
    "author_association": "CONTRIBUTOR",
    "body": "as said above, this is not good data management, nor likely to be supported by pandas. this leads to really inefficient representations of data.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/213509305",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-213509305",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 213509305,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzUwOTMwNQ==",
    "user": {
      "login": "libbkmz",
      "id": 1144960,
      "node_id": "MDQ6VXNlcjExNDQ5NjA=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1144960?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/libbkmz",
      "html_url": "https://github.com/libbkmz",
      "followers_url": "https://api.github.com/users/libbkmz/followers",
      "following_url": "https://api.github.com/users/libbkmz/following{/other_user}",
      "gists_url": "https://api.github.com/users/libbkmz/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/libbkmz/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/libbkmz/subscriptions",
      "organizations_url": "https://api.github.com/users/libbkmz/orgs",
      "repos_url": "https://api.github.com/users/libbkmz/repos",
      "events_url": "https://api.github.com/users/libbkmz/events{/privacy}",
      "received_events_url": "https://api.github.com/users/libbkmz/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-04-22T16:53:46Z",
    "updated_at": "2016-04-22T16:53:46Z",
    "author_association": "NONE",
    "body": "@jreback Yeah, I agree with you. But, when I'm getting data from MongoDB with really nested structure, and I want to make some columns for data processing, this is only way to preprocess data and save shape references between origianl data and preprocessed dataset\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/213514572",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-213514572",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 213514572,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIxMzUxNDU3Mg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-04-22T17:05:33Z",
    "updated_at": "2016-04-22T17:05:33Z",
    "author_association": "CONTRIBUTOR",
    "body": "@libbkmz then you need a proper layer in between. you can certainly pre-process using pandas, but de-listifying (ala `exploding`) encourages poor data representation in the first place :<\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/355866144",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-355866144",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 355866144,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1NTg2NjE0NA==",
    "user": {
      "login": "NirantK",
      "id": 3250749,
      "node_id": "MDQ6VXNlcjMyNTA3NDk=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/3250749?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/NirantK",
      "html_url": "https://github.com/NirantK",
      "followers_url": "https://api.github.com/users/NirantK/followers",
      "following_url": "https://api.github.com/users/NirantK/following{/other_user}",
      "gists_url": "https://api.github.com/users/NirantK/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/NirantK/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/NirantK/subscriptions",
      "organizations_url": "https://api.github.com/users/NirantK/orgs",
      "repos_url": "https://api.github.com/users/NirantK/repos",
      "events_url": "https://api.github.com/users/NirantK/events{/privacy}",
      "received_events_url": "https://api.github.com/users/NirantK/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-01-08T00:33:32Z",
    "updated_at": "2018-01-08T00:33:32Z",
    "author_association": "NONE",
    "body": "Hello @jreback , just wanted to ask if you want to close this issue? Do you want to tag it as `won't fix` for now? "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/358433375",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-358433375",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 358433375,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODQzMzM3NQ==",
    "user": {
      "login": "chaxor",
      "id": 1639151,
      "node_id": "MDQ6VXNlcjE2MzkxNTE=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1639151?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/chaxor",
      "html_url": "https://github.com/chaxor",
      "followers_url": "https://api.github.com/users/chaxor/followers",
      "following_url": "https://api.github.com/users/chaxor/following{/other_user}",
      "gists_url": "https://api.github.com/users/chaxor/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/chaxor/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/chaxor/subscriptions",
      "organizations_url": "https://api.github.com/users/chaxor/orgs",
      "repos_url": "https://api.github.com/users/chaxor/repos",
      "events_url": "https://api.github.com/users/chaxor/events{/privacy}",
      "received_events_url": "https://api.github.com/users/chaxor/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-01-17T20:25:04Z",
    "updated_at": "2018-01-17T20:25:04Z",
    "author_association": "NONE",
    "body": "I would think that the number of people that run into this problem of having lists or iterable structures within cells of a dataframe would give credence to this issue.  I fully understand that it is less efficient and there are likely better dataframe architectures.  However, I (and looking at the number of stackoverflow questions on this - many, many others) have run into this an astounding number of times.  \r\nMany times this is not even the developer that makes this decision but is handed some datatype which translates to a dataframe with this structure.  Also, you can always make the argument of efficiency / performance for architecture differences and ultimately end up not using interpreted languages at all, but here we are.  Python is used in many communities because of it's ability to do higher level functions, not because of it's performance.\r\n\r\nTherefore, I would think it highly useful to have at least an `unlistify` method for dataframes, as it would make things much faster than trying to find the most efficient / least amount of lines of code stackoverflow question every time you run into this issue in different situations.  That way people at least have a very simple method baked into pandas to 'correct' some of the bad architecture yielded by other data structures given to them."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/358490308",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-358490308",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 358490308,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODQ5MDMwOA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-01-17T23:57:48Z",
    "updated_at": "2018-01-17T23:57:48Z",
    "author_association": "CONTRIBUTOR",
    "body": "@chaxor \r\n\r\n> I  would think that the number of people that run into this problem of having lists or iterable structures within cells of a dataframe would give credence to this issue. \r\n\r\nnot sure what to make of that statement. pandas has almost 2200 issues, and no full time folks working on. People prioritize what they will. Do you want to submit a pull-request to fix this? if so great."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/361972013",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-361972013",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 361972013,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2MTk3MjAxMw==",
    "user": {
      "login": "dmarinav",
      "id": 20301636,
      "node_id": "MDQ6VXNlcjIwMzAxNjM2",
      "avatar_url": "https://avatars2.githubusercontent.com/u/20301636?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dmarinav",
      "html_url": "https://github.com/dmarinav",
      "followers_url": "https://api.github.com/users/dmarinav/followers",
      "following_url": "https://api.github.com/users/dmarinav/following{/other_user}",
      "gists_url": "https://api.github.com/users/dmarinav/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dmarinav/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dmarinav/subscriptions",
      "organizations_url": "https://api.github.com/users/dmarinav/orgs",
      "repos_url": "https://api.github.com/users/dmarinav/repos",
      "events_url": "https://api.github.com/users/dmarinav/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dmarinav/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-01-31T15:42:36Z",
    "updated_at": "2018-01-31T15:42:36Z",
    "author_association": "NONE",
    "body": "Pandas might have 2200 issues (like any other software or app nowadays), but  I believe this one is very important when dealing with unstructured data.  I work with unstructured data, and listify() and unlistify() can be very handy here and save lots of valuable time."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/361980247",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-361980247",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 361980247,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2MTk4MDI0Nw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-01-31T16:06:06Z",
    "updated_at": "2018-01-31T16:06:06Z",
    "author_association": "CONTRIBUTOR",
    "body": "@dmarinav and you are welcome to submit a fix. what folks choose to work on is pretty much up to them."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/362368513",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-362368513",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 362368513,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjM2ODUxMw==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-01T19:04:42Z",
    "updated_at": "2018-02-01T19:05:59Z",
    "author_association": "CONTRIBUTOR",
    "body": "FWIW, I can see someone building a JSONArray on top of https://github.com/pandas-dev/pandas/pull/19268 (probably not within pandas). I think that + a [custom `.json` accessor](http://pandas-docs.github.io/pandas-docs-travis/developer.html#developer-register-accessors) would make for a useful library. Users could store nested data in that array type, and have a bunch of methods at only apply to nested data, like `listify` and `unlistify`."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/397717235",
    "html_url": "https://github.com/pandas-dev/pandas/issues/10511#issuecomment-397717235",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/10511",
    "id": 397717235,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM5NzcxNzIzNQ==",
    "user": {
      "login": "summerela",
      "id": 9097886,
      "node_id": "MDQ6VXNlcjkwOTc4ODY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/9097886?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/summerela",
      "html_url": "https://github.com/summerela",
      "followers_url": "https://api.github.com/users/summerela/followers",
      "following_url": "https://api.github.com/users/summerela/following{/other_user}",
      "gists_url": "https://api.github.com/users/summerela/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/summerela/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/summerela/subscriptions",
      "organizations_url": "https://api.github.com/users/summerela/orgs",
      "repos_url": "https://api.github.com/users/summerela/repos",
      "events_url": "https://api.github.com/users/summerela/events{/privacy}",
      "received_events_url": "https://api.github.com/users/summerela/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-06-15T19:15:31Z",
    "updated_at": "2018-06-15T19:15:31Z",
    "author_association": "NONE",
    "body": "I end up having to do this kind of thing all the time.. and it's a complete PITA. Having a feature that allows us to \"explode\" a column containing lists into multiple rows would be wonderful. "
  }
]
