[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/11382736",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2521#issuecomment-11382736",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2521",
    "id": 11382736,
    "node_id": "MDEyOklzc3VlQ29tbWVudDExMzgyNzM2",
    "user": {
      "login": "wesm",
      "id": 329591,
      "node_id": "MDQ6VXNlcjMyOTU5MQ==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/329591?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/wesm",
      "html_url": "https://github.com/wesm",
      "followers_url": "https://api.github.com/users/wesm/followers",
      "following_url": "https://api.github.com/users/wesm/following{/other_user}",
      "gists_url": "https://api.github.com/users/wesm/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/wesm/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/wesm/subscriptions",
      "organizations_url": "https://api.github.com/users/wesm/orgs",
      "repos_url": "https://api.github.com/users/wesm/repos",
      "events_url": "https://api.github.com/users/wesm/events{/privacy}",
      "received_events_url": "https://api.github.com/users/wesm/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-12-14T16:42:09Z",
    "updated_at": "2012-12-14T16:42:09Z",
    "author_association": "MEMBER",
    "body": "user also posted:\n\n```\nHello All,\n\nThank you for your replies, after a day of fiddling around with pandas and moving up the ranks from newbie to conversant, I've figured out how do what I want to do. First of all my first example was wrong, I was not trying to figure out the sum of my positions at a given Frequency at a specific time, rather I was trying to determine my actual position at a given frequency for a given time. In the end, the code that I needed to write looked like this:\n\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport pytz\npositions = [10,100,30,150,170,12,90,100,30]\ntimestamps = pd.DatetimeIndex(['2012-01-01 09:10:00','2012-01-01 14:10:00','2012-01-01 17:15:00','2012-01-02 09:11:00','2012-01-02 12:10:00','2012-01-02 17:59:00','2012-01-02 18:10:00','2012-01-03 05:10:00','2012-01-03 18:10:00'])\nsymbols = ['SDF','SDF','SDF','HS','SDF','HS','SDF','HS','SDF']\ndf = pd.DataFrame(zip(timestamps,positions,symbols),columns=['timestamp','position','symbol'],index=timestamps)\nstart = df.first_valid_index().replace(hour=17,minute=59,second=59)\nend = df.last_valid_index().replace(hour=17,minute=59, second=59)\nselection = pd.date_range(start, end, freq='D')\n# positions_at_close = df['position'].asof(selection)\ndf2 = pd.DataFrame()\ng = df.groupby('symbol')\nfor key, data in g:\n    df2 = df2.append(pd.concat([data['position'].asof(selection),data['symbol'].asof(selection)], axis=1, keys=['position','symbol']))\n\nWhich took the DataFrame df:\n\nIn [574]: df\nOut[574]: \n                               timestamp  position symbol\n2012-01-01 09:10:00  2012-01-01 09:10:00        10    SDF\n2012-01-01 14:10:00  2012-01-01 14:10:00       100    SDF\n2012-01-01 17:15:00  2012-01-01 17:15:00        30    SDF\n2012-01-02 09:11:00  2012-01-02 09:11:00       150     HS\n2012-01-02 12:10:00  2012-01-02 12:10:00       170    SDF\n2012-01-02 17:59:00  2012-01-02 17:59:00        12     HS\n2012-01-02 18:10:00  2012-01-02 18:10:00        90    SDF\n2012-01-03 05:10:00  2012-01-03 05:10:00       100     HS\n2012-01-03 18:10:00  2012-01-03 18:10:00        30    SDF\n\nTo df2:\nIn [575]: df2\nOut[575]: \n                     position symbol\n2012-01-01 17:59:59       NaN    NaN\n2012-01-02 17:59:59        12     HS\n2012-01-03 17:59:59       100     HS\n2012-01-01 17:59:59        30    SDF\n2012-01-02 17:59:59       170    SDF\n2012-01-03 17:59:59        90    SDF\n\nThere is probably a more elegant way to do this, but I this works.\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/11411898",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2521#issuecomment-11411898",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2521",
    "id": 11411898,
    "node_id": "MDEyOklzc3VlQ29tbWVudDExNDExODk4",
    "user": {
      "login": "aabdullah-bos",
      "id": 1293062,
      "node_id": "MDQ6VXNlcjEyOTMwNjI=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1293062?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/aabdullah-bos",
      "html_url": "https://github.com/aabdullah-bos",
      "followers_url": "https://api.github.com/users/aabdullah-bos/followers",
      "following_url": "https://api.github.com/users/aabdullah-bos/following{/other_user}",
      "gists_url": "https://api.github.com/users/aabdullah-bos/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/aabdullah-bos/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/aabdullah-bos/subscriptions",
      "organizations_url": "https://api.github.com/users/aabdullah-bos/orgs",
      "repos_url": "https://api.github.com/users/aabdullah-bos/repos",
      "events_url": "https://api.github.com/users/aabdullah-bos/events{/privacy}",
      "received_events_url": "https://api.github.com/users/aabdullah-bos/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-12-15T23:23:55Z",
    "updated_at": "2012-12-15T23:23:55Z",
    "author_association": "NONE",
    "body": "Hello Wes,\n\nThanks for posting this. I just wanted to make one small change, to the code above. The selection needs to made inside the loop over the groups, so that you don't get the \"as of\" date for dates when data shouldn't exist.\n\nfor key, data in g:\n    start_rng = data.first_valid_index().replace(hour=17,minute=59,second=59)\n    end_rng = data.last_valid_index().replace(hour=17,minute=59,second=59)\n    selection = pd.date_range(start_rng,end_rng, freq='D')\n    df2 = df2.append(pd.concat([data['position'].asof(selection),data['symbol'].asof(selection)], axis=1, keys=['position','symbol']))\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/44474688",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2521#issuecomment-44474688",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2521",
    "id": 44474688,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NDc0Njg4",
    "user": {
      "login": "hayd",
      "id": 1931852,
      "node_id": "MDQ6VXNlcjE5MzE4NTI=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1931852?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hayd",
      "html_url": "https://github.com/hayd",
      "followers_url": "https://api.github.com/users/hayd/followers",
      "following_url": "https://api.github.com/users/hayd/following{/other_user}",
      "gists_url": "https://api.github.com/users/hayd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hayd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hayd/subscriptions",
      "organizations_url": "https://api.github.com/users/hayd/orgs",
      "repos_url": "https://api.github.com/users/hayd/repos",
      "events_url": "https://api.github.com/users/hayd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hayd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-05-28T22:48:43Z",
    "updated_at": "2014-05-28T22:48:43Z",
    "author_association": "CONTRIBUTOR",
    "body": "This seems like something that we should use the `base` argument of resample for.\n"
  }
]
