[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31554762",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31554762",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31554762,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTU0NzYy",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-03T21:22:06Z",
    "updated_at": "2014-01-03T21:22:06Z",
    "author_association": "CONTRIBUTOR",
    "body": "cc @jacobschaer\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31559756",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31559756",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31559756,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTU5NzU2",
    "user": {
      "login": "jacobschaer",
      "id": 5303784,
      "node_id": "MDQ6VXNlcjUzMDM3ODQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5303784?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jacobschaer",
      "html_url": "https://github.com/jacobschaer",
      "followers_url": "https://api.github.com/users/jacobschaer/followers",
      "following_url": "https://api.github.com/users/jacobschaer/following{/other_user}",
      "gists_url": "https://api.github.com/users/jacobschaer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jacobschaer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jacobschaer/subscriptions",
      "organizations_url": "https://api.github.com/users/jacobschaer/orgs",
      "repos_url": "https://api.github.com/users/jacobschaer/repos",
      "events_url": "https://api.github.com/users/jacobschaer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jacobschaer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-03T22:38:12Z",
    "updated_at": "2014-01-03T22:38:12Z",
    "author_association": "CONTRIBUTOR",
    "body": "@markdregan Can you possibly share the type of query? For instance, was it something like \"SELECT *\", or what kind of filters were you using? Also, what do you mean by duplicates?\n\nIt would also be useful if you could send your bq.py version. This can be retrieved from the command line using:\n`bq version`\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31561849",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31561849",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31561849,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTYxODQ5",
    "user": {
      "login": "markdregan",
      "id": 1952278,
      "node_id": "MDQ6VXNlcjE5NTIyNzg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1952278?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdregan",
      "html_url": "https://github.com/markdregan",
      "followers_url": "https://api.github.com/users/markdregan/followers",
      "following_url": "https://api.github.com/users/markdregan/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdregan/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdregan/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdregan/subscriptions",
      "organizations_url": "https://api.github.com/users/markdregan/orgs",
      "repos_url": "https://api.github.com/users/markdregan/repos",
      "events_url": "https://api.github.com/users/markdregan/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdregan/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-03T23:11:53Z",
    "updated_at": "2014-01-04T00:21:37Z",
    "author_association": "NONE",
    "body": "This is BigQuery CLI v2.0.17\n\nThe query was similar to below:\n\n```\nSELECT variable_a, var_b, etc FROM dataset.table_name WHERE var_x IN (\"String A\", \"String B\") AND exception_flag = \"5. No Flag\" AND (renewal_date_str BETWEEN \"2014-03-31\" AND \"2014-07-01\" OR renewal_date_str BETWEEN \"2013-01-01\" AND \"2013-12-31\")\n```\n\nRunning the exact same query in the BQ Web UI produces different output. By duplicates, I mean there are rows duplicated. In BQ UI, I see 1 row. In the Pandas dataframe, there are some duplicates. Quantifying this, there are ~100k rows that have duplicate key values. Total dataframe is ~404k.\n\nLet me know if there are other tests I can do.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31563579",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31563579",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31563579,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTYzNTc5",
    "user": {
      "login": "markdregan",
      "id": 1952278,
      "node_id": "MDQ6VXNlcjE5NTIyNzg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1952278?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdregan",
      "html_url": "https://github.com/markdregan",
      "followers_url": "https://api.github.com/users/markdregan/followers",
      "following_url": "https://api.github.com/users/markdregan/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdregan/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdregan/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdregan/subscriptions",
      "organizations_url": "https://api.github.com/users/markdregan/orgs",
      "repos_url": "https://api.github.com/users/markdregan/repos",
      "events_url": "https://api.github.com/users/markdregan/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdregan/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-03T23:44:01Z",
    "updated_at": "2014-01-03T23:44:09Z",
    "author_association": "NONE",
    "body": "On the off chance this is a factor, I am unable to access any gbq functions when I import pandas as\n`import pandas as pd`\n\nI am only able to access read_gbq() when I import the following:\n`from pandas.io import gbq`\n\nSeemed unusual. Even the IPython tab completion couldn't find gbq in pandas.io\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31563861",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31563861",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31563861,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTYzODYx",
    "user": {
      "login": "jacobschaer",
      "id": 5303784,
      "node_id": "MDQ6VXNlcjUzMDM3ODQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5303784?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jacobschaer",
      "html_url": "https://github.com/jacobschaer",
      "followers_url": "https://api.github.com/users/jacobschaer/followers",
      "following_url": "https://api.github.com/users/jacobschaer/following{/other_user}",
      "gists_url": "https://api.github.com/users/jacobschaer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jacobschaer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jacobschaer/subscriptions",
      "organizations_url": "https://api.github.com/users/jacobschaer/orgs",
      "repos_url": "https://api.github.com/users/jacobschaer/repos",
      "events_url": "https://api.github.com/users/jacobschaer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jacobschaer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-03T23:50:15Z",
    "updated_at": "2014-01-03T23:50:15Z",
    "author_association": "CONTRIBUTOR",
    "body": "How are you comparing the two? Do you export from Web UI as CSV and then import into pandas using `read_csv()` ? To clarify, you:\n\n1) Run your query in the web console: [bigquery.cloud.google.com]\n2) You get 404k rows as a result\n3) You run your query using `read_gbq()` and also get 404k rows as a result\n4) You somehow compare these 404k row result sets and identify that 100k rows from `read_gbq()` are duplicates. However, there are no duplicates in the results from the Web Console?\n\nOr perhaps, when you say: 'In BQ UI, I see 1 row. ' does this mean you are getting 403.999k rows more rows from pandas.io.gbq?\n\nPlease try using the command line tool to isolate the problem to our code or Google's code:\n`bq query --format=csv 'select {YOUR QUERY} from {YOUR DATASET}.{YOUR TABLE}`\n\nAs far as the imports, I had thought we were in the top level of pandas, but I normally just do: \n`from pandas.io import gbq`\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31564374",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31564374",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31564374,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTY0Mzc0",
    "user": {
      "login": "markdregan",
      "id": 1952278,
      "node_id": "MDQ6VXNlcjE5NTIyNzg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1952278?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdregan",
      "html_url": "https://github.com/markdregan",
      "followers_url": "https://api.github.com/users/markdregan/followers",
      "following_url": "https://api.github.com/users/markdregan/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdregan/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdregan/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdregan/subscriptions",
      "organizations_url": "https://api.github.com/users/markdregan/orgs",
      "repos_url": "https://api.github.com/users/markdregan/repos",
      "events_url": "https://api.github.com/users/markdregan/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdregan/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-04T00:02:11Z",
    "updated_at": "2014-01-04T00:02:11Z",
    "author_association": "NONE",
    "body": "Correct, I execute the query in the web console. I get 404k rows. I save the result as a table so I can query it later.\n\nIn pandas, I import using read_gbq and the same query as above. I get 404k rows.\n\nI note that the following query in the web console produces no sum greater than 1:\n\n```\nSELECT\n  domain_name,\n  SUM(1)\nFROM dataset.table\nGROUP BY 1\n```\n\nI then note that the equivalent pandas function does return many results where sum > 1\n\n```\nchurn_data.groupby(by='domain_name').size().order(ascending=False)\n```\n\nI then do some spot checks between pandas and BQ web console. I do this by filtering on specific domain_names. This showed pandas dataframe to have duplicates and the BQ web console to have only one row per domain. The latter is expected as it is a unique key for the data set.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31565119",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31565119",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31565119,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTY1MTE5",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-04T00:19:03Z",
    "updated_at": "2014-01-04T00:24:27Z",
    "author_association": "CONTRIBUTOR",
    "body": "`read_gbq` is not in the top-level name space as its experimental (though it prob should be as we have other experimental modules there)....will add an issue to do this, see #5843\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31565606",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31565606",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31565606,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTY1NjA2",
    "user": {
      "login": "markdregan",
      "id": 1952278,
      "node_id": "MDQ6VXNlcjE5NTIyNzg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1952278?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdregan",
      "html_url": "https://github.com/markdregan",
      "followers_url": "https://api.github.com/users/markdregan/followers",
      "following_url": "https://api.github.com/users/markdregan/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdregan/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdregan/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdregan/subscriptions",
      "organizations_url": "https://api.github.com/users/markdregan/orgs",
      "repos_url": "https://api.github.com/users/markdregan/repos",
      "events_url": "https://api.github.com/users/markdregan/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdregan/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-04T00:30:39Z",
    "updated_at": "2014-01-04T00:30:39Z",
    "author_association": "NONE",
    "body": "I can confirm running the query via the command line returns the same results as the web console. And that they conflict with the results from data loaded into pandas using `read_gbq()`\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31569331",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31569331",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31569331,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTY5MzMx",
    "user": {
      "login": "markdregan",
      "id": 1952278,
      "node_id": "MDQ6VXNlcjE5NTIyNzg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1952278?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdregan",
      "html_url": "https://github.com/markdregan",
      "followers_url": "https://api.github.com/users/markdregan/followers",
      "following_url": "https://api.github.com/users/markdregan/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdregan/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdregan/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdregan/subscriptions",
      "organizations_url": "https://api.github.com/users/markdregan/orgs",
      "repos_url": "https://api.github.com/users/markdregan/repos",
      "events_url": "https://api.github.com/users/markdregan/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdregan/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-04T02:36:47Z",
    "updated_at": "2014-01-04T02:37:15Z",
    "author_association": "NONE",
    "body": "I limited the query down to 3 fields. One of the fields seems to contain both INTEGERS and FLOATS (eg. 78 vs 34.12). The BQ web console lists the field as a float. When I remove this field (only 2 fields remaining) no duplicates are generated in the pandas dataframe.\n\nI then add the field back but I cast it using BQ SQL `INTEGER()` function. When I do so, pandas imports the data with no duplicates.\n\nI haven't been able to exhaustively test this with other variables. I'm also aware of some fields containing Infinity values - so I wouldn't rule them out as possible culprits too.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31569848",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31569848",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31569848,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTY5ODQ4",
    "user": {
      "login": "azbones",
      "id": 4975596,
      "node_id": "MDQ6VXNlcjQ5NzU1OTY=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/4975596?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/azbones",
      "html_url": "https://github.com/azbones",
      "followers_url": "https://api.github.com/users/azbones/followers",
      "following_url": "https://api.github.com/users/azbones/following{/other_user}",
      "gists_url": "https://api.github.com/users/azbones/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/azbones/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/azbones/subscriptions",
      "organizations_url": "https://api.github.com/users/azbones/orgs",
      "repos_url": "https://api.github.com/users/azbones/repos",
      "events_url": "https://api.github.com/users/azbones/events{/privacy}",
      "received_events_url": "https://api.github.com/users/azbones/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-04T03:00:19Z",
    "updated_at": "2014-01-08T00:17:19Z",
    "author_association": "NONE",
    "body": "@markdregan Interesting- that must be the problem.  While you were doing that, I was trying to duplicate this with the public shakespeare dataset from BigQuery and haven't found any dup problems yet.  \n\nThe csv case was `SELECT * FROM [publicdata:samples.shakespeare];` download the whole table via the Google BigQuery UI, save as temp table, export to Google Cloud Storage and then download and load into pandas via `from_csv`.\n\nThe gbq case was:\n\n```\nfrom pandas.io import gbq\n\nquery='SELECT * FROM [publicdata:samples.shakespeare];'\nproject_id=xxx\ndf_gbq=gbq.read_gbq(query,project_id)\n```\n\nThe results were:\n\n```\ndf_csv.describe()\nOut[45]: \n          word_count    corpus_date\ncount  164656.000000  164656.000000\nmean        5.744370    1551.364572\nstd        25.706592     275.347840\nmin         1.000000       0.000000\n25%         1.000000    1595.000000\n50%         1.000000    1599.000000\n75%         3.000000    1606.000000\nmax       995.000000    1612.000000\n\n[8 rows x 2 columns]\n\ndf_gbq.describe()\nOut[46]: \n          word_count    corpus_date\ncount  164656.000000  164656.000000\nmean        5.744370    1551.364572\nstd        25.706592     275.347840\nmin         1.000000       0.000000\n25%         1.000000    1595.000000\n50%         1.000000    1599.000000\n75%         3.000000    1606.000000\nmax       995.000000    1612.000000\n\n[8 rows x 2 columns]\n\ndf_csv['word'].nunique()\nOut[47]: 32786\n\ndf_gbq['word'].nunique()\nOut[48]: 32786\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31569860",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31569860",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31569860,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTY5ODYw",
    "user": {
      "login": "jacobschaer",
      "id": 5303784,
      "node_id": "MDQ6VXNlcjUzMDM3ODQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5303784?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jacobschaer",
      "html_url": "https://github.com/jacobschaer",
      "followers_url": "https://api.github.com/users/jacobschaer/followers",
      "following_url": "https://api.github.com/users/jacobschaer/following{/other_user}",
      "gists_url": "https://api.github.com/users/jacobschaer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jacobschaer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jacobschaer/subscriptions",
      "organizations_url": "https://api.github.com/users/jacobschaer/orgs",
      "repos_url": "https://api.github.com/users/jacobschaer/repos",
      "events_url": "https://api.github.com/users/jacobschaer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jacobschaer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-04T03:00:32Z",
    "updated_at": "2014-01-04T03:00:32Z",
    "author_association": "CONTRIBUTOR",
    "body": "From your last comment, it makes me think there's a logic issue in our casting. I'm not looking at the code right now, but I do remember there was some discussion on how to handle INTEGERS/FLOATS. While BigQuery does support Integer types, they can be \"Null\", which means that raw int's would have problems (an issue inherited from numpy if I recall). So, we use an internal pandas method to downcast numeric columns - ultimately resulting in mixed types (which is not such a bad thing).\n\nI'll take a peek at the code and see if anything pops out to me. One thing that would be very appreciated is if you can try to replicate this using BigQuery's public sample datasets. If you can give me an example using those public datasets (I'm sure one of them must have FLOATS and INTEGERS), we can make a Unit test out of this and ensure it doesn't happen again.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31569971",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31569971",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31569971,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTY5OTcx",
    "user": {
      "login": "azbones",
      "id": 4975596,
      "node_id": "MDQ6VXNlcjQ5NzU1OTY=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/4975596?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/azbones",
      "html_url": "https://github.com/azbones",
      "followers_url": "https://api.github.com/users/azbones/followers",
      "following_url": "https://api.github.com/users/azbones/following{/other_user}",
      "gists_url": "https://api.github.com/users/azbones/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/azbones/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/azbones/subscriptions",
      "organizations_url": "https://api.github.com/users/azbones/orgs",
      "repos_url": "https://api.github.com/users/azbones/repos",
      "events_url": "https://api.github.com/users/azbones/events{/privacy}",
      "received_events_url": "https://api.github.com/users/azbones/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-04T03:06:40Z",
    "updated_at": "2014-01-04T03:06:40Z",
    "author_association": "NONE",
    "body": "@jacobschaer When we talk to Google next, we need to include this in our discussions of test datasets.  Ideally, we can not only solve the solution for testing writes, but also having a public dataset with some of these cases.  Do you recall Felipe's github handle?  Maybe we can copy him on this issue...\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31570206",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31570206",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31570206,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTcwMjA2",
    "user": {
      "login": "jacobschaer",
      "id": 5303784,
      "node_id": "MDQ6VXNlcjUzMDM3ODQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5303784?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jacobschaer",
      "html_url": "https://github.com/jacobschaer",
      "followers_url": "https://api.github.com/users/jacobschaer/followers",
      "following_url": "https://api.github.com/users/jacobschaer/following{/other_user}",
      "gists_url": "https://api.github.com/users/jacobschaer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jacobschaer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jacobschaer/subscriptions",
      "organizations_url": "https://api.github.com/users/jacobschaer/orgs",
      "repos_url": "https://api.github.com/users/jacobschaer/repos",
      "events_url": "https://api.github.com/users/jacobschaer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jacobschaer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-04T03:20:06Z",
    "updated_at": "2014-01-04T03:20:06Z",
    "author_association": "CONTRIBUTOR",
    "body": "@markdregan Can you post the dtypes of the dataframe from gbq, along with the column types reported by BigQuery UI?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31583753",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31583753",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31583753,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTgzNzUz",
    "user": {
      "login": "markdregan",
      "id": 1952278,
      "node_id": "MDQ6VXNlcjE5NTIyNzg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1952278?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdregan",
      "html_url": "https://github.com/markdregan",
      "followers_url": "https://api.github.com/users/markdregan/followers",
      "following_url": "https://api.github.com/users/markdregan/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdregan/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdregan/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdregan/subscriptions",
      "organizations_url": "https://api.github.com/users/markdregan/orgs",
      "repos_url": "https://api.github.com/users/markdregan/repos",
      "events_url": "https://api.github.com/users/markdregan/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdregan/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-04T17:34:47Z",
    "updated_at": "2014-01-04T17:38:03Z",
    "author_association": "NONE",
    "body": "@jacobschaer Here is a comparison between BQ and Pandas dtypes when I import all fields in the dataset. All of the fields in BQ are also NULLABLE.\n\n| Field | BQ dtype | Pandas dtype |\n| --- | --- | --- |\n| avg_br_norm_productc_num_30da_users | FLOAT | float64 |\n| avg_br_norm_productb_num_30da_users | FLOAT | float64 |\n| avg_br_norm_producta_num_30da_users | FLOAT | float64 |\n| avg_br_norm_num_30da_users | FLOAT | float64 |\n| avg_productc_num_30da_users | FLOAT | int64 |\n| avg_d_max_norm_productc_num_30da_users | FLOAT | float64 |\n| avg_d_max_norm_productb_num_30da_users | FLOAT | float64 |\n| avg_d_max_norm_producta_num_30da_users | FLOAT | float64 |\n| avg_d_max_norm_num_30da_users | FLOAT | float64 |\n| avg_d_range_norm_productc_num_30da_users | FLOAT | float64 |\n| avg_d_range_norm_productb_num_30da_users | FLOAT | float64 |\n| avg_d_range_norm_producta_num_30da_users | FLOAT | float64 |\n| avg_d_range_norm_num_30da_users | FLOAT | float64 |\n| avg_productb_num_30da_users | FLOAT | int64 |\n| avg_producta_num_30da_users | FLOAT | int64 |\n| avg_num_30da_users | FLOAT | int64 |\n| br_norm_productc_num_30da_users | FLOAT | float64 |\n| br_norm_productb_num_30da_users | FLOAT | float64 |\n| br_norm_producta_num_30da_users | FLOAT | float64 |\n| br_norm_num_30da_users | FLOAT | float64 |\n| business_unit | STRING | object |\n| productc_num_30da_users | INTEGER | int64 |\n| country | STRING | object |\n| customer_type | STRING | object |\n| d_max_norm_productc_num_30da_users | FLOAT | float64 |\n| d_max_norm_productb_num_30da_users | FLOAT | float64 |\n| d_max_norm_producta_num_30da_users | FLOAT | float64 |\n| d_max_norm_num_30da_users | FLOAT | float64 |\n| d_range_norm_productc_num_30da_users | FLOAT | int64 |\n| d_range_norm_productb_num_30da_users | FLOAT | int64 |\n| d_range_norm_producta_num_30da_users | FLOAT | int64 |\n| d_range_norm_num_30da_users | FLOAT | int64 |\n| days_to_renewal_event | INTEGER | int64 |\n| productb_num_30da_users | INTEGER | int64 |\n| domain_class | STRING | object |\n| domain_name | STRING | object |\n| domain_usd_for_renewal | FLOAT | float64 |\n| exception_flag | STRING | object |\n| producta_num_30da_users | INTEGER | int64 |\n| has_renewed | BOOLEAN | bool |\n| max_num_allowed_users | INTEGER | int64 |\n| min_max_range_num_allowed_users | INTEGER | int64 |\n| min_num_allowed_users | INTEGER | int64 |\n| num_30da_users | INTEGER | int64 |\n| order_usd_for_renewal | FLOAT | float64 |\n| region | STRING | object |\n| renewal_classification | STRING | object |\n| renewal_date_str | STRING | object |\n| renewal_grace_period_expired | BOOLEAN | bool |\n| sales_channel_type | STRING | object |\n| sales_segment | STRING | object |\n| sales_unit | STRING | object |\n| snapshot_date_str | STRING | object |\n| stddev_br_norm_productc_num_30da_users | FLOAT | int64 |\n| stddev_br_norm_productb_num_30da_users | FLOAT | int64 |\n| stddev_br_norm_producta_num_30da_users | FLOAT | int64 |\n| stddev_br_norm_num_30da_users | FLOAT | int64 |\n| stddev_productc_num_30da_users | FLOAT | int64 |\n| stddev_d_max_norm_productc_num_30da_users | FLOAT | int64 |\n| stddev_d_max_norm_productb_num_30da_users | FLOAT | int64 |\n| stddev_d_max_norm_producta_num_30da_users | FLOAT | int64 |\n| stddev_d_max_norm_num_30da_users | FLOAT | int64 |\n| stddev_d_range_norm_productc_num_30da_users | FLOAT | int64 |\n| stddev_d_range_norm_productb_num_30da_users | FLOAT | int64 |\n| stddev_d_range_norm_producta_num_30da_users | FLOAT | int64 |\n| stddev_d_range_norm_num_30da_users | FLOAT | int64 |\n| stddev_productb_num_30da_users | FLOAT | int64 |\n| stddev_producta_num_30da_users | FLOAT | int64 |\n| stddev_num_30da_users | FLOAT | int64 |\n| term_in_days | INTEGER | int64 |\n| users_for_renewal | FLOAT | int64 |\n| zscore_br_norm_productc_num_30da_users | FLOAT | int64 |\n| zscore_br_norm_productb_num_30da_users | FLOAT | int64 |\n| zscore_br_norm_producta_num_30da_users | FLOAT | int64 |\n| zscore_br_norm_num_30da_users | FLOAT | int64 |\n| zscore_productc_num_30da_users | FLOAT | int64 |\n| zscore_d_max_norm_productc_num_30da_users | FLOAT | int64 |\n| zscore_d_max_norm_productb_num_30da_users | FLOAT | int64 |\n| zscore_d_max_norm_producta_num_30da_users | FLOAT | int64 |\n| zscore_d_max_norm_num_30da_users | FLOAT | int64 |\n| zscore_d_range_norm_productc_num_30da_users | FLOAT | int64 |\n| zscore_d_range_norm_productb_num_30da_users | FLOAT | int64 |\n| zscore_d_range_norm_producta_num_30da_users | FLOAT | int64 |\n| zscore_d_range_norm_num_30da_users | FLOAT | int64 |\n| zscore_productb_num_30da_users | FLOAT | int64 |\n| zscore_producta_num_30da_users | FLOAT | int64 |\n| zscore_num_30da_users | FLOAT | int64 |\n\nIt seems strange that the STRING fields from BQ appeared as objects dtypes in pandas. When I import just domain_name and renewal_date_str (recall importing only these did not cause duplication in pandas dataframe) the dtypes are still \"object\" for both.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31583987",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31583987",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31583987,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNTgzOTg3",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-04T17:45:06Z",
    "updated_at": "2014-01-04T17:45:06Z",
    "author_association": "CONTRIBUTOR",
    "body": "@markdregan string dtypes are always `object` in pandas\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31688285",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31688285",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31688285,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjg4Mjg1",
    "user": {
      "login": "jacobschaer",
      "id": 5303784,
      "node_id": "MDQ6VXNlcjUzMDM3ODQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5303784?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jacobschaer",
      "html_url": "https://github.com/jacobschaer",
      "followers_url": "https://api.github.com/users/jacobschaer/followers",
      "following_url": "https://api.github.com/users/jacobschaer/following{/other_user}",
      "gists_url": "https://api.github.com/users/jacobschaer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jacobschaer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jacobschaer/subscriptions",
      "organizations_url": "https://api.github.com/users/jacobschaer/orgs",
      "repos_url": "https://api.github.com/users/jacobschaer/repos",
      "events_url": "https://api.github.com/users/jacobschaer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jacobschaer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-06T21:21:37Z",
    "updated_at": "2014-01-06T21:21:37Z",
    "author_association": "CONTRIBUTOR",
    "body": "I did some spot checking, and I was able to replicate the issue with a similarly sized dataset. This doesn't seem to occur for smaller datasets, so I'm guessing that, once again, we are having result paging issues. I'm going to keep looking at it. The gap between duplicates is at least 100k rows, which is why it wasn't an issue with our previous test suite.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31690752",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31690752",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31690752,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjkwNzUy",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-06T21:47:52Z",
    "updated_at": "2014-01-06T21:47:52Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jacobshaer\n\nas a future enhancement\n\nyou might want to offer an iterator/chunk size option for read_gbq for returning results (that may or may not involve different page sizes for results from gbq)\n\nsee io.pytables for an example\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31694501",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31694501",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31694501,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNjk0NTAx",
    "user": {
      "login": "jacobschaer",
      "id": 5303784,
      "node_id": "MDQ6VXNlcjUzMDM3ODQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5303784?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jacobschaer",
      "html_url": "https://github.com/jacobschaer",
      "followers_url": "https://api.github.com/users/jacobschaer/followers",
      "following_url": "https://api.github.com/users/jacobschaer/following{/other_user}",
      "gists_url": "https://api.github.com/users/jacobschaer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jacobschaer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jacobschaer/subscriptions",
      "organizations_url": "https://api.github.com/users/jacobschaer/orgs",
      "repos_url": "https://api.github.com/users/jacobschaer/repos",
      "events_url": "https://api.github.com/users/jacobschaer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jacobschaer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-06T22:30:22Z",
    "updated_at": "2014-01-06T22:30:22Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jreback : That is definitely a feature on the backlog. We had spoken with Google about some API thoughts, so we were waiting on that.\n\n@fhoffa : I'm having trouble seeing what has gone wrong with our codebase. I looked through `bq.py` and nothing has changed. We are basically just doing what `BigqueryClient.ReadSchemaAndRows()` does, except we manipulate the data as we go through the pages. However, the `bq` command line client works perfectly still. The spacing between duplicates are fairly consistent and it looks like we might be getting the same page repeatedly.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31785113",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31785113",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31785113,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzg1MTEz",
    "user": {
      "login": "azbones",
      "id": 4975596,
      "node_id": "MDQ6VXNlcjQ5NzU1OTY=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/4975596?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/azbones",
      "html_url": "https://github.com/azbones",
      "followers_url": "https://api.github.com/users/azbones/followers",
      "following_url": "https://api.github.com/users/azbones/following{/other_user}",
      "gists_url": "https://api.github.com/users/azbones/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/azbones/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/azbones/subscriptions",
      "organizations_url": "https://api.github.com/users/azbones/orgs",
      "repos_url": "https://api.github.com/users/azbones/repos",
      "events_url": "https://api.github.com/users/azbones/events{/privacy}",
      "received_events_url": "https://api.github.com/users/azbones/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-07T22:07:08Z",
    "updated_at": "2014-01-07T22:07:08Z",
    "author_association": "NONE",
    "body": "I tried another comparison between csv downloaded from the UI using `from_csv` and the `read_gbq`.  This time I used a table with more columns from the public natality_testing dataset which we added a column to with unique row numbers (row_number) and selected 500K rows from.\n\nThen I plotted the result using a histogram with 250 bins:\n\n```\nuniques_df=len(gbq_df['row_number'].drop_duplicates())\nuniques_csv=len(csv_df['row_number'].drop_duplicates())\n\nsubplots_adjust(hspace=.5)\nsubplot(2,1,0)\ntitle('Histogram of Unique Row Value Count From GBQ- {:,} Unique Values'.format(uniques_df))\nhist(gbq_df['row_number'], bins=250)\nxticks(range(0,500000,10000), rotation=90)\nxlabel('Unique Row Number')\nylabel('Count')\n\nsubplot(2,1,1)\ntitle('Histogram of Unique Row Value Count From CSV Download to DF- {:,} Unique Values'.format(uniques_csv))\nhist(csv_df['row_number'], bins=250)\nxticks(range(0,500000,10000), rotation=90)\nxlabel('Unique Row Number')\nylabel('Count')\n```\n\nGiven 500,000 unique values and 250 bins, each bin should have a count of 2,000 if the distribution is equal.  Looking at the plots below, the `read_gbq` dataframe shows that some ranges have the correct number, some have none, and some have multiples.  The `from_csv` dataframe correctly has 500,000 unique row numbers while the `read_gbq` has 336,382 which should be incorrect.\n\nSo, it seems like the paging is somehow off with these larger datasets.  Apparently, the total size of the data returned (rows x columns) is leading to this problem as I didn't see it with similar numbers of rows with fewer columns.\n\n![df_test_hist_v_csv](https://f.cloud.github.com/assets/4975596/1863684/7735bd66-77e6-11e3-993d-17a2469a7b41.png)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31785845",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31785845",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31785845,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzg1ODQ1",
    "user": {
      "login": "azbones",
      "id": 4975596,
      "node_id": "MDQ6VXNlcjQ5NzU1OTY=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/4975596?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/azbones",
      "html_url": "https://github.com/azbones",
      "followers_url": "https://api.github.com/users/azbones/followers",
      "following_url": "https://api.github.com/users/azbones/following{/other_user}",
      "gists_url": "https://api.github.com/users/azbones/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/azbones/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/azbones/subscriptions",
      "organizations_url": "https://api.github.com/users/azbones/orgs",
      "repos_url": "https://api.github.com/users/azbones/repos",
      "events_url": "https://api.github.com/users/azbones/events{/privacy}",
      "received_events_url": "https://api.github.com/users/azbones/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-07T22:16:17Z",
    "updated_at": "2014-01-07T22:16:17Z",
    "author_association": "NONE",
    "body": "Just to confirm, there are whole ranges that have no results in the `read_gbq` dataframe like looking at row_number values between 40,000 and 80,000 as follows:\n\n```\ngbq_df[(gbq_df['row_number']>40000)&(gbq_df['row_number']<80000)]\nOut[47]: \n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 0 entries\nData columns (total 32 columns):\nsource_year               0  non-null values\nyear                      0  non-null values\nmonth                     0  non-null values\nday                       0  non-null values\nwday                      0  non-null values\nstate                     0  non-null values\nis_male                   0  non-null values\nchild_race                0  non-null values\nweight_pounds             0  non-null values\nplurality                 0  non-null values\napgar_1min                0  non-null values\napgar_5min                0  non-null values\nmother_residence_state    0  non-null values\nmother_race               0  non-null values\nmother_age                0  non-null values\ngestation_weeks           0  non-null values\nlmp                       0  non-null values\nmother_married            0  non-null values\nmother_birth_state        0  non-null values\ncigarette_use             0  non-null values\ncigarettes_per_day        0  non-null values\nalcohol_use               0  non-null values\ndrinks_per_week           0  non-null values\nweight_gain_pounds        0  non-null values\nborn_alive_alive          0  non-null values\nborn_alive_dead           0  non-null values\nborn_dead                 0  non-null values\never_born                 0  non-null values\nfather_race               0  non-null values\nfather_age                0  non-null values\nrecord_weight             0  non-null values\nrow_number                0  non-null values\ndtypes: bool(2), float64(12), int64(12), object(6)\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31793802",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31793802",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31793802,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzkzODAy",
    "user": {
      "login": "jacobschaer",
      "id": 5303784,
      "node_id": "MDQ6VXNlcjUzMDM3ODQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5303784?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jacobschaer",
      "html_url": "https://github.com/jacobschaer",
      "followers_url": "https://api.github.com/users/jacobschaer/followers",
      "following_url": "https://api.github.com/users/jacobschaer/following{/other_user}",
      "gists_url": "https://api.github.com/users/jacobschaer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jacobschaer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jacobschaer/subscriptions",
      "organizations_url": "https://api.github.com/users/jacobschaer/orgs",
      "repos_url": "https://api.github.com/users/jacobschaer/repos",
      "events_url": "https://api.github.com/users/jacobschaer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jacobschaer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-08T00:09:20Z",
    "updated_at": "2014-01-08T00:09:20Z",
    "author_association": "CONTRIBUTOR",
    "body": "We created a StackOverflow question for this:\nhttp://stackoverflow.com/questions/20984592/bigquery-results-not-including-page-token\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/31867099",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-31867099",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 31867099,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxODY3MDk5",
    "user": {
      "login": "azbones",
      "id": 4975596,
      "node_id": "MDQ6VXNlcjQ5NzU1OTY=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/4975596?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/azbones",
      "html_url": "https://github.com/azbones",
      "followers_url": "https://api.github.com/users/azbones/followers",
      "following_url": "https://api.github.com/users/azbones/following{/other_user}",
      "gists_url": "https://api.github.com/users/azbones/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/azbones/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/azbones/subscriptions",
      "organizations_url": "https://api.github.com/users/azbones/orgs",
      "repos_url": "https://api.github.com/users/azbones/repos",
      "events_url": "https://api.github.com/users/azbones/events{/privacy}",
      "received_events_url": "https://api.github.com/users/azbones/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-08T19:11:07Z",
    "updated_at": "2014-01-08T19:11:07Z",
    "author_association": "NONE",
    "body": "@jacobschaer had me run the native Google BQ client to see if it is having the same issues with page tokens. It appears to have the same problem, but the results are different- there are many more duplicates, but no gaps. That is most likely due to the differences in our error handling when the Google API returns JSON with no token. \n\nThe first subplot is downloading from the Google Cloud Storage UI, the second is the Google BQ client to csv, and the third is our Pandas gbq method.\n\n![gbq_bquicsv_bq_csv](https://f.cloud.github.com/assets/4975596/1871546/3b021684-7898-11e3-9b83-2e478b4a0e98.png)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32339187",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-32339187",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 32339187,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyMzM5MTg3",
    "user": {
      "login": "jacobschaer",
      "id": 5303784,
      "node_id": "MDQ6VXNlcjUzMDM3ODQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5303784?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jacobschaer",
      "html_url": "https://github.com/jacobschaer",
      "followers_url": "https://api.github.com/users/jacobschaer/followers",
      "following_url": "https://api.github.com/users/jacobschaer/following{/other_user}",
      "gists_url": "https://api.github.com/users/jacobschaer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jacobschaer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jacobschaer/subscriptions",
      "organizations_url": "https://api.github.com/users/jacobschaer/orgs",
      "repos_url": "https://api.github.com/users/jacobschaer/repos",
      "events_url": "https://api.github.com/users/jacobschaer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jacobschaer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-15T07:02:05Z",
    "updated_at": "2014-01-15T07:02:05Z",
    "author_association": "CONTRIBUTOR",
    "body": "@markdregan : Sorry this hasn't been updated in a while. As @azbones said, we tested and confirmed that the bq client was having the same issue, and most of the heavylifting for our module is handled by their code. Google knows about it, and from what we heard today are still looking into it.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/32493139",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-32493139",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 32493139,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNDkzMTM5",
    "user": {
      "login": "markdregan",
      "id": 1952278,
      "node_id": "MDQ6VXNlcjE5NTIyNzg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1952278?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdregan",
      "html_url": "https://github.com/markdregan",
      "followers_url": "https://api.github.com/users/markdregan/followers",
      "following_url": "https://api.github.com/users/markdregan/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdregan/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdregan/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdregan/subscriptions",
      "organizations_url": "https://api.github.com/users/markdregan/orgs",
      "repos_url": "https://api.github.com/users/markdregan/repos",
      "events_url": "https://api.github.com/users/markdregan/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdregan/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-16T17:50:42Z",
    "updated_at": "2014-01-16T17:50:42Z",
    "author_association": "NONE",
    "body": "Thanks @jacobschaer. Let me know if I can connect you with folks on the BQ side. I work here in Google.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/33096299",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-33096299",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 33096299,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzMDk2Mjk5",
    "user": {
      "login": "jacobschaer",
      "id": 5303784,
      "node_id": "MDQ6VXNlcjUzMDM3ODQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5303784?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jacobschaer",
      "html_url": "https://github.com/jacobschaer",
      "followers_url": "https://api.github.com/users/jacobschaer/followers",
      "following_url": "https://api.github.com/users/jacobschaer/following{/other_user}",
      "gists_url": "https://api.github.com/users/jacobschaer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jacobschaer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jacobschaer/subscriptions",
      "organizations_url": "https://api.github.com/users/jacobschaer/orgs",
      "repos_url": "https://api.github.com/users/jacobschaer/repos",
      "events_url": "https://api.github.com/users/jacobschaer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jacobschaer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-23T04:31:17Z",
    "updated_at": "2014-01-23T04:31:17Z",
    "author_association": "CONTRIBUTOR",
    "body": "@markdregan - We've been in touch with Google for a while - in fact, we'll be dropping by the Mountain View campus next week for a visit! :-) It looks like this bug should be resolved soon per: http://stackoverflow.com/questions/20984592/bigquery-results-not-including-page-token/21009144?noredirect=1#comment32090677_21009144\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/33334136",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-33334136",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 33334136,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzMzM0MTM2",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-26T23:18:51Z",
    "updated_at": "2014-01-26T23:18:51Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jacobschaer \n\nhow's this coming along?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/33334627",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-33334627",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 33334627,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzMzM0NjI3",
    "user": {
      "login": "jacobschaer",
      "id": 5303784,
      "node_id": "MDQ6VXNlcjUzMDM3ODQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5303784?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jacobschaer",
      "html_url": "https://github.com/jacobschaer",
      "followers_url": "https://api.github.com/users/jacobschaer/followers",
      "following_url": "https://api.github.com/users/jacobschaer/following{/other_user}",
      "gists_url": "https://api.github.com/users/jacobschaer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jacobschaer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jacobschaer/subscriptions",
      "organizations_url": "https://api.github.com/users/jacobschaer/orgs",
      "repos_url": "https://api.github.com/users/jacobschaer/repos",
      "events_url": "https://api.github.com/users/jacobschaer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jacobschaer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-26T23:39:27Z",
    "updated_at": "2014-01-26T23:39:27Z",
    "author_association": "CONTRIBUTOR",
    "body": "Surprisingly, no changes have been pushed to the client code. Shall I put this in place of the previous bug documentation in the docstrings? Per: https://github.com/pydata/pandas/issues/6096#issuecomment-33302738\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/33335133",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-33335133",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 33335133,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzMzM1MTMz",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-27T00:04:49Z",
    "updated_at": "2014-01-27T00:04:49Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jacobschaer cerainly if their is a change you want to make in the docs (for this bug) or other minor changes...go ahead and do a PR.....\n\ngoing to finish up 0.13.1 shortly...next few days....did you want the unicode fixes to go in? (is their a PR for this), or still on your branch?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/33548630",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-33548630",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 33548630,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTQ4NjMw",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-29T01:41:56Z",
    "updated_at": "2014-01-29T01:41:56Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jacobschaer PR on this, or shall we move to 0.14?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/33548941",
    "html_url": "https://github.com/pandas-dev/pandas/issues/5840#issuecomment-33548941",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/5840",
    "id": 33548941,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTQ4OTQx",
    "user": {
      "login": "jacobschaer",
      "id": 5303784,
      "node_id": "MDQ6VXNlcjUzMDM3ODQ=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5303784?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jacobschaer",
      "html_url": "https://github.com/jacobschaer",
      "followers_url": "https://api.github.com/users/jacobschaer/followers",
      "following_url": "https://api.github.com/users/jacobschaer/following{/other_user}",
      "gists_url": "https://api.github.com/users/jacobschaer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jacobschaer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jacobschaer/subscriptions",
      "organizations_url": "https://api.github.com/users/jacobschaer/orgs",
      "repos_url": "https://api.github.com/users/jacobschaer/repos",
      "events_url": "https://api.github.com/users/jacobschaer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jacobschaer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-01-29T01:48:20Z",
    "updated_at": "2014-01-29T01:48:20Z",
    "author_association": "CONTRIBUTOR",
    "body": "Move to 0.14 - we might not have anything to do in the client code, but it will still need validation. No release deadline was given, but we chatted with them and it's \"very soon\".\n"
  }
]
