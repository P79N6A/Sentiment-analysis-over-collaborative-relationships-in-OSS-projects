[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/311946279",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-311946279",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 311946279,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMTk0NjI3OQ==",
    "user": {
      "login": "jorisvandenbossche",
      "id": 1020496,
      "node_id": "MDQ6VXNlcjEwMjA0OTY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jorisvandenbossche",
      "html_url": "https://github.com/jorisvandenbossche",
      "followers_url": "https://api.github.com/users/jorisvandenbossche/followers",
      "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}",
      "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions",
      "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs",
      "repos_url": "https://api.github.com/users/jorisvandenbossche/repos",
      "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-29T12:02:48Z",
    "updated_at": "2017-06-29T12:02:48Z",
    "author_association": "MEMBER",
    "body": "cc @shoyer @MaximilianR \r\n\r\nI think the `read_excel` can be \"rather easily\" done manually by the user if he/she wants that (since it is just writing different parts of the frame to different sheets. Of course it will be less convenient, but not impossible). The HDF5 seems more problematic to overcome with current proposed alternatives. \r\nIs there support for HDF5 planned in xarray?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/311951544",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-311951544",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 311951544,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMTk1MTU0NA==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-29T12:27:52Z",
    "updated_at": "2017-06-29T12:27:52Z",
    "author_association": "CONTRIBUTOR",
    "body": "xarray already has netcdf support; is that sufficient?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/311956116",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-311956116",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 311956116,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMTk1NjExNg==",
    "user": {
      "login": "shsymoen",
      "id": 18554627,
      "node_id": "MDQ6VXNlcjE4NTU0NjI3",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18554627?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shsymoen",
      "html_url": "https://github.com/shsymoen",
      "followers_url": "https://api.github.com/users/shsymoen/followers",
      "following_url": "https://api.github.com/users/shsymoen/following{/other_user}",
      "gists_url": "https://api.github.com/users/shsymoen/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shsymoen/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shsymoen/subscriptions",
      "organizations_url": "https://api.github.com/users/shsymoen/orgs",
      "repos_url": "https://api.github.com/users/shsymoen/repos",
      "events_url": "https://api.github.com/users/shsymoen/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shsymoen/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-29T12:48:58Z",
    "updated_at": "2017-06-29T12:53:54Z",
    "author_association": "NONE",
    "body": "Is this possible with xarray and netcdf? Appending a 2D dataframe or series to the already created HDF5 file.\r\n\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nstore = pd.HDFStore('test.h5')\r\n\r\ndata = np.random.rand(4,4)\r\ndf_raw_data = pd.DataFrame(data=data)\r\n\r\ndf_raw_data.to_hdf(store, key='raw_data', mode='a')\r\nstore.close()\r\n```"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/311957291",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-311957291",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 311957291,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMTk1NzI5MQ==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-29T12:54:05Z",
    "updated_at": "2017-06-29T12:54:05Z",
    "author_association": "CONTRIBUTOR",
    "body": "@shsymoen I'm not sure I understand your example. That's writing a DataFrame, which will continue to work.\r\n\r\nSince panel is deprecated, in future versions of pandas you'll need to either\r\n\r\n- use a MultiIndexed pandas object, and write that to HDF5\r\n-  Build an xarray object and serialize it as documented [here](http://xarray.pydata.org/en/stable/io.html#netcdf)"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/312001710",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-312001710",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 312001710,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjAwMTcxMA==",
    "user": {
      "login": "shsymoen",
      "id": 18554627,
      "node_id": "MDQ6VXNlcjE4NTU0NjI3",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18554627?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shsymoen",
      "html_url": "https://github.com/shsymoen",
      "followers_url": "https://api.github.com/users/shsymoen/followers",
      "following_url": "https://api.github.com/users/shsymoen/following{/other_user}",
      "gists_url": "https://api.github.com/users/shsymoen/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shsymoen/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shsymoen/subscriptions",
      "organizations_url": "https://api.github.com/users/shsymoen/orgs",
      "repos_url": "https://api.github.com/users/shsymoen/repos",
      "events_url": "https://api.github.com/users/shsymoen/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shsymoen/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-29T15:25:54Z",
    "updated_at": "2017-06-29T15:25:54Z",
    "author_association": "NONE",
    "body": "@TomAugspurger I realized my example was not really clear and added the line that it append the DataFrame to the already created HDF5 file.\r\nFor me the MultiIndexed pandas objects are less intuitive to use. And I don't know whether it is possible to append a DataFrame to a serialized xarray object (no experience with xarray or netcdf)\r\n\r\nI will try to clarify my use case a bit better:\r\nI'm starting from a single DataFrame called: 'raw'\r\nI perform some operations on the raw DataFrame resulting in a new DataFrame with the same indices and column names: 'processed_1'\r\nDifferent operations: 'processed_2'\r\n\r\nI'm adding the newly created DataFrames one by one to a dictionary. In the end I convert the dict to a Panel to be able to export to an HDF5 file containing some DataFrames in different keys.\r\nI hope this explanation makes it more clear."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/312003989",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-312003989",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 312003989,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjAwMzk4OQ==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-29T15:33:17Z",
    "updated_at": "2017-06-29T15:33:17Z",
    "author_association": "CONTRIBUTOR",
    "body": "Can you iterate over the key-value pairs of your dictionary and write each to the HDF5 file under a separate key?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/312005240",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-312005240",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 312005240,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjAwNTI0MA==",
    "user": {
      "login": "shsymoen",
      "id": 18554627,
      "node_id": "MDQ6VXNlcjE4NTU0NjI3",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18554627?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shsymoen",
      "html_url": "https://github.com/shsymoen",
      "followers_url": "https://api.github.com/users/shsymoen/followers",
      "following_url": "https://api.github.com/users/shsymoen/following{/other_user}",
      "gists_url": "https://api.github.com/users/shsymoen/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shsymoen/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shsymoen/subscriptions",
      "organizations_url": "https://api.github.com/users/shsymoen/orgs",
      "repos_url": "https://api.github.com/users/shsymoen/repos",
      "events_url": "https://api.github.com/users/shsymoen/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shsymoen/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-29T15:37:19Z",
    "updated_at": "2017-06-30T06:45:39Z",
    "author_association": "NONE",
    "body": "In principle that's possible. But I think the resulting file will be larger because you are saving, for every DataFrame, the same column names and indices. Reading the data from the HDF5 is also more complicated due to the extra iteration step."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/312047270",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-312047270",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 312047270,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjA0NzI3MA==",
    "user": {
      "login": "max-sixty",
      "id": 5635139,
      "node_id": "MDQ6VXNlcjU2MzUxMzk=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/5635139?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/max-sixty",
      "html_url": "https://github.com/max-sixty",
      "followers_url": "https://api.github.com/users/max-sixty/followers",
      "following_url": "https://api.github.com/users/max-sixty/following{/other_user}",
      "gists_url": "https://api.github.com/users/max-sixty/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/max-sixty/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/max-sixty/subscriptions",
      "organizations_url": "https://api.github.com/users/max-sixty/orgs",
      "repos_url": "https://api.github.com/users/max-sixty/repos",
      "events_url": "https://api.github.com/users/max-sixty/events{/privacy}",
      "received_events_url": "https://api.github.com/users/max-sixty/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-29T18:00:15Z",
    "updated_at": "2017-06-29T18:00:15Z",
    "author_association": "CONTRIBUTOR",
    "body": "That's a good case, thanks for sharing @shsymoen \r\n\r\nI think the options are:\r\n1. Build workarounds, such as a dictionary of dataframes\r\n2. Force people to use tabular data, and use `MultiIndex`es\r\n3. Add this functionality into `xarray`\r\n4. Leave `Panel` hanging around in a deprecated state\r\n5. Reverse deprecation of `Panel`\r\n\r\nI would imagine we can manage through with a combination of 1-3, depending on the case. \r\n\r\nThere is already some similar functionality in `xarray` as @TomAugspurger mentioned re netCDF. That could be expanded to a more general HDF5 case. I think there's less overlap between the `xarray` and MS Excel communities, so 1&2 likely more appropriate there"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/312051951",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-312051951",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 312051951,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjA1MTk1MQ==",
    "user": {
      "login": "shoyer",
      "id": 1217238,
      "node_id": "MDQ6VXNlcjEyMTcyMzg=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shoyer",
      "html_url": "https://github.com/shoyer",
      "followers_url": "https://api.github.com/users/shoyer/followers",
      "following_url": "https://api.github.com/users/shoyer/following{/other_user}",
      "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions",
      "organizations_url": "https://api.github.com/users/shoyer/orgs",
      "repos_url": "https://api.github.com/users/shoyer/repos",
      "events_url": "https://api.github.com/users/shoyer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shoyer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-29T18:17:24Z",
    "updated_at": "2017-06-29T18:17:32Z",
    "author_association": "MEMBER",
    "body": "Pandas uses a customized HDF5 format (based on pytables) for serializing `pandas.Panel`. In principle, we could read/write it in xarray but there are plans to do so. Our primary file format is NetCDF, which is a different file format also based on HDF5 (when using NetCDF4, which is the default).\r\n\r\nXarray *could* be used for reading Excel data but I agree that it's not a great fit, in part because the flexibility of spreadsheets means they come in lots of different formats. My inclination would be to read Excel files with multiple sheets into a DataFrame with a MultiIndex of some sort. That would keep all Excel IO within pandas. If you really need 3D data structures, converting into xarray from pandas data structures with a MultiIndex is usually quite straightforward."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/312126433",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-312126433",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 312126433,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjEyNjQzMw==",
    "user": {
      "login": "bashtage",
      "id": 5585221,
      "node_id": "MDQ6VXNlcjU1ODUyMjE=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5585221?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bashtage",
      "html_url": "https://github.com/bashtage",
      "followers_url": "https://api.github.com/users/bashtage/followers",
      "following_url": "https://api.github.com/users/bashtage/following{/other_user}",
      "gists_url": "https://api.github.com/users/bashtage/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bashtage/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bashtage/subscriptions",
      "organizations_url": "https://api.github.com/users/bashtage/orgs",
      "repos_url": "https://api.github.com/users/bashtage/repos",
      "events_url": "https://api.github.com/users/bashtage/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bashtage/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-29T22:31:55Z",
    "updated_at": "2017-06-29T22:31:55Z",
    "author_association": "CONTRIBUTOR",
    "body": "```python\r\npnl.to_frame().to_hdf('test.h5', key='df')\r\n```\r\n\r\nworks fine and is a valid representation for a 3D data set.  \r\n\r\nOf course one could also use\r\n\r\n```python\r\nstore = pd.HDFStore('test.h5', mode='w')\r\nfor item in pnl:\r\n    store.put(item,pnl[item])\r\nstore.close()\r\n```\r\n\r\nas a 3-d store for data."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/312127082",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-312127082",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 312127082,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjEyNzA4Mg==",
    "user": {
      "login": "bashtage",
      "id": 5585221,
      "node_id": "MDQ6VXNlcjU1ODUyMjE=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5585221?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bashtage",
      "html_url": "https://github.com/bashtage",
      "followers_url": "https://api.github.com/users/bashtage/followers",
      "following_url": "https://api.github.com/users/bashtage/following{/other_user}",
      "gists_url": "https://api.github.com/users/bashtage/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bashtage/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bashtage/subscriptions",
      "organizations_url": "https://api.github.com/users/bashtage/orgs",
      "repos_url": "https://api.github.com/users/bashtage/repos",
      "events_url": "https://api.github.com/users/bashtage/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bashtage/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-06-29T22:35:54Z",
    "updated_at": "2017-06-29T22:35:54Z",
    "author_association": "CONTRIBUTOR",
    "body": "To be clear, have recently worked with `Panel` and `MultIndex` df, there is a strong case for MI df over Panel.  In particular, in a Panel there is no way to correctly store variables like a `Cateogrical` .  It is also easily possible to end up with different data types for the same variables, e.g. `int` for columns in a column of a panel's item, and `float64` for the same variable for a different \"entity\" since it has one or more missing values.  Using a MI df avoids both of these, at the cost of learning a different access pattern."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/312455302",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-312455302",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 312455302,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjQ1NTMwMg==",
    "user": {
      "login": "shsymoen",
      "id": 18554627,
      "node_id": "MDQ6VXNlcjE4NTU0NjI3",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18554627?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shsymoen",
      "html_url": "https://github.com/shsymoen",
      "followers_url": "https://api.github.com/users/shsymoen/followers",
      "following_url": "https://api.github.com/users/shsymoen/following{/other_user}",
      "gists_url": "https://api.github.com/users/shsymoen/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shsymoen/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shsymoen/subscriptions",
      "organizations_url": "https://api.github.com/users/shsymoen/orgs",
      "repos_url": "https://api.github.com/users/shsymoen/repos",
      "events_url": "https://api.github.com/users/shsymoen/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shsymoen/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-01T21:00:29Z",
    "updated_at": "2017-07-01T21:00:29Z",
    "author_association": "NONE",
    "body": "I agree for the solution of iterating over the key-value pairs of the dict for outputting to excel but I think you lose some functionality if one has to do the same for storing to HDF5.\r\nIs there a possibility to make a MultIndex df of the dictionary that holds multiple DataFrames?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/313098434",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-313098434",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 313098434,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzA5ODQzNA==",
    "user": {
      "login": "bashtage",
      "id": 5585221,
      "node_id": "MDQ6VXNlcjU1ODUyMjE=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5585221?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bashtage",
      "html_url": "https://github.com/bashtage",
      "followers_url": "https://api.github.com/users/bashtage/followers",
      "following_url": "https://api.github.com/users/bashtage/following{/other_user}",
      "gists_url": "https://api.github.com/users/bashtage/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bashtage/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bashtage/subscriptions",
      "organizations_url": "https://api.github.com/users/bashtage/orgs",
      "repos_url": "https://api.github.com/users/bashtage/repos",
      "events_url": "https://api.github.com/users/bashtage/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bashtage/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-05T13:11:10Z",
    "updated_at": "2017-07-05T13:11:10Z",
    "author_association": "CONTRIBUTOR",
    "body": "I can't think of a 1-liner since it is necessary to rename columns using the dict's key.\r\n\r\n```\r\nd = {'a':pd.DataFrame(np.random.randn(10,2)),\r\n     'b':pd.DataFrame(np.random.randn(10,2))}\r\n\r\ndfs=[]\r\ncols=[]\r\nfor k,v in d.items():\r\n    dfs.append(v.stack())\r\n    cols.append(k)\r\ndf = pd.concat(dfs,1)\r\ndf.columns=cols\r\n```\r\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/313167570",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-313167570",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 313167570,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzE2NzU3MA==",
    "user": {
      "login": "shoyer",
      "id": 1217238,
      "node_id": "MDQ6VXNlcjEyMTcyMzg=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/shoyer",
      "html_url": "https://github.com/shoyer",
      "followers_url": "https://api.github.com/users/shoyer/followers",
      "following_url": "https://api.github.com/users/shoyer/following{/other_user}",
      "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions",
      "organizations_url": "https://api.github.com/users/shoyer/orgs",
      "repos_url": "https://api.github.com/users/shoyer/repos",
      "events_url": "https://api.github.com/users/shoyer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/shoyer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-05T17:13:24Z",
    "updated_at": "2017-07-05T17:13:24Z",
    "author_association": "MEMBER",
    "body": "You can do this with the `keys` argument to `concat`, e.g., `pd.concat(dfs.values(), keys=df.keys())`:\r\nhttps://stackoverflow.com/questions/23600582/concatenate-pandas-columns-under-new-multi-index-level"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/313175249",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-313175249",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 313175249,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzE3NTI0OQ==",
    "user": {
      "login": "bashtage",
      "id": 5585221,
      "node_id": "MDQ6VXNlcjU1ODUyMjE=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/5585221?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bashtage",
      "html_url": "https://github.com/bashtage",
      "followers_url": "https://api.github.com/users/bashtage/followers",
      "following_url": "https://api.github.com/users/bashtage/following{/other_user}",
      "gists_url": "https://api.github.com/users/bashtage/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bashtage/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bashtage/subscriptions",
      "organizations_url": "https://api.github.com/users/bashtage/orgs",
      "repos_url": "https://api.github.com/users/bashtage/repos",
      "events_url": "https://api.github.com/users/bashtage/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bashtage/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-05T17:42:53Z",
    "updated_at": "2017-07-05T17:42:53Z",
    "author_association": "CONTRIBUTOR",
    "body": "Then I suppose one could have a not-totally-horrible one-liner:\r\n\r\n```\r\ndf = pd.concat([v.stack() for v in d.values()],1, keys=d.keys())\r\n```"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/313243640",
    "html_url": "https://github.com/pandas-dev/pandas/issues/16795#issuecomment-313243640",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/16795",
    "id": 313243640,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzI0MzY0MA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-07-05T22:24:29Z",
    "updated_at": "2017-07-05T22:24:29Z",
    "author_association": "CONTRIBUTOR",
    "body": "closing as this is purely a user issue. if anyone feels the docs needs enhacement pls feel free. the solutions above are quite adequate though."
  }
]
