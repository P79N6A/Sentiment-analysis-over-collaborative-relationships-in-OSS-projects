[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/54769013",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8055#issuecomment-54769013",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8055",
    "id": 54769013,
    "node_id": "MDEyOklzc3VlQ29tbWVudDU0NzY5MDEz",
    "user": {
      "login": "jtratner",
      "id": 1598379,
      "node_id": "MDQ6VXNlcjE1OTgzNzk=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1598379?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jtratner",
      "html_url": "https://github.com/jtratner",
      "followers_url": "https://api.github.com/users/jtratner/followers",
      "following_url": "https://api.github.com/users/jtratner/following{/other_user}",
      "gists_url": "https://api.github.com/users/jtratner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jtratner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jtratner/subscriptions",
      "organizations_url": "https://api.github.com/users/jtratner/orgs",
      "repos_url": "https://api.github.com/users/jtratner/repos",
      "events_url": "https://api.github.com/users/jtratner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jtratner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-09-08T01:42:21Z",
    "updated_at": "2014-09-08T01:42:21Z",
    "author_association": "CONTRIBUTOR",
    "body": "@rockg so it's on a network drive as well? this is a bit out there, are you able to simplify it at all?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/54822979",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8055#issuecomment-54822979",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8055",
    "id": 54822979,
    "node_id": "MDEyOklzc3VlQ29tbWVudDU0ODIyOTc5",
    "user": {
      "login": "rockg",
      "id": 3195015,
      "node_id": "MDQ6VXNlcjMxOTUwMTU=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/3195015?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rockg",
      "html_url": "https://github.com/rockg",
      "followers_url": "https://api.github.com/users/rockg/followers",
      "following_url": "https://api.github.com/users/rockg/following{/other_user}",
      "gists_url": "https://api.github.com/users/rockg/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rockg/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rockg/subscriptions",
      "organizations_url": "https://api.github.com/users/rockg/orgs",
      "repos_url": "https://api.github.com/users/rockg/repos",
      "events_url": "https://api.github.com/users/rockg/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rockg/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-09-08T14:10:15Z",
    "updated_at": "2014-09-08T14:10:15Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jtratner It is on a network drive.  I tried with a local file and that doesn't exhibit this behavior.  I'm open to suggestions on how to simplify but it's not immediately obvious what I could do.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/54842608",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8055#issuecomment-54842608",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8055",
    "id": 54842608,
    "node_id": "MDEyOklzc3VlQ29tbWVudDU0ODQyNjA4",
    "user": {
      "login": "jtratner",
      "id": 1598379,
      "node_id": "MDQ6VXNlcjE1OTgzNzk=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1598379?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jtratner",
      "html_url": "https://github.com/jtratner",
      "followers_url": "https://api.github.com/users/jtratner/followers",
      "following_url": "https://api.github.com/users/jtratner/following{/other_user}",
      "gists_url": "https://api.github.com/users/jtratner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jtratner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jtratner/subscriptions",
      "organizations_url": "https://api.github.com/users/jtratner/orgs",
      "repos_url": "https://api.github.com/users/jtratner/repos",
      "events_url": "https://api.github.com/users/jtratner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jtratner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2014-09-08T15:58:00Z",
    "updated_at": "2014-09-08T15:58:00Z",
    "author_association": "CONTRIBUTOR",
    "body": "@rockg given that it's something with a program open and a network connection, it's going to be hard for us to reproduce. I suggest you might try 'delta debugging' (basically, go look at tokenizer.c and stub out methods or parts of methods until you don't see this segfault any more. Then you know, generally, where the error is occurring and can narrow down which lines are involved). \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/88202984",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8055#issuecomment-88202984",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8055",
    "id": 88202984,
    "node_id": "MDEyOklzc3VlQ29tbWVudDg4MjAyOTg0",
    "user": {
      "login": "rockg",
      "id": 3195015,
      "node_id": "MDQ6VXNlcjMxOTUwMTU=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/3195015?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rockg",
      "html_url": "https://github.com/rockg",
      "followers_url": "https://api.github.com/users/rockg/followers",
      "following_url": "https://api.github.com/users/rockg/following{/other_user}",
      "gists_url": "https://api.github.com/users/rockg/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rockg/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rockg/subscriptions",
      "organizations_url": "https://api.github.com/users/rockg/orgs",
      "repos_url": "https://api.github.com/users/rockg/repos",
      "events_url": "https://api.github.com/users/rockg/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rockg/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-03-31T18:40:06Z",
    "updated_at": "2015-03-31T18:40:06Z",
    "author_association": "CONTRIBUTOR",
    "body": "Finally have some time to work on this and it has become a big enough nuisance to try and figure out.  I turned on the trace and it seems like fread is reading many more bytes when the file is open in LibreOffice vs not.\n\n```\n#File Open\n_tokenize_helper: Asked to tokenize 2 rows, datapos=0, datalen=0\nparser_buffer_bytes self->cb_io: nbytes=262144, datalen: 262144, status=0\ndatalen: 262144\n_tokenize_helper: Trying to process 262144 bytes, datalen=262144, datapos= 0\n```\n\n```\n#File Closed\n_tokenize_helper: Asked to tokenize 2 rows, datapos=0, datalen=0\nparser_buffer_bytes self->cb_io: nbytes=262144, datalen: 131, status=0\ndatalen: 131\n_tokenize_helper: Trying to process 131 bytes, datalen=131, datapos= 0\n```\n\nThe latter makes sense as there are 131 characters in the file.  I pulled out the specific functions, `buffer_file_bytes` and `new_file_source` in src/parser/io.c and compiled them outside of pandas but in both cases 131 bytes were read so it has to be something else outside of the core c functions.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/89091659",
    "html_url": "https://github.com/pandas-dev/pandas/issues/8055#issuecomment-89091659",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/8055",
    "id": 89091659,
    "node_id": "MDEyOklzc3VlQ29tbWVudDg5MDkxNjU5",
    "user": {
      "login": "rockg",
      "id": 3195015,
      "node_id": "MDQ6VXNlcjMxOTUwMTU=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/3195015?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/rockg",
      "html_url": "https://github.com/rockg",
      "followers_url": "https://api.github.com/users/rockg/followers",
      "following_url": "https://api.github.com/users/rockg/following{/other_user}",
      "gists_url": "https://api.github.com/users/rockg/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/rockg/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/rockg/subscriptions",
      "organizations_url": "https://api.github.com/users/rockg/orgs",
      "repos_url": "https://api.github.com/users/rockg/repos",
      "events_url": "https://api.github.com/users/rockg/events{/privacy}",
      "received_events_url": "https://api.github.com/users/rockg/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2015-04-03T00:22:31Z",
    "updated_at": "2015-04-03T00:22:31Z",
    "author_association": "CONTRIBUTOR",
    "body": "So after looking this we figured out the issue is with the default chunksize in the parser and some interaction with libreoffice on cifs mounted drives.  Basically at 2^17+ chunksize, fread starts to not be able to detect the end of the file and continues to keep reading the file.  Given this, I would like to make `tokenize_chunksize` in parser.pyx a keyword argument to `read_csv`.  `chunksize` is already a parameter, but it is used differently than `tokenize_chunksize`.  The other option is to add it to the pandas options which I kind of like better.  Any thoughts?\n"
  }
]
