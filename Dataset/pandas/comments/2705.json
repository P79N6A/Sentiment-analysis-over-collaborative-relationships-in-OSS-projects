[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12390926",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12390926",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12390926,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyMzkwOTI2",
    "user": {
      "login": "wesm",
      "id": 329591,
      "node_id": "MDQ6VXNlcjMyOTU5MQ==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/329591?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/wesm",
      "html_url": "https://github.com/wesm",
      "followers_url": "https://api.github.com/users/wesm/followers",
      "following_url": "https://api.github.com/users/wesm/following{/other_user}",
      "gists_url": "https://api.github.com/users/wesm/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/wesm/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/wesm/subscriptions",
      "organizations_url": "https://api.github.com/users/wesm/orgs",
      "repos_url": "https://api.github.com/users/wesm/repos",
      "events_url": "https://api.github.com/users/wesm/events{/privacy}",
      "received_events_url": "https://api.github.com/users/wesm/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-17T20:50:58Z",
    "updated_at": "2013-01-17T20:50:58Z",
    "author_association": "MEMBER",
    "body": "You should also try using HDFStore (require PyTables)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12391143",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12391143",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12391143,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyMzkxMTQz",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-17T20:55:36Z",
    "updated_at": "2013-01-17T20:55:48Z",
    "author_association": "CONTRIBUTOR",
    "body": "make sure you are on 0.10.1-dev\n\n```\nstore = pd.HDFStore('my_large_frame.h5','w')\n```\n\nthis is queryable (and preserves dtypes)\n\n```\nstore.append('df',df)\n```\n\nThis preserves dtypes, but is not-queryable (but will write much faster)\n\n```\nstore.put('df',df)\n```\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12391369",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12391369",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12391369,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyMzkxMzY5",
    "user": {
      "login": "daggre-gmu",
      "id": 1409063,
      "node_id": "MDQ6VXNlcjE0MDkwNjM=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1409063?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/daggre-gmu",
      "html_url": "https://github.com/daggre-gmu",
      "followers_url": "https://api.github.com/users/daggre-gmu/followers",
      "following_url": "https://api.github.com/users/daggre-gmu/following{/other_user}",
      "gists_url": "https://api.github.com/users/daggre-gmu/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/daggre-gmu/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/daggre-gmu/subscriptions",
      "organizations_url": "https://api.github.com/users/daggre-gmu/orgs",
      "repos_url": "https://api.github.com/users/daggre-gmu/repos",
      "events_url": "https://api.github.com/users/daggre-gmu/events{/privacy}",
      "received_events_url": "https://api.github.com/users/daggre-gmu/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-17T21:00:35Z",
    "updated_at": "2013-01-17T21:00:35Z",
    "author_association": "NONE",
    "body": "I was trying to use hdfstore and my workhorse machine somehow didn't get it compiled in correctly.  I can import pytables, but pandas doesn't know about it...  I'll dig in on that as my workaround though.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12407274",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12407274",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12407274,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyNDA3Mjc0",
    "user": {
      "login": "jostheim",
      "id": 132902,
      "node_id": "MDQ6VXNlcjEzMjkwMg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/132902?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jostheim",
      "html_url": "https://github.com/jostheim",
      "followers_url": "https://api.github.com/users/jostheim/followers",
      "following_url": "https://api.github.com/users/jostheim/following{/other_user}",
      "gists_url": "https://api.github.com/users/jostheim/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jostheim/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jostheim/subscriptions",
      "organizations_url": "https://api.github.com/users/jostheim/orgs",
      "repos_url": "https://api.github.com/users/jostheim/repos",
      "events_url": "https://api.github.com/users/jostheim/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jostheim/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-18T04:25:36Z",
    "updated_at": "2013-01-18T04:25:36Z",
    "author_association": "NONE",
    "body": "I was posting under the wrong account before (I am the person who started this issue), but I got HDFStore working and immediately ran into:\n\nFile \"hdf5Extension.pyx\", line 884, in tables.hdf5Extension.Array._createArray (tables/hdf5Extension.c:8498)\ntables.exceptions.HDF5ExtError: Problems creating the Array.\n\nThat was on 0.10.0, I tired compiling 0.10.1.dev, but I couldn't even import pandas:\n\n> > > import pandas\n> > > numpy.dtype has the wrong size, try recompiling\n> > > Traceback (most recent call last):\n> > >   File \"<stdin>\", line 1, in <module>\n> > >   File \"/Library/Python/2.7/site-packages/pandas-0.10.1.dev_6e2b6ea-py2.7-macosx-10.8-intel.egg/pandas/**init**.py\", line 6, in <module>\n> > >     from . import hashtable, tslib, lib\n> > >   File \"numpy.pxd\", line 156, in init pandas.hashtable (pandas/hashtable.c:20380)\n> > > ValueError: numpy.dtype has the wrong size, try recompiling\n\nSo I am still stuck.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12408019",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12408019",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12408019,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyNDA4MDE5",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-18T05:07:08Z",
    "updated_at": "2013-01-18T13:32:39Z",
    "author_association": "CONTRIBUTOR",
    "body": "heard building yourself is a little tough on mac\ndid you try this: http://ericjang.tumblr.com/post/25096909713/annoying-pytables-build-on-mac-osx-10-7\nfrom your error looks like pandas and pytables built against different numpy\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12426675",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12426675",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12426675,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyNDI2Njc1",
    "user": {
      "login": "jostheim",
      "id": 132902,
      "node_id": "MDQ6VXNlcjEzMjkwMg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/132902?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jostheim",
      "html_url": "https://github.com/jostheim",
      "followers_url": "https://api.github.com/users/jostheim/followers",
      "following_url": "https://api.github.com/users/jostheim/following{/other_user}",
      "gists_url": "https://api.github.com/users/jostheim/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jostheim/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jostheim/subscriptions",
      "organizations_url": "https://api.github.com/users/jostheim/orgs",
      "repos_url": "https://api.github.com/users/jostheim/repos",
      "events_url": "https://api.github.com/users/jostheim/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jostheim/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-18T15:28:28Z",
    "updated_at": "2013-01-18T15:28:28Z",
    "author_association": "NONE",
    "body": "I was able to save smaller dataframes to a HDF5 store with 0.10.0, so that works, is there any reason to expect 0.10.1.dev will allow me to save larger ones?\n\nThat problem installing 0.10.1.dev actually screwed up my entire numpy install, I had to re-install from scratch, so I'd rather not try that again.\n\nI suppose I can just write out a csv file myself with the dtypes in a header row and cast the columns myself.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12427627",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12427627",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12427627,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyNDI3NjI3",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-18T15:47:43Z",
    "updated_at": "2013-01-18T15:47:43Z",
    "author_association": "CONTRIBUTOR",
    "body": "It depends on what dtypes you are tring to save. Strings are broken in 0.10.0 (they work just very slowly). Also, depending if you need query capability (e.g. you want to save as a table) - which I'll recommend because strings and other data types are more effeciently stored. \n\ncan you post a df.get_dtype_counts() on your frame?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12428395",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12428395",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12428395,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyNDI4Mzk1",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-18T16:04:40Z",
    "updated_at": "2013-01-18T16:04:40Z",
    "author_association": "CONTRIBUTOR",
    "body": "are you storing as `put` or `append`? are you anticpating reading the entire frame into memory for operations later on?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12428640",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12428640",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12428640,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyNDI4NjQw",
    "user": {
      "login": "jostheim",
      "id": 132902,
      "node_id": "MDQ6VXNlcjEzMjkwMg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/132902?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jostheim",
      "html_url": "https://github.com/jostheim",
      "followers_url": "https://api.github.com/users/jostheim/followers",
      "following_url": "https://api.github.com/users/jostheim/following{/other_user}",
      "gists_url": "https://api.github.com/users/jostheim/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jostheim/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jostheim/subscriptions",
      "organizations_url": "https://api.github.com/users/jostheim/orgs",
      "repos_url": "https://api.github.com/users/jostheim/repos",
      "events_url": "https://api.github.com/users/jostheim/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jostheim/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-18T16:09:44Z",
    "updated_at": "2013-01-18T16:09:44Z",
    "author_association": "NONE",
    "body": "I'll add that call, though it takes hours to get to the dataframe I want to write out (hence me wanting to save it).  \n\nI am storing as a `put` currently:  \n\n`store['blah'] = df` \n\nwhich the docs say is a `put`.\n\nI expect to pull the entire dataframe out to operate on it this is truly just a way to store intermediate processing.  The dataframe definitely has strings in it.\n\nIn all likelhood I'll simply write my own serializer that will tell me which columns are datetimes so I can specify those columns in pd.read_csv (for my data I have to specify the datetime columns explicitly in order to get them parsed).  None of this would matter if I could get pandas to set the dtype on a datetime column correctly (it is always object for me, despite the fact I successfully parse the date).  Perhaps I'll open another issue for the datetime columns to get some separate advice.  \n\nI just want to say since I sound like I am complaining, I love pandas, it has been a huge help in getting to where I got with this data so quickly.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12429134",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12429134",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12429134,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyNDI5MTM0",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-18T16:19:46Z",
    "updated_at": "2013-01-18T16:19:46Z",
    "author_association": "CONTRIBUTOR",
    "body": "object type is bad! definitily try to convert\n\njust a general recommendation - definitntly try to split up frames and store in separate hdf files\neasier to debug and inspect things. esp when I am doing something new, I make lots of intermediate data steps (where I save data); you can always combine later. \n\ntry `df.convert_objects()` to convert your dates\ntake a look at this question as well: http://stackoverflow.com/questions/14355151/how-to-make-pandas-hdfstore-put-operation-faster/14370190#14370190\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12429940",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12429940",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12429940,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyNDI5OTQw",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-18T16:36:15Z",
    "updated_at": "2013-01-18T16:36:15Z",
    "author_association": "CONTRIBUTOR",
    "body": "fyi...the reason many use hdf5 is just raw speed....e.g. a random 2.5GB file (1.5M rows)..its atcually a panel stored as a table for much slower than a raw df....(50 columns or so), all floats, took about 30s. In addition PyTables supports compression and utilizied multi-core to read....(and I'm just a fan of PyTables!)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12430799",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12430799",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12430799,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyNDMwNzk5",
    "user": {
      "login": "jostheim",
      "id": 132902,
      "node_id": "MDQ6VXNlcjEzMjkwMg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/132902?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jostheim",
      "html_url": "https://github.com/jostheim",
      "followers_url": "https://api.github.com/users/jostheim/followers",
      "following_url": "https://api.github.com/users/jostheim/following{/other_user}",
      "gists_url": "https://api.github.com/users/jostheim/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jostheim/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jostheim/subscriptions",
      "organizations_url": "https://api.github.com/users/jostheim/orgs",
      "repos_url": "https://api.github.com/users/jostheim/repos",
      "events_url": "https://api.github.com/users/jostheim/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jostheim/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-18T16:54:19Z",
    "updated_at": "2013-01-18T16:54:39Z",
    "author_association": "NONE",
    "body": "I tried convert_objects with no success.  I don't know if this is the problem, but the columns with datetimes have missing values which I am putting as np.nan (when I cannot parse the date, I've tried None too).  This may make it look like a \"mixed\" type column, which it really isn't.  I just couldn't figure out what to fill in for the missing values that would connote missing but allow for proper typing.  Same situation I think for the string columns, the missing values are represented as np.nan which is a float, so pandas believes they are mixed types.\n\nDo I have this right?  Are there any suggestions for handling this?  \n\nPytables looks amazing, unfortunately right now I am just trying to get something done so I haven't had time to experiment, but I am glad I got it all installed so I can when I have more time.\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12431330",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12431330",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12431330,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyNDMxMzMw",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-18T17:06:20Z",
    "updated_at": "2013-01-18T17:07:05Z",
    "author_association": "CONTRIBUTOR",
    "body": "try this for creation (works in 0.10.0 i think)....0.10.1 has a little better handling\n\n```\nimport pandas as pd\n\n# objvious you can also use Timestamp objects as well\ns = Series([datetime(2001, 1, 2, 0, 0), pd.tslib.iNaT], dtype='M8[ns]') \n```\n\nnp.nan assignment in a datetime series will automatically get you an object type with no hope of getting out\n(though in 0.10.1 you have a datetime64[ns] and assign a np.nan it will work) \n\nstrings have much better support in the Table objects (e.g. pass table=True to put or use append). as they are represented as individual columns and nan conversion is done ( see docs at http://pandas.pydata.org/pandas-docs/dev/io.html#storing-mixed-types-in-a-table - also has an example of a NaT) - some of this might work in 0.10.0...best to use 0.10.1-dev - several bugs specifically related to nan handling were fixed in 0.10.1-dev\n\nnp.nan is correct for strings.....its just that PyTables (in 0.10.0) doesn't deal well with this...\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12431603",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12431603",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12431603,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyNDMxNjAz",
    "user": {
      "login": "jostheim",
      "id": 132902,
      "node_id": "MDQ6VXNlcjEzMjkwMg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/132902?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jostheim",
      "html_url": "https://github.com/jostheim",
      "followers_url": "https://api.github.com/users/jostheim/followers",
      "following_url": "https://api.github.com/users/jostheim/following{/other_user}",
      "gists_url": "https://api.github.com/users/jostheim/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jostheim/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jostheim/subscriptions",
      "organizations_url": "https://api.github.com/users/jostheim/orgs",
      "repos_url": "https://api.github.com/users/jostheim/repos",
      "events_url": "https://api.github.com/users/jostheim/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jostheim/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-18T17:12:26Z",
    "updated_at": "2013-01-18T17:12:26Z",
    "author_association": "NONE",
    "body": "And I just found this: https://github.com/pydata/pandas/pull/2595\n\nSo I see this is an issue... I'll try to install 0.10.1 again sometime today and cross my fingers that numpy remains :)\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/12432713",
    "html_url": "https://github.com/pandas-dev/pandas/issues/2705#issuecomment-12432713",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/2705",
    "id": 12432713,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEyNDMyNzEz",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-01-18T17:37:10Z",
    "updated_at": "2013-01-18T17:37:10Z",
    "author_association": "CONTRIBUTOR",
    "body": "if u want to hack it out\nthere are no cython changes in this so u could just update the python code in order to test it (its not that much)\n"
  }
]
