[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/425098629",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-425098629",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 425098629,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTA5ODYyOQ==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-09-27T13:46:16Z",
    "updated_at": "2018-09-27T13:46:16Z",
    "author_association": "MEMBER",
    "body": "Looks like this requires a bit more research. I'm not activating the conda environment, so I was guessing whether this would fail or not. And it seems it does.\r\n\r\nThis answers your question. Defining them as steps, when one fails, the job is interrupted. An alternative would be to create a job for each, but I think that will create too many jobs, and it'll make it difficult to find the jobs of the tests. Will do some research and see if it's possible to continue the steps when one is failing.\r\n\r\nI think yaml should support having scripts with multiple lines, I'll give that a try. I think that should be neater than having a script for each check with a loop."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/425100406",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-425100406",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 425100406,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTEwMDQwNg==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-09-27T13:51:08Z",
    "updated_at": "2018-09-27T13:51:08Z",
    "author_association": "CONTRIBUTOR",
    "body": "https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema?view=vsts#job\r\n\r\nLooks like there's a `continueOnError` field that determines this. That can be set at the job or script level. We'll want `true`."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/425121345",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-425121345",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 425121345,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTEyMTM0NQ==",
    "user": {
      "login": "codecov[bot]",
      "id": 22429695,
      "node_id": "MDM6Qm90MjI0Mjk2OTU=",
      "avatar_url": "https://avatars2.githubusercontent.com/in/254?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/codecov%5Bbot%5D",
      "html_url": "https://github.com/apps/codecov",
      "followers_url": "https://api.github.com/users/codecov%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/codecov%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/codecov%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/codecov%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/codecov%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/codecov%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/codecov%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/codecov%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/codecov%5Bbot%5D/received_events",
      "type": "Bot",
      "site_admin": false
    },
    "created_at": "2018-09-27T14:47:47Z",
    "updated_at": "2018-12-03T00:03:37Z",
    "author_association": "NONE",
    "body": "# [Codecov](https://codecov.io/gh/pandas-dev/pandas/pull/22854?src=pr&el=h1) Report\n> Merging [#22854](https://codecov.io/gh/pandas-dev/pandas/pull/22854?src=pr&el=desc) into [master](https://codecov.io/gh/pandas-dev/pandas/commit/45f880b63e7fbbed832c4f4d7eec0c617520d1c8?src=pr&el=desc) will **decrease** coverage by `<.01%`.\n> The diff coverage is `100%`.\n\n[![Impacted file tree graph](https://codecov.io/gh/pandas-dev/pandas/pull/22854/graphs/tree.svg?width=650&token=eZ4WkYLtcO&height=150&src=pr)](https://codecov.io/gh/pandas-dev/pandas/pull/22854?src=pr&el=tree)\n\n```diff\n@@            Coverage Diff             @@\n##           master   #22854      +/-   ##\n==========================================\n- Coverage   42.45%   42.44%   -0.01%     \n==========================================\n  Files         161      161              \n  Lines       51561    51559       -2     \n==========================================\n- Hits        21888    21886       -2     \n  Misses      29673    29673\n```\n\n| Flag | Coverage Δ | |\n|---|---|---|\n| #single | `42.44% <100%> (-0.01%)` | :arrow_down: |\n\n| [Impacted Files](https://codecov.io/gh/pandas-dev/pandas/pull/22854?src=pr&el=tree) | Coverage Δ | |\n|---|---|---|\n| [pandas/core/panel.py](https://codecov.io/gh/pandas-dev/pandas/pull/22854/diff?src=pr&el=tree#diff-cGFuZGFzL2NvcmUvcGFuZWwucHk=) | `42.02% <ø> (ø)` | :arrow_up: |\n| [pandas/core/tools/timedeltas.py](https://codecov.io/gh/pandas-dev/pandas/pull/22854/diff?src=pr&el=tree#diff-cGFuZGFzL2NvcmUvdG9vbHMvdGltZWRlbHRhcy5weQ==) | `66.66% <ø> (ø)` | :arrow_up: |\n| [pandas/core/frame.py](https://codecov.io/gh/pandas-dev/pandas/pull/22854/diff?src=pr&el=tree#diff-cGFuZGFzL2NvcmUvZnJhbWUucHk=) | `38.7% <ø> (ø)` | :arrow_up: |\n| [pandas/io/json/json.py](https://codecov.io/gh/pandas-dev/pandas/pull/22854/diff?src=pr&el=tree#diff-cGFuZGFzL2lvL2pzb24vanNvbi5weQ==) | `16.66% <ø> (ø)` | :arrow_up: |\n| [pandas/io/gbq.py](https://codecov.io/gh/pandas-dev/pandas/pull/22854/diff?src=pr&el=tree#diff-cGFuZGFzL2lvL2dicS5weQ==) | `25% <ø> (ø)` | :arrow_up: |\n| [pandas/core/window.py](https://codecov.io/gh/pandas-dev/pandas/pull/22854/diff?src=pr&el=tree#diff-cGFuZGFzL2NvcmUvd2luZG93LnB5) | `28.93% <100%> (ø)` | :arrow_up: |\n| [pandas/core/arrays/period.py](https://codecov.io/gh/pandas-dev/pandas/pull/22854/diff?src=pr&el=tree#diff-cGFuZGFzL2NvcmUvYXJyYXlzL3BlcmlvZC5weQ==) | `36.97% <0%> (-0.15%)` | :arrow_down: |\n| [pandas/core/arrays/datetimes.py](https://codecov.io/gh/pandas-dev/pandas/pull/22854/diff?src=pr&el=tree#diff-cGFuZGFzL2NvcmUvYXJyYXlzL2RhdGV0aW1lcy5weQ==) | `63.41% <0%> (-0.08%)` | :arrow_down: |\n| [pandas/core/strings.py](https://codecov.io/gh/pandas-dev/pandas/pull/22854/diff?src=pr&el=tree#diff-cGFuZGFzL2NvcmUvc3RyaW5ncy5weQ==) | `33% <0%> (ø)` | :arrow_up: |\n\n------\n\n[Continue to review full report at Codecov](https://codecov.io/gh/pandas-dev/pandas/pull/22854?src=pr&el=continue).\n> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)\n> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`\n> Powered by [Codecov](https://codecov.io/gh/pandas-dev/pandas/pull/22854?src=pr&el=footer). Last update [45f880b...498cebb](https://codecov.io/gh/pandas-dev/pandas/pull/22854?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/425211614",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-425211614",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 425211614,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTIxMTYxNA==",
    "user": {
      "login": "pep8speaks",
      "id": 24736507,
      "node_id": "MDQ6VXNlcjI0NzM2NTA3",
      "avatar_url": "https://avatars1.githubusercontent.com/u/24736507?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pep8speaks",
      "html_url": "https://github.com/pep8speaks",
      "followers_url": "https://api.github.com/users/pep8speaks/followers",
      "following_url": "https://api.github.com/users/pep8speaks/following{/other_user}",
      "gists_url": "https://api.github.com/users/pep8speaks/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pep8speaks/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pep8speaks/subscriptions",
      "organizations_url": "https://api.github.com/users/pep8speaks/orgs",
      "repos_url": "https://api.github.com/users/pep8speaks/repos",
      "events_url": "https://api.github.com/users/pep8speaks/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pep8speaks/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-09-27T19:17:58Z",
    "updated_at": "2018-11-12T16:58:06Z",
    "author_association": "NONE",
    "body": "Hello @datapythonista! Thanks for updating the PR.\n\n - There are no PEP8 issues in the file [`scripts/generate_pip_deps_from_conda.py`](https://github.com/datapythonista/pandas/blob/eb558dfd6575d038553a77acec79f73c1a4f7c25/scripts/generate_pip_deps_from_conda.py) !\n\n\n\n##### Comment last updated on November 12, 2018 at 16:58 Hours UTC"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/425225896",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-425225896",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 425225896,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTIyNTg5Ng==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-09-27T20:08:07Z",
    "updated_at": "2018-09-27T20:08:07Z",
    "author_association": "MEMBER",
    "body": "@TomAugspurger seems like the `continueOnError` is not working at the job level (it should based on the docs), it needs to be at step level. But more important, continuing means that the build will be successful when an step fails, so it's not an option.\r\n\r\nI think the log is much clearer, I personally thing it'd be great if we could use azure for the linting. But I think the drawbacks are probably deal breakers, and I don't think they can be fixed:\r\n- We can't run all the linting/checks, seems like when one in each job fails it has to stop. And I don't think we want to have one job per test, that would make things much more complicated (both in the dashboard and in the code).\r\n- Having the checking in the yaml, we can't run `./ci/lint.sh` locally. We could have a script that parses the yaml and executes all the checks, or we could build the yaml from a script. But I don't think any of them is actually worth.\r\n\r\nThoughts?\r\n\r\nCC @chrisrpatterson"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/425633664",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-425633664",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 425633664,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTYzMzY2NA==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-09-29T10:12:57Z",
    "updated_at": "2018-09-29T10:12:57Z",
    "author_association": "MEMBER",
    "body": "Looks like `continueOnError` is converting the error in a warning, but adding `condition: true` is what makes that a step is executed no matter the outcome of the previous.\r\n\r\nThis looks cool now:\r\nhttps://dev.azure.com/pandas-dev/pandas/_build/results?buildId=367&view=logs\r\n\r\nAnd seems like we can have links to the source code line with the linting error, which may also be helpful in some cases.\r\n\r\nI guess we still want to be able to run all the linting and checks locally. I think a script that parses the yaml and execute every command on it should be really easy, and would do the work for now.\r\n\r\nThoughts? @TomAugspurger @jreback "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/425637870",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-425637870",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 425637870,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTYzNzg3MA==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-09-29T11:28:16Z",
    "updated_at": "2018-09-29T11:28:16Z",
    "author_association": "CONTRIBUTOR",
    "body": "Yes, that looks quite nice. Thanks.\n\nAs an alternative to parsing the YAML, could we have a directory of scripts\nlike `ci/lint/lint-py.sh`, `ci/lint/lint-c.sh`. Each of those would be one\nof the `script` lines in your YAML.\n\nThen we could have a `ci/lint.sh` that loops over all the `ci/lint/*.sh` to\nrun them all?\n\nOn Sat, Sep 29, 2018 at 5:13 AM Marc Garcia <notifications@github.com>\nwrote:\n\n> Looks like continueOnError is converting the error in a warning, but\n> adding condition: true is what makes that a step is executed no matter\n> the outcome of the previous.\n>\n> This looks cool now:\n>\n> https://dev.azure.com/pandas-dev/pandas/_build/results?buildId=367&view=logs\n>\n> And seems like we can have links to the source code line with the linting\n> error, which may also be helpful in some cases.\n>\n> I guess we still want to be able to run all the linting and checks\n> locally. I think a script that parses the yaml and execute every command on\n> it should be really easy, and would do the work for now.\n>\n> Thoughts? @TomAugspurger <https://github.com/TomAugspurger> @jreback\n> <https://github.com/jreback>\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pandas-dev/pandas/pull/22854#issuecomment-425633664>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABQHIqDamrYYcQ5DYWaC0mzikWqSj0Ziks5uf0exgaJpZM4W8qbh>\n> .\n>\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/425640790",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-425640790",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 425640790,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTY0MDc5MA==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-09-29T12:20:52Z",
    "updated_at": "2018-09-29T12:20:52Z",
    "author_association": "MEMBER",
    "body": "I unified all the linting of `*.py` files in #22863 (https://github.com/pandas-dev/pandas/pull/22863/commits/adcda478c3af1ae0edeaf09630ce2c3d6926b36a), which I think that simplifies things, and adds few value to have them separate, even in azure.\r\n\r\nBut even with that we'd have more than 10 scripts. And while that would surely guarantee the syncronization between azure and `lint.sh` in the exact commands, I think we can end up having differences on which scripts are called in each place. And, I think we'd loose the command being executed (e.g. we'd see in the logs `./ci/check_deprecated_directive.sh` instead of `grep -v \".. deprecated::`, which I think makes things more difficult to debug).\r\n\r\nSo, I think I prefer another option (which look much simpler to me):\r\n- We could simply not have anything to call all checks (linting .py files is as simple as `flake8 .` with the current state of #22863, and the other checks we can probably wait for the CI)\r\n- Have the `lint.sh` that iterates over `azure-pipelines.yml` and run its commands"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/425658708",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-425658708",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 425658708,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTY1ODcwOA==",
    "user": {
      "login": "jbrockmendel",
      "id": 8078968,
      "node_id": "MDQ6VXNlcjgwNzg5Njg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/8078968?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jbrockmendel",
      "html_url": "https://github.com/jbrockmendel",
      "followers_url": "https://api.github.com/users/jbrockmendel/followers",
      "following_url": "https://api.github.com/users/jbrockmendel/following{/other_user}",
      "gists_url": "https://api.github.com/users/jbrockmendel/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jbrockmendel/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jbrockmendel/subscriptions",
      "organizations_url": "https://api.github.com/users/jbrockmendel/orgs",
      "repos_url": "https://api.github.com/users/jbrockmendel/repos",
      "events_url": "https://api.github.com/users/jbrockmendel/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jbrockmendel/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-09-29T16:44:53Z",
    "updated_at": "2018-09-29T16:44:53Z",
    "author_association": "MEMBER",
    "body": "> But even with that we'd have more than 10 scripts.\r\n\r\nMy only real thought here is that I prefer a centralized ci/lint.sh to less-centralized.  I have a hard enough time keeping track of what is checked where as it is."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/429983301",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-429983301",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 429983301,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyOTk4MzMwMQ==",
    "user": {
      "login": "vtbassmatt",
      "id": 714283,
      "node_id": "MDQ6VXNlcjcxNDI4Mw==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/714283?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vtbassmatt",
      "html_url": "https://github.com/vtbassmatt",
      "followers_url": "https://api.github.com/users/vtbassmatt/followers",
      "following_url": "https://api.github.com/users/vtbassmatt/following{/other_user}",
      "gists_url": "https://api.github.com/users/vtbassmatt/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vtbassmatt/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vtbassmatt/subscriptions",
      "organizations_url": "https://api.github.com/users/vtbassmatt/orgs",
      "repos_url": "https://api.github.com/users/vtbassmatt/repos",
      "events_url": "https://api.github.com/users/vtbassmatt/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vtbassmatt/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-15T19:29:37Z",
    "updated_at": "2018-10-15T19:29:37Z",
    "author_association": "CONTRIBUTOR",
    "body": "Hey @datapythonista -- you asked me in another PR to take a look here. I'm working on getting #23111 back in good shape. What were you specifically looking for in this one?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/430062377",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-430062377",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 430062377,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDA2MjM3Nw==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-16T00:46:54Z",
    "updated_at": "2018-10-16T00:46:54Z",
    "author_association": "MEMBER",
    "body": "Thanks @vtbassmatt.\r\n\r\nThe idea here is to move the code validations from travis to azure-pipepines. Mainly because the presentation is much better, and it's much easier to find the code errors.\r\n\r\nA general look would be useful, to see if it makes sense what I did. But there are few more things that would be great to see if can be done and how.\r\n\r\n- Adding the same format used in flake8 to cpplint, the doctests...\r\n- See if there is away to avoid creating a miniconda environment and compiling the code just for the linting (e.g. reusing the environment from another job)\r\n- Pushing the errors to a github comment (same as pep8speak does, which would not be necessary anymore)\r\n- Creating links from the error messages to the location of the failing code. A colleague of yours said we would get them if using the format we are using, but I don't see links being created.\r\n\r\nAnd anything else you think could make better use of azure-pipelines for our code checks."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/430323850",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-430323850",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 430323850,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDMyMzg1MA==",
    "user": {
      "login": "vtbassmatt",
      "id": 714283,
      "node_id": "MDQ6VXNlcjcxNDI4Mw==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/714283?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vtbassmatt",
      "html_url": "https://github.com/vtbassmatt",
      "followers_url": "https://api.github.com/users/vtbassmatt/followers",
      "following_url": "https://api.github.com/users/vtbassmatt/following{/other_user}",
      "gists_url": "https://api.github.com/users/vtbassmatt/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vtbassmatt/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vtbassmatt/subscriptions",
      "organizations_url": "https://api.github.com/users/vtbassmatt/orgs",
      "repos_url": "https://api.github.com/users/vtbassmatt/repos",
      "events_url": "https://api.github.com/users/vtbassmatt/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vtbassmatt/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-16T17:23:11Z",
    "updated_at": "2018-10-16T17:23:11Z",
    "author_association": "CONTRIBUTOR",
    "body": "Gotcha, thanks. I'm not super deep on doctests (and never used cpplint before!) so I don't know if I can accelerate you there.\r\n\r\nAvoiding the recompile: each job runs on a new agent, and no files are retained between them. So there are two options:\r\n1. Slot in the linting after one of the existing build jobs. This can be done as a template so it's still logically separate, but this way it would run on the same agent.\r\n2. Publish build artifacts at the end of one job, then consume them at the start of another.\r\n\r\nLet me know which of those seems more appealing and I can put something together. Personally I prefer the former.\r\n\r\npep8speaks is cool; I had never seen that before! I need to do some thinking about the model here, but I think at a minimum, we could publish an example of how to do that. @DavidStaheli you might be interested in this as well.\r\n\r\nLinks to files: from casual inspection, what you're doing looks right. @azureDaveOps do we have a bug in how we show links to error lines in code files?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/430451470",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-430451470",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 430451470,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDQ1MTQ3MA==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-17T00:54:32Z",
    "updated_at": "2018-10-17T00:54:32Z",
    "author_association": "MEMBER",
    "body": "Not sure about the details, but having a job that publish an artifact sounds actually really great. Not only for the linting, but for everything. If we can have a job that downloads the source code of the PR and the miniconda installer, and we don't need to repeat that in every job, we would save a decent amount of resources.\r\n\r\nIt would probably be even better if we could reuse the artifact with the conda dependencies already installed from one build to the next, but I don't know if that's easy, and we should answer questions in our side like when to expire that.\r\n\r\nHaving the linting in one of the testing jobs is what we have now in Travis. But I really like how things are presented know in separate jobs in the azure dashboard. Having the lint failures in a job \"Testing linux\" is not as clear as having it in \"Code checks\" in my opinion.\r\n\r\nThanks a lot for the help with this."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/430452010",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-430452010",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 430452010,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDQ1MjAxMA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-17T00:57:41Z",
    "updated_at": "2018-10-17T00:57:41Z",
    "author_association": "CONTRIBUTOR",
    "body": "@datapythonista \r\n\r\n> See if there is away to avoid creating a miniconda environment and compiling the code just for the linting (e.g. reusing the environment from another job)\r\n\r\nwe won't ever do this. From long experience this often ends up being pretty complicated, and is just asking for trouble. you want completely independent builds, that have NO interactions."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/430525474",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-430525474",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 430525474,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDUyNTQ3NA==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-17T07:47:00Z",
    "updated_at": "2018-10-17T07:47:00Z",
    "author_association": "MEMBER",
    "body": "Fair enough. I guess for the linting, as it's already with one of the builds, we can see if it's not complicated to do the same, but in a separate job. I think this will be same as now, but I think it'll make things clearer if it appears in a separate job in the dashboard (as it's shown in the CI of this PR already)."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/430564819",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-430564819",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 430564819,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDU2NDgxOQ==",
    "user": {
      "login": "vtbassmatt",
      "id": 714283,
      "node_id": "MDQ6VXNlcjcxNDI4Mw==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/714283?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vtbassmatt",
      "html_url": "https://github.com/vtbassmatt",
      "followers_url": "https://api.github.com/users/vtbassmatt/followers",
      "following_url": "https://api.github.com/users/vtbassmatt/following{/other_user}",
      "gists_url": "https://api.github.com/users/vtbassmatt/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vtbassmatt/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vtbassmatt/subscriptions",
      "organizations_url": "https://api.github.com/users/vtbassmatt/orgs",
      "repos_url": "https://api.github.com/users/vtbassmatt/repos",
      "events_url": "https://api.github.com/users/vtbassmatt/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vtbassmatt/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-17T09:50:43Z",
    "updated_at": "2018-10-17T09:50:43Z",
    "author_association": "CONTRIBUTOR",
    "body": "I'm hoping to find some time to crank this out for you, but it won't be until tomorrow at the earliest. In the meantime, here's a rough (untested) sketch of the setup you'll want:\r\n\r\n```yaml\r\njobs:\r\n- job: Build\r\n  steps:\r\n  - script: echo Do my build stuff!\r\n  - task: CopyFiles@2\r\n    inputs:\r\n      #sourceFolder: # ideally, your build outputs would be in some particular subdir, that way you don't have to publish your entire source and intermediate build results\r\n      targetFolder: $(Build.ArtifactStagingDirectory)\r\n  - task: PublishBuildArtifacts@1\r\n\r\n- job: Lint\r\n  dependsOn: Build  # this is the name we gave the job that publishes build artifacts\r\n  steps:\r\n  - task: DownloadBuildArtifacts@0  # this will download all the build artifacts from previous jobs\r\n  - script: echo Do my linting stuff!\r\n    workingDirectory: $(System.ArtifactsDirectory)\r\n```\r\n\r\nThe last 2 things the Build job does are copy files to a staging directory and then upload them as a build artifact. The copy step isn't _strictly_ necessary, but it makes it easier to grab various pieces from the build tree and stage them for a single upload. By default, the artifact is called `drop` but you can change that with [arguments to the Publish task](https://docs.microsoft.com/azure/devops/pipelines/tasks/utility/publish-build-artifacts?view=vsts).\r\n\r\nIn that Lint job, we'll still download source first. Then the first task is to grab the build artifacts from previous steps. Artifacts will be downloaded into $(System.ArtifactsDirectory) by default. This is changeable with some [inputs to the task](https://docs.microsoft.com/azure/devops/pipelines/tasks/utility/download-build-artifacts?view=vsts). What I'm not 100% on is behavior like, what exact directories do we lay things down into, what if there are filename conflicts, etc."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/430565116",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-430565116",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 430565116,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzMDU2NTExNg==",
    "user": {
      "login": "vtbassmatt",
      "id": 714283,
      "node_id": "MDQ6VXNlcjcxNDI4Mw==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/714283?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vtbassmatt",
      "html_url": "https://github.com/vtbassmatt",
      "followers_url": "https://api.github.com/users/vtbassmatt/followers",
      "following_url": "https://api.github.com/users/vtbassmatt/following{/other_user}",
      "gists_url": "https://api.github.com/users/vtbassmatt/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vtbassmatt/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vtbassmatt/subscriptions",
      "organizations_url": "https://api.github.com/users/vtbassmatt/orgs",
      "repos_url": "https://api.github.com/users/vtbassmatt/repos",
      "events_url": "https://api.github.com/users/vtbassmatt/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vtbassmatt/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-17T09:51:37Z",
    "updated_at": "2018-10-17T09:51:37Z",
    "author_association": "CONTRIBUTOR",
    "body": "(And soon I hope to wrap some of that up with native YAML syntax, because having to know about 3 different tasks is kinda hostile.)"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/435650240",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-435650240",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 435650240,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTY1MDI0MA==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-04T09:04:15Z",
    "updated_at": "2018-11-04T09:05:45Z",
    "author_association": "MEMBER",
    "body": "Adding screenshot of how the errors display, before I fix them, so the PR can be merged:\r\n\r\n![azure_errors](https://user-images.githubusercontent.com/10058240/47961709-1ca90800-e008-11e8-80d7-cccc2c2e5776.png)\r\n\r\nand the link:\r\nhttps://dev.azure.com/pandas-dev/pandas/_build/results?buildId=2349&view=logs"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/435653969",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-435653969",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 435653969,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTY1Mzk2OQ==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-04T09:18:46Z",
    "updated_at": "2018-11-04T09:18:46Z",
    "author_association": "MEMBER",
    "body": "@TomAugspurger @jreback I'd merge this PR as it is. There is some more work to do, like trying to write github comments with the azure results, and reusing the conda of another job for the linting, but I'd take care of them in separate PRs.\r\n\r\nLet me know if this looks good, or this needs any change (note that the CI for this will fail until #23486 is merged)."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/435662653",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-435662653",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 435662653,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTY2MjY1Mw==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-04T11:43:25Z",
    "updated_at": "2018-11-04T11:43:25Z",
    "author_association": "CONTRIBUTOR",
    "body": "is this actually building in the code checks job?\r\nall of the long checks don’t need a build but the doctest do"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/435663784",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-435663784",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 435663784,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTY2Mzc4NA==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-04T12:01:27Z",
    "updated_at": "2018-11-04T12:01:27Z",
    "author_association": "MEMBER",
    "body": "That's a very good point. No, I just realize now, that the linting works, but the parts that depend on the build don't. Thanks!"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/435665175",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-435665175",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 435665175,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTY2NTE3NQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-04T12:23:28Z",
    "updated_at": "2018-11-04T12:23:28Z",
    "author_association": "CONTRIBUTOR",
    "body": "so it might be ok to move just the doctests back to the travis build "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/435665701",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-435665701",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 435665701,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTY2NTcwMQ==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-04T12:31:32Z",
    "updated_at": "2018-11-04T12:31:32Z",
    "author_association": "MEMBER",
    "body": "That's surely an option. I can also move the linting to the linux test job, so that would be equivalent to what we have now in travis.\r\n\r\nAnd I also can try what @vtbassmatt suggested, and publish the files of one of the builds (built source, conda environment), and reuse them for the code checks job. This is a bit more complex, but the results would be the clearest in the azure dashboard, so it's probably worth giving it a try.\r\n\r\nI'll do some research and I'll be back with what I think it's the best approach.\r\n\r\nThanks!"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/435785613",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-435785613",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 435785613,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNTc4NTYxMw==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-05T08:04:18Z",
    "updated_at": "2018-11-05T08:04:18Z",
    "author_association": "MEMBER",
    "body": "Related to this, I created an issue in `pytest` to see if we can show the pytest errors in azure in the same way that we do with `flake8`: https://github.com/pytest-dev/pytest/issues/4311 "
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/437624655",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-437624655",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 437624655,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzYyNDY1NQ==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-10T22:00:30Z",
    "updated_at": "2018-11-10T22:00:30Z",
    "author_association": "MEMBER",
    "body": "@TomAugspurger @jorisvandenbossche can you take a look at what I'm doing with the docs here, to see if you think it's reasonable, before I continue with this path?"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/437625626",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-437625626",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 437625626,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzYyNTYyNg==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-10T22:13:58Z",
    "updated_at": "2018-11-10T22:13:58Z",
    "author_association": "CONTRIBUTOR",
    "body": "Just to make sure I understand: the linting and doc build will be done on the same job right? That all seems reasonable to me."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/437626522",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-437626522",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 437626522,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzYyNjUyMg==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-10T22:28:02Z",
    "updated_at": "2018-11-10T22:28:18Z",
    "author_association": "MEMBER",
    "body": "Yes, that's what I'm doing here. I'm not sure, but I think travis has a timeout that azure doesn't, so that's an advantage of moving it here.\r\n\r\nAnd I found it simpler, as the job has a script of its own, we don't need the `LINT=true` or `DOC=true` that we used in travis. And for me at least, it's conceptually more clear to find all the non-test failures in a single job.\r\n\r\nI'm open to other structures, I was just testing options, but personally I'm quite happy how this looks like. My idea is to also add the `validate_docstrings.py` here (after #23560 is merged)."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/437626880",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-437626880",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 437626880,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzYyNjg4MA==",
    "user": {
      "login": "TomAugspurger",
      "id": 1312546,
      "node_id": "MDQ6VXNlcjEzMTI1NDY=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/TomAugspurger",
      "html_url": "https://github.com/TomAugspurger",
      "followers_url": "https://api.github.com/users/TomAugspurger/followers",
      "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}",
      "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions",
      "organizations_url": "https://api.github.com/users/TomAugspurger/orgs",
      "repos_url": "https://api.github.com/users/TomAugspurger/repos",
      "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}",
      "received_events_url": "https://api.github.com/users/TomAugspurger/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-10T22:34:52Z",
    "updated_at": "2018-11-10T22:34:52Z",
    "author_association": "CONTRIBUTOR",
    "body": "Sounds good. IIRC the main reason the doc build as moved to allowed\nfailures was because it was timing out.\n\nOn Sat, Nov 10, 2018 at 4:28 PM Marc Garcia <notifications@github.com>\nwrote:\n\n> Yes, that's what I'm doing here. I'm not sure, but I think travis has a\n> timeout that azure doesn't, so that's an advantage of moving it here.\n>\n> And I found it simple, as the job has a script of its own, we don't need\n> the LINT=true or DOC=true that we used in travis. And for me at least,\n> it's conceptually more clear to find all the non-test failures in a single\n> job.\n>\n> I'm open to other structures, I was just testing options, but personally\n> I'm quite happy how this looks like. My idea is to also add the\n> validate_docstrings.py here (after #23560\n> <https://github.com/pandas-dev/pandas/pull/23560> is merged).\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pandas-dev/pandas/pull/22854#issuecomment-437626522>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABQHIsDECi2Wq3EU1at7v3z6WIvL-hpZks5ut1L2gaJpZM4W8qbh>\n> .\n>\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/437691038",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-437691038",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 437691038,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzY5MTAzOA==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-11T18:03:04Z",
    "updated_at": "2018-11-11T18:03:04Z",
    "author_association": "CONTRIBUTOR",
    "body": "is there a reason to conflate the docs & code checks on a single build?\r\n\r\nwhy not just create another azure build for code-checks? e.g. you could then run the linting check very early and fail the build if that doesn't pass\r\n\r\nthen buidl & run the rest of the code checks.\r\n\r\nI know it seems heavy weight to create another build, but azure is pretty fast."
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/437691513",
    "html_url": "https://github.com/pandas-dev/pandas/pull/22854#issuecomment-437691513",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/22854",
    "id": 437691513,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzY5MTUxMw==",
    "user": {
      "login": "datapythonista",
      "id": 10058240,
      "node_id": "MDQ6VXNlcjEwMDU4MjQw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10058240?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/datapythonista",
      "html_url": "https://github.com/datapythonista",
      "followers_url": "https://api.github.com/users/datapythonista/followers",
      "following_url": "https://api.github.com/users/datapythonista/following{/other_user}",
      "gists_url": "https://api.github.com/users/datapythonista/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/datapythonista/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/datapythonista/subscriptions",
      "organizations_url": "https://api.github.com/users/datapythonista/orgs",
      "repos_url": "https://api.github.com/users/datapythonista/repos",
      "events_url": "https://api.github.com/users/datapythonista/events{/privacy}",
      "received_events_url": "https://api.github.com/users/datapythonista/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-11T18:09:15Z",
    "updated_at": "2018-11-11T18:09:15Z",
    "author_association": "MEMBER",
    "body": "Do you mean that if the build with only the code checks fail, we should cancel building the docs and the builds of the tests?\r\n\r\nThe main reason was as you guessed to have one less build, so we save setting up the environment and building pandas once."
  }
]
