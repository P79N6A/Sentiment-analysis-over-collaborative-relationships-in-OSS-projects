[
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/189715572",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12485#issuecomment-189715572",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12485",
    "id": 189715572,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4OTcxNTU3Mg==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-27T20:10:00Z",
    "updated_at": "2016-02-27T20:10:00Z",
    "author_association": "CONTRIBUTOR",
    "body": "why do you think this should be in pandas rather than `PySpark`?\n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/189742874",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12485#issuecomment-189742874",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12485",
    "id": 189742874,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4OTc0Mjg3NA==",
    "user": {
      "login": "danfrankj",
      "id": 616139,
      "node_id": "MDQ6VXNlcjYxNjEzOQ==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/616139?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/danfrankj",
      "html_url": "https://github.com/danfrankj",
      "followers_url": "https://api.github.com/users/danfrankj/followers",
      "following_url": "https://api.github.com/users/danfrankj/following{/other_user}",
      "gists_url": "https://api.github.com/users/danfrankj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/danfrankj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/danfrankj/subscriptions",
      "organizations_url": "https://api.github.com/users/danfrankj/orgs",
      "repos_url": "https://api.github.com/users/danfrankj/repos",
      "events_url": "https://api.github.com/users/danfrankj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/danfrankj/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-27T22:49:59Z",
    "updated_at": "2016-02-27T22:49:59Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jreback \n\nI did notice that pyspark.sql.createDataFrame accepts a pandas.DataFrame so most of the work is done  but having it linked from pandas might be nice so that it's more discoverable? I guess I don't have terribly strong feelings about the translation layer living in pyspark instead but pandas does link into other DataFrame-like objects with some of the pandas.DataFrame.to_\\* methods and wouldn't be hard to have a to_spark method. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/189743031",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12485#issuecomment-189743031",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12485",
    "id": 189743031,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE4OTc0MzAzMQ==",
    "user": {
      "login": "jreback",
      "id": 953992,
      "node_id": "MDQ6VXNlcjk1Mzk5Mg==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jreback",
      "html_url": "https://github.com/jreback",
      "followers_url": "https://api.github.com/users/jreback/followers",
      "following_url": "https://api.github.com/users/jreback/following{/other_user}",
      "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jreback/subscriptions",
      "organizations_url": "https://api.github.com/users/jreback/orgs",
      "repos_url": "https://api.github.com/users/jreback/repos",
      "events_url": "https://api.github.com/users/jreback/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jreback/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-02-27T22:51:16Z",
    "updated_at": "2016-02-27T22:52:14Z",
    "author_association": "CONTRIBUTOR",
    "body": "@danfrankj I am not saying this is hard. But _why_ this should be a good thing to live in pandas. It is _already_ in `PySpark`. Why does pandas have to know about this? what good is that?\n\nIn effect you are making `PySpark` an optional dependency. \n"
  },
  {
    "url": "https://api.github.com/repos/pandas-dev/pandas/issues/comments/195421475",
    "html_url": "https://github.com/pandas-dev/pandas/issues/12485#issuecomment-195421475",
    "issue_url": "https://api.github.com/repos/pandas-dev/pandas/issues/12485",
    "id": 195421475,
    "node_id": "MDEyOklzc3VlQ29tbWVudDE5NTQyMTQ3NQ==",
    "user": {
      "login": "danfrankj",
      "id": 616139,
      "node_id": "MDQ6VXNlcjYxNjEzOQ==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/616139?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/danfrankj",
      "html_url": "https://github.com/danfrankj",
      "followers_url": "https://api.github.com/users/danfrankj/followers",
      "following_url": "https://api.github.com/users/danfrankj/following{/other_user}",
      "gists_url": "https://api.github.com/users/danfrankj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/danfrankj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/danfrankj/subscriptions",
      "organizations_url": "https://api.github.com/users/danfrankj/orgs",
      "repos_url": "https://api.github.com/users/danfrankj/repos",
      "events_url": "https://api.github.com/users/danfrankj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/danfrankj/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-03-11T15:43:42Z",
    "updated_at": "2016-03-11T15:43:42Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jreback thinking about it some more, I think you're right. Probably best for this to just live in pyspark. Closing issue. Thanks!\n"
  }
]
