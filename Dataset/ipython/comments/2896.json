[
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/13278166",
    "html_url": "https://github.com/ipython/ipython/issues/2896#issuecomment-13278166",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/2896",
    "id": 13278166,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMjc4MTY2",
    "user": {
      "login": "minrk",
      "id": 151929,
      "node_id": "MDQ6VXNlcjE1MTkyOQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/151929?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/minrk",
      "html_url": "https://github.com/minrk",
      "followers_url": "https://api.github.com/users/minrk/followers",
      "following_url": "https://api.github.com/users/minrk/following{/other_user}",
      "gists_url": "https://api.github.com/users/minrk/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/minrk/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/minrk/subscriptions",
      "organizations_url": "https://api.github.com/users/minrk/orgs",
      "repos_url": "https://api.github.com/users/minrk/repos",
      "events_url": "https://api.github.com/users/minrk/events{/privacy}",
      "received_events_url": "https://api.github.com/users/minrk/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-08T06:00:01Z",
    "updated_at": "2013-02-08T06:00:01Z",
    "author_association": "MEMBER",
    "body": "how do you start the controller such that interrupting the notebook has any effect on the controller?\n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/13278331",
    "html_url": "https://github.com/ipython/ipython/issues/2896#issuecomment-13278331",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/2896",
    "id": 13278331,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMjc4MzMx",
    "user": {
      "login": "cioc",
      "id": 520839,
      "node_id": "MDQ6VXNlcjUyMDgzOQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/520839?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cioc",
      "html_url": "https://github.com/cioc",
      "followers_url": "https://api.github.com/users/cioc/followers",
      "following_url": "https://api.github.com/users/cioc/following{/other_user}",
      "gists_url": "https://api.github.com/users/cioc/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cioc/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cioc/subscriptions",
      "organizations_url": "https://api.github.com/users/cioc/orgs",
      "repos_url": "https://api.github.com/users/cioc/repos",
      "events_url": "https://api.github.com/users/cioc/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cioc/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-08T06:09:20Z",
    "updated_at": "2013-02-08T06:14:42Z",
    "author_association": "NONE",
    "body": "The controller is started with this command:\n\nipcontroller --ip=\\* --log-to-file=True\n\nThe notebook with this command:\n\nipython notebook --profile=nbserver\n\n(nbserver has no custom configuration)\n\nIs this the best resource for cluster configuration: http://ipython.org/ipython-doc/dev/parallel/parallel_process.html ?\n\nAre there other resources?  If not, i'm going to create one; i would really like to put together a way to configure and launch ipython clusters reliably, that are themselves reliable.  \n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/13278474",
    "html_url": "https://github.com/ipython/ipython/issues/2896#issuecomment-13278474",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/2896",
    "id": 13278474,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMjc4NDc0",
    "user": {
      "login": "minrk",
      "id": 151929,
      "node_id": "MDQ6VXNlcjE1MTkyOQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/151929?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/minrk",
      "html_url": "https://github.com/minrk",
      "followers_url": "https://api.github.com/users/minrk/followers",
      "following_url": "https://api.github.com/users/minrk/following{/other_user}",
      "gists_url": "https://api.github.com/users/minrk/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/minrk/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/minrk/subscriptions",
      "organizations_url": "https://api.github.com/users/minrk/orgs",
      "repos_url": "https://api.github.com/users/minrk/repos",
      "events_url": "https://api.github.com/users/minrk/events{/privacy}",
      "received_events_url": "https://api.github.com/users/minrk/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-08T06:17:53Z",
    "updated_at": "2013-02-08T06:17:53Z",
    "author_association": "MEMBER",
    "body": "in different shell sessions?  Different SSH sessions, screen, tmux, etc.?\n\n> Are there other resources? If not, i'm going to create one; i would really like to put together a way to configure and launch ipython clusters reliably, that are themselves reliable.\n\nIt would be great to have more docs.  I've run hundreds of engines doing thousands of tasks for days at a time on EC2 and local clusters, started in a fairly wide variety of ways. I cannot explain what you are experiencing.\n\nIf I read correctly, when you send 'interrupt kernel' in the notebook UI, the _controller_ dies?  Is this reliable?  What is the controller's log, and what is the output of the controller process when you do this?\n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/13278521",
    "html_url": "https://github.com/ipython/ipython/issues/2896#issuecomment-13278521",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/2896",
    "id": 13278521,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMjc4NTIx",
    "user": {
      "login": "cioc",
      "id": 520839,
      "node_id": "MDQ6VXNlcjUyMDgzOQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/520839?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cioc",
      "html_url": "https://github.com/cioc",
      "followers_url": "https://api.github.com/users/cioc/followers",
      "following_url": "https://api.github.com/users/cioc/following{/other_user}",
      "gists_url": "https://api.github.com/users/cioc/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cioc/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cioc/subscriptions",
      "organizations_url": "https://api.github.com/users/cioc/orgs",
      "repos_url": "https://api.github.com/users/cioc/repos",
      "events_url": "https://api.github.com/users/cioc/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cioc/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-08T06:20:53Z",
    "updated_at": "2013-02-08T06:20:53Z",
    "author_association": "NONE",
    "body": "Each is run in a dtach'd session.  \n\nI do not have the logs, as the instance were terminated.  I'll try to reproduce this tomorrow.\n\nWere you using starcluster to manage your ipython cluster for those large deployments?\n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/13278746",
    "html_url": "https://github.com/ipython/ipython/issues/2896#issuecomment-13278746",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/2896",
    "id": 13278746,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMjc4NzQ2",
    "user": {
      "login": "minrk",
      "id": 151929,
      "node_id": "MDQ6VXNlcjE1MTkyOQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/151929?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/minrk",
      "html_url": "https://github.com/minrk",
      "followers_url": "https://api.github.com/users/minrk/followers",
      "following_url": "https://api.github.com/users/minrk/following{/other_user}",
      "gists_url": "https://api.github.com/users/minrk/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/minrk/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/minrk/subscriptions",
      "organizations_url": "https://api.github.com/users/minrk/orgs",
      "repos_url": "https://api.github.com/users/minrk/repos",
      "events_url": "https://api.github.com/users/minrk/events{/privacy}",
      "received_events_url": "https://api.github.com/users/minrk/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-08T06:31:55Z",
    "updated_at": "2013-02-08T06:31:55Z",
    "author_association": "MEMBER",
    "body": "I've used starcluster the most, probably, but also a variety of combinations SSH sessions, IPCluster with SSH and SGE config, as well as MPI.\n\n> I do not have the logs, as the instance were terminated. I'll try to reproduce this tomorrow.\n\nNo, but you can either let it log to the terminal, or `tail -f` the log file while you are debugging.\nI _strongly_ recommend running ipcontroller in a simple shell session, logging to the terminal,\nwhen you have something to debug.  Any other approach is just unnecessary discarding of information.\n\nMake sure you can reproduce the issue _without_ using dtach.  Start with just a single SSH session, and run `ipcontroller --ip=*`, and let it log to the terminal.  Leave that open while you start up the notebook, and go through your repro steps.  If that doesn't cause a problem, I suspect it might be that dtach isn't properly detaching the process from signals.  For instance, after dtaching ipcontroller, does ^C in the shell cause an issue?\n\nIs it the first time you send a SIGINT to the kernel that this happens?  What is the kernel doing when you do this?  Can you post exact code that you are running that will reproduce the issue?\n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/13305513",
    "html_url": "https://github.com/ipython/ipython/issues/2896#issuecomment-13305513",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/2896",
    "id": 13305513,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMzA1NTEz",
    "user": {
      "login": "cioc",
      "id": 520839,
      "node_id": "MDQ6VXNlcjUyMDgzOQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/520839?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cioc",
      "html_url": "https://github.com/cioc",
      "followers_url": "https://api.github.com/users/cioc/followers",
      "following_url": "https://api.github.com/users/cioc/following{/other_user}",
      "gists_url": "https://api.github.com/users/cioc/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cioc/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cioc/subscriptions",
      "organizations_url": "https://api.github.com/users/cioc/orgs",
      "repos_url": "https://api.github.com/users/cioc/repos",
      "events_url": "https://api.github.com/users/cioc/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cioc/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-08T18:58:28Z",
    "updated_at": "2013-02-08T18:59:40Z",
    "author_association": "NONE",
    "body": "I was able to reproduce the problem kind of.  \n\nI was tailing the controller.  (Everything is still running dtach'd because i wanted to see if i could reproduce things exactly.  \n\nAfter first interrupting the kernel, every time i tell ipython to run a cell in the notebook it claims that the kernel is busy.  It remains busy for a very long time and then crashes.  From the controller log:\n\n2013-02-08 18:49:19.763 [IPControllerApp] client::client '8bf6e0e9-e4c5-4127-83e9-68d305308af7' requested 'connection_request'\n2013-02-08 18:49:19.764 [IPControllerApp] client::client ['8bf6e0e9-e4c5-4127-83e9-68d305308af7'] connected\n2013-02-08 18:50:09.757 [IPControllerApp] client::client '3d9cd9b2-b52f-45da-9655-634d4f9eee62' requested 'connection_request'\n2013-02-08 18:50:09.758 [IPControllerApp] client::client ['3d9cd9b2-b52f-45da-9655-634d4f9eee62'] connected\n2013-02-08 18:51:11.891 [IPControllerApp] client::client '874ecab8-09e6-4534-8468-ec8489fdaf53' requested 'connection_request'\n2013-02-08 18:51:11.892 [IPControllerApp] client::client ['874ecab8-09e6-4534-8468-ec8489fdaf53'] connected\n\nEach invocation of run after an interrupt added a connection request and connection line but no program actually runs. \n\nAfter a long while, when the kernel ceases to be busy, this is the result:\n\n``` python\nAttributeError                            Traceback (most recent call last)\n<ipython-input-14-2127427c0a8f> in <module>()\n     19 with dview.sync_imports():\n     20     import leargist\n---> 21     import scipy\n     22 \n     23 #calculate our gists\n\n/usr/lib/python2.7/contextlib.pyc in __exit__(self, type, value, traceback)\n     22         if type is None:\n     23             try:\n---> 24                 self.gen.next()\n     25             except StopIteration:\n     26                 return\n\n/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/view.pyc in sync_imports(self, local, quiet)\n    494         for r in results:\n    495             # raise possible remote ImportErrors here\n--> 496             r.get()\n    497 \n    498 \n\n/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/asyncresult.pyc in get(self, timeout)\n    116         by get() inside a `RemoteError`.\n    117         \"\"\"\n--> 118         if not self.ready():\n    119             self.wait(timeout)\n    120 \n\n/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/asyncresult.pyc in ready(self)\n    130         \"\"\"Return whether the call has completed.\"\"\"\n    131         if not self._ready:\n--> 132             self.wait(0)\n    133         return self._ready\n    134 \n\n/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/asyncresult.pyc in wait(self, timeout)\n    140         if self._ready:\n    141             return\n--> 142         self._ready = self._client.wait(self.msg_ids, timeout)\n    143         if self._ready:\n    144             try:\n\n/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/client.pyc in wait(self, jobs, timeout)\n   1056         if not theids.intersection(self.outstanding):\n   1057             return True\n-> 1058         self.spin()\n   1059         while theids.intersection(self.outstanding):\n   1060             if timeout >= 0 and ( time.time()-tic ) > timeout:\n\n/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/client.pyc in spin(self)\n   1011             self._flush_iopub(self._iopub_socket)\n   1012         if self._mux_socket:\n-> 1013             self._flush_results(self._mux_socket)\n   1014         if self._task_socket:\n   1015             self._flush_results(self._task_socket)\n\n/usr/local/lib/python2.7/dist-packages/IPython/parallel/client/client.pyc in _flush_results(self, sock)\n    819             handler = self._queue_handlers.get(msg_type, None)\n    820             if handler is None:\n--> 821                 raise Exception(\"Unhandled message type: %s\"%msg.msg_type)\n    822             else:\n    823                 handler(msg)\n```\n\nAttributeError: 'dict' object has no attribute 'msg_type'\n\nThis occurs in this block of code:\n\nwith dview.sync_imports():\n    import leargist\n    import scipy\n\nI will not try to reproduce this without the dtach.  \n\nThanks for your help. \n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/13308102",
    "html_url": "https://github.com/ipython/ipython/issues/2896#issuecomment-13308102",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/2896",
    "id": 13308102,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMzA4MTAy",
    "user": {
      "login": "cioc",
      "id": 520839,
      "node_id": "MDQ6VXNlcjUyMDgzOQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/520839?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cioc",
      "html_url": "https://github.com/cioc",
      "followers_url": "https://api.github.com/users/cioc/followers",
      "following_url": "https://api.github.com/users/cioc/following{/other_user}",
      "gists_url": "https://api.github.com/users/cioc/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cioc/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cioc/subscriptions",
      "organizations_url": "https://api.github.com/users/cioc/orgs",
      "repos_url": "https://api.github.com/users/cioc/repos",
      "events_url": "https://api.github.com/users/cioc/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cioc/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-08T19:53:38Z",
    "updated_at": "2013-02-08T19:53:38Z",
    "author_association": "NONE",
    "body": "I think the kernel crashes when i am distributing relatively large data structures out to the cluster:\n\n``` python\n#find nearest neighbors and return distances of closest 500\ndview['normalized_gists'] = normalized_gists\n```\n\nnormalized_gists is an array of about 4000 elements whose elements are numpy arrays of 960 float64s\n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/13326833",
    "html_url": "https://github.com/ipython/ipython/issues/2896#issuecomment-13326833",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/2896",
    "id": 13326833,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMzI2ODMz",
    "user": {
      "login": "minrk",
      "id": 151929,
      "node_id": "MDQ6VXNlcjE1MTkyOQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/151929?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/minrk",
      "html_url": "https://github.com/minrk",
      "followers_url": "https://api.github.com/users/minrk/followers",
      "following_url": "https://api.github.com/users/minrk/following{/other_user}",
      "gists_url": "https://api.github.com/users/minrk/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/minrk/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/minrk/subscriptions",
      "organizations_url": "https://api.github.com/users/minrk/orgs",
      "repos_url": "https://api.github.com/users/minrk/repos",
      "events_url": "https://api.github.com/users/minrk/events{/privacy}",
      "received_events_url": "https://api.github.com/users/minrk/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-09T05:44:11Z",
    "updated_at": "2013-02-09T05:44:11Z",
    "author_association": "MEMBER",
    "body": "> After first interrupting the kernel, every time i tell ipython to run a cell in the notebook it claims that the kernel is busy.\n\nDoes the running call give a KeyboardInterrupt when you do this? If not, the interrupt was unsuccessful, so kernel being busy and unresponsive would actually be expected.  What is the code you are trying to interrupt?\n\n> Each invocation of run after an interrupt added a connection request and connection line but no program actually runs.\n\nI'm not sure what you mean by this. What code is actually executed?\n\n> AttributeError: 'dict' object has no attribute 'msg_type'\n\nThis is the second report of this bug (#2814) (the typo is fixed in master, but the bug that causes the unhandled message is probably the same).  I haven't been able to reproduce it.  I honestly have no idea how this could happen - it means that a message bound for a kernel somehow ended up at the Client instead.\n\n> normalized_gists is an array of about 4000 elements whose elements are numpy arrays of 960 float64s\n\nWhen you say `array`, do you mean a _list_ or a numpy array?  Because the performance characteristics of the two are _wildly_ different.  Serialization of large containers is one of the things dramatically improved in 0.14.\n\n> I will not try to reproduce this without the dtach.\n\nThat's interesting.  Why not?\n\nSome of the things you have encountered are known bugs or issues fixed in master.  Are you in a situation where you can try out master, and see if the situation is improved?\n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/13333050",
    "html_url": "https://github.com/ipython/ipython/issues/2896#issuecomment-13333050",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/2896",
    "id": 13333050,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMzMzMDUw",
    "user": {
      "login": "cioc",
      "id": 520839,
      "node_id": "MDQ6VXNlcjUyMDgzOQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/520839?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cioc",
      "html_url": "https://github.com/cioc",
      "followers_url": "https://api.github.com/users/cioc/followers",
      "following_url": "https://api.github.com/users/cioc/following{/other_user}",
      "gists_url": "https://api.github.com/users/cioc/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cioc/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cioc/subscriptions",
      "organizations_url": "https://api.github.com/users/cioc/orgs",
      "repos_url": "https://api.github.com/users/cioc/repos",
      "events_url": "https://api.github.com/users/cioc/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cioc/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-09T15:57:51Z",
    "updated_at": "2013-02-09T15:57:51Z",
    "author_association": "NONE",
    "body": "> I will not try to reproduce this without the dtach.\n\nGosh.  Sorry for the type.  I meant, I will NOW try to reproduce this without the dtach and let you know how it goes.\n\n> normalized_gists is an array of about 4000 elements whose elements are numpy arrays of 960 float64s\n\nBy array i mean numpy array not a list.  However, i tried the list too and the same issue occurred.  \n\nI have been using the master branch of ipython for all of these tests.  \n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/13335561",
    "html_url": "https://github.com/ipython/ipython/issues/2896#issuecomment-13335561",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/2896",
    "id": 13335561,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMzM1NTYx",
    "user": {
      "login": "minrk",
      "id": 151929,
      "node_id": "MDQ6VXNlcjE1MTkyOQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/151929?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/minrk",
      "html_url": "https://github.com/minrk",
      "followers_url": "https://api.github.com/users/minrk/followers",
      "following_url": "https://api.github.com/users/minrk/following{/other_user}",
      "gists_url": "https://api.github.com/users/minrk/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/minrk/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/minrk/subscriptions",
      "organizations_url": "https://api.github.com/users/minrk/orgs",
      "repos_url": "https://api.github.com/users/minrk/repos",
      "events_url": "https://api.github.com/users/minrk/events{/privacy}",
      "received_events_url": "https://api.github.com/users/minrk/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-09T18:15:20Z",
    "updated_at": "2013-02-09T18:15:20Z",
    "author_association": "MEMBER",
    "body": "> I meant, I will NOW try to reproduce this without the dtach and let you know how it goes.\n\nGreat, thanks.  That makes a lot more sense.\n\n> By array i mean numpy array not a list.\n\nOkay, so it's a simple `(4000, 960)` 2D numpy array (30 MB)?  You say you are running 9 engines, each on its own micro instance, while the controller and notebook server are together on another micro instance?  I suspect you may be running into memory issues. That's the only explanation I can think of for the machine itself becoming unresponsive.  Can you perhaps try a small or medium instance for the controller / nbserver machine?\nYou might add to your testing a terminal window running htop, so you can watch usage while this is happening.\n\nPushing a 30MB array to N engines can result in up to N \\* 30 MB being resident in the Scheduler, and if you are really unlucky and garbage collection and/or zmq is being slow, up to `(2 * N + 1) * 30 MB = 570 MB (N=9)` active across the Hub, Scheduler, and Client, all of which are on the same instance, if I read correctly.\n\n> I have been using the master branch of ipython for all of these tests.\n\nI don't think you have, or at least not fully up to date.  The line with the error you mentioned is not in master.  What do you get from `print IPython.sys_info()`?\n\nCan you further describe (or, better yet, post) the code you are trying to interrupt?  For instance, why are you interrupting it?  If you are trying to interrupt it because it has become unresponsive, the issue has probably already happened, and there's nothing related to the interrupt actually causing problems.\n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/13342306",
    "html_url": "https://github.com/ipython/ipython/issues/2896#issuecomment-13342306",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/2896",
    "id": 13342306,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMzQyMzA2",
    "user": {
      "login": "cioc",
      "id": 520839,
      "node_id": "MDQ6VXNlcjUyMDgzOQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/520839?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cioc",
      "html_url": "https://github.com/cioc",
      "followers_url": "https://api.github.com/users/cioc/followers",
      "following_url": "https://api.github.com/users/cioc/following{/other_user}",
      "gists_url": "https://api.github.com/users/cioc/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cioc/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cioc/subscriptions",
      "organizations_url": "https://api.github.com/users/cioc/orgs",
      "repos_url": "https://api.github.com/users/cioc/repos",
      "events_url": "https://api.github.com/users/cioc/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cioc/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-10T01:02:42Z",
    "updated_at": "2013-02-10T01:02:42Z",
    "author_association": "NONE",
    "body": "I think you were right about the memory issues.  While i didn't crash the system completly in subsequent times, the calculation does crash and unused memory gets very close to zero at this point.  Furthermore, i tried systems with larger memories (medium instances ~3.7 GB) and the problem seems to be gone.  \n\nThe output of sys_info():\n\n``` python\n{'commit_hash': '177894e',\n 'commit_source': 'installation',\n 'default_encoding': 'UTF-8',\n 'ipython_path': '/usr/local/lib/python2.7/dist-packages/IPython',\n 'ipython_version': '0.13.1',\n 'os_name': 'posix',\n 'platform': 'Linux-3.2.0-31-virtual-x86_64-with-Ubuntu-12.04-precise',\n 'sys_executable': '/usr/bin/python',\n 'sys_platform': 'linux2',\n 'sys_version': '2.7.3 (default, Aug  1 2012, 05:14:39) \\n[GCC 4.6.3]'}\n```\n\nI believe that you are again correct about my ipython version.  I incorrectly thought that i was using master for ipython.  That was another package i was thinking of.  \n\nIs this the best resource for learning about the scheduler: http://ipython.org/ipython-doc/dev/parallel/parallel_task.html#schedulers  Would the best way be just to read the source?\n\n> Pushing a 30MB array to N engines can result in up to N \\* 30 MB being resident in the Scheduler, and if you are really unlucky and garbage collection and/or zmq is being slow, up to (2 \\* N + 1) \\* 30 MB = 570 MB (N=9) active across the Hub, Scheduler, and Client, all of which are on the same instance, if I read correctly.\n\nI am confused about memory use in the scheduler.  Why would the array exist N times on the controller if it is just being copied to the engines?  Couldn't this be achieved by one copy?  This is why i am interested in the inner workings of the scheduler.  I think that these N copies would be a large problem as the size of the data structure that is being distributed to the engine goes.  \n\nThank you very much for your help!\n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/13342715",
    "html_url": "https://github.com/ipython/ipython/issues/2896#issuecomment-13342715",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/2896",
    "id": 13342715,
    "node_id": "MDEyOklzc3VlQ29tbWVudDEzMzQyNzE1",
    "user": {
      "login": "minrk",
      "id": 151929,
      "node_id": "MDQ6VXNlcjE1MTkyOQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/151929?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/minrk",
      "html_url": "https://github.com/minrk",
      "followers_url": "https://api.github.com/users/minrk/followers",
      "following_url": "https://api.github.com/users/minrk/following{/other_user}",
      "gists_url": "https://api.github.com/users/minrk/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/minrk/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/minrk/subscriptions",
      "organizations_url": "https://api.github.com/users/minrk/orgs",
      "repos_url": "https://api.github.com/users/minrk/repos",
      "events_url": "https://api.github.com/users/minrk/events{/privacy}",
      "received_events_url": "https://api.github.com/users/minrk/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2013-02-10T01:42:01Z",
    "updated_at": "2013-02-10T01:42:01Z",
    "author_association": "MEMBER",
    "body": "> Is this the best resource for learning about the scheduler: http://ipython.org/ipython-doc/dev/parallel/parallel_task.html#schedulers Would the best way be just to read the source?\n\nActually, no.  That doc is for the load-balanced scheduler, and irrelevant here.  The most relevant doc is probably [parallel connections](http://ipython.org/ipython-doc/rel-0.13.1/development/parallel_connections.html#parallel-connections).\n\nThe Multiplexer Scheduler you are using here is just a single call to a zmq device (a GIL-free C function provided by pyzmq), forwarding messages between Engines and Clients to the Hub.  The reason it becomes so large is that the splitting happens at the _Client_ level - the _Client_ sends to each engine `push(data)`, so the array passes N times through the scheduler.  The Client actually has no awareness of the scheduler at all - it thinks is is directly connected to each engine individually.\n\n```\nrc[:4]['a'] = data\n```\n\nis perfectly identical to\n\n```\nfor i in range(4):\n    rc[i]['a'] = data\n```\n\nin terms of messages sent.\n\nThere are no copies at any point within a given process, but this means that we have one array in the Client, but the same data passing N times through the scheduler.  The scheduler then echos every message to the Hub, so the same N are sent over to the Hub for database storage (or discard, if no db is active). Over time, the memory footprint of all this is zero, as it leaves the scheduler, and the Hub pushes it to the db or drops it.  However, if things are going exceptionally slowly, all copies may be resident in the scheduler's memory while all copies are also resident in the Hub's memory, plus the initial copy in the Client (2 \\* N + 1).  It's actually quite difficult to reach this upper limit unless performance is exceedingly poor, but EC2 micro instances are barely functional.\n\nBroadcast of data with `dview.push` is probably the single worst action in IPython.parallel, largely because there is no native notion of broadcast.  There are other, vastly improved implementations of broadcast, such as with a [spanning b-tree](https://github.com/ipython/ipython/tree/master/examples/parallel/interengine), where network load is minimized for any given point.\n\nAs for a recommendation for course of action, I would say there are a few basic principals to keep in mind:\n1. minimize data movement by generating large data structures on Engines, rather than broadcasting them from the Client.  Computation is generally much cheaper than communication, so duplicate computations to load structures rapidly becomes preferable to broadcast.\n2. use `scatter` when possible, because it partitions data, rather than duplicating the same data across all engines.\n3. the Controller is never going to be a tiny, light service, it needs appreciable resources dedicated to it (mainly memory).  This is especially true if you have many and/or large tasks moving through it.\n4. If you really need broadcast, set up inter-engine communication (via MPI or zmq), and use the Client only for _coordination_ of a genuine broadcast implementation, rather than using the fully serialized broadcast provided by IPython.parallel.\n"
  }
]
