[
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/3474690",
    "html_url": "https://github.com/ipython/ipython/issues/1260#issuecomment-3474690",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/1260",
    "id": 3474690,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzQ2OTA=",
    "user": {
      "login": "fperez",
      "id": 57394,
      "node_id": "MDQ6VXNlcjU3Mzk0",
      "avatar_url": "https://avatars1.githubusercontent.com/u/57394?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/fperez",
      "html_url": "https://github.com/fperez",
      "followers_url": "https://api.github.com/users/fperez/followers",
      "following_url": "https://api.github.com/users/fperez/following{/other_user}",
      "gists_url": "https://api.github.com/users/fperez/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/fperez/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/fperez/subscriptions",
      "organizations_url": "https://api.github.com/users/fperez/orgs",
      "repos_url": "https://api.github.com/users/fperez/repos",
      "events_url": "https://api.github.com/users/fperez/events{/privacy}",
      "received_events_url": "https://api.github.com/users/fperez/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-01-13T03:00:42Z",
    "updated_at": "2012-01-13T03:00:42Z",
    "author_association": "MEMBER",
    "body": "Thanks for the careful analysis, Min.  Some thoughts:\n- Your solution #2 sounds like the way to go for now.  I'm not sure I understand precisely what allowing for 2 io_threads in that Context object would buy us, could you clarify for me (keeping in mind my ignorance of libzmq minutiae)?\n- Your second optimization is interesting, but we should certainly benchmark things out.  It sounds like a tradeoff of latency vs throughput from where I stand, is that correct?  But in any case, I'd rather err towards the non-copying side, since I imagine that using non-copying for small messages will at most add small amounts of delay to things that are quick to begin with, where as the opposite (using copying sends for potentially large messages) can lead to catastrophic loss of performance or even running out of memory.\n- I'll leave the decision on the first optimization up to you, since it's a pyzmq improvement.  But I hope if you do it, that doesn't mean we bump our minimum pyzmq requirement for IPython.  I think for a while we should try to keep the dependency chain easy for users, as we gain adoption of the notebook and the parallel zmq-based code...\n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/3474889",
    "html_url": "https://github.com/ipython/ipython/issues/1260#issuecomment-3474889",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/1260",
    "id": 3474889,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzQ4ODk=",
    "user": {
      "login": "minrk",
      "id": 151929,
      "node_id": "MDQ6VXNlcjE1MTkyOQ==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/151929?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/minrk",
      "html_url": "https://github.com/minrk",
      "followers_url": "https://api.github.com/users/minrk/followers",
      "following_url": "https://api.github.com/users/minrk/following{/other_user}",
      "gists_url": "https://api.github.com/users/minrk/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/minrk/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/minrk/subscriptions",
      "organizations_url": "https://api.github.com/users/minrk/orgs",
      "repos_url": "https://api.github.com/users/minrk/repos",
      "events_url": "https://api.github.com/users/minrk/events{/privacy}",
      "received_events_url": "https://api.github.com/users/minrk/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-01-13T03:24:53Z",
    "updated_at": "2012-01-13T03:24:53Z",
    "author_association": "MEMBER",
    "body": "> - Your solution #2 sounds like the way to go for now. I'm not sure I understand precisely what allowing for 2 io_threads in that Context object would buy us, could you clarify for me (keeping in mind my ignorance of libzmq minutiae)?\n\nlibzmq can be multithreaded _itself_.  The io_threads are simple worker threads for processing zmq events.  Since zmq events are typically so lightweight, the load has to be pretty enormous for more than one to make any sense. By default, this is one, so if there is an action that takes a bit (e.g. asking for the GIL), all other zmq activity is blocked.  This is an issue unique to pyzmq noncopying sends (or other tools which take over memory management from libzmq).  If you have more io_threads, then activities can continue even if one is being slow.  This doesn't solve the problem _in general_, because it's possible that a bubble would appear in each pipe, but it does diminish the impact of a single bubble.\n\n> - Your second optimization is interesting, but we should certainly benchmark things out. It sounds like a tradeoff of latency vs throughput from where I stand, is that correct?\n\nAlmost - instantiating tracking objects, and the involvement of the GIL in the non-copying case make it less clear-cut which is faster for small messages, rather than a simple latency vs throughput tension. The only truly certain comparison is memory footprint.\n\n> But in any case, I'd rather err towards the non-copying side, since I imagine that using non-copying for small messages will at most add small amounts of delay to things that are quick to begin with, where as the opposite (using copying sends for potentially large messages) can lead to catastrophic loss of performance or even running out of memory.\n\nIndeed, I would certainly put a cutoff, so that it's only small messages that are copied.  It's possible the threshold for this in IPython is as high as 1kB or more, I really don't know.  In libzmq itself, which is much more lightweight, they have the notion of a VSM (very small message), where non-copying requests are simply ignored.  This threshold is something like 32B.  But pyzmq/Python perform quite a few more actions per message, so a simple memcopy may be faster than invocation of the refcount/tracking machinery.  If the cost is small, then the extra logic may not be worth it, in any case.\n\n> - I'll leave the decision on the first optimization up to you, since it's a pyzmq improvement. But I hope if you do it, that doesn't mean we bump our minimum pyzmq requirement for IPython. I think for a while we should try to keep the dependency chain easy for users, as we gain adoption of the notebook and the parallel zmq-based code...\n\nSince it would be an optimization, it wouldn't change any APIs.  It would be a simple action to let the GIL-grabbing action fire in a thread that does not block libzmq.  The GIL would still be involved in exactly the same way, but the waiting would just happen in another thread.\n\nRight now, it's not likely to happen, because I don't have the time, energy, or interest to work on something like that.\n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/3475615",
    "html_url": "https://github.com/ipython/ipython/issues/1260#issuecomment-3475615",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/1260",
    "id": 3475615,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzU2MTU=",
    "user": {
      "login": "ellisonbg",
      "id": 27600,
      "node_id": "MDQ6VXNlcjI3NjAw",
      "avatar_url": "https://avatars3.githubusercontent.com/u/27600?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ellisonbg",
      "html_url": "https://github.com/ellisonbg",
      "followers_url": "https://api.github.com/users/ellisonbg/followers",
      "following_url": "https://api.github.com/users/ellisonbg/following{/other_user}",
      "gists_url": "https://api.github.com/users/ellisonbg/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ellisonbg/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ellisonbg/subscriptions",
      "organizations_url": "https://api.github.com/users/ellisonbg/orgs",
      "repos_url": "https://api.github.com/users/ellisonbg/repos",
      "events_url": "https://api.github.com/users/ellisonbg/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ellisonbg/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-01-13T05:07:44Z",
    "updated_at": "2012-01-13T05:07:44Z",
    "author_association": "MEMBER",
    "body": "I agree with @fperez and @minrk that option 2 is the best.  As far as the optimization for small messages, I would probably not worry about it for now.\n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/3475626",
    "html_url": "https://github.com/ipython/ipython/issues/1260#issuecomment-3475626",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/1260",
    "id": 3475626,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzU2MjY=",
    "user": {
      "login": "ellisonbg",
      "id": 27600,
      "node_id": "MDQ6VXNlcjI3NjAw",
      "avatar_url": "https://avatars3.githubusercontent.com/u/27600?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ellisonbg",
      "html_url": "https://github.com/ellisonbg",
      "followers_url": "https://api.github.com/users/ellisonbg/followers",
      "following_url": "https://api.github.com/users/ellisonbg/following{/other_user}",
      "gists_url": "https://api.github.com/users/ellisonbg/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ellisonbg/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ellisonbg/subscriptions",
      "organizations_url": "https://api.github.com/users/ellisonbg/orgs",
      "repos_url": "https://api.github.com/users/ellisonbg/repos",
      "events_url": "https://api.github.com/users/ellisonbg/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ellisonbg/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-01-13T05:08:19Z",
    "updated_at": "2012-01-13T05:08:19Z",
    "author_association": "MEMBER",
    "body": "Oh, and fantastic job tracking this down and summarizing it here.  It is also good to see cython.inline in this context.\n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/3527569",
    "html_url": "https://github.com/ipython/ipython/issues/1260#issuecomment-3527569",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/1260",
    "id": 3527569,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1Mjc1Njk=",
    "user": {
      "login": "bluescarni",
      "id": 623038,
      "node_id": "MDQ6VXNlcjYyMzAzOA==",
      "avatar_url": "https://avatars2.githubusercontent.com/u/623038?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bluescarni",
      "html_url": "https://github.com/bluescarni",
      "followers_url": "https://api.github.com/users/bluescarni/followers",
      "following_url": "https://api.github.com/users/bluescarni/following{/other_user}",
      "gists_url": "https://api.github.com/users/bluescarni/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bluescarni/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bluescarni/subscriptions",
      "organizations_url": "https://api.github.com/users/bluescarni/orgs",
      "repos_url": "https://api.github.com/users/bluescarni/repos",
      "events_url": "https://api.github.com/users/bluescarni/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bluescarni/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-01-17T13:15:01Z",
    "updated_at": "2012-01-17T13:15:01Z",
    "author_association": "NONE",
    "body": "Thanks for looking into the issue, I'm hopeful this fixes the problems I'm having with the notebook becoming unresponsive when doing long computations in a C++ library wrapped in Python.\n\nThe library uses Boost.Python for the wrapping, and I'm pretty sure this results in the GIL being grabbed every time the C++/Python boundary is crossed. For now I work around the problem by setting a high time_to_dead value.\n\nI'll try to update my Ipython installation to confirm that the problem is solved. Thanks again!\n"
  },
  {
    "url": "https://api.github.com/repos/ipython/ipython/issues/comments/3533453",
    "html_url": "https://github.com/ipython/ipython/issues/1260#issuecomment-3533453",
    "issue_url": "https://api.github.com/repos/ipython/ipython/issues/1260",
    "id": 3533453,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MzM0NTM=",
    "user": {
      "login": "fperez",
      "id": 57394,
      "node_id": "MDQ6VXNlcjU3Mzk0",
      "avatar_url": "https://avatars1.githubusercontent.com/u/57394?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/fperez",
      "html_url": "https://github.com/fperez",
      "followers_url": "https://api.github.com/users/fperez/followers",
      "following_url": "https://api.github.com/users/fperez/following{/other_user}",
      "gists_url": "https://api.github.com/users/fperez/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/fperez/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/fperez/subscriptions",
      "organizations_url": "https://api.github.com/users/fperez/orgs",
      "repos_url": "https://api.github.com/users/fperez/repos",
      "events_url": "https://api.github.com/users/fperez/events{/privacy}",
      "received_events_url": "https://api.github.com/users/fperez/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2012-01-17T18:56:09Z",
    "updated_at": "2012-01-17T18:56:09Z",
    "author_association": "MEMBER",
    "body": "@bluescarni: even though this issue is now closed, please do drop us a line with feedback on how it goes for you in practice after updating.  It's always useful to have that feedback in the long run, in case we ever see similar problems in the future.\n"
  }
]
