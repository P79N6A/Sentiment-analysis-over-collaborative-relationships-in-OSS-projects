[
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/433377894",
    "html_url": "https://github.com/grpc/grpc/issues/17001#issuecomment-433377894",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/17001",
    "id": 433377894,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzMzM3Nzg5NA==",
    "user": {
      "login": "ericgribkoff",
      "id": 5067076,
      "node_id": "MDQ6VXNlcjUwNjcwNzY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5067076?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ericgribkoff",
      "html_url": "https://github.com/ericgribkoff",
      "followers_url": "https://api.github.com/users/ericgribkoff/followers",
      "following_url": "https://api.github.com/users/ericgribkoff/following{/other_user}",
      "gists_url": "https://api.github.com/users/ericgribkoff/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ericgribkoff/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ericgribkoff/subscriptions",
      "organizations_url": "https://api.github.com/users/ericgribkoff/orgs",
      "repos_url": "https://api.github.com/users/ericgribkoff/repos",
      "events_url": "https://api.github.com/users/ericgribkoff/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ericgribkoff/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-26T11:31:32Z",
    "updated_at": "2018-10-26T11:31:32Z",
    "author_association": "CONTRIBUTOR",
    "body": "Thanks for the detailed bug report and analysis! Your diagnosis as to the cause seems reasonable, but I haven't been able to repro/verify this yet. Initial thoughts are below:\r\n\r\nIn spirit, I don't think the Cython `_close` method should need to release the GIL before invoking `grpc_shutdown()`, as this call should only decrement a counter and return until all application-owned gRPC objects have been destroyed (see docstring [here](https://github.com/grpc/grpc/blob/ef053d87ce2033c84c7bbb217eab74c19363e7b6/include/grpc/grpc.h#L78), and implementation [here](https://github.com/grpc/grpc/blob/ef053d87ce2033c84c7bbb217eab74c19363e7b6/src/core/lib/surface/init.cc#L160) - core tracks the # of calls to `grpc_init`, and `grpc_shutdown` only actually shuts things down when the count drops to 0). So if the credentials count as application-owned gRPC objects, they should have been destroyed before `grpc_shutdown()` actually performs non-trivial operations, and the gRPC C++ code will not call back into Python, and can't block on other code that requires the GIL. This is not what's happening today - as you are running into, the credentials objects still exist in Python when `grpc_shutdown()` is shutting down, and results in the callback into the Python credentials code.\r\n\r\nI would think that the credential objects returned by the call to `grpc_metadata_credentials_create_from_plugin()` should count as application owned gRPC objects, and hence should make use of the `grpc_init()`/`grpc_shutdown()` \"ref\" counting mechanism. However, looking at the Cython `credentials.pyx.pxi` file, while this *is* being done for server-side credentials (note the calls to `fork_handlers_and_grpc_init()` and `grpc_shutdown()` in, e.g., `ServerCredentials`), there are no such calls to `grpc_init()` for the `MetadataPluginCallCredentials` objects that end up used by the client code in your example. I'm not sure of the reasoning (if any) behind the different treatment for client and server credentials objects. I'm not intimately familiar with the gRPC core credential \"plugin\" mechanism that Python is using, so I'll need to dig into that code a little further to determine if I'm on the right track with a fix here.\r\n\r\nI'll be traveling/out-of-office through next week, but I'll try to find some time to investigate this a bit more and will update this issue once I have more info."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/444336704",
    "html_url": "https://github.com/grpc/grpc/issues/17001#issuecomment-444336704",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/17001",
    "id": 444336704,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NDMzNjcwNA==",
    "user": {
      "login": "ericgribkoff",
      "id": 5067076,
      "node_id": "MDQ6VXNlcjUwNjcwNzY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5067076?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ericgribkoff",
      "html_url": "https://github.com/ericgribkoff",
      "followers_url": "https://api.github.com/users/ericgribkoff/followers",
      "following_url": "https://api.github.com/users/ericgribkoff/following{/other_user}",
      "gists_url": "https://api.github.com/users/ericgribkoff/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ericgribkoff/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ericgribkoff/subscriptions",
      "organizations_url": "https://api.github.com/users/ericgribkoff/orgs",
      "repos_url": "https://api.github.com/users/ericgribkoff/repos",
      "events_url": "https://api.github.com/users/ericgribkoff/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ericgribkoff/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-05T02:36:06Z",
    "updated_at": "2018-12-05T02:36:06Z",
    "author_association": "CONTRIBUTOR",
    "body": "Sorry for the delay. This should now be fixed on master via #17396.\r\n\r\nI was unable to reproduce this failure directly, but it's clear from the backtraces you provided (extremely helpful, thank you for those!) and further auditing the codepaths involved that the \"final\" `grpc_shutdown()` call should not be made until the credentials object is fully destroyed. More details are in the PR description. The current `grpc_init()`/`grpc_shutdown()` logic in our Python layer is a bit more finicky than I would like; let me know if I have missed some case and these problems persist, and we will reopen the issue. Thanks again."
  }
]
