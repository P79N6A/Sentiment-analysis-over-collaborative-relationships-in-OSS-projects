[
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/238087407",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-238087407",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 238087407,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzODA4NzQwNw==",
    "user": {
      "login": "vjpai",
      "id": 8864912,
      "node_id": "MDQ6VXNlcjg4NjQ5MTI=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/8864912?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vjpai",
      "html_url": "https://github.com/vjpai",
      "followers_url": "https://api.github.com/users/vjpai/followers",
      "following_url": "https://api.github.com/users/vjpai/following{/other_user}",
      "gists_url": "https://api.github.com/users/vjpai/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vjpai/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vjpai/subscriptions",
      "organizations_url": "https://api.github.com/users/vjpai/orgs",
      "repos_url": "https://api.github.com/users/vjpai/repos",
      "events_url": "https://api.github.com/users/vjpai/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vjpai/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-07T15:02:34Z",
    "updated_at": "2016-08-08T17:32:57Z",
    "author_association": "MEMBER",
    "body": "This is expected behavior. You can only have 1 outstanding asynchronous\nwrite on the same side of the same stream without waiting for the completion queue\nnotification to indicate that it is OK to do another write to that side of the stream.\nThis is a documented part of the async API.\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/238126069",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-238126069",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 238126069,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzODEyNjA2OQ==",
    "user": {
      "login": "jinq0123",
      "id": 63832,
      "node_id": "MDQ6VXNlcjYzODMy",
      "avatar_url": "https://avatars2.githubusercontent.com/u/63832?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jinq0123",
      "html_url": "https://github.com/jinq0123",
      "followers_url": "https://api.github.com/users/jinq0123/followers",
      "following_url": "https://api.github.com/users/jinq0123/following{/other_user}",
      "gists_url": "https://api.github.com/users/jinq0123/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jinq0123/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jinq0123/subscriptions",
      "organizations_url": "https://api.github.com/users/jinq0123/orgs",
      "repos_url": "https://api.github.com/users/jinq0123/repos",
      "events_url": "https://api.github.com/users/jinq0123/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jinq0123/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-08T02:01:47Z",
    "updated_at": "2016-08-08T02:01:47Z",
    "author_association": "NONE",
    "body": "We need REAL async API.\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/238312312",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-238312312",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 238312312,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzODMxMjMxMg==",
    "user": {
      "login": "vjpai",
      "id": 8864912,
      "node_id": "MDQ6VXNlcjg4NjQ5MTI=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/8864912?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vjpai",
      "html_url": "https://github.com/vjpai",
      "followers_url": "https://api.github.com/users/vjpai/followers",
      "following_url": "https://api.github.com/users/vjpai/following{/other_user}",
      "gists_url": "https://api.github.com/users/vjpai/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vjpai/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vjpai/subscriptions",
      "organizations_url": "https://api.github.com/users/vjpai/orgs",
      "repos_url": "https://api.github.com/users/vjpai/repos",
      "events_url": "https://api.github.com/users/vjpai/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vjpai/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-08T17:35:03Z",
    "updated_at": "2016-08-08T17:35:03Z",
    "author_association": "MEMBER",
    "body": "The justification for allowing only 1 write before a completion notification is straightforward; async operations are intended to be concurrent, but concurrent operations on the same side of a stream are not allowed since each side of the stream has operations that must appear to be in-order. (Note that I've made a corresponding edit to my previous response) This is still concurrent with regard to the receiver side of the stream in the sense that multiple messages can be outstanding before the receiver operates on them, and in the sense that multiple streams (RPCs) can go on the same channel.\n\nThat said, we always welcome API feedback. I'd be glad to hear your detailed critique of the C++ async API as well as to understand what you would expect in a \"REAL\" (sic) API. Note that the C++ async API is already used by several projects, including TensorFlow.\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/238438357",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-238438357",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 238438357,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzODQzODM1Nw==",
    "user": {
      "login": "jinq0123",
      "id": 63832,
      "node_id": "MDQ6VXNlcjYzODMy",
      "avatar_url": "https://avatars2.githubusercontent.com/u/63832?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jinq0123",
      "html_url": "https://github.com/jinq0123",
      "followers_url": "https://api.github.com/users/jinq0123/followers",
      "following_url": "https://api.github.com/users/jinq0123/following{/other_user}",
      "gists_url": "https://api.github.com/users/jinq0123/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jinq0123/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jinq0123/subscriptions",
      "organizations_url": "https://api.github.com/users/jinq0123/orgs",
      "repos_url": "https://api.github.com/users/jinq0123/repos",
      "events_url": "https://api.github.com/users/jinq0123/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jinq0123/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-09T02:46:21Z",
    "updated_at": "2016-08-09T02:46:21Z",
    "author_association": "NONE",
    "body": "I will try to change grpc_call::active_batches from an array to a list to allow multi async Write() without blocking waiting for the completion notification. That will be easier to use.\n\n``` C\nstruct grpc_call {\n  batch_control active_batches[MAX_CONCURRENT_BATCHES];\n  ...\n};\n```\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/238451120",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-238451120",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 238451120,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzODQ1MTEyMA==",
    "user": {
      "login": "vjpai",
      "id": 8864912,
      "node_id": "MDQ6VXNlcjg4NjQ5MTI=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/8864912?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vjpai",
      "html_url": "https://github.com/vjpai",
      "followers_url": "https://api.github.com/users/vjpai/followers",
      "following_url": "https://api.github.com/users/vjpai/following{/other_user}",
      "gists_url": "https://api.github.com/users/vjpai/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vjpai/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vjpai/subscriptions",
      "organizations_url": "https://api.github.com/users/vjpai/orgs",
      "repos_url": "https://api.github.com/users/vjpai/repos",
      "events_url": "https://api.github.com/users/vjpai/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vjpai/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-09T04:35:34Z",
    "updated_at": "2016-08-09T04:35:34Z",
    "author_association": "MEMBER",
    "body": "For starters, let me request you not to start coding this up as a pull request without a strong justification. I will not accept such a change, nor will any other team member. Changing the grpc_call from an array to a list will add needless allocations (and thus locking) to an extremely critical path, will hinder performance, and will make the whole system prone to memory leaks. \n\nBefore you start coding this, please just answer my question: what would you expect to see in a \"REAL\" API? What do you expect to accomplish by allowing multiple writes on the same side of a stream without a notification in between? How do you intend to redefine the concurrency contract to handle such operations? Let me again emphasize that our reason for this restriction is to make sure that we can provide sane stream semantics in an asynchronous system that is typically used with high concurrency.\n\nWe're an open-source project, so you can fork your own version and make whatever changes you want to your version, but I can't envision a situation where such changes would be accepted upstream unless there is a real justification.\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/239146776",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-239146776",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 239146776,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTE0Njc3Ng==",
    "user": {
      "login": "jinq0123",
      "id": 63832,
      "node_id": "MDQ6VXNlcjYzODMy",
      "avatar_url": "https://avatars2.githubusercontent.com/u/63832?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jinq0123",
      "html_url": "https://github.com/jinq0123",
      "followers_url": "https://api.github.com/users/jinq0123/followers",
      "following_url": "https://api.github.com/users/jinq0123/following{/other_user}",
      "gists_url": "https://api.github.com/users/jinq0123/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jinq0123/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jinq0123/subscriptions",
      "organizations_url": "https://api.github.com/users/jinq0123/orgs",
      "repos_url": "https://api.github.com/users/jinq0123/repos",
      "events_url": "https://api.github.com/users/jinq0123/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jinq0123/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-11T12:28:41Z",
    "updated_at": "2016-08-11T12:28:41Z",
    "author_association": "NONE",
    "body": "> what would you expect to see in a \"REAL\" API?\n\nNo crash() in Write(). No wait before next Write().\n\n> What do you expect to accomplish by allowing multiple writes on the same side of a stream without a notification in between?\n\nWhy need notification? Users want to write messages without notification.\n\n> How do you intend to redefine the concurrency contract to handle such operations?\n\nKeep it the old way but no crash and no wait.\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/239311187",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-239311187",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 239311187,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTMxMTE4Nw==",
    "user": {
      "login": "nicolasnoble",
      "id": 7281574,
      "node_id": "MDQ6VXNlcjcyODE1NzQ=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/7281574?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/nicolasnoble",
      "html_url": "https://github.com/nicolasnoble",
      "followers_url": "https://api.github.com/users/nicolasnoble/followers",
      "following_url": "https://api.github.com/users/nicolasnoble/following{/other_user}",
      "gists_url": "https://api.github.com/users/nicolasnoble/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/nicolasnoble/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/nicolasnoble/subscriptions",
      "organizations_url": "https://api.github.com/users/nicolasnoble/orgs",
      "repos_url": "https://api.github.com/users/nicolasnoble/repos",
      "events_url": "https://api.github.com/users/nicolasnoble/events{/privacy}",
      "received_events_url": "https://api.github.com/users/nicolasnoble/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-11T22:20:22Z",
    "updated_at": "2016-08-11T22:20:22Z",
    "author_association": "CONTRIBUTOR",
    "body": "When we designed the C and C++ API, we chose to provide something that would allow the highest performance possible. This is that model, with these contracts. With that said, you may have a misunderstanding of the notification mechanism: it isn't to mean the call has been fully processed, received and responded - otherwise, it wouldn't be a true async API. The notification is to mean that the API is now ready to receive another write from your software. There is no \"wait\" time in the sense that the API will not block between the Write and the notification. This is merely the API ingesting your call and preparing itself to send it. All outstanding calls will still happen asynchronously, and concurrently.\n\nI'll say it again: the API will not block in any way between the Write and the notification. This is merely the core trying to process your call in the fastest possible way, and signaling you immediately after it's done evaluating how to do so that it's ready for another Write.\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/239344705",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-239344705",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 239344705,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTM0NDcwNQ==",
    "user": {
      "login": "jinq0123",
      "id": 63832,
      "node_id": "MDQ6VXNlcjYzODMy",
      "avatar_url": "https://avatars2.githubusercontent.com/u/63832?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jinq0123",
      "html_url": "https://github.com/jinq0123",
      "followers_url": "https://api.github.com/users/jinq0123/followers",
      "following_url": "https://api.github.com/users/jinq0123/following{/other_user}",
      "gists_url": "https://api.github.com/users/jinq0123/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jinq0123/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jinq0123/subscriptions",
      "organizations_url": "https://api.github.com/users/jinq0123/orgs",
      "repos_url": "https://api.github.com/users/jinq0123/repos",
      "events_url": "https://api.github.com/users/jinq0123/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jinq0123/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-12T02:05:34Z",
    "updated_at": "2016-08-12T02:05:34Z",
    "author_association": "NONE",
    "body": "Can I have a ClientAsyncWriter::WriteAndAsyncNext() without blocking?\n\nIn async_end2end_test.cc, there is a blocking wait for the completion notification:\n\n```\n        for (;;) {\n          auto r = cq->AsyncNext(...);\n          ...\n        }\n```\n\nIs there an async way to do it? How?\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/239366914",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-239366914",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 239366914,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTM2NjkxNA==",
    "user": {
      "login": "nicolasnoble",
      "id": 7281574,
      "node_id": "MDQ6VXNlcjcyODE1NzQ=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/7281574?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/nicolasnoble",
      "html_url": "https://github.com/nicolasnoble",
      "followers_url": "https://api.github.com/users/nicolasnoble/followers",
      "following_url": "https://api.github.com/users/nicolasnoble/following{/other_user}",
      "gists_url": "https://api.github.com/users/nicolasnoble/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/nicolasnoble/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/nicolasnoble/subscriptions",
      "organizations_url": "https://api.github.com/users/nicolasnoble/orgs",
      "repos_url": "https://api.github.com/users/nicolasnoble/repos",
      "events_url": "https://api.github.com/users/nicolasnoble/events{/privacy}",
      "received_events_url": "https://api.github.com/users/nicolasnoble/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-12T05:55:23Z",
    "updated_at": "2016-08-12T15:44:53Z",
    "author_association": "CONTRIBUTOR",
    "body": "There are several `AsyncNext` in that file, some are blocking, some aren't. The only reason some of these calls should be blocking is if there's a non-zero deadline set, and gRPC is waiting for work to process from the network or other threads.\n\nFor example, this call that has a deadline set to 0 won't be blocking:\n\n``` cpp\n      for (;;) {\n        auto r = cq->AsyncNext(&got_tag, &ok, gpr_time_0(GPR_CLOCK_REALTIME));\n        if (r == CompletionQueue::TIMEOUT) continue;\n        if (r == CompletionQueue::GOT_EVENT) break;\n```\n\nIn that case, `AsyncNext` will either have not done anything, because there's no work to do, and return `CompletionQueue::TIMEOUT`, or it will have processed some work, and return `CompletionQueue::GOT_EVENT` with the tag and ok result set to the appropriate event that happened.\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/239382758",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-239382758",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 239382758,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTM4Mjc1OA==",
    "user": {
      "login": "jinq0123",
      "id": 63832,
      "node_id": "MDQ6VXNlcjYzODMy",
      "avatar_url": "https://avatars2.githubusercontent.com/u/63832?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jinq0123",
      "html_url": "https://github.com/jinq0123",
      "followers_url": "https://api.github.com/users/jinq0123/followers",
      "following_url": "https://api.github.com/users/jinq0123/following{/other_user}",
      "gists_url": "https://api.github.com/users/jinq0123/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jinq0123/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jinq0123/subscriptions",
      "organizations_url": "https://api.github.com/users/jinq0123/orgs",
      "repos_url": "https://api.github.com/users/jinq0123/repos",
      "events_url": "https://api.github.com/users/jinq0123/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jinq0123/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-12T07:48:12Z",
    "updated_at": "2016-08-12T07:48:12Z",
    "author_association": "NONE",
    "body": "AsyncNext(..., gpr_time_0(...)) is non-blocking, but the for loop is busy waiting. It will wait until some other threads set the completion event.\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/239457818",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-239457818",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 239457818,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTQ1NzgxOA==",
    "user": {
      "login": "vjpai",
      "id": 8864912,
      "node_id": "MDQ6VXNlcjg4NjQ5MTI=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/8864912?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vjpai",
      "html_url": "https://github.com/vjpai",
      "followers_url": "https://api.github.com/users/vjpai/followers",
      "following_url": "https://api.github.com/users/vjpai/following{/other_user}",
      "gists_url": "https://api.github.com/users/vjpai/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vjpai/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vjpai/subscriptions",
      "organizations_url": "https://api.github.com/users/vjpai/orgs",
      "repos_url": "https://api.github.com/users/vjpai/repos",
      "events_url": "https://api.github.com/users/vjpai/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vjpai/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-12T14:15:27Z",
    "updated_at": "2016-08-12T14:15:27Z",
    "author_association": "MEMBER",
    "body": "I'm going to back up a level and say that we won't add a `ClientAsyncWriter::WriteAndAsyncNext()` method. Our approach to API is conservative - we won't add an API that combines two things that can already be easily done separately (separate call to `Write` and `Next` or `AsyncNext` in this case). If someone wants to do that, they can easily write those two lines of code in their own function. We are willing to add to the API for features that can't be provided in the existing API, but not otherwise.\n\nA single `WriteAndAsyncNext` limits options such as doing `Write` on other streams before checking any given one. In practice, code responds to `Next` or `AsyncNext` by using the tag to reference some structure that stores state associated with that stream, which is then allowed to continue to the next stage of its processing (such as doing another `Write`).\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/239482114",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-239482114",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 239482114,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTQ4MjExNA==",
    "user": {
      "login": "nicolasnoble",
      "id": 7281574,
      "node_id": "MDQ6VXNlcjcyODE1NzQ=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/7281574?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/nicolasnoble",
      "html_url": "https://github.com/nicolasnoble",
      "followers_url": "https://api.github.com/users/nicolasnoble/followers",
      "following_url": "https://api.github.com/users/nicolasnoble/following{/other_user}",
      "gists_url": "https://api.github.com/users/nicolasnoble/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/nicolasnoble/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/nicolasnoble/subscriptions",
      "organizations_url": "https://api.github.com/users/nicolasnoble/orgs",
      "repos_url": "https://api.github.com/users/nicolasnoble/repos",
      "events_url": "https://api.github.com/users/nicolasnoble/events{/privacy}",
      "received_events_url": "https://api.github.com/users/nicolasnoble/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-12T15:44:30Z",
    "updated_at": "2016-08-12T15:44:45Z",
    "author_association": "CONTRIBUTOR",
    "body": "I'll also add that an API that does exactly what you want would actually do the following under the hood:\n- Create a worker thread.\n- Accumulate all the Writes to do in a worker queue (which could lead to out of memory problems, but that's another topic).\n- Process the worker queue in the worker thread.\n\nThe bad part about that model is that it's doing extra work that some users may not desire (create a thread-safe list, and a worker thread).\n\nThe good part about that model is that it's currently very easy for someone to write on top of current API. \n\nImagine a networked video game for instance, running on a low-end device. It may be resource-constrained, and cannot afford threads. Its main loop would definitely be a busy loop anyway, and would look like something along these lines:\n\n``` cpp\nAbsoluteTime now = 0;\nTimeDifference frameDelta = 0;\nwhile (!UserWantsToQuit()) {\n  AbsoluteTime currentTime = GetCurrentTime();\n  frameDelta = currentTime - now;\n  now = currentTime;\n\n  // Prepare our next frame data\n  ProcessAI(now, frameDelta);\n  ProcessNetwork(now, frameDelta); // calls cq->AsyncNext(... gpr_time_0(GPR_CLOCK_REALTIME));\n  ProcessOtherPlayers(now, frameDelta);\n  ProcessAnimations(now, frameDelta);\n  ProcessUI(now, frameDelta);\n\n  // Draw and play our next frame\n  DrawFrame(now, frameDelta);\n  OutputSound(now, frameDelta);\n}\n```\n\nWe preferred to leave the option to the developer about which exact model they want, and that was our design choice.\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/239521881",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-239521881",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 239521881,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTUyMTg4MQ==",
    "user": {
      "login": "vjpai",
      "id": 8864912,
      "node_id": "MDQ6VXNlcjg4NjQ5MTI=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/8864912?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vjpai",
      "html_url": "https://github.com/vjpai",
      "followers_url": "https://api.github.com/users/vjpai/followers",
      "following_url": "https://api.github.com/users/vjpai/following{/other_user}",
      "gists_url": "https://api.github.com/users/vjpai/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vjpai/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vjpai/subscriptions",
      "organizations_url": "https://api.github.com/users/vjpai/orgs",
      "repos_url": "https://api.github.com/users/vjpai/repos",
      "events_url": "https://api.github.com/users/vjpai/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vjpai/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-12T18:19:54Z",
    "updated_at": "2016-08-12T18:19:54Z",
    "author_association": "MEMBER",
    "body": "I propose closing this issue as it seems to have reached a meaningful conclusion.\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/239530942",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-239530942",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 239530942,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTUzMDk0Mg==",
    "user": {
      "login": "pgrosu",
      "id": 6555937,
      "node_id": "MDQ6VXNlcjY1NTU5Mzc=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/6555937?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pgrosu",
      "html_url": "https://github.com/pgrosu",
      "followers_url": "https://api.github.com/users/pgrosu/followers",
      "following_url": "https://api.github.com/users/pgrosu/following{/other_user}",
      "gists_url": "https://api.github.com/users/pgrosu/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pgrosu/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pgrosu/subscriptions",
      "organizations_url": "https://api.github.com/users/pgrosu/orgs",
      "repos_url": "https://api.github.com/users/pgrosu/repos",
      "events_url": "https://api.github.com/users/pgrosu/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pgrosu/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-12T18:55:35Z",
    "updated_at": "2016-08-15T22:32:35Z",
    "author_association": "NONE",
    "body": "Hi Jin (@jinq0123),\n\nI share your passion for self-optimized all-in-one functions, but one thing to keep in mind is that gRPC can be just the initialization part at times - yet still a critical part, though it can be also be a large part too depending on the implementation requirements - of the transmission of data in the microservices space.  Sometimes it just initiates the connections and then passes it to another type of protocol for reading and writing data, such as [RDMA over Converged Ethernet](https://en.wikipedia.org/wiki/RDMA_over_Converged_Ethernet) to minimize overhead and CPU resources, while maximizing data throughput.  Then there are additional distributed data structures and algorithms one can utilize to optimize based on these latency numbers - by Jeff Dean and Peter Norvig - which I'm sure you are already aware of, and still apply today :)\n\n```\n Latency Comparison Numbers\n--------------------------\nL1 cache reference                           0.5 ns\nBranch mispredict                            5   ns\nL2 cache reference                           7   ns                      14x L1 cache\nMutex lock/unlock                           25   ns\nMain memory reference                      100   ns                      20x L2 cache, 200x L1 cache\nCompress 1K bytes with Zippy             3,000   ns        3 us\nSend 1K bytes over 1 Gbps network       10,000   ns       10 us\nRead 4K randomly from SSD*             150,000   ns      150 us          ~1GB/sec SSD\nRead 1 MB sequentially from memory     250,000   ns      250 us\nRound trip within same datacenter      500,000   ns      500 us\nRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory\nDisk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip\nRead 1 MB sequentially from disk    20,000,000   ns   20,000 us   20 ms  80x memory, 20X SSD\nSend packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 ms\n```\n\nSo there are many more protocols one can take advantage of, and there is a reason Google can deal with 1.3 Petabits/sec of throughput using their custom-written control stack - and if you're interested here is a link to their nice paper:\n\n[Jupiter Rising: A Decade of Clos Topologies and Centralized Control in Google’s Datacenter Network](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43837.pdf)\n\nThe Google gRPC Team is doing the community a fantastic service by open-sourcing this, but basically gRPC can be sometimes only the initialization of the data communication in the microservices space, or can be most of it too, and that depends on the implementation requirements. \n\nHope it helps,\nPaul\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/239847634",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-239847634",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 239847634,
    "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTg0NzYzNA==",
    "user": {
      "login": "ctiller",
      "id": 10120821,
      "node_id": "MDQ6VXNlcjEwMTIwODIx",
      "avatar_url": "https://avatars3.githubusercontent.com/u/10120821?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ctiller",
      "html_url": "https://github.com/ctiller",
      "followers_url": "https://api.github.com/users/ctiller/followers",
      "following_url": "https://api.github.com/users/ctiller/following{/other_user}",
      "gists_url": "https://api.github.com/users/ctiller/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ctiller/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ctiller/subscriptions",
      "organizations_url": "https://api.github.com/users/ctiller/orgs",
      "repos_url": "https://api.github.com/users/ctiller/repos",
      "events_url": "https://api.github.com/users/ctiller/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ctiller/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-15T16:12:54Z",
    "updated_at": "2016-08-15T16:12:54Z",
    "author_association": "MEMBER",
    "body": "Necro, but I've been out for a while.\n\nThe other big reason for the 'one outstanding' rule is to allow pushback\nfrom the network to the application. Without that, a slow consumer of\nwrites will cause an unlimited buffer build up somewhere in the gRPC stack,\nand we have strong evidence (in the form of scars from production outages)\nthat this will lead to OOM vectors in real applications.\n\nWe chose one outstanding message as any larger finite value suffers from\nthe same bugs, only more rarely (which means they're less likely to be\ncaught, and more likely to bite our users in actual production scenarios).\n\nOn Mon, Aug 8, 2016 at 10:58 AM Vijay Pai notifications@github.com wrote:\n\n> The justification for allowing only 1 write before a completion\n> notification is straightforward; async operations are intended to be\n> concurrent, but concurrent operations on the same side of a stream are not\n> allowed since each side of the stream has operations that must appear to be\n> in-order. (Note that I've made a corresponding edit to my previous\n> response) This is still concurrent with regard to the receiver side of the\n> stream in the sense that multiple messages can be outstanding before the\n> receiver operates on them, and in the sense that multiple streams (RPCs)\n> can go on the same channel.\n> \n> That said, we always welcome API feedback. I'd be glad to hear your\n> detailed critique of the C++ async API as well as to understand what you\n> would expect in a \"REAL\" (sic) API. Note that the C++ async API is already\n> used by several projects, including TensorFlow.\n> \n> —\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/grpc/grpc/issues/7659#issuecomment-238312312, or mute\n> the thread\n> https://github.com/notifications/unsubscribe-auth/AJpudb6or1L-qUxmwkPBtiiIa_RIYz4rks5qd2jXgaJpZM4Jeeu7\n> .\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/240018766",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-240018766",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 240018766,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI0MDAxODc2Ng==",
    "user": {
      "login": "jinq0123",
      "id": 63832,
      "node_id": "MDQ6VXNlcjYzODMy",
      "avatar_url": "https://avatars2.githubusercontent.com/u/63832?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jinq0123",
      "html_url": "https://github.com/jinq0123",
      "followers_url": "https://api.github.com/users/jinq0123/followers",
      "following_url": "https://api.github.com/users/jinq0123/following{/other_user}",
      "gists_url": "https://api.github.com/users/jinq0123/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jinq0123/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jinq0123/subscriptions",
      "organizations_url": "https://api.github.com/users/jinq0123/orgs",
      "repos_url": "https://api.github.com/users/jinq0123/repos",
      "events_url": "https://api.github.com/users/jinq0123/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jinq0123/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-16T06:56:42Z",
    "updated_at": "2016-08-16T06:56:42Z",
    "author_association": "NONE",
    "body": "Zeromq has a ZMQ_HWM option.\n\nFrom: http://api.zeromq.org/2-1:zmq-setsockopt\n\n> ZMQ_HWM: Set high water mark\n> \n> The ZMQ_HWM option shall set the high water mark for the specified socket. The high water mark is a hard limit on the maximum number of outstanding messages ØMQ shall queue in memory for any single peer that the specified socket is communicating with.\n> \n> The default ZMQ_HWM value of zero means \"no limit\".\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/240022292",
    "html_url": "https://github.com/grpc/grpc/issues/7659#issuecomment-240022292",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/7659",
    "id": 240022292,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI0MDAyMjI5Mg==",
    "user": {
      "login": "vjpai",
      "id": 8864912,
      "node_id": "MDQ6VXNlcjg4NjQ5MTI=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/8864912?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vjpai",
      "html_url": "https://github.com/vjpai",
      "followers_url": "https://api.github.com/users/vjpai/followers",
      "following_url": "https://api.github.com/users/vjpai/following{/other_user}",
      "gists_url": "https://api.github.com/users/vjpai/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vjpai/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vjpai/subscriptions",
      "organizations_url": "https://api.github.com/users/vjpai/orgs",
      "repos_url": "https://api.github.com/users/vjpai/repos",
      "events_url": "https://api.github.com/users/vjpai/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vjpai/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2016-08-16T07:16:52Z",
    "updated_at": "2016-08-16T07:16:52Z",
    "author_association": "MEMBER",
    "body": "That's a completely separate issue. As @nicolasnoble and I both mentioned in our responses, there may very well be more messages queued on a socket to the peer in the gRPC async API. In fact, there actually is no limit from gRPC's side, though the socket parameters of the underlying network would place a limit on it.\n"
  }
]
