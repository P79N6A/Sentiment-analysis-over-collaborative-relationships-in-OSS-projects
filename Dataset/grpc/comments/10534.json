[
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/292739690",
    "html_url": "https://github.com/grpc/grpc/issues/10534#issuecomment-292739690",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/10534",
    "id": 292739690,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI5MjczOTY5MA==",
    "user": {
      "login": "jtattermusch",
      "id": 9939684,
      "node_id": "MDQ6VXNlcjk5Mzk2ODQ=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/9939684?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jtattermusch",
      "html_url": "https://github.com/jtattermusch",
      "followers_url": "https://api.github.com/users/jtattermusch/followers",
      "following_url": "https://api.github.com/users/jtattermusch/following{/other_user}",
      "gists_url": "https://api.github.com/users/jtattermusch/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jtattermusch/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jtattermusch/subscriptions",
      "organizations_url": "https://api.github.com/users/jtattermusch/orgs",
      "repos_url": "https://api.github.com/users/jtattermusch/repos",
      "events_url": "https://api.github.com/users/jtattermusch/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jtattermusch/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-04-08T19:20:05Z",
    "updated_at": "2017-04-08T19:21:21Z",
    "author_association": "CONTRIBUTOR",
    "body": "My theory is that this is related to value of `Server.RequestCallTokensPerCompletionQueue`.\r\nTo prevent flooding of a server, new calls on the server side are accepted via a request, by default, there is 2000 request \"tokens\" per completion queue. A new token is only added when a call finishes. \r\nIn your case, with streaming calls, you seem to be running out of tokens. Try setting `Server.RequestCallTokensPerCompletionQueue` in additions to `MaxConcurrentStreams` \r\n\r\nThe relevant code is here:\r\nhttps://github.com/grpc/grpc/blob/f6a63a2f96f8be1053e9d0cbcc429bfd4738b567/src/csharp/Grpc.Core/Server.cs#L139\r\n\r\nPlease let me know if it helped."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/292771333",
    "html_url": "https://github.com/grpc/grpc/issues/10534#issuecomment-292771333",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/10534",
    "id": 292771333,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI5Mjc3MTMzMw==",
    "user": {
      "login": "neuecc",
      "id": 46207,
      "node_id": "MDQ6VXNlcjQ2MjA3",
      "avatar_url": "https://avatars0.githubusercontent.com/u/46207?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/neuecc",
      "html_url": "https://github.com/neuecc",
      "followers_url": "https://api.github.com/users/neuecc/followers",
      "following_url": "https://api.github.com/users/neuecc/following{/other_user}",
      "gists_url": "https://api.github.com/users/neuecc/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/neuecc/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/neuecc/subscriptions",
      "organizations_url": "https://api.github.com/users/neuecc/orgs",
      "repos_url": "https://api.github.com/users/neuecc/repos",
      "events_url": "https://api.github.com/users/neuecc/events{/privacy}",
      "received_events_url": "https://api.github.com/users/neuecc/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-04-09T08:09:36Z",
    "updated_at": "2017-04-09T08:09:36Z",
    "author_association": "NONE",
    "body": "Thank you, your answer is perfect.\r\nMy application works fine.\r\n\r\nI think how many RequestCallTokensPerCompletionQueue should be set.\r\n\r\nIf subscribe per connection is 20, \r\nconcurrentConnectionLimit = RequestCallTokensPerCompletionQueue * ThreadPoolSize / 20\r\nIf 8 Core CPU(threadpool size = 4) and target to 10000 concurrent user,\r\nRequestCallTokensPerCompletionQueue will be 50000.\r\n\r\nHowever, if set to 50000, the server did not start up.\r\nI'll do GrpcEnvironment.SetThreadPoolSize(16) and RequestCallTokensPerCompletionQueue = 20000.\r\nIs this decision OK?"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/292872160",
    "html_url": "https://github.com/grpc/grpc/issues/10534#issuecomment-292872160",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/10534",
    "id": 292872160,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI5Mjg3MjE2MA==",
    "user": {
      "login": "jtattermusch",
      "id": 9939684,
      "node_id": "MDQ6VXNlcjk5Mzk2ODQ=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/9939684?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jtattermusch",
      "html_url": "https://github.com/jtattermusch",
      "followers_url": "https://api.github.com/users/jtattermusch/followers",
      "following_url": "https://api.github.com/users/jtattermusch/following{/other_user}",
      "gists_url": "https://api.github.com/users/jtattermusch/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jtattermusch/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jtattermusch/subscriptions",
      "organizations_url": "https://api.github.com/users/jtattermusch/orgs",
      "repos_url": "https://api.github.com/users/jtattermusch/repos",
      "events_url": "https://api.github.com/users/jtattermusch/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jtattermusch/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-04-10T07:36:23Z",
    "updated_at": "2017-04-10T07:36:23Z",
    "author_association": "CONTRIBUTOR",
    "body": "It's really hard to guess what the right setting for your situations are without knowing a lot of context.\r\n\r\nBut a few notes:\r\n- It probably doesn't make sense to have more than 8 threads in the threadpool on 8core cpu (because they will be fighting over resources).\r\n- set RequestCallTokensPerCompletion queue to whatever you need (the only tradeoff is that each token will occupy some small amount of memory and will be initialized at startup and disposed at shutdown (that that's probably not even noticeable to you). "
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/325899778",
    "html_url": "https://github.com/grpc/grpc/issues/10534#issuecomment-325899778",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/10534",
    "id": 325899778,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNTg5OTc3OA==",
    "user": {
      "login": "amitwaisel",
      "id": 21170412,
      "node_id": "MDQ6VXNlcjIxMTcwNDEy",
      "avatar_url": "https://avatars2.githubusercontent.com/u/21170412?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/amitwaisel",
      "html_url": "https://github.com/amitwaisel",
      "followers_url": "https://api.github.com/users/amitwaisel/followers",
      "following_url": "https://api.github.com/users/amitwaisel/following{/other_user}",
      "gists_url": "https://api.github.com/users/amitwaisel/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/amitwaisel/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/amitwaisel/subscriptions",
      "organizations_url": "https://api.github.com/users/amitwaisel/orgs",
      "repos_url": "https://api.github.com/users/amitwaisel/repos",
      "events_url": "https://api.github.com/users/amitwaisel/events{/privacy}",
      "received_events_url": "https://api.github.com/users/amitwaisel/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-08-30T06:53:56Z",
    "updated_at": "2017-08-30T06:53:56Z",
    "author_association": "NONE",
    "body": "@jtattermusch I encountered the same problem of 8000-streams limitation (C# server), and luckily found this thread.\r\nFirst, it appears the `RequestCallTokensPerCompletionQueue` is limited to `32768 == 2^15` (`SHRT_MAX+1`). Any value above that results the server to hang and consume very high CPU. Is it by design or a bug? (after all, this value is defined as `int`)\r\nSecond, besides the limitation described above, is there any other limitation for the max-tokens value? Or is it just \"logical\" limitation which can be increased as much as we want?\r\nThird, it will be better, in my opinion, to document this value better, for others who might be interested in using it.\r\nThanks!"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/328894982",
    "html_url": "https://github.com/grpc/grpc/issues/10534#issuecomment-328894982",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/10534",
    "id": 328894982,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyODg5NDk4Mg==",
    "user": {
      "login": "jtattermusch",
      "id": 9939684,
      "node_id": "MDQ6VXNlcjk5Mzk2ODQ=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/9939684?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jtattermusch",
      "html_url": "https://github.com/jtattermusch",
      "followers_url": "https://api.github.com/users/jtattermusch/followers",
      "following_url": "https://api.github.com/users/jtattermusch/following{/other_user}",
      "gists_url": "https://api.github.com/users/jtattermusch/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jtattermusch/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jtattermusch/subscriptions",
      "organizations_url": "https://api.github.com/users/jtattermusch/orgs",
      "repos_url": "https://api.github.com/users/jtattermusch/repos",
      "events_url": "https://api.github.com/users/jtattermusch/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jtattermusch/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-09-12T15:47:11Z",
    "updated_at": "2017-09-12T15:47:11Z",
    "author_association": "CONTRIBUTOR",
    "body": "On Wed, Aug 30, 2017 at 8:54 AM, amitwaisel <notifications@github.com>\nwrote:\n\n> @jtattermusch <https://github.com/jtattermusch> I encountered the same\n> problem of 8000-streams limitation (C# server), and luckily found this\n> thread.\n> First, it appears the RequestCallTokensPerCompletionQueue is limited to 32768\n> == 2^15 (SHRT_MAX+1). Any value above that results the server to hang and\n> consume very high CPU. Is it by design or a bug? (after all, this value is\n> defined as int)\n>\nNo, the server shouldn't hang. Can you provide more info what the\nconditions is (it might be a bug)?   Also  getting 32000 tokens per\ncompletion queue while having more completion queues (you can have 1 per\nthread) can actually give you a large number of concurrent calls (256000\nfor 8 threads which seems pretty high) - how many do you need?\n\n\n> Second, besides the limitation described above, is there any other\n> limitation for the max-tokens value? Or is it just \"logical\" limitation\n> which can be increased as much as we want?\n>\nNo, it's just logical and each token also allocates some memory (~ several\nhundreds of bytes each).\n\n\n> Third, it will be better, in my opinion, to document this value better,\n> for others who might be interested in using it.\n> Thanks!\n>\n> â€”\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/grpc/grpc/issues/10534#issuecomment-325899778>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AJeq5G_ozx8PHlzw_E4BjmtxLSK7BMXnks5sdQcZgaJpZM4M3wuh>\n> .\n>\n\n\n\n-- \n\nJan\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/329062286",
    "html_url": "https://github.com/grpc/grpc/issues/10534#issuecomment-329062286",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/10534",
    "id": 329062286,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyOTA2MjI4Ng==",
    "user": {
      "login": "amitwaisel",
      "id": 21170412,
      "node_id": "MDQ6VXNlcjIxMTcwNDEy",
      "avatar_url": "https://avatars2.githubusercontent.com/u/21170412?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/amitwaisel",
      "html_url": "https://github.com/amitwaisel",
      "followers_url": "https://api.github.com/users/amitwaisel/followers",
      "following_url": "https://api.github.com/users/amitwaisel/following{/other_user}",
      "gists_url": "https://api.github.com/users/amitwaisel/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/amitwaisel/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/amitwaisel/subscriptions",
      "organizations_url": "https://api.github.com/users/amitwaisel/orgs",
      "repos_url": "https://api.github.com/users/amitwaisel/repos",
      "events_url": "https://api.github.com/users/amitwaisel/events{/privacy}",
      "received_events_url": "https://api.github.com/users/amitwaisel/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-09-13T05:22:37Z",
    "updated_at": "2017-09-13T05:22:37Z",
    "author_association": "NONE",
    "body": "In my C# code, I initialize two `Grpc.Core.Server` instances (on different TCP ports). For each of them, I am required to support (very) high number of opened gRPC streams (those are for pending requests, and there can be hundreds of thousands of those).\r\nTherefore, I do the following:\r\n```C#\r\n_server1.RequestCallTokensPerCompletionQueue = 32768;  // Total 32K * 4 (vProc/2) == 128K streams\r\n_server2.RequestCallTokensPerCompletionQueue = 32768;  // Total 32K * 4 (vProc/2) == 128K streams\r\n```\r\nJust to clarify, I do **not** change the thread pool size (`GrpcEnvironment.SetThreadPoolSize`) or the completion queue count (`SetCompletionQueueCount`).\r\n\r\nAs far as I can check, whenever I increment the count to 32769 (from 32768), the server does not response to all incoming requests (if to any at all), and one of the thread's CPU consumption is at 100% (for that thread). Meaning, on 8-cores machine, with 2 servers initialized, my process constantly has 25% CPU usage (2 threads, 12.5% overall CPU each).\r\nDo you think it is related to having two servers on the same gRPC environment?\r\nI hope this helps."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/329104202",
    "html_url": "https://github.com/grpc/grpc/issues/10534#issuecomment-329104202",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/10534",
    "id": 329104202,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyOTEwNDIwMg==",
    "user": {
      "login": "jtattermusch",
      "id": 9939684,
      "node_id": "MDQ6VXNlcjk5Mzk2ODQ=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/9939684?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jtattermusch",
      "html_url": "https://github.com/jtattermusch",
      "followers_url": "https://api.github.com/users/jtattermusch/followers",
      "following_url": "https://api.github.com/users/jtattermusch/following{/other_user}",
      "gists_url": "https://api.github.com/users/jtattermusch/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jtattermusch/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jtattermusch/subscriptions",
      "organizations_url": "https://api.github.com/users/jtattermusch/orgs",
      "repos_url": "https://api.github.com/users/jtattermusch/repos",
      "events_url": "https://api.github.com/users/jtattermusch/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jtattermusch/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-09-13T08:59:43Z",
    "updated_at": "2017-09-13T08:59:43Z",
    "author_association": "CONTRIBUTOR",
    "body": "@sreecha   is there a limit on number of request_call operations per cq in C core (right now it seems to be 32768)? If so, is that intended or is it a bug? "
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/329292892",
    "html_url": "https://github.com/grpc/grpc/issues/10534#issuecomment-329292892",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/10534",
    "id": 329292892,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyOTI5Mjg5Mg==",
    "user": {
      "login": "sreecha",
      "id": 2754995,
      "node_id": "MDQ6VXNlcjI3NTQ5OTU=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/2754995?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sreecha",
      "html_url": "https://github.com/sreecha",
      "followers_url": "https://api.github.com/users/sreecha/followers",
      "following_url": "https://api.github.com/users/sreecha/following{/other_user}",
      "gists_url": "https://api.github.com/users/sreecha/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sreecha/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sreecha/subscriptions",
      "organizations_url": "https://api.github.com/users/sreecha/orgs",
      "repos_url": "https://api.github.com/users/sreecha/repos",
      "events_url": "https://api.github.com/users/sreecha/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sreecha/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-09-13T20:50:17Z",
    "updated_at": "2017-09-13T20:51:04Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jtattermusch , this is by design (because we need storage to reserve those many available-request-ids per server-completion-queue and when the number of server-completion-queues is already high, this quickly adds up).\r\n\r\nI am not sure of the C# api... but generally this is what the server (user of grpc-c-core library) should be doing **for each RPC 'Foo'**:\r\n -   `grpc_server_request_call(..)` a few times (each call will reserve a 'token') [atleast once - lets say we called \"x\" times - so we have \"x\" tokens available]\r\n -   When grpc-c-core receives an incoming request, it uses up one of the 'token' it allocated from the step above. So the number of tokens is \"x-1\"\r\n - The higher layer should call `grpc_server_request_call(..)` again ASAP (good practice is to do this before it even started  as **it started (not completed) processing** a request for 'Foo') to give back the 'token'. So that we maintain \"x\" available tokens.\r\n\r\nSo the number \"x\" is really the max number of requests you are expecting to hit the server all at the same time..  and NOT the max number of active concurrent requests the server can handle at the same time (because that can be a higher number than x).."
  }
]
