[
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/410581558",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-410581558",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 410581558,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDU4MTU1OA==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-06T03:51:56Z",
    "updated_at": "2018-08-06T03:51:56Z",
    "author_association": "NONE",
    "body": "```\n****************************************************************\n\nlibgrpc.so\n\n     VM SIZE                                                                            FILE SIZE\n ++++++++++++++ GROWING                                                              ++++++++++++++\n  +0.1%    +935 [None]                                                               +5.07Ki  +0.1%\n      +0.1%    +919 [Unmapped]                                                           +5.05Ki  +0.1%\n       +25%     +16 client_channel_factory_vtable                                            +16   +25%\n   +16%    +264 src/core/lib/channel/channel_stack_builder.cc                           +264   +16%\n      [NEW]    +252 grpc_channel_stack_builder_get_subchannel_call_size                     +252  [NEW]\n      +6.9%     +12 [Unmapped]                                                               +12  +6.9%\n  +1.4%     +80 src/core/lib/surface/channel.cc                                          +80  +1.4%\n      +6.5%     +80 grpc_channel_create_with_builder                                         +80  +6.5%\n  +2.3%     +21 src/core/ext/transport/chttp2/client/insecure/channel_create.cc          +21  +2.3%\n      [NEW]     +21 _GLOBAL__sub_I_channel_create.cc                                         +21  [NEW]\n  +1.0%     +21 src/core/ext/transport/chttp2/client/secure/secure_channel_create.cc     +21  +1.0%\n      [NEW]     +21 _GLOBAL__sub_I_secure_channel_create.cc                                  +21  [NEW]\n  +7.8%     +16 src/core/ext/filters/client_channel/client_channel_factory.cc            +16  +7.8%\n       +12%      +8 [Unmapped]                                                                +8   +12%\n      [NEW]      +7 grpc_client_channel_factory_get_stream_size                               +7  [NEW]\n       +20%      +1 grpc_client_channel_factory_ref                                           +1   +20%\n  +0.0%      +7 src/core/ext/transport/chttp2/transport/chttp2_transport.cc               +7  +0.0%\n      [NEW]      +6 grpc_chttp2_get_stream_size                                               +6  [NEW]\n      +0.1%      +1 [Unmapped]                                                                +1  +0.1%\n\n  +0.1% +1.31Ki TOTAL                                                                +5.47Ki  +0.1%\n\n\n****************************************************************\n\nlibgrpc++.so\n\n     VM SIZE        FILE SIZE\n ++++++++++++++  ++++++++++++++\n\n  [ = ]       0        0  [ = ]\n\n\n\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/410581933",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-410581933",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 410581933,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDU4MTkzMw==",
    "user": {
      "login": "AspirinSJL",
      "id": 3314176,
      "node_id": "MDQ6VXNlcjMzMTQxNzY=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/3314176?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AspirinSJL",
      "html_url": "https://github.com/AspirinSJL",
      "followers_url": "https://api.github.com/users/AspirinSJL/followers",
      "following_url": "https://api.github.com/users/AspirinSJL/following{/other_user}",
      "gists_url": "https://api.github.com/users/AspirinSJL/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AspirinSJL/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AspirinSJL/subscriptions",
      "organizations_url": "https://api.github.com/users/AspirinSJL/orgs",
      "repos_url": "https://api.github.com/users/AspirinSJL/repos",
      "events_url": "https://api.github.com/users/AspirinSJL/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AspirinSJL/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-06T03:55:31Z",
    "updated_at": "2018-08-06T03:55:31Z",
    "author_association": "MEMBER",
    "body": "This should reduce the inuse memory of the 1-channel-1streaming-call case by ~10 KB. I checked the log and saw the arena is allocated only once now. \r\n\r\nBut my data collected for a period (15s) is not stable. Need to figure out why."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/410582335",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-410582335",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 410582335,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDU4MjMzNQ==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-06T03:59:21Z",
    "updated_at": "2018-08-06T03:59:21Z",
    "author_association": "NONE",
    "body": "```\n[trickle] No significant performance differences\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/410582538",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-410582538",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 410582538,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDU4MjUzOA==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-06T04:01:09Z",
    "updated_at": "2018-08-06T04:01:09Z",
    "author_association": "NONE",
    "body": "```\n****************************************************************\n\nlibgrpc.so\n\n     VM SIZE                                                                            FILE SIZE\n ++++++++++++++ GROWING                                                              ++++++++++++++\n  +0.1%    +935 [None]                                                               +5.07Ki  +0.1%\n      +0.1%    +919 [Unmapped]                                                           +5.05Ki  +0.1%\n       +25%     +16 client_channel_factory_vtable                                            +16   +25%\n   +16%    +264 src/core/lib/channel/channel_stack_builder.cc                           +264   +16%\n      [NEW]    +252 grpc_channel_stack_builder_get_subchannel_call_size                     +252  [NEW]\n      +6.9%     +12 [Unmapped]                                                               +12  +6.9%\n  +1.4%     +80 src/core/lib/surface/channel.cc                                          +80  +1.4%\n      +6.5%     +80 grpc_channel_create_with_builder                                         +80  +6.5%\n  +2.3%     +21 src/core/ext/transport/chttp2/client/insecure/channel_create.cc          +21  +2.3%\n      [NEW]     +21 _GLOBAL__sub_I_channel_create.cc                                         +21  [NEW]\n  +1.0%     +21 src/core/ext/transport/chttp2/client/secure/secure_channel_create.cc     +21  +1.0%\n      [NEW]     +21 _GLOBAL__sub_I_secure_channel_create.cc                                  +21  [NEW]\n  +7.8%     +16 src/core/ext/filters/client_channel/client_channel_factory.cc            +16  +7.8%\n       +12%      +8 [Unmapped]                                                                +8   +12%\n      [NEW]      +7 grpc_client_channel_factory_get_stream_size                               +7  [NEW]\n       +20%      +1 grpc_client_channel_factory_ref                                           +1   +20%\n  +0.0%      +7 src/core/ext/transport/chttp2/transport/chttp2_transport.cc               +7  +0.0%\n      [NEW]      +6 grpc_chttp2_get_stream_size                                               +6  [NEW]\n      +0.1%      +1 [Unmapped]                                                                +1  +0.1%\n\n  +0.1% +1.31Ki TOTAL                                                                +5.47Ki  +0.1%\n\n\n****************************************************************\n\nlibgrpc++.so\n\n     VM SIZE        FILE SIZE\n ++++++++++++++  ++++++++++++++\n\n  [ = ]       0        0  [ = ]\n\n\n\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/410583602",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-410583602",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 410583602,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDU4MzYwMg==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-06T04:10:46Z",
    "updated_at": "2018-08-06T04:10:46Z",
    "author_association": "NONE",
    "body": "```\n[trickle] No significant performance differences\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/410585322",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-410585322",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 410585322,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDU4NTMyMg==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-06T04:26:24Z",
    "updated_at": "2018-08-06T04:26:24Z",
    "author_association": "NONE",
    "body": "```\nObjective-C binary sizes\n*****************STATIC******************\n  New size                      Old size\n 1,981,314      Total (>)      1,980,683\n\n No significant differences in binary sizes\n\n***************FRAMEWORKS****************\n  New size                      Old size\n 3,613,770       Core (>)      3,612,674\n\n10,812,860      Total (>)     10,811,764\n\n\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/410587368",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-410587368",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 410587368,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDU4NzM2OA==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-06T04:44:02Z",
    "updated_at": "2018-08-06T04:44:02Z",
    "author_association": "NONE",
    "body": "```\n[microbenchmarks] No significant performance differences\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/410588404",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-410588404",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 410588404,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDU4ODQwNA==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-06T04:53:07Z",
    "updated_at": "2018-08-06T04:53:07Z",
    "author_association": "NONE",
    "body": "```\n[microbenchmarks] Performance differences noted:\nBenchmark                                                                                 cpu_time    real_time\n----------------------------------------------------------------------------------------  ----------  -----------\nBM_StreamingPingPongMsgs<InProcess, NoOpMutator, NoOpMutator>/262144                      +4%         +4%\nBM_StreamingPingPongMsgs<InProcess, NoOpMutator, NoOpMutator>/32768                       +5%         +5%\nBM_StreamingPingPongMsgs<MinInProcess, NoOpMutator, NoOpMutator>/32768                    +6%         +6%\nBM_StreamingPingPongWithCoalescingApi<MinInProcess, NoOpMutator, NoOpMutator>/262144/2/1  +4%         +4%\nBM_UnaryPingPong<MinInProcess, NoOpMutator, NoOpMutator>/0/262144                         +10%        +10%\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/411561178",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-411561178",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 411561178,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMTU2MTE3OA==",
    "user": {
      "login": "markdroth",
      "id": 18664614,
      "node_id": "MDQ6VXNlcjE4NjY0NjE0",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18664614?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdroth",
      "html_url": "https://github.com/markdroth",
      "followers_url": "https://api.github.com/users/markdroth/followers",
      "following_url": "https://api.github.com/users/markdroth/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdroth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdroth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdroth/subscriptions",
      "organizations_url": "https://api.github.com/users/markdroth/orgs",
      "repos_url": "https://api.github.com/users/markdroth/repos",
      "events_url": "https://api.github.com/users/markdroth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdroth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-08T21:39:17Z",
    "updated_at": "2018-08-08T21:39:17Z",
    "author_association": "MEMBER",
    "body": "I've had another thought about this, and I'd like input from @hcaseyal and @a11r on this.\r\n\r\nThe core problem here is that each time we need to grow the arena, we double its size (e.g., if the arena starts at 10K and we need 12K, we will double it to 20K and wind up wasting 8K).  This generally affects only those RPCs started on a channel before the first RPC on that channel is completed, since we update the channel's arena size estimate as calls complete.  For those RPCs, this minimizes the number of slow mallocs we need to do at the expense of wasting memory.  However, I am wondering if that's really a good trade-off.\r\n\r\nIn the common case (frequent unary RPCs), this trade-off is reasonable, but not essential -- neither the cost nor the benefit are very large:\r\n- The trade-off affects only a small number of calls in this case, because unary calls generally finish fairly quickly, and the problem goes away as soon as the first RPC finishes and we update the channel's arena size estimate.\r\n- The benefit is that it mimimizes the allocation overhead of the first few RPCs on the channel, thus improving performance for these RPCs.  However, that's not a huge benefit, since the first few RPCs are usually delayed anyway by the need to do name resolution and establish connections with the backend(s).\r\n- The cost is that we waste some memory.  However, this waste doesn't have a big impact, because unary calls finish fairly quickly, so the wasted memory we allocate for a given call gets freed fairly quickly.\r\n\r\nHowever, for the long-running streaming RPC case, this trade-off doesn't work well, because the benefit is much lower and the cost is much higher:\r\n- The trade-off affects a potentially large number of calls in this case, because streaming calls are generally long-lived, and the problem does not go away until the first RPC finishes and we update the channel's arena size estimate.\r\n- The benefit is that it mimimizes the allocation overhead of the affected calls on the channel, thus improving performance for these RPCs.  However, this benefit is much smaller than in the unary case, since we generally want to optimize streaming performance over per-RPC performance in this case (i.e., we can tolerate the per-RPC performance hit because we what we really care about is how well we perform at sending and receiving messages within the call).\r\n- The cost is that we waste memory.  However, this cost is much higher than in the unary case, because the calls last a long time, so the wasted memory we allocate for a given call stays wasted for a long time.\r\n\r\nGiven all of that, I am wondering if this trade-off is really the right thing.  Instead, I am thinking that we should consider the opposite trade-off: we should prefer to avoid wasting memory, even at the expense of having more allocations per call until the first call on the channel completes.  This would have the following impact relative to what we have today:\r\n- In the unary case, neither the cost nor the benefit are very large to begin with, so swapping this trade-off shouldn't make much difference.  There will be more allocations but less wasted memory for the affected RPCs.  Probably no one will notice either one.\r\n- In the streaming case, the benefit would be to reduce the memory waste, probably by a very significant amount.  The cost would be that there will be more allocations per call for a potentially larger number of calls, but I suspect this overhead would not be noticable as long as it doesn't affect streaming performance.\r\n\r\nIf this makes sense to everyone, then the implementation I had in mind would be to change the arena such that instead of doubling when it's not large enough, we allocate only the amount we actually need (i.e., the size passed to `gpr_arena_alloc()`).\r\n\r\nThoughts...?"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/411679518",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-411679518",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 411679518,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMTY3OTUxOA==",
    "user": {
      "login": "AspirinSJL",
      "id": 3314176,
      "node_id": "MDQ6VXNlcjMzMTQxNzY=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/3314176?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AspirinSJL",
      "html_url": "https://github.com/AspirinSJL",
      "followers_url": "https://api.github.com/users/AspirinSJL/followers",
      "following_url": "https://api.github.com/users/AspirinSJL/following{/other_user}",
      "gists_url": "https://api.github.com/users/AspirinSJL/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AspirinSJL/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AspirinSJL/subscriptions",
      "organizations_url": "https://api.github.com/users/AspirinSJL/orgs",
      "repos_url": "https://api.github.com/users/AspirinSJL/repos",
      "events_url": "https://api.github.com/users/AspirinSJL/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AspirinSJL/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-09T08:28:47Z",
    "updated_at": "2018-08-09T08:30:46Z",
    "author_association": "MEMBER",
    "body": "On Wed, Aug 8, 2018 at 2:40 PM Mark D. Roth <notifications@github.com>\r\nwrote:\r\n\r\n> I've had another thought about this, and I'd like input from @hcaseyal\r\n> <https://github.com/hcaseyal> and @a11r <https://github.com/a11r> on this.\r\n>\r\n> The core problem here is that each time we need to grow the arena, we\r\n> double its size (e.g., if the arena starts at 10K and we need 12K, we will\r\n> double it to 20K and wind up wasting 8K).\r\n>\r\nActually, it's worse than that. Since the current zone is not big enough\r\nfor the allocation (10 < 12) and we want to allocate continuous memory, we\r\nwill throw away that 10K, and create a 12K * 2 zone. So we are wasting\r\n22K...\r\n\r\n> This generally affects only those RPCs started on a channel before the\r\n> first RPC on that channel is completed, since we update the channel's arena\r\n> size estimate as calls complete. For those RPCs, this minimizes the number\r\n> of slow mallocs we need to do at the expense of wasting memory. However, I\r\n> am wondering if that's really a good trade-off.\r\n>\r\n> In the common case (frequent unary RPCs), this trade-off is reasonable,\r\n> but not essential -- neither the cost nor the benefit are very large:\r\n>\r\n>    - The trade-off affects only a small number of calls in this case,\r\n>    because unary calls generally finish fairly quickly, and the problem goes\r\n>    away as soon as the first RPC finishes and we update the channel's arena\r\n>    size estimate.\r\n>\r\n\r\n(Might be unrelated: this is true if we are increasing the size; if it's\r\nshrinking, we will converge slower\r\nhttps://github.com/grpc/grpc/blob/master/src/core/lib/surface/channel.cc#L264\r\n.)\r\n\r\n\r\n>\r\n>    - The benefit is that it mimimizes the allocation overhead of the\r\n>    first few RPCs on the channel, thus improving performance for these RPCs.\r\n>    However, that's not a huge benefit, since the first few RPCs are usually\r\n>    delayed anyway by the need to do name resolution and establish connections\r\n>    with the backend(s).\r\n>    - The cost is that we waste some memory. However, this waste doesn't\r\n>    have a big impact, because unary calls finish fairly quickly, so the wasted\r\n>    memory we allocate for a given call gets freed fairly quickly.\r\n>\r\n> However, for the long-running streaming RPC case, this trade-off doesn't\r\n> work well, because the benefit is much lower and the cost is much higher:\r\n>\r\n>    - The trade-off affects a potentially large number of calls in this\r\n>    case, because streaming calls are generally long-lived, and the problem\r\n>    does not go away until the first RPC finishes and we update the channel's\r\n>    arena size estimate.\r\n>    - The benefit is that it mimimizes the allocation overhead of the\r\n>    affected calls on the channel, thus improving performance for these RPCs.\r\n>    However, this benefit is much smaller than in the unary case, since we\r\n>    generally want to optimize streaming performance over per-RPC performance\r\n>    in this case (i.e., we can tolerate the per-RPC performance hit because we\r\n>    what we really care about is how well we perform at sending and receiving\r\n>    messages within the call).\r\n>\r\n\r\nThe streaming performance might still be affected if the message sending\r\nand receiving need to allocate memory from the arena.\r\n\r\n\r\n>\r\n>    - The cost is that we waste memory. However, this cost is much higher\r\n>    than in the unary case, because the calls last a long time, so the wasted\r\n>    memory we allocate for a given call stays wasted for a long time.\r\n>\r\n> Given all of that, I am wondering if this trade-off is really the right\r\n> thing. Instead, I am thinking that we should consider the opposite\r\n> trade-off: we should prefer to avoid wasting memory, even at the expense of\r\n> having more allocations per call until the first call on the channel\r\n> completes. This would have the following impact relative to what we have\r\n> today:\r\n>\r\n>    - In the unary case, neither the cost nor the benefit are very large\r\n>    to begin with, so swapping this trade-off shouldn't make much difference.\r\n>    There will be more allocations but less wasted memory for the affected\r\n>    RPCs. Probably no one will notice either one.\r\n>    - In the streaming case, the benefit would be to reduce the memory\r\n>    waste, probably by a very significant amount. The cost would be that there\r\n>    will be more allocations per call for a potentially larger number of calls,\r\n>    but I suspect this overhead would not be noticable as long as it doesn't\r\n>    affect streaming performance.\r\n>\r\n> If this makes sense to everyone, then the implementation I had in mind\r\n> would be to change the arena such that instead of doubling when it's not\r\n> large enough, we allocate only the amount we actually need (i.e., the size\r\n> passed to gpr_arena_alloc()).\r\n>\r\n\r\nWe should also create the arena with the max size of the initial call\r\nestimate and the first allocation from the arena. (It's doable because we\r\nallocate the first block from the arena right after we create the arena\r\nwhen creating a call.) It's important to utilize the first zone better\r\nbecause it's usually large.\r\n\r\n\r\n> Thoughts...?\r\n>\r\nBasically I agree with this change. I'm not a big fan of the current arena\r\nimplementation. I remembered @a11r mentioned that the arena needs some big\r\nsurgery.\r\n\r\nMaybe a moderate approach to this issue is to do the size doubling from the\r\nsecond zone. We can do the following:\r\n1. We try our best to have an accurate initial estimate, including all the\r\nbig parts plus some buffer. And we expect this is enough for most cases.\r\n2. If for some cases the first zone is not big enough, e.g., long-lived\r\nstreaming calls, the second zone will start from some small size (i.e., the\r\nrequested allocation size when we first exceed the first zone) and the\r\nfollowing zones will double the zone sizes. (Currently, we double the total\r\nsize of the arena.)\r\n\r\nThis is apparently more complex than your proposed approach, but it's not\r\nfar more complex than what we have now.\r\n\r\n—\r\n> You are receiving this because you were mentioned.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/grpc/grpc/pull/16248#issuecomment-411561178>, or mute\r\n> the thread\r\n> <https://github.com/notifications/unsubscribe-auth/ADKSALwop9Prjijtw1WHB3EtL5FT6aN1ks5uO1qxgaJpZM4VvtX8>\r\n> .\r\n>\r\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/411809472",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-411809472",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 411809472,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMTgwOTQ3Mg==",
    "user": {
      "login": "markdroth",
      "id": 18664614,
      "node_id": "MDQ6VXNlcjE4NjY0NjE0",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18664614?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdroth",
      "html_url": "https://github.com/markdroth",
      "followers_url": "https://api.github.com/users/markdroth/followers",
      "following_url": "https://api.github.com/users/markdroth/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdroth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdroth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdroth/subscriptions",
      "organizations_url": "https://api.github.com/users/markdroth/orgs",
      "repos_url": "https://api.github.com/users/markdroth/repos",
      "events_url": "https://api.github.com/users/markdroth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdroth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-09T16:02:20Z",
    "updated_at": "2018-08-09T16:02:20Z",
    "author_association": "MEMBER",
    "body": "@AspirinSJL wrote:\r\n> (Might be unrelated: this is true if we are increasing the size; if it's\r\nshrinking, we will converge slower\r\nhttps://github.com/grpc/grpc/blob/master/src/core/lib/surface/channel.cc#L264\r\n.)\r\n\r\nThat's certainly true.  But the case we're trying to address here is the case where the arena is too small, not the one where it's too large.  In practice, I suspect that we never set the initial estimate too high, so this probably isn't an issue.  And even if it is, my proposal is orthogonal to that issue; it doesn't try to fix that problem, but it also does nothing to make it worse.\r\n\r\n> The streaming performance might still be affected if the message sending\r\nand receiving need to allocate memory from the arena.\r\n\r\nThat's true, but I don't think that we have any such cases.  We have always tried to avoid that, because a streaming call can have an arbitrarily large number of messages, and arena allocations don't get freed until the call is complete.  So if we ever allocated something on the arena for each message, the memory usage of the streaming call would grow without bound and not get freed until the call is complete.\r\n\r\n(Caveat: I think we do some per-message arena allocations in the retry code, but they're fairly small, and they stop happening as soon as retries are committed.  This is sub-optimal and probably something we should fix before the retry code is actually used, but at least it doesn't keep happening for every single message on a long-running RPC.)\r\n\r\n> We should also create the arena with the max size of the initial call\r\nestimate and the first allocation from the arena. (It's doable because we\r\nallocate the first block from the arena right after we create the arena\r\nwhen creating a call.) It's important to utilize the first zone better\r\nbecause it's usually large.\r\n\r\nIs there ever a case where the initial size estimate is smaller than the first allocation?  I think our initial estimate always covers at least the size of the first allocation.\r\n\r\n> Maybe a moderate approach to this issue is to do the size doubling from the\r\nsecond zone. We can do the following:\r\n> 1. We try our best to have an accurate initial estimate, including all the\r\nbig parts plus some buffer. And we expect this is enough for most cases.\r\n\r\nOne of the motivations for my proposal is seeing how complex it is to actually generate an accurate initial size estimate.  I'd prefer to avoid all of the plumbing that we're needing to do in this PR if possible.\r\n\r\n> 2. If for some cases the first zone is not big enough, e.g., long-lived\r\nstreaming calls, the second zone will start from some small size (i.e., the\r\nrequested allocation size when we first exceed the first zone) and the\r\nfollowing zones will double the zone sizes. (Currently, we double the total\r\nsize of the arena.)\r\n\r\nWhat's the benefit of doubling after the second allocation?  Do we have evidence that it's only the second allocation that would cause the problem, and that no subsequent allocation would do so?  And even if that's true today, how do we know that future changes won't affect this?\r\n\r\n> This is apparently more complex than your proposed approach, but it's not\r\nfar more complex than what we have now.\r\n\r\nI could certainly live with that complexity if it buys us something, but it's not clear to me that it does.  I suspect that we don't have a large number of arena allocations per call (although I believe that @hcaseyal was going to do an audit to tell us for sure where we're doing so), so the total number of allocations is probably small anyway.  Given that, it seems like we don't save much with the doubling anyway, so we might as well err on the side of avoiding wasting memory."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/412121841",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-412121841",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 412121841,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMjEyMTg0MQ==",
    "user": {
      "login": "hcaseyal",
      "id": 8952658,
      "node_id": "MDQ6VXNlcjg5NTI2NTg=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/8952658?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hcaseyal",
      "html_url": "https://github.com/hcaseyal",
      "followers_url": "https://api.github.com/users/hcaseyal/followers",
      "following_url": "https://api.github.com/users/hcaseyal/following{/other_user}",
      "gists_url": "https://api.github.com/users/hcaseyal/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hcaseyal/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hcaseyal/subscriptions",
      "organizations_url": "https://api.github.com/users/hcaseyal/orgs",
      "repos_url": "https://api.github.com/users/hcaseyal/repos",
      "events_url": "https://api.github.com/users/hcaseyal/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hcaseyal/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-10T15:40:56Z",
    "updated_at": "2018-08-10T15:40:56Z",
    "author_association": "CONTRIBUTOR",
    "body": "@markdroth The change seems agreeable to me. It might be a good idea to experiment with different resize values. For instance, instead of allocating just the amount we need when the arena isn't large enough, maybe we allocate twice the amount needed.\r\n\r\nIn terms of the audit of allocations, I believe @AspirinSJL has already done that. "
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/412127947",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-412127947",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 412127947,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMjEyNzk0Nw==",
    "user": {
      "login": "markdroth",
      "id": 18664614,
      "node_id": "MDQ6VXNlcjE4NjY0NjE0",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18664614?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdroth",
      "html_url": "https://github.com/markdroth",
      "followers_url": "https://api.github.com/users/markdroth/followers",
      "following_url": "https://api.github.com/users/markdroth/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdroth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdroth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdroth/subscriptions",
      "organizations_url": "https://api.github.com/users/markdroth/orgs",
      "repos_url": "https://api.github.com/users/markdroth/repos",
      "events_url": "https://api.github.com/users/markdroth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdroth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-10T16:01:21Z",
    "updated_at": "2018-08-10T16:01:21Z",
    "author_association": "MEMBER",
    "body": "@hcaseyal, as I said above, it's not clear to me that there's enough benefit to be gained by allocating more than what we immediately need.  It seems like that would put us right back where we are now in terms of wasting memory.  It *might* waste less than we're currently wasting, but it could also waste more (e.g., if the *next* allocation is larger than twice the previous one).  And I think the code would need to be a lot more complex to support it.\r\n\r\nIn any case, my main argument is that the benefit of not doing as many allocations for the affected RPCs is really fairly small and therefore not worth *any* memory waste.  I don't object to running an experiment to verify that, but I think it would have to provide significant benefit to be worth doing.  And I don't want that experiment to delay this change.  If the experiment is going to take a long time, let's first change it to allocate only what is needed and then experiment with other approaches afterwards."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/412140551",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-412140551",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 412140551,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxMjE0MDU1MQ==",
    "user": {
      "login": "hcaseyal",
      "id": 8952658,
      "node_id": "MDQ6VXNlcjg5NTI2NTg=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/8952658?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/hcaseyal",
      "html_url": "https://github.com/hcaseyal",
      "followers_url": "https://api.github.com/users/hcaseyal/followers",
      "following_url": "https://api.github.com/users/hcaseyal/following{/other_user}",
      "gists_url": "https://api.github.com/users/hcaseyal/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/hcaseyal/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/hcaseyal/subscriptions",
      "organizations_url": "https://api.github.com/users/hcaseyal/orgs",
      "repos_url": "https://api.github.com/users/hcaseyal/repos",
      "events_url": "https://api.github.com/users/hcaseyal/events{/privacy}",
      "received_events_url": "https://api.github.com/users/hcaseyal/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-10T16:48:21Z",
    "updated_at": "2018-08-10T16:48:21Z",
    "author_association": "CONTRIBUTOR",
    "body": "@markdroth, sure, I totally agree with your last statement: \"If the experiment is going to take a long time, let's first change it to allocate only what is needed and then experiment with other approaches afterwards.\" However, I do think we should get numbers for this change to verify the benefit and tradeoffs, and that shouldn't take long - we can just run our benchmarks. "
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/415833043",
    "html_url": "https://github.com/grpc/grpc/pull/16248#issuecomment-415833043",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16248",
    "id": 415833043,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQxNTgzMzA0Mw==",
    "user": {
      "login": "AspirinSJL",
      "id": 3314176,
      "node_id": "MDQ6VXNlcjMzMTQxNzY=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/3314176?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AspirinSJL",
      "html_url": "https://github.com/AspirinSJL",
      "followers_url": "https://api.github.com/users/AspirinSJL/followers",
      "following_url": "https://api.github.com/users/AspirinSJL/following{/other_user}",
      "gists_url": "https://api.github.com/users/AspirinSJL/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AspirinSJL/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AspirinSJL/subscriptions",
      "organizations_url": "https://api.github.com/users/AspirinSJL/orgs",
      "repos_url": "https://api.github.com/users/AspirinSJL/repos",
      "events_url": "https://api.github.com/users/AspirinSJL/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AspirinSJL/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-08-24T17:49:29Z",
    "updated_at": "2018-08-24T17:49:29Z",
    "author_association": "MEMBER",
    "body": "This PR adds much complexity without apparent benefit. Closing it in favor of https://github.com/grpc/grpc/pull/16396.\r\n\r\nThanks for reviewing it!"
  }
]
