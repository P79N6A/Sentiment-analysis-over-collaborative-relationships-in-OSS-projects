[
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/362126911",
    "html_url": "https://github.com/grpc/grpc/issues/14260#issuecomment-362126911",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/14260",
    "id": 362126911,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjEyNjkxMQ==",
    "user": {
      "login": "markdroth",
      "id": 18664614,
      "node_id": "MDQ6VXNlcjE4NjY0NjE0",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18664614?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdroth",
      "html_url": "https://github.com/markdroth",
      "followers_url": "https://api.github.com/users/markdroth/followers",
      "following_url": "https://api.github.com/users/markdroth/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdroth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdroth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdroth/subscriptions",
      "organizations_url": "https://api.github.com/users/markdroth/orgs",
      "repos_url": "https://api.github.com/users/markdroth/repos",
      "events_url": "https://api.github.com/users/markdroth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdroth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-01T01:21:05Z",
    "updated_at": "2018-02-01T01:21:05Z",
    "author_association": "MEMBER",
    "body": "Are you using a secure channel?  If so, I suspect that what you're seeing here is the effect of #12767.  Prior to that PR, we were (incorrectly) failing to share subchannels to the same backend between channels when a security connector is in place.  Now, we do share the subchannels, which is what we were always supposed to do.\r\n\r\nNote that subchannel sharing only occurs when the subchannels are for the same address and have exactly the same set of channel args.  So in a case like yours where you don't actually want the sharing, an easy way to disable the sharing is to supply a different meaningless channel arg to each channel.  For example, use a channel arg key like \"my_channel_index\" and set the value to an integer whose value is incremented each time through the loop.\r\n\r\nPlease let me know if you have any questions about any of this."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/362128473",
    "html_url": "https://github.com/grpc/grpc/issues/14260#issuecomment-362128473",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/14260",
    "id": 362128473,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjEyODQ3Mw==",
    "user": {
      "login": "mradmila",
      "id": 11877520,
      "node_id": "MDQ6VXNlcjExODc3NTIw",
      "avatar_url": "https://avatars3.githubusercontent.com/u/11877520?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mradmila",
      "html_url": "https://github.com/mradmila",
      "followers_url": "https://api.github.com/users/mradmila/followers",
      "following_url": "https://api.github.com/users/mradmila/following{/other_user}",
      "gists_url": "https://api.github.com/users/mradmila/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mradmila/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mradmila/subscriptions",
      "organizations_url": "https://api.github.com/users/mradmila/orgs",
      "repos_url": "https://api.github.com/users/mradmila/repos",
      "events_url": "https://api.github.com/users/mradmila/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mradmila/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-01T01:29:43Z",
    "updated_at": "2018-02-01T01:29:43Z",
    "author_association": "NONE",
    "body": "I am using an insecure channel. Yes, the address of the LB and the port are exactly the same every time, but I guess I could provide some meaningless identifier for the request. Wouldn't that do the opposite, create the subchannel every time? Then the burden is on client to create some pool?\r\n\r\nI guess the meta-question is: how does one get proper server side load-balancing? I was going through default k8s load-balancer, and also using Envoy. Surely we don't want to overload one server from a client that produces a lot of work, especially if we have multiple servers to work with? What do you recommend as a standard way of doing this N clients to M servers through an LB where N << M?"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/362128892",
    "html_url": "https://github.com/grpc/grpc/issues/14260#issuecomment-362128892",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/14260",
    "id": 362128892,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjEyODg5Mg==",
    "user": {
      "login": "mradmila",
      "id": 11877520,
      "node_id": "MDQ6VXNlcjExODc3NTIw",
      "avatar_url": "https://avatars3.githubusercontent.com/u/11877520?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mradmila",
      "html_url": "https://github.com/mradmila",
      "followers_url": "https://api.github.com/users/mradmila/followers",
      "following_url": "https://api.github.com/users/mradmila/following{/other_user}",
      "gists_url": "https://api.github.com/users/mradmila/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mradmila/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mradmila/subscriptions",
      "organizations_url": "https://api.github.com/users/mradmila/orgs",
      "repos_url": "https://api.github.com/users/mradmila/repos",
      "events_url": "https://api.github.com/users/mradmila/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mradmila/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-01T01:32:09Z",
    "updated_at": "2018-02-01T01:32:09Z",
    "author_association": "NONE",
    "body": "Server is doing the heavy-lifting, of course... client is lightweight."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/362183592",
    "html_url": "https://github.com/grpc/grpc/issues/14260#issuecomment-362183592",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/14260",
    "id": 362183592,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjE4MzU5Mg==",
    "user": {
      "login": "mradmila",
      "id": 11877520,
      "node_id": "MDQ6VXNlcjExODc3NTIw",
      "avatar_url": "https://avatars3.githubusercontent.com/u/11877520?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mradmila",
      "html_url": "https://github.com/mradmila",
      "followers_url": "https://api.github.com/users/mradmila/followers",
      "following_url": "https://api.github.com/users/mradmila/following{/other_user}",
      "gists_url": "https://api.github.com/users/mradmila/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mradmila/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mradmila/subscriptions",
      "organizations_url": "https://api.github.com/users/mradmila/orgs",
      "repos_url": "https://api.github.com/users/mradmila/repos",
      "events_url": "https://api.github.com/users/mradmila/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mradmila/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-01T07:41:06Z",
    "updated_at": "2018-02-01T07:41:06Z",
    "author_association": "NONE",
    "body": "Hey Mark, I left some notes on GitHub. Can you please comment/offer some guidance? Perhaps an example on what other people do in this situation?\n\nThanks,\n\nMarko\n\nGet Outlook for iOS<https://aka.ms/o0ukef>\n________________________________\nFrom: Mark D. Roth <notifications@github.com>\nSent: Wednesday, January 31, 2018 5:21:24 PM\nTo: grpc/grpc\nCc: Marko Radmilac; Author\nSubject: Re: [grpc/grpc] gRPC client caches connection through LB after version 1.8, so LB happens (#14260)\n\n\nClosed #14260<https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgrpc%2Fgrpc%2Fissues%2F14260&data=02%7C01%7C%7Ce929dcd074d94984c1d908d569121c60%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C636530448860325723&sdata=T5MlvWgBn1IvZxyuOlk%2FOmopOYHMX1jr0Ekgysm9Kx0%3D&reserved=0>.\n\nâ€”\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub<https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgrpc%2Fgrpc%2Fissues%2F14260%23event-1452040709&data=02%7C01%7C%7Ce929dcd074d94984c1d908d569121c60%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C636530448860325723&sdata=3XoacOudU0urxQfAQcTeYfOpu2owpPcGhDy2mQBYqEE%3D&reserved=0>, or mute the thread<https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FALU8kLfXYd4KuPZlKyj1-oiwf3s3jh88ks5tQRGUgaJpZM4R0wTj&data=02%7C01%7C%7Ce929dcd074d94984c1d908d569121c60%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C636530448860325723&sdata=xCg2yhHpNJf%2BS%2BvTPaJca%2BI2mgW5B6Pu7p%2BXlpIR8b4%3D&reserved=0>.\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/362298290",
    "html_url": "https://github.com/grpc/grpc/issues/14260#issuecomment-362298290",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/14260",
    "id": 362298290,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjI5ODI5MA==",
    "user": {
      "login": "markdroth",
      "id": 18664614,
      "node_id": "MDQ6VXNlcjE4NjY0NjE0",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18664614?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdroth",
      "html_url": "https://github.com/markdroth",
      "followers_url": "https://api.github.com/users/markdroth/followers",
      "following_url": "https://api.github.com/users/markdroth/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdroth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdroth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdroth/subscriptions",
      "organizations_url": "https://api.github.com/users/markdroth/orgs",
      "repos_url": "https://api.github.com/users/markdroth/repos",
      "events_url": "https://api.github.com/users/markdroth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdroth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-01T15:20:59Z",
    "updated_at": "2018-02-01T15:20:59Z",
    "author_association": "MEMBER",
    "body": "> I am using an insecure channel.\r\n\r\nIf you're using an insecure channel, then #12767 wouldn't have had any effect.  But in that case, subchannel sharing should have been working all along, so I'm not sure why you saw any behavior change in 1.8.  But in any case, the behavior you're seeing now is the intended behavior, and using channel args to disable sharing should work around it.\r\n\r\n> Yes, the address of the LB and the port are exactly the same every time, but I guess I could provide some meaningless identifier for the request. Wouldn't that do the opposite, create the subchannel every time? Then the burden is on client to create some pool?\r\n\r\nYes, that will cause each channel to create its own subchannel.  I thought that was what you were asking about, but based on the above question, I suspect that I'm misunderstanding something.\r\n\r\nMy understanding of the problem you've reported here was that the client created multiple channels to the same server and that resulted in all of the channels sharing the same subchannel rather than having each channel create its own subchannel.  But if you don't want the client to have to create a pool of channels, then why are you concerned about the behavior when there are multiple channels in the first place?\r\n\r\nWait -- maybe you're trying to create a separate channel each time through the loop, where the channel is destroyed by the end of the loop, rather than having multiple channels exist at the same time?  If so, my suspicion is that the channel in each iteration of the loop is actually living longer than the end of the loop.  This seems particularly likely to me, given that you are depending upon python's garbage collection to actually destroy the channel, and it might not be happening when you expect.  But I can't say for sure without seeing your code.\r\n\r\nIn any case, if your concern is that we will cache subchannels even after a channel is destroyed and then reuse those subchannels for a channel created later, the answer is that we should not do that (unless of course there is a third channel to the same server that existed before the first channel was destroyed and continued to exist until after the second channel was created).\r\n\r\nHowever, it's also worth pointing out here that the intended use of the channel API is to create a single channel and leave it existing as long as you're going to need to use it.  You should not be creating a single channel for each RPC (or even small group of RPCs) you send, destroying it, and then creating another one a short time later.  Instead, just create it once, use it whenever you need to, and destroy it when the client is completely finished.\r\n\r\n> I guess the meta-question is: how does one get proper server side load-balancing? I was going through default k8s load-balancer, and also using Envoy. Surely we don't want to overload one server from a client that produces a lot of work, especially if we have multiple servers to work with? What do you recommend as a standard way of doing this N clients to M servers through an LB where N << M?\r\n\r\nThe exact way that you want to set this up depends heavily on your environment and requirements.  Keep in mind, though, that even if clients split their load across multiple connections, you aren't actually guaranteed to spread load evenly across your backends, because you can't guarantee that Envoy will always send multiple connections from the same client to different backends.\r\n\r\nAn alternative would be to use a gRPC-level proxy (as opposed to an HTTP/2 proxy), which could spread the traffic out across the backends on a per-call (rather than per-connection) basis using either round_robin or grpclb.  That approach requires a bit more infrastructure, but it will probably yield better balancing (especially if you use grpclb with a balancer that knows the load of the individual backends)."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/362384059",
    "html_url": "https://github.com/grpc/grpc/issues/14260#issuecomment-362384059",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/14260",
    "id": 362384059,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjM4NDA1OQ==",
    "user": {
      "login": "mradmila",
      "id": 11877520,
      "node_id": "MDQ6VXNlcjExODc3NTIw",
      "avatar_url": "https://avatars3.githubusercontent.com/u/11877520?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mradmila",
      "html_url": "https://github.com/mradmila",
      "followers_url": "https://api.github.com/users/mradmila/followers",
      "following_url": "https://api.github.com/users/mradmila/following{/other_user}",
      "gists_url": "https://api.github.com/users/mradmila/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mradmila/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mradmila/subscriptions",
      "organizations_url": "https://api.github.com/users/mradmila/orgs",
      "repos_url": "https://api.github.com/users/mradmila/repos",
      "events_url": "https://api.github.com/users/mradmila/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mradmila/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-01T19:59:15Z",
    "updated_at": "2018-02-01T19:59:15Z",
    "author_association": "NONE",
    "body": "Thanks for your prompt replies. Perhaps it's worth-while popping back one level. My actual app, naturally, is not helloworld, but it exhibits the same behavior. I open a channel to the server pool for each request (which is perhaps silly), through LB (L4 or L7), which is a simple VIP from the client's perspective. Whether I use Python or C# did not seem to matter, unless I explicitly shutdown the channel (in C# by calling channel.ShutdownAsync, in which case I get different servers responding). I now tried caching the channel in Python, in 1.7.3, and I get the same behavior as 1.8 (connections go to the same server every time). This confirms your suspicion about Python and garbage collection.\r\n\r\nI will likely end up using gRPC-level proxy at the end, but I am trying to understand how the whole system works, and what are my options. It seems like in 1.7.3 there was a mechanism that was cleaning up channels more proactively, in both C# and Python, and in 1.8 there is more caching happening behind the screens for multiple created channels (using the same subchannel I guess).\r\n\r\nI do want to make sure that for streaming calls, since my app has state, I don't get multiple servers randomly responding (ping pong). That should never happen, correct?\r\n\r\nAgain, thanks a lot for your time and comments."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/362386978",
    "html_url": "https://github.com/grpc/grpc/issues/14260#issuecomment-362386978",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/14260",
    "id": 362386978,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjM4Njk3OA==",
    "user": {
      "login": "markdroth",
      "id": 18664614,
      "node_id": "MDQ6VXNlcjE4NjY0NjE0",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18664614?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdroth",
      "html_url": "https://github.com/markdroth",
      "followers_url": "https://api.github.com/users/markdroth/followers",
      "following_url": "https://api.github.com/users/markdroth/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdroth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdroth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdroth/subscriptions",
      "organizations_url": "https://api.github.com/users/markdroth/orgs",
      "repos_url": "https://api.github.com/users/markdroth/repos",
      "events_url": "https://api.github.com/users/markdroth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdroth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-01T20:10:00Z",
    "updated_at": "2018-02-01T20:10:00Z",
    "author_association": "MEMBER",
    "body": "> I do want to make sure that for streaming calls, since my app has state, I don't get multiple servers randomly responding (ping pong). That should never happen, correct?\r\n\r\nCorrect.  An individual RPC, whether unary or streaming, will always be to a single server."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/362412823",
    "html_url": "https://github.com/grpc/grpc/issues/14260#issuecomment-362412823",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/14260",
    "id": 362412823,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjQxMjgyMw==",
    "user": {
      "login": "mradmila",
      "id": 11877520,
      "node_id": "MDQ6VXNlcjExODc3NTIw",
      "avatar_url": "https://avatars3.githubusercontent.com/u/11877520?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mradmila",
      "html_url": "https://github.com/mradmila",
      "followers_url": "https://api.github.com/users/mradmila/followers",
      "following_url": "https://api.github.com/users/mradmila/following{/other_user}",
      "gists_url": "https://api.github.com/users/mradmila/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mradmila/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mradmila/subscriptions",
      "organizations_url": "https://api.github.com/users/mradmila/orgs",
      "repos_url": "https://api.github.com/users/mradmila/repos",
      "events_url": "https://api.github.com/users/mradmila/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mradmila/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-01T21:47:17Z",
    "updated_at": "2018-02-01T21:47:17Z",
    "author_association": "NONE",
    "body": "Sorry, another really quick question: there is no code today in grpc client that will say something like: \"there are already 100 **concurrent** channels pounding on the same underlying connection/subchannel, let me pump in a few more subchannels and internally load-balance\"?"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/362414010",
    "html_url": "https://github.com/grpc/grpc/issues/14260#issuecomment-362414010",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/14260",
    "id": 362414010,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjQxNDAxMA==",
    "user": {
      "login": "markdroth",
      "id": 18664614,
      "node_id": "MDQ6VXNlcjE4NjY0NjE0",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18664614?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdroth",
      "html_url": "https://github.com/markdroth",
      "followers_url": "https://api.github.com/users/markdroth/followers",
      "following_url": "https://api.github.com/users/markdroth/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdroth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdroth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdroth/subscriptions",
      "organizations_url": "https://api.github.com/users/markdroth/orgs",
      "repos_url": "https://api.github.com/users/markdroth/repos",
      "events_url": "https://api.github.com/users/markdroth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdroth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-02-01T21:51:34Z",
    "updated_at": "2018-02-01T21:51:34Z",
    "author_association": "MEMBER",
    "body": "No, there is no such functionality today.  We've had some discussions about possibly supporting something like that in the context of avoiding HTTP/2 `MAX_CONCURRENT_STREAMS` limits (see #11704), but we have not yet agreed on anything."
  }
]
