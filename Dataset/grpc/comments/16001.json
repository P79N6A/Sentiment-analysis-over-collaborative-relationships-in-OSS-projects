[
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/404630743",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-404630743",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 404630743,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwNDYzMDc0Mw==",
    "user": {
      "login": "mehrdada",
      "id": 900411,
      "node_id": "MDQ6VXNlcjkwMDQxMQ==",
      "avatar_url": "https://avatars3.githubusercontent.com/u/900411?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mehrdada",
      "html_url": "https://github.com/mehrdada",
      "followers_url": "https://api.github.com/users/mehrdada/followers",
      "following_url": "https://api.github.com/users/mehrdada/following{/other_user}",
      "gists_url": "https://api.github.com/users/mehrdada/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mehrdada/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mehrdada/subscriptions",
      "organizations_url": "https://api.github.com/users/mehrdada/orgs",
      "repos_url": "https://api.github.com/users/mehrdada/repos",
      "events_url": "https://api.github.com/users/mehrdada/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mehrdada/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-07-12T19:52:55Z",
    "updated_at": "2018-07-12T19:52:55Z",
    "author_association": "CONTRIBUTOR",
    "body": "@ericgribkoff is this a supported use-case?"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/404638589",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-404638589",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 404638589,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQwNDYzODU4OQ==",
    "user": {
      "login": "ericgribkoff",
      "id": 5067076,
      "node_id": "MDQ6VXNlcjUwNjcwNzY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5067076?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ericgribkoff",
      "html_url": "https://github.com/ericgribkoff",
      "followers_url": "https://api.github.com/users/ericgribkoff/followers",
      "following_url": "https://api.github.com/users/ericgribkoff/following{/other_user}",
      "gists_url": "https://api.github.com/users/ericgribkoff/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ericgribkoff/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ericgribkoff/subscriptions",
      "organizations_url": "https://api.github.com/users/ericgribkoff/orgs",
      "repos_url": "https://api.github.com/users/ericgribkoff/repos",
      "events_url": "https://api.github.com/users/ericgribkoff/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ericgribkoff/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-07-12T20:22:30Z",
    "updated_at": "2018-07-12T20:22:30Z",
    "author_association": "CONTRIBUTOR",
    "body": "No, this is not supported.  `futures.ProcessPoolExecutor` forks in response to submitted tasks, meaning after the server starts (gRPC Python sends tasks to the executor to handle incoming RPCs). This is not compatible with gRPC's fork support on the server-side. You will need to pre-fork, meaning fork your subprocesses and then have each one (separately) start their own gRPC server instance.\r\n\r\n> What did you expect to see?\r\n>\r\n> Based on doc https://github.com/grpc/grpc/blob/master/doc/fork_support.md\r\ngRPC server should run on 4 processes\r\n\r\n@p1c2u Thanks for pointing this out. I see that our documentation could be a bit confusing if you're looking at using fork with gRPC servers: we should update that document to make it more clear that the fork-support there is for client-side usage. (cc @kpayson64)"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/424497742",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-424497742",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 424497742,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyNDQ5Nzc0Mg==",
    "user": {
      "login": "mohit-chawla",
      "id": 7635109,
      "node_id": "MDQ6VXNlcjc2MzUxMDk=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/7635109?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mohit-chawla",
      "html_url": "https://github.com/mohit-chawla",
      "followers_url": "https://api.github.com/users/mohit-chawla/followers",
      "following_url": "https://api.github.com/users/mohit-chawla/following{/other_user}",
      "gists_url": "https://api.github.com/users/mohit-chawla/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mohit-chawla/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mohit-chawla/subscriptions",
      "organizations_url": "https://api.github.com/users/mohit-chawla/orgs",
      "repos_url": "https://api.github.com/users/mohit-chawla/repos",
      "events_url": "https://api.github.com/users/mohit-chawla/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mohit-chawla/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-09-25T20:53:21Z",
    "updated_at": "2018-09-26T20:06:06Z",
    "author_association": "NONE",
    "body": "[PYTHON]   @ericgribkoff , I have ran into a use case where i am using a gRPC for a server side CPU bound task (and need to use python multi processing as there isn't an option in pure Python). Can you please suggest a solution here as i see no support for server side for fork ?\r\n\r\nI am facing `grpc._channel._Rendezvous: <_Rendezvous of RPC that terminated with (StatusCode.INTERNAL, Received RST_STREAM with error code 2)>`\r\n\r\n\r\n@evanj How did you deal with https://github.com/grpc/grpc/issues/15334#issuecomment-397048855 ? "
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/424498346",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-424498346",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 424498346,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQyNDQ5ODM0Ng==",
    "user": {
      "login": "kriticism",
      "id": 10485230,
      "node_id": "MDQ6VXNlcjEwNDg1MjMw",
      "avatar_url": "https://avatars2.githubusercontent.com/u/10485230?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/kriticism",
      "html_url": "https://github.com/kriticism",
      "followers_url": "https://api.github.com/users/kriticism/followers",
      "following_url": "https://api.github.com/users/kriticism/following{/other_user}",
      "gists_url": "https://api.github.com/users/kriticism/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/kriticism/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/kriticism/subscriptions",
      "organizations_url": "https://api.github.com/users/kriticism/orgs",
      "repos_url": "https://api.github.com/users/kriticism/repos",
      "events_url": "https://api.github.com/users/kriticism/events{/privacy}",
      "received_events_url": "https://api.github.com/users/kriticism/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-09-25T20:55:24Z",
    "updated_at": "2018-09-25T20:55:24Z",
    "author_association": "NONE",
    "body": "@ericgribkoff , @evanj  : I'm facing the same issue as @mohit-chawla  "
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/433378231",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-433378231",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 433378231,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzMzM3ODIzMQ==",
    "user": {
      "login": "yogin16",
      "id": 1974080,
      "node_id": "MDQ6VXNlcjE5NzQwODA=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/1974080?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/yogin16",
      "html_url": "https://github.com/yogin16",
      "followers_url": "https://api.github.com/users/yogin16/followers",
      "following_url": "https://api.github.com/users/yogin16/following{/other_user}",
      "gists_url": "https://api.github.com/users/yogin16/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/yogin16/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/yogin16/subscriptions",
      "organizations_url": "https://api.github.com/users/yogin16/orgs",
      "repos_url": "https://api.github.com/users/yogin16/repos",
      "events_url": "https://api.github.com/users/yogin16/events{/privacy}",
      "received_events_url": "https://api.github.com/users/yogin16/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-26T11:33:06Z",
    "updated_at": "2018-10-26T11:33:06Z",
    "author_association": "NONE",
    "body": "+1"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/433794991",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-433794991",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 433794991,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzMzc5NDk5MQ==",
    "user": {
      "login": "ericgribkoff",
      "id": 5067076,
      "node_id": "MDQ6VXNlcjUwNjcwNzY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5067076?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ericgribkoff",
      "html_url": "https://github.com/ericgribkoff",
      "followers_url": "https://api.github.com/users/ericgribkoff/followers",
      "following_url": "https://api.github.com/users/ericgribkoff/following{/other_user}",
      "gists_url": "https://api.github.com/users/ericgribkoff/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ericgribkoff/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ericgribkoff/subscriptions",
      "organizations_url": "https://api.github.com/users/ericgribkoff/orgs",
      "repos_url": "https://api.github.com/users/ericgribkoff/repos",
      "events_url": "https://api.github.com/users/ericgribkoff/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ericgribkoff/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-10-29T05:46:59Z",
    "updated_at": "2018-10-29T05:46:59Z",
    "author_association": "CONTRIBUTOR",
    "body": "The following two approaches should help with combining gRPC Python servers and the `fork()` syscall (e.g., using Python's multiprocessing library). The main constraint that must be satisified is that your process must only invoke the `fork()` syscall *before* you create your gRPC server(s).\r\n\r\nOption 1:\r\n\r\nIf your environment supports the [SO_REUSEPORT](https://lwn.net/Articles/542629/) socket option, you can run multiple copies of your gRPC server in individual processes started via `multiprocessing.Process`, and all of the servers can listen on the same port. SO_REUSEPORT is set by default if you build gRPC from source on Linux, but it is not available in the manylinux spec used by the binaries we distribute on pip, so depending on your environment you may have to resort to option 2. \r\n\r\nThis type of pre-fork + SO_REUSEPORT would look something like the following:\r\n\r\n```\r\ndef startGrpcServer():\r\n    server = grpc.server()\r\n    server.add_insecure_port('[::]:50051')\r\n    server.start()\r\n\r\nfor i in range(5):\r\n  p = multiprocessing.Process(target=startGrpcServer)\r\n  p.start()\r\n```\r\n\r\nOption 2:\r\n\r\nRun a single gRPC Python server, but offload all CPU-intensive work to a [`multiprocessing.Pool`](https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.pool) started *before* you create the gRPC server.\r\n\r\nThis would look like the following:\r\n\r\n```\r\npool = multiprocessing.Pool(processes=4)\r\n\r\n# The implementation of your RPC method. This will run in the main process, \r\n# but the work will be done asynchronously by the pool of pre-forked workers.\r\ndef rpcMethod(self, request, context):\r\n  result = pool.apply_async(someExpensiveFunction(request)\r\n  return result.get(timeout=1)\r\n\r\nserver = grpc.server()\r\nserver.add_insecure_port('[::]:50051')\r\nserver.start()\r\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/437713934",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-437713934",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 437713934,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzcxMzkzNA==",
    "user": {
      "login": "ferrouswheel",
      "id": 120327,
      "node_id": "MDQ6VXNlcjEyMDMyNw==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/120327?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ferrouswheel",
      "html_url": "https://github.com/ferrouswheel",
      "followers_url": "https://api.github.com/users/ferrouswheel/followers",
      "following_url": "https://api.github.com/users/ferrouswheel/following{/other_user}",
      "gists_url": "https://api.github.com/users/ferrouswheel/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ferrouswheel/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ferrouswheel/subscriptions",
      "organizations_url": "https://api.github.com/users/ferrouswheel/orgs",
      "repos_url": "https://api.github.com/users/ferrouswheel/repos",
      "events_url": "https://api.github.com/users/ferrouswheel/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ferrouswheel/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-11T23:05:17Z",
    "updated_at": "2018-11-11T23:06:22Z",
    "author_association": "NONE",
    "body": "Did this behaviour change recently?\r\n\r\nI have a grpc server invoking tensorflow, but tensorflow doesn't have anyway to explicitly let go of GPU memory. \r\n\r\nThus my solution, when receiving a grpc request, was to spawn a new process to do the work, then let it terminate after the work was done.\r\n\r\nI was pretty sure I had this working with grpc earlier in 2018, but now I get `Failed accept4: Invalid argument`... :thinking:\r\n\r\n(I can work around it in an awkward way, but I'd like to clarify if I'm going mad)"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/437945153",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-437945153",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 437945153,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzNzk0NTE1Mw==",
    "user": {
      "login": "ericgribkoff",
      "id": 5067076,
      "node_id": "MDQ6VXNlcjUwNjcwNzY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5067076?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ericgribkoff",
      "html_url": "https://github.com/ericgribkoff",
      "followers_url": "https://api.github.com/users/ericgribkoff/followers",
      "following_url": "https://api.github.com/users/ericgribkoff/following{/other_user}",
      "gists_url": "https://api.github.com/users/ericgribkoff/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ericgribkoff/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ericgribkoff/subscriptions",
      "organizations_url": "https://api.github.com/users/ericgribkoff/orgs",
      "repos_url": "https://api.github.com/users/ericgribkoff/repos",
      "events_url": "https://api.github.com/users/ericgribkoff/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ericgribkoff/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-12T16:31:35Z",
    "updated_at": "2018-11-12T16:31:35Z",
    "author_association": "CONTRIBUTOR",
    "body": "@ferrouswheel gRPC servers using `fork()` (without following this with an immediate `exec()`) to process incoming requests has never been supported. Depending on a variety of factors (including the version of gRPC, what polling engine was in use) it *might* have worked *sometimes*, but probably not often enough to appear functional through any non-trivial amount of usage.\r\n\r\nHowever, if you were spawning a new process via `fork()+exec()`, that should have worked - and should continue to work."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/438035306",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-438035306",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 438035306,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQzODAzNTMwNg==",
    "user": {
      "login": "ferrouswheel",
      "id": 120327,
      "node_id": "MDQ6VXNlcjEyMDMyNw==",
      "avatar_url": "https://avatars1.githubusercontent.com/u/120327?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ferrouswheel",
      "html_url": "https://github.com/ferrouswheel",
      "followers_url": "https://api.github.com/users/ferrouswheel/followers",
      "following_url": "https://api.github.com/users/ferrouswheel/following{/other_user}",
      "gists_url": "https://api.github.com/users/ferrouswheel/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ferrouswheel/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ferrouswheel/subscriptions",
      "organizations_url": "https://api.github.com/users/ferrouswheel/orgs",
      "repos_url": "https://api.github.com/users/ferrouswheel/repos",
      "events_url": "https://api.github.com/users/ferrouswheel/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ferrouswheel/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-12T21:31:04Z",
    "updated_at": "2018-11-12T21:31:04Z",
    "author_association": "NONE",
    "body": "@ericgribkoff Thank you for the clarification. I must have just got lucky with a prior combination of factors."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/440271128",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-440271128",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 440271128,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MDI3MTEyOA==",
    "user": {
      "login": "yifeikong",
      "id": 1035487,
      "node_id": "MDQ6VXNlcjEwMzU0ODc=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/1035487?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/yifeikong",
      "html_url": "https://github.com/yifeikong",
      "followers_url": "https://api.github.com/users/yifeikong/followers",
      "following_url": "https://api.github.com/users/yifeikong/following{/other_user}",
      "gists_url": "https://api.github.com/users/yifeikong/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/yifeikong/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/yifeikong/subscriptions",
      "organizations_url": "https://api.github.com/users/yifeikong/orgs",
      "repos_url": "https://api.github.com/users/yifeikong/repos",
      "events_url": "https://api.github.com/users/yifeikong/events{/privacy}",
      "received_events_url": "https://api.github.com/users/yifeikong/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-20T13:21:11Z",
    "updated_at": "2018-11-20T13:21:11Z",
    "author_association": "NONE",
    "body": "@ericgribkoff Do you mean that if we build a executor that preforks before grpc server starts, then it would work?"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/440365392",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-440365392",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 440365392,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MDM2NTM5Mg==",
    "user": {
      "login": "ericgribkoff",
      "id": 5067076,
      "node_id": "MDQ6VXNlcjUwNjcwNzY=",
      "avatar_url": "https://avatars2.githubusercontent.com/u/5067076?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ericgribkoff",
      "html_url": "https://github.com/ericgribkoff",
      "followers_url": "https://api.github.com/users/ericgribkoff/followers",
      "following_url": "https://api.github.com/users/ericgribkoff/following{/other_user}",
      "gists_url": "https://api.github.com/users/ericgribkoff/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ericgribkoff/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ericgribkoff/subscriptions",
      "organizations_url": "https://api.github.com/users/ericgribkoff/orgs",
      "repos_url": "https://api.github.com/users/ericgribkoff/repos",
      "events_url": "https://api.github.com/users/ericgribkoff/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ericgribkoff/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-20T17:41:16Z",
    "updated_at": "2018-11-20T17:41:16Z",
    "author_association": "CONTRIBUTOR",
    "body": "@yifeikong Not exactly: you will need to prefork before any calls into gRPC, including instantiation of the server."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/468451738",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-468451738",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 468451738,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ2ODQ1MTczOA==",
    "user": {
      "login": "jshlbrd",
      "id": 5711448,
      "node_id": "MDQ6VXNlcjU3MTE0NDg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5711448?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jshlbrd",
      "html_url": "https://github.com/jshlbrd",
      "followers_url": "https://api.github.com/users/jshlbrd/followers",
      "following_url": "https://api.github.com/users/jshlbrd/following{/other_user}",
      "gists_url": "https://api.github.com/users/jshlbrd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jshlbrd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jshlbrd/subscriptions",
      "organizations_url": "https://api.github.com/users/jshlbrd/orgs",
      "repos_url": "https://api.github.com/users/jshlbrd/repos",
      "events_url": "https://api.github.com/users/jshlbrd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jshlbrd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-02-28T21:48:13Z",
    "updated_at": "2019-02-28T21:48:13Z",
    "author_association": "NONE",
    "body": "@ericgribkoff any chance you can flesh out a more concrete example for multiprocessing.Pool? I'm not seeing how one could offload incoming calls to the pool (i.e. in your example, how would `rpcMethod` be referenced by the gRPC server?)"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/468459035",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-468459035",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 468459035,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ2ODQ1OTAzNQ==",
    "user": {
      "login": "lidizheng",
      "id": 7394928,
      "node_id": "MDQ6VXNlcjczOTQ5Mjg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/7394928?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lidizheng",
      "html_url": "https://github.com/lidizheng",
      "followers_url": "https://api.github.com/users/lidizheng/followers",
      "following_url": "https://api.github.com/users/lidizheng/following{/other_user}",
      "gists_url": "https://api.github.com/users/lidizheng/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lidizheng/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lidizheng/subscriptions",
      "organizations_url": "https://api.github.com/users/lidizheng/orgs",
      "repos_url": "https://api.github.com/users/lidizheng/repos",
      "events_url": "https://api.github.com/users/lidizheng/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lidizheng/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-02-28T22:10:17Z",
    "updated_at": "2019-02-28T22:10:17Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jshlbrd I think Eric's option 1 answers your question better. You start gRPC server in the process worker function, and the incoming traffic will be automatically distributed due to \r\nSO_REUSEPORT."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/468470686",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-468470686",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 468470686,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ2ODQ3MDY4Ng==",
    "user": {
      "login": "jshlbrd",
      "id": 5711448,
      "node_id": "MDQ6VXNlcjU3MTE0NDg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5711448?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jshlbrd",
      "html_url": "https://github.com/jshlbrd",
      "followers_url": "https://api.github.com/users/jshlbrd/followers",
      "following_url": "https://api.github.com/users/jshlbrd/following{/other_user}",
      "gists_url": "https://api.github.com/users/jshlbrd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jshlbrd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jshlbrd/subscriptions",
      "organizations_url": "https://api.github.com/users/jshlbrd/orgs",
      "repos_url": "https://api.github.com/users/jshlbrd/repos",
      "events_url": "https://api.github.com/users/jshlbrd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jshlbrd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-02-28T22:49:21Z",
    "updated_at": "2019-02-28T22:49:21Z",
    "author_association": "NONE",
    "body": "@lidizheng -- thanks, yeah that's what I thought, and I was able to get something like that working for my application. However, that spins up a gRPC server in each child process, I was curious if it's possible to run one gRPC server from the main process and distribute the calls to a group of child processes. My main use for this is to support use of signals -- you can't use signals from within threads, but you can from within processes."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/468489061",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-468489061",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 468489061,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ2ODQ4OTA2MQ==",
    "user": {
      "login": "lidizheng",
      "id": 7394928,
      "node_id": "MDQ6VXNlcjczOTQ5Mjg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/7394928?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lidizheng",
      "html_url": "https://github.com/lidizheng",
      "followers_url": "https://api.github.com/users/lidizheng/followers",
      "following_url": "https://api.github.com/users/lidizheng/following{/other_user}",
      "gists_url": "https://api.github.com/users/lidizheng/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lidizheng/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lidizheng/subscriptions",
      "organizations_url": "https://api.github.com/users/lidizheng/orgs",
      "repos_url": "https://api.github.com/users/lidizheng/repos",
      "events_url": "https://api.github.com/users/lidizheng/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lidizheng/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-01T00:02:45Z",
    "updated_at": "2019-03-01T00:02:45Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jshlbrd Unfortunately, the fork type you are talking about is currently not supported for gRPC Python server. The fork support currently only available for gRPC Python client, and it is actually harder than people expected. We are using C extension and perform a lot of IO without GIL with multiple threads with different responsibilities, and it is challenging to prevent CPython from dead locking itself."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/468524588",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-468524588",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 468524588,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ2ODUyNDU4OA==",
    "user": {
      "login": "gnossen",
      "id": 1644595,
      "node_id": "MDQ6VXNlcjE2NDQ1OTU=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1644595?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gnossen",
      "html_url": "https://github.com/gnossen",
      "followers_url": "https://api.github.com/users/gnossen/followers",
      "following_url": "https://api.github.com/users/gnossen/following{/other_user}",
      "gists_url": "https://api.github.com/users/gnossen/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gnossen/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gnossen/subscriptions",
      "organizations_url": "https://api.github.com/users/gnossen/orgs",
      "repos_url": "https://api.github.com/users/gnossen/repos",
      "events_url": "https://api.github.com/users/gnossen/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gnossen/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-01T03:02:22Z",
    "updated_at": "2019-03-01T18:48:30Z",
    "author_association": "CONTRIBUTOR",
    "body": "It's worth noting that our [`manylinux` wheels do not support `SO_REUSEPORT`](https://github.com/grpc/grpc/issues/18210), so for the moment, if you want to take advantage of this feature on Linux, you'll need to compile from source. You can do this by installing with `pip install gprcio --no-binary grpcio`."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/470185940",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-470185940",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 470185940,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3MDE4NTk0MA==",
    "user": {
      "login": "jshlbrd",
      "id": 5711448,
      "node_id": "MDQ6VXNlcjU3MTE0NDg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5711448?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jshlbrd",
      "html_url": "https://github.com/jshlbrd",
      "followers_url": "https://api.github.com/users/jshlbrd/followers",
      "following_url": "https://api.github.com/users/jshlbrd/following{/other_user}",
      "gists_url": "https://api.github.com/users/jshlbrd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jshlbrd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jshlbrd/subscriptions",
      "organizations_url": "https://api.github.com/users/jshlbrd/orgs",
      "repos_url": "https://api.github.com/users/jshlbrd/repos",
      "events_url": "https://api.github.com/users/jshlbrd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jshlbrd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-06T16:53:36Z",
    "updated_at": "2019-03-06T16:58:27Z",
    "author_association": "NONE",
    "body": "I'd like to share this as a proposed workaround for this problem and seek feedback on this technique. Here's a proof-of-concept for how I've got this working (warning, some pseudo-code is present here):\r\n\r\n```py\r\nfrom concurrent import futures\r\nfrom concurrent.futures import TimeoutError\r\n\r\nimport grpc\r\nimport pebble\r\n\r\ndef make_widget(i):\r\n    return i * 2\r\n\r\nclass WidgetServicer(widget_pb2_grpc.WidgetServicer):\r\n    def __init__(self, pool):\r\n        self.pool = pool\r\n\r\n    def WidgetRequest(self, request, context):\r\n        response = widget_pb2.Response()\r\n        future = self.pool.schedule(make_widget, args=[request.Value], timeout=context.time_remaining())\r\n\r\n        try:\r\n            response.Widget = future.result()\r\n        except TimeoutError:\r\n            context.abort(grpc.StatusCode.DEADLINE_EXCEEDED, 'Timeout')  # this handles process timeout\r\n        except pebble.common.ProcessExpired:\r\n            context.abort(grpc.StatusCode.RESOURCE_EXHAUSTED, 'Abnormal termination')  # this handles process crashes        \r\n\r\n        return response\r\n\r\ndef main():\r\n    pool = pebble.ProcessPool(max_workers=processes, max_tasks=tasks)\r\n    executor = futures.ThreadPoolExecutor(max_workers=processes)\r\n    server = grpc.server(executor)\r\n    servicer = WidgetServicer(pool)\r\n    <start your server and block forever>\r\n```\r\n\r\nHere's how _I _think__ this is working: when you set both the ProcessPool and ThreadPoolExecutor to the same count, it locks the gRPC servicer into only feeding requests to the number child processes that are available. If you were to increase the ThreadPoolExecutor count, then requests would queue in the ProcessPool creating a backlog of work that may never be delivered upon; keeping this count the same, the gRPC servicer will maintain control over the life of the request and never queue them in the ProcessPool (if the count of requests exhausts the number of available processes, then eventually the client would get a timeout). \r\n\r\nThere's also some error checking for timeouts and process crashes in the ProcessPool."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/470224826",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-470224826",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 470224826,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3MDIyNDgyNg==",
    "user": {
      "login": "gnossen",
      "id": 1644595,
      "node_id": "MDQ6VXNlcjE2NDQ1OTU=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1644595?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gnossen",
      "html_url": "https://github.com/gnossen",
      "followers_url": "https://api.github.com/users/gnossen/followers",
      "following_url": "https://api.github.com/users/gnossen/following{/other_user}",
      "gists_url": "https://api.github.com/users/gnossen/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gnossen/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gnossen/subscriptions",
      "organizations_url": "https://api.github.com/users/gnossen/orgs",
      "repos_url": "https://api.github.com/users/gnossen/repos",
      "events_url": "https://api.github.com/users/gnossen/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gnossen/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-06T18:40:17Z",
    "updated_at": "2019-03-06T18:40:17Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jshlbrd That's exactly right. To be precise, your maximum concurrency is `min(thread_count, process_count)`. If the bottleneck is your thread count, then requests will queue [here](https://github.com/grpc/grpc/blob/2bd7ad0112f56d2bdbc37d01a431c1e375039f2e/src/python/grpcio/grpc/_server.py#L581). If the bottleneck is your process count, then the queueing will happen at your call to `self.pool.schedule`.\r\n\r\nGenerally, you'll want the process count to match your processor count and you'll want your thread count to be equal to or higher than that (but not too much higher or you'll get thrashing from context switching). This will buy you the maximum possible concurrency.\r\n\r\nBy default, [Python will initialize a `ProcessPoolExecutor` with `max_workers` equal to your processor count and it will initialize a `ThreadPoolExecutor` with a `max_workers` value five times that.](https://docs.python.org/3/library/concurrent.futures.html).\r\n\r\nIt's worth noting that if the work done in your handler releases the GIL, (i.e. by using a C extension like `numpy`), you probably don't need to spawn subprocesses at all."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/470227685",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-470227685",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 470227685,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3MDIyNzY4NQ==",
    "user": {
      "login": "jshlbrd",
      "id": 5711448,
      "node_id": "MDQ6VXNlcjU3MTE0NDg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5711448?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jshlbrd",
      "html_url": "https://github.com/jshlbrd",
      "followers_url": "https://api.github.com/users/jshlbrd/followers",
      "following_url": "https://api.github.com/users/jshlbrd/following{/other_user}",
      "gists_url": "https://api.github.com/users/jshlbrd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jshlbrd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jshlbrd/subscriptions",
      "organizations_url": "https://api.github.com/users/jshlbrd/orgs",
      "repos_url": "https://api.github.com/users/jshlbrd/repos",
      "events_url": "https://api.github.com/users/jshlbrd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jshlbrd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-06T18:47:45Z",
    "updated_at": "2019-03-06T18:47:45Z",
    "author_association": "NONE",
    "body": "Woohoo, thanks for the feedback! \r\n\r\nYou're correct with regard to possibly not needing subprocesses. In my case, the tasks being performed by the gRPC server are CPU-intensive and can range in time from sub-second to several minutes -- that's why I need to use subprocesses that can be timed out."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/472228435",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-472228435",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 472228435,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3MjIyODQzNQ==",
    "user": {
      "login": "gnossen",
      "id": 1644595,
      "node_id": "MDQ6VXNlcjE2NDQ1OTU=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/1644595?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gnossen",
      "html_url": "https://github.com/gnossen",
      "followers_url": "https://api.github.com/users/gnossen/followers",
      "following_url": "https://api.github.com/users/gnossen/following{/other_user}",
      "gists_url": "https://api.github.com/users/gnossen/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gnossen/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gnossen/subscriptions",
      "organizations_url": "https://api.github.com/users/gnossen/orgs",
      "repos_url": "https://api.github.com/users/gnossen/repos",
      "events_url": "https://api.github.com/users/gnossen/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gnossen/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-13T00:06:27Z",
    "updated_at": "2019-03-13T00:08:10Z",
    "author_association": "CONTRIBUTOR",
    "body": "Hopefully, [this example](https://github.com/grpc/grpc/tree/b8241addc380e63b28be850c3da2fb04dc75212b/examples/python/multiprocessing) will serve as a good reference for anyone who runs across this in the future."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/472243284",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-472243284",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 472243284,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3MjI0MzI4NA==",
    "user": {
      "login": "jshlbrd",
      "id": 5711448,
      "node_id": "MDQ6VXNlcjU3MTE0NDg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5711448?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jshlbrd",
      "html_url": "https://github.com/jshlbrd",
      "followers_url": "https://api.github.com/users/jshlbrd/followers",
      "following_url": "https://api.github.com/users/jshlbrd/following{/other_user}",
      "gists_url": "https://api.github.com/users/jshlbrd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jshlbrd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jshlbrd/subscriptions",
      "organizations_url": "https://api.github.com/users/jshlbrd/orgs",
      "repos_url": "https://api.github.com/users/jshlbrd/repos",
      "events_url": "https://api.github.com/users/jshlbrd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jshlbrd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-13T01:24:46Z",
    "updated_at": "2019-03-13T02:08:37Z",
    "author_association": "NONE",
    "body": "That’s a good example of utilizing multiple cores when your server isn’t running CPU-intensive tasks, but I think it still may not address the need to natively support process pools and thread pools. \r\n\r\nFor example, when using that example as a template for CPU-intensive tasks, you could reduce the number of threads inside each gRPC servicer to one, but because each sub process is running a different server, they aren’t working from a shared RPC queue and (IIRC) reuseport appears to randomly select one of the connected servers — depending on your application, this can lead to uneven balancing across cores.\r\n\r\nProbably goes without saying that no one should think of reuseport as anything more than a simple load balancer, but the value of a single RPC queue is lost in that example. \r\n\r\nEdit: Reading into reuseport more, it uses IP/port hashing to distribute packets to the servers. I’m curious if that means that any of these gRPC servers behind a load balancer (like Envoy) would lead to uneven distribution. I haven’t tested this, but it’s leading me to believe that a more stable solution may be to use a local load balancer and spin up multiple gRPC servers on different ports? "
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/472490685",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-472490685",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 472490685,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3MjQ5MDY4NQ==",
    "user": {
      "login": "jshlbrd",
      "id": 5711448,
      "node_id": "MDQ6VXNlcjU3MTE0NDg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5711448?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jshlbrd",
      "html_url": "https://github.com/jshlbrd",
      "followers_url": "https://api.github.com/users/jshlbrd/followers",
      "following_url": "https://api.github.com/users/jshlbrd/following{/other_user}",
      "gists_url": "https://api.github.com/users/jshlbrd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jshlbrd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jshlbrd/subscriptions",
      "organizations_url": "https://api.github.com/users/jshlbrd/orgs",
      "repos_url": "https://api.github.com/users/jshlbrd/repos",
      "events_url": "https://api.github.com/users/jshlbrd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jshlbrd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-13T16:08:48Z",
    "updated_at": "2019-03-13T16:08:48Z",
    "author_association": "NONE",
    "body": "Based on more testing, I'm now convinced that pre-forking via subprocess pools isn't a viable method for handling this (too many failure scenarios to deal with). Here's a summary of techniques that _can work_ with their pitfalls:\r\n\r\n**Pools (including multiprocessing.Pool, billiard.Pool)**:\r\nSetup pool before gRPC server is started (pre-fork)\r\nMust ensure that no subprocesses crash or stop, otherwise pool becomes broken\r\nMust ensure that no subprocesses are restarted, otherwise main thread seg faults\r\n\r\n**Processes w/ SO_REUSEPORT**:\r\nSetup processes, each process runs its own gRPC server bound to the same port w/ SO_REUSEPORT (pre-fork)\r\nSO_REUSEPORT uses IP/port hashing for load balancing and will lead to uneven task distribution if a single client sends many requests\r\nSO_REUSEPORT may lead to uneven task distribution when used with a frontend proxy/load balancer (e.g. Envoy) (untested)\r\nRPC queue not shared across processes\r\n\r\n**Processes w/o SO_REUSEPORT**:\r\nSetup processes, each process runs its own gRPC server bound to a unique port (pre-fork)\r\nRequires a local load balancer to distribute tasks\r\nRPC queue not shared across processes"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/475439137",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-475439137",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 475439137,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3NTQzOTEzNw==",
    "user": {
      "login": "jshlbrd",
      "id": 5711448,
      "node_id": "MDQ6VXNlcjU3MTE0NDg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5711448?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jshlbrd",
      "html_url": "https://github.com/jshlbrd",
      "followers_url": "https://api.github.com/users/jshlbrd/followers",
      "following_url": "https://api.github.com/users/jshlbrd/following{/other_user}",
      "gists_url": "https://api.github.com/users/jshlbrd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jshlbrd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jshlbrd/subscriptions",
      "organizations_url": "https://api.github.com/users/jshlbrd/orgs",
      "repos_url": "https://api.github.com/users/jshlbrd/repos",
      "events_url": "https://api.github.com/users/jshlbrd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jshlbrd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-21T23:19:56Z",
    "updated_at": "2019-03-21T23:20:48Z",
    "author_association": "NONE",
    "body": "@gnossen any feedback on using the file system to communicate tasks between gRPC threads and subprocesses? I don't know the gRPC internals well enough to know if post-forking subprocesses that do not directly interact with the gRPC service would cause problems in this scenario. Here's some pseudo-code ...\r\n\r\n```py\r\nTMP_REQ = '/path/to/your/tmp/requests/'\r\nTMP_RESP = '/path/to/your/tmp/responses/'\r\n\r\nclass WidgetServicer(widget_pb2_grpc.WidgetServicer):\r\n    def __init__(self, queue):\r\n        self.queue = queue\r\n\r\n    def StreamWidget(self, request_iterator, context):\r\n        resp = widget_pb2.Response()\r\n        uid = uuid.uuid4().hex\r\n        tmp_req = os.path.join(TMP_REQ, uid)\r\n        tmp_resp = os.path.join(TMP_RESP, uid)\r\n\r\n        with open(tmp_req, 'wb') as f:\r\n            for request in request_iterator:\r\n                f.write(request.widget)\r\n\r\n        self.queue.put(\r\n             {'tmp_req': tmp_req,\r\n             'tmp_resp': tmp_resp,\r\n             'timeout': context.time_remaining()},\r\n        )\r\n\r\n        while context.is_active():\r\n            if os.path.isfile(tmp_resp):\r\n                with open(tmp_resp) as f:\r\n                    resp.widget = f.read()\r\n                os.remove(tmp_resp)\r\n                return resp\r\n            time.sleep(0.1)\r\n\r\n\r\nrun = 1\r\n\r\n\r\ndef main():\r\n    def handler(sig, frame):\r\n        global run\r\n        run = 0\r\n\r\n    signal.signal(signal.SIGTERM, handler)\r\n    signal.signal(signal.SIGINT, handler)\r\n\r\n    q = multiprocessing.Queue()\r\n    workers = []\r\n    for _ in range(4):\r\n        p = Worker(q)  # multiprocessing.process or some other kind of subproc\r\n        p.start()\r\n        workers.append(p)\r\n\r\n\r\n    executor = futures.ThreadPoolExecutor(max_workers=8)\r\n    server = grpc.server(executor,\r\n                         maximum_concurrent_rpcs=100)\r\n    widget_pb2_grpc.add_WidgetServicer_to_server(WidgetServicer(q), server)\r\n    server.add_insecure_port('127.0.0.1:8443')\r\n    server.start()\r\n\r\n    while run:\r\n        for p in list(workers):\r\n            if not p.is_alive():\r\n                p.join()\r\n                workers.remove(p)\r\n                p = Worker(q)  # multiprocessing.process or some other kind of subproc\r\n                p.start()\r\n                workers.append(p)\r\n        time.sleep(5)\r\n\r\n    stop = server.stop(10)\r\n    stop.wait()\r\n    for p in list(workers):\r\n        p.shutdown()\r\n        p.join()\r\n```\r\n\r\nI have code that follows this pattern that appears to work, but I'd like to get some confirmation that this design doesn't cause issues with the gRPC internals. "
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/475460559",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-475460559",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 475460559,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3NTQ2MDU1OQ==",
    "user": {
      "login": "lidizheng",
      "id": 7394928,
      "node_id": "MDQ6VXNlcjczOTQ5Mjg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/7394928?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lidizheng",
      "html_url": "https://github.com/lidizheng",
      "followers_url": "https://api.github.com/users/lidizheng/followers",
      "following_url": "https://api.github.com/users/lidizheng/following{/other_user}",
      "gists_url": "https://api.github.com/users/lidizheng/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lidizheng/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lidizheng/subscriptions",
      "organizations_url": "https://api.github.com/users/lidizheng/orgs",
      "repos_url": "https://api.github.com/users/lidizheng/repos",
      "events_url": "https://api.github.com/users/lidizheng/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lidizheng/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-22T01:19:17Z",
    "updated_at": "2019-03-22T01:19:17Z",
    "author_association": "CONTRIBUTOR",
    "body": "@jshlbrd Communicating through files will result in race condition unless you are using RWLock or similar synchronization mechanism. In another word, you may read incomplete data.\r\n\r\nAlso, if you want to start new Worker in the second half, using `subprocess` might be a better choice.\r\n\r\nPS. Couple days ago, @gnossen confirmed that SO_REUSEPORT is not evenly distributing the workload across processes. Thank you for pointing that out."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/475464141",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-475464141",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 475464141,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3NTQ2NDE0MQ==",
    "user": {
      "login": "jshlbrd",
      "id": 5711448,
      "node_id": "MDQ6VXNlcjU3MTE0NDg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5711448?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jshlbrd",
      "html_url": "https://github.com/jshlbrd",
      "followers_url": "https://api.github.com/users/jshlbrd/followers",
      "following_url": "https://api.github.com/users/jshlbrd/following{/other_user}",
      "gists_url": "https://api.github.com/users/jshlbrd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jshlbrd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jshlbrd/subscriptions",
      "organizations_url": "https://api.github.com/users/jshlbrd/orgs",
      "repos_url": "https://api.github.com/users/jshlbrd/repos",
      "events_url": "https://api.github.com/users/jshlbrd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jshlbrd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-22T01:39:25Z",
    "updated_at": "2019-03-22T03:04:33Z",
    "author_association": "NONE",
    "body": "Thanks for the info! I think for my app synchronization is handled by\r\nsequencing, but it’d be helpful if you could double check my logic here ...\r\nthe request is written to a unique file by the RPC, a pointer to that (now\r\nclosed) request file is placed in a multiprocessing queue, and the RPC sits\r\nin a while loop waiting for a response file to be written; at the same\r\ntime, worker processes run continuously trying to pick tasks off the queue,\r\nthey pick a task, read/delete the request file, process the task, and write\r\nthe result to the response file pre-determined by the RPC. After the RPC\r\nreads the response file, it deletes it. The RPC and workers should never\r\ntouch the files while each are being operated over.\r\n\r\nThe risk that needs to be accounted for is what happens when an RPC times\r\nout — this could leave dangling files. However, that could be handled by a\r\nseparate process (e.g. delete any files that haven’t been modified for N\r\nseconds/minutes).\r\n\r\nConvoluted, but it can work if the gRPC servicer is OK with processes\r\nspawning after the service is started — that’s my main concern. The only\r\ndirect communication between the gRPC threads and processes are via the\r\nqueue.\r\n\r\nUpdate: Thought about this a bit more and I suspect that using Redis might be a better option than the file system -- all operations are atomic so there's no risk of race conditions if the proper commands are used. \r\n\r\nOn Thu, Mar 21, 2019 at 6:19 PM Lidi Zheng <notifications@github.com> wrote:\r\n\r\n> @jshlbrd <https://github.com/jshlbrd> Communicating through files will\r\n> result in race condition unless you are using RWLock or similar\r\n> synchronization mechanism. In another word, you may read incomplete data.\r\n>\r\n> Also, if you want to start new Worker in the second half, using subprocess\r\n> might be a better choice.\r\n>\r\n> PS. Couple days ago, @gnossen <https://github.com/gnossen> confirmed that\r\n> SO_REUSEPORT is not evenly distributing the workload across processes.\r\n> Thank you for pointing that out.\r\n>\r\n> —\r\n> You are receiving this because you were mentioned.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/grpc/grpc/issues/16001#issuecomment-475460559>, or mute\r\n> the thread\r\n> <https://github.com/notifications/unsubscribe-auth/AFcmWN52VILYCH7HY4OsPZzQ6DMtmphjks5vZC-vgaJpZM4VMnia>\r\n> .\r\n>\r\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/475730674",
    "html_url": "https://github.com/grpc/grpc/issues/16001#issuecomment-475730674",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/16001",
    "id": 475730674,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3NTczMDY3NA==",
    "user": {
      "login": "jshlbrd",
      "id": 5711448,
      "node_id": "MDQ6VXNlcjU3MTE0NDg=",
      "avatar_url": "https://avatars1.githubusercontent.com/u/5711448?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jshlbrd",
      "html_url": "https://github.com/jshlbrd",
      "followers_url": "https://api.github.com/users/jshlbrd/followers",
      "following_url": "https://api.github.com/users/jshlbrd/following{/other_user}",
      "gists_url": "https://api.github.com/users/jshlbrd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jshlbrd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jshlbrd/subscriptions",
      "organizations_url": "https://api.github.com/users/jshlbrd/orgs",
      "repos_url": "https://api.github.com/users/jshlbrd/repos",
      "events_url": "https://api.github.com/users/jshlbrd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jshlbrd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-22T18:25:47Z",
    "updated_at": "2019-03-22T18:31:19Z",
    "author_association": "NONE",
    "body": "Apologies for spamming the issue, but here's a more complete example of what I described in the previous message. All of these Redis commands are atomic, which enables synchronization. Things become more complicated (but not impossible) when dealing with streaming RPCs.\r\n\r\n```python\r\nclass Worker(multiprocessing.process):  # or use some other kind of subproc\r\n    def __init__(self):\r\n        super().__init__()\r\n        # used as the task queue\r\n        self.r0 = redis.StrictRedis(host='localhost', port=6379, db=0)\r\n        # used to temporarily store requests\r\n        self.r1 = redis.StrictRedis(host='localhost', port=6379, db=1)\r\n        # used to temporarily store results\r\n        self.r2 = redis.StrictRedis(host='localhost', port=6379, db=2)\r\n\r\n    def run(self):\r\n        while 1:\r\n            task = self.r0.blpop('queue', timeout=1)  # wait forever w/ timeout=0\r\n            if task:\r\n                loaded_task = json.loads(task[1])\r\n                try:\r\n                    with interruptingcow.timeout(loaded_task['timeout'], RuntimeError):  # interruptingcow is a convenient package for timing out operations, but you could substitute signal too\r\n                        request = self.r1.get(loaded_task['uid'])\r\n                        result = process(request)  # do something with the request\r\n                        self.r2.setex(task['uid'], 30, result)\r\n                except RuntimeError:\r\n                    print('RPC timed out')\r\n    \r\n\r\nclass WidgetServicer(widget_pb2_grpc.WidgetServicer):\r\n    def __init__(self):\r\n        # used as a task queue\r\n        self.r0 = redis.StrictRedis(host='localhost', port=6379, db=0)\r\n        # used to temporarily store requests\r\n        self.r1 = redis.StrictRedis(host='localhost', port=6379, db=1)\r\n        # used to temporarily store results\r\n        self.r2 = redis.StrictRedis(host='localhost', port=6379, db=2)\r\n\r\n        \r\n    def UnaryWidget(self, request, context):\r\n        resp = widget_pb2.Response()\r\n        uid = uuid.uuid4().hex\r\n        task = {\r\n            'uid': uid,\r\n            '...': {},  # add any additional data provided by request to the task\r\n        }\r\n\r\n        self.r1.setex(uid, 30, request.widget)\r\n        task['timeout'] = context.time_remaining()\r\n        self.r0.rpush('queue', json.dumps(task))\r\n\r\n        while context.is_active():\r\n            result = self.r2.get(uid)\r\n            if result is not None:\r\n                resp.widget = result\r\n                break\r\n            time.sleep(0.1)\r\n\r\n        return resp\r\n\r\n\r\nrun = 1\r\n\r\n\r\ndef main():\r\n    def handler(sig, frame):\r\n        global run\r\n        run = 0\r\n\r\n    signal.signal(signal.SIGTERM, handler)\r\n    signal.signal(signal.SIGINT, handler)\r\n\r\n    workers = []\r\n    for _ in range(4):\r\n        p = Worker()  # multiprocessing.process or some other kind of subproc\r\n        p.start()\r\n        workers.append(p)\r\n\r\n    executor = futures.ThreadPoolExecutor(max_workers=4)\r\n    server = grpc.server(executor,\r\n                         maximum_concurrent_rpcs=100)\r\n    widget_pb2_grpc.add_WidgetServicer_to_server(WidgetServicer(), server)\r\n    server.add_insecure_port('127.0.0.1:8443')  # please don't do this in production\r\n    server.start()\r\n\r\n    while run:\r\n        for p in list(workers):\r\n            if not p.is_alive():\r\n                p.join()\r\n                workers.remove(p)\r\n                p = Worker()  # multiprocessing.process or some other kind of subproc\r\n                p.start()\r\n                workers.append(p)\r\n        time.sleep(5)\r\n\r\n    stop = server.stop(10)\r\n    stop.wait()\r\n    for p in list(workers):\r\n        p.shutdown()\r\n        p.join()\r\n```\r\n\r\nThere's some flexibility here with which Redis commands are used (e.g. I am explicitly not deleting keys from the Redis databases and instead letting the expiration time clean everything up) and a simple service would likely only need to utilize two Redis databases. I think this might be the only solution proposed so far that lets you safely integrate rotating subprocesses with a gRPC servicer that uses a single bound network address?\r\n\r\ncc @gnossen @lidizheng "
  }
]
