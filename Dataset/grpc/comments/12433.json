[
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/327965460",
    "html_url": "https://github.com/grpc/grpc/issues/12433#issuecomment-327965460",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12433",
    "id": 327965460,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMyNzk2NTQ2MA==",
    "user": {
      "login": "vjpai",
      "id": 8864912,
      "node_id": "MDQ6VXNlcjg4NjQ5MTI=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/8864912?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vjpai",
      "html_url": "https://github.com/vjpai",
      "followers_url": "https://api.github.com/users/vjpai/followers",
      "following_url": "https://api.github.com/users/vjpai/following{/other_user}",
      "gists_url": "https://api.github.com/users/vjpai/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vjpai/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vjpai/subscriptions",
      "organizations_url": "https://api.github.com/users/vjpai/orgs",
      "repos_url": "https://api.github.com/users/vjpai/repos",
      "events_url": "https://api.github.com/users/vjpai/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vjpai/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-09-08T00:22:01Z",
    "updated_at": "2017-09-08T00:22:01Z",
    "author_association": "MEMBER",
    "body": "Should probably just not let a send message op actually complete until its contents are recv'ed. That will have the effect of maintaining the 1 op rule from the surface all the way down through the transport. As @ctiller points out, HTTP has to buffer to tolerate network latency but that isn't an issue for inproc. Additionally, moving away from slice_buffer_list might enable the use of less locking down the road."
  }
]
