[
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/271134118",
    "html_url": "https://github.com/grpc/grpc/pull/9237#issuecomment-271134118",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/9237",
    "id": 271134118,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI3MTEzNDExOA==",
    "user": {
      "login": "qiuxd",
      "id": 20919073,
      "node_id": "MDQ6VXNlcjIwOTE5MDcz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/20919073?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/qiuxd",
      "html_url": "https://github.com/qiuxd",
      "followers_url": "https://api.github.com/users/qiuxd/followers",
      "following_url": "https://api.github.com/users/qiuxd/following{/other_user}",
      "gists_url": "https://api.github.com/users/qiuxd/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/qiuxd/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/qiuxd/subscriptions",
      "organizations_url": "https://api.github.com/users/qiuxd/orgs",
      "repos_url": "https://api.github.com/users/qiuxd/repos",
      "events_url": "https://api.github.com/users/qiuxd/events{/privacy}",
      "received_events_url": "https://api.github.com/users/qiuxd/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-01-08T06:55:26Z",
    "updated_at": "2017-01-10T01:42:46Z",
    "author_association": "NONE",
    "body": "my sence is not like this.\r\n\r\nthe first request is sended out, while the second request is stilled in waiting_concurrent list.\r\nthe second call will time out . and i try to destroy it, it will core down.\r\n\r\ni try to write the gt case below,  it may not correct, but it will core down with errors info“client stream 0 still included in list 11” .\r\n\r\n```cpp\r\nstatic void test_max_concurrent_streams_with_timeout_2(\r\n    grpc_end2end_test_config config) {\r\n  grpc_end2end_test_fixture f;\r\n  grpc_arg server_arg;\r\n  grpc_channel_args server_args;\r\n  grpc_call *c1;\r\n  grpc_call *c2;\r\n  grpc_call *s1;\r\n//  grpc_call *s2;\r\n  cq_verifier *cqv;\r\n  grpc_call_details call_details;\r\n  grpc_metadata_array request_metadata_recv;\r\n  grpc_metadata_array initial_metadata_recv1;\r\n  grpc_metadata_array trailing_metadata_recv1;\r\n  grpc_metadata_array initial_metadata_recv2;\r\n  grpc_metadata_array trailing_metadata_recv2;\r\n  grpc_status_code status1;\r\n  grpc_call_error error;\r\n  char *details1 = NULL;\r\n  size_t details_capacity1 = 0;\r\n  grpc_status_code status2;\r\n  char *details2 = NULL;\r\n  size_t details_capacity2 = 0;\r\n  grpc_op ops[6];\r\n  grpc_op *op;\r\n  int was_cancelled;\r\n\r\n  server_arg.key = GRPC_ARG_MAX_CONCURRENT_STREAMS;\r\n  server_arg.type = GRPC_ARG_INTEGER;\r\n  server_arg.value.integer = 1;\r\n\r\n  server_args.num_args = 1;\r\n  server_args.args = &server_arg;\r\n\r\n  f = begin_test(config, \"test_max_concurrent_streams_with_timeout\", NULL,\r\n                 &server_args);\r\n  cqv = cq_verifier_create(f.cq);\r\n\r\n  grpc_metadata_array_init(&request_metadata_recv);\r\n  grpc_metadata_array_init(&initial_metadata_recv1);\r\n  grpc_metadata_array_init(&trailing_metadata_recv1);\r\n  grpc_metadata_array_init(&initial_metadata_recv2);\r\n  grpc_metadata_array_init(&trailing_metadata_recv2);\r\n  grpc_call_details_init(&call_details);\r\n\r\n  /* perform a ping-pong to ensure that settings have had a chance to round\r\n     trip */\r\n  simple_request_body(f);\r\n  /* perform another one to make sure that the one stream case still works */\r\n  simple_request_body(f);\r\n\r\n  /* start two requests - ensuring that the second is not accepted until\r\n     the first completes , and the second request will timeout in the concurrent_list */\r\n  c1 = grpc_channel_create_call(f.client, NULL, GRPC_PROPAGATE_DEFAULTS, f.cq,\r\n                                \"/alpha\", \"foo.test.google.fr:1234\",\r\n                                n_seconds_time(1000), NULL);\r\n  GPR_ASSERT(c1);\r\n  c2 = grpc_channel_create_call(f.client, NULL, GRPC_PROPAGATE_DEFAULTS, f.cq,\r\n                                \"/beta\", \"foo.test.google.fr:1234\",\r\n                                n_seconds_time(3), NULL);\r\n  GPR_ASSERT(c2);\r\n\r\n  GPR_ASSERT(GRPC_CALL_OK == grpc_server_request_call(\r\n                                 f.server, &s1, &call_details,\r\n                                 &request_metadata_recv, f.cq, f.cq, tag(101)));\r\n\r\n  memset(ops, 0, sizeof(ops));\r\n  op = ops;\r\n  op->op = GRPC_OP_SEND_INITIAL_METADATA;\r\n  op->data.send_initial_metadata.count = 0;\r\n  op->flags = 0;\r\n  op->reserved = NULL;\r\n  op++;\r\n  op->op = GRPC_OP_SEND_CLOSE_FROM_CLIENT;\r\n  op->flags = 0;\r\n  op->reserved = NULL;\r\n  op++;\r\n  error = grpc_call_start_batch(c1, ops, (size_t)(op - ops), tag(301), NULL);\r\n  GPR_ASSERT(GRPC_CALL_OK == error);\r\n\r\n  memset(ops, 0, sizeof(ops));\r\n  op = ops;\r\n  op->op = GRPC_OP_RECV_STATUS_ON_CLIENT;\r\n  op->data.recv_status_on_client.trailing_metadata = &trailing_metadata_recv1;\r\n  op->data.recv_status_on_client.status = &status1;\r\n  op->data.recv_status_on_client.status_details = &details1;\r\n  op->data.recv_status_on_client.status_details_capacity = &details_capacity1;\r\n  op->flags = 0;\r\n  op->reserved = NULL;\r\n  op++;\r\n  op->op = GRPC_OP_RECV_INITIAL_METADATA;\r\n  op->data.recv_initial_metadata = &initial_metadata_recv1;\r\n  op->flags = 0;\r\n  op->reserved = NULL;\r\n  op++;\r\n  error = grpc_call_start_batch(c1, ops, (size_t)(op - ops), tag(302), NULL);\r\n  GPR_ASSERT(GRPC_CALL_OK == error);\r\n\r\n  cq_expect_completion(cqv, tag(101), 1);\r\n  cq_expect_completion(cqv, tag(301), 1);\r\n  cq_verify(cqv);\r\n\r\n  memset(ops, 0, sizeof(ops));\r\n  op = ops;\r\n  op->op = GRPC_OP_SEND_INITIAL_METADATA;\r\n  op->data.send_initial_metadata.count = 0;\r\n  op->flags = 0;\r\n  op->reserved = NULL;\r\n  op++;\r\n  op->op = GRPC_OP_SEND_CLOSE_FROM_CLIENT;\r\n  op->flags = 0;\r\n  op->reserved = NULL;\r\n  op++;\r\n  error = grpc_call_start_batch(c2, ops, (size_t)(op - ops), tag(401), NULL);\r\n  GPR_ASSERT(GRPC_CALL_OK == error);\r\n\r\n  memset(ops, 0, sizeof(ops));\r\n  op = ops;\r\n  op->op = GRPC_OP_RECV_STATUS_ON_CLIENT;\r\n  op->data.recv_status_on_client.trailing_metadata = &trailing_metadata_recv2;\r\n  op->data.recv_status_on_client.status = &status2;\r\n  op->data.recv_status_on_client.status_details = &details2;\r\n  op->data.recv_status_on_client.status_details_capacity = &details_capacity2;\r\n  op->flags = 0;\r\n  op->reserved = NULL;\r\n  op++;\r\n  op->op = GRPC_OP_RECV_INITIAL_METADATA;\r\n  op->data.recv_initial_metadata = &initial_metadata_recv1;\r\n  op->flags = 0;\r\n  op->reserved = NULL;\r\n  op++;\r\n  error = grpc_call_start_batch(c2, ops, (size_t)(op - ops), tag(402), NULL);\r\n  GPR_ASSERT(GRPC_CALL_OK == error);\r\n\r\n  /* the second request is time out*/\r\n  cq_expect_completion(cqv, tag(401), 0);\r\n  cq_expect_completion(cqv, tag(402), 1);\r\n  cq_verify(cqv);\r\n  \r\n  /* second request is finished because of time out, so destroy the second call */\r\n  grpc_call_destroy(c2);\r\n\r\n  /* now reply the first call */\r\n  memset(ops, 0, sizeof(ops));\r\n  op = ops;\r\n  op->op = GRPC_OP_SEND_INITIAL_METADATA;\r\n  op->data.send_initial_metadata.count = 0;\r\n  op->flags = 0;\r\n  op->reserved = NULL;\r\n  op++;\r\n  op->op = GRPC_OP_RECV_CLOSE_ON_SERVER;\r\n  op->data.recv_close_on_server.cancelled = &was_cancelled;\r\n  op->flags = 0;\r\n  op->reserved = NULL;\r\n  op++;\r\n  op->op = GRPC_OP_SEND_STATUS_FROM_SERVER;\r\n  op->data.send_status_from_server.trailing_metadata_count = 0;\r\n  op->data.send_status_from_server.status = GRPC_STATUS_UNIMPLEMENTED;\r\n  op->data.send_status_from_server.status_details = \"xyz\";\r\n  op->flags = 0;\r\n  op->reserved = NULL;\r\n  op++;\r\n  error = grpc_call_start_batch(s1, ops, (size_t)(op - ops), tag(102), NULL);\r\n  GPR_ASSERT(GRPC_CALL_OK == error);\r\n\r\n  cq_expect_completion(cqv, tag(302), 1);\r\n  cq_expect_completion(cqv, tag(102), 1);\r\n  cq_verify(cqv);\r\n\r\n  cq_verifier_destroy(cqv);\r\n\r\n  grpc_call_destroy(c1);\r\n  grpc_call_destroy(s1);\r\n\r\n\r\n  gpr_free(details1);\r\n  gpr_free(details2);\r\n  grpc_metadata_array_destroy(&initial_metadata_recv1);\r\n  grpc_metadata_array_destroy(&trailing_metadata_recv1);\r\n  grpc_metadata_array_destroy(&initial_metadata_recv2);\r\n  grpc_metadata_array_destroy(&trailing_metadata_recv2);\r\n  grpc_metadata_array_destroy(&request_metadata_recv);\r\n  grpc_call_details_destroy(&call_details);\r\n\r\n  end_test(&f);\r\n  config.tear_down_data(&f);\r\n}\r\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/272495269",
    "html_url": "https://github.com/grpc/grpc/pull/9237#issuecomment-272495269",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/9237",
    "id": 272495269,
    "node_id": "MDEyOklzc3VlQ29tbWVudDI3MjQ5NTI2OQ==",
    "user": {
      "login": "ctiller",
      "id": 10120821,
      "node_id": "MDQ6VXNlcjEwMTIwODIx",
      "avatar_url": "https://avatars3.githubusercontent.com/u/10120821?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ctiller",
      "html_url": "https://github.com/ctiller",
      "followers_url": "https://api.github.com/users/ctiller/followers",
      "following_url": "https://api.github.com/users/ctiller/following{/other_user}",
      "gists_url": "https://api.github.com/users/ctiller/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ctiller/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ctiller/subscriptions",
      "organizations_url": "https://api.github.com/users/ctiller/orgs",
      "repos_url": "https://api.github.com/users/ctiller/repos",
      "events_url": "https://api.github.com/users/ctiller/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ctiller/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-01-13T17:24:07Z",
    "updated_at": "2017-01-13T17:24:07Z",
    "author_association": "MEMBER",
    "body": "Ok, so adding your test reproduces the failure on this branch.\r\n\r\nI've gone ahead and additionally added it to master in #9236 and it doesn't reproduce (so I'm claiming this fixed at master).\r\n\r\nThe fix will be included in an upcoming release."
  }
]
