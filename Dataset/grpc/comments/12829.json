[
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/334290875",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-334290875",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 334290875,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNDI5MDg3NQ==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-04T21:12:06Z",
    "updated_at": "2017-10-04T21:12:06Z",
    "author_association": "NONE",
    "body": "```\n[trickle] No significant performance differences\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/334305487",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-334305487",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 334305487,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNDMwNTQ4Nw==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-04T22:16:42Z",
    "updated_at": "2017-10-04T22:16:42Z",
    "author_association": "NONE",
    "body": "```\n[microbenchmarks] No significant performance differences\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/334642939",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-334642939",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 334642939,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNDY0MjkzOQ==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-06T02:33:01Z",
    "updated_at": "2017-10-06T02:33:01Z",
    "author_association": "NONE",
    "body": "```\n****************************************************************\n\nlibgrpc.so\n\n     VM SIZE                                                                                FILE SIZE\n ++++++++++++++ GROWING                                                                  ++++++++++++++\n  +0.0%    +224 [None]                                                                      +616  +0.0%\n  +0.4%     +64 src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc               +64  +0.4%\n       +18%     +52 update_lb_connectivity_status_locked                                         +52   +18%\n      +5.1%      +8 glb_ping_one_locked                                                           +8  +5.1%\n      +1.8%      +8 glb_lb_channel_on_connectivity_changed_cb                                     +8  +1.8%\n      +1.1%      +3 glb_destroy                                                                   +3  +1.1%\n       +25%      +3 glb_check_connectivity_locked                                                 +3   +25%\n       +33%      +3 glb_notify_on_state_change_locked                                             +3   +33%\n  +0.4%     +48 src/core/ext/filters/client_channel/client_channel.cc                        +48  +0.4%\n      [NEW]     +66 request_reresolution_locked                                                  +66  [NEW]\n      +1.9%     +48 on_resolver_result_changed_locked                                            +48  +1.9%\n      +6.2%     +14 [Unmapped]                                                                   +14  +6.2%\n  +0.2%     +16 src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc     +16  +0.2%\n       +20%     +26 [Unmapped]                                                                   +26   +20%\n      +1.9%      +8 rr_shutdown_locked                                                            +8  +1.9%\n      +1.7%      +8 get_next_ready_subchannel_index_locked                                        +8  +1.7%\n      +0.2%      +3 rr_update_locked                                                              +3  +0.2%\n      +1.9%      +3 update_last_ready_subchannel_index_locked                                     +3  +1.9%\n\n  +0.0%    +352 TOTAL                                                                       +744  +0.0%\n\n\n****************************************************************\n\nlibgrpc++.so\n\n     VM SIZE        FILE SIZE\n ++++++++++++++  ++++++++++++++\n\n  [ = ]       0        0  [ = ]\n\n\n\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/334643740",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-334643740",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 334643740,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNDY0Mzc0MA==",
    "user": {
      "login": "AspirinSJL",
      "id": 3314176,
      "node_id": "MDQ6VXNlcjMzMTQxNzY=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/3314176?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AspirinSJL",
      "html_url": "https://github.com/AspirinSJL",
      "followers_url": "https://api.github.com/users/AspirinSJL/followers",
      "following_url": "https://api.github.com/users/AspirinSJL/following{/other_user}",
      "gists_url": "https://api.github.com/users/AspirinSJL/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AspirinSJL/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AspirinSJL/subscriptions",
      "organizations_url": "https://api.github.com/users/AspirinSJL/orgs",
      "repos_url": "https://api.github.com/users/AspirinSJL/repos",
      "events_url": "https://api.github.com/users/AspirinSJL/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AspirinSJL/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-06T02:39:59Z",
    "updated_at": "2017-10-06T02:39:59Z",
    "author_association": "MEMBER",
    "body": "Still looking at an assertion failure and an asan issues.\r\n```\r\nI1005 19:34:15.665715543  157105 grpclb_end2end_test.cc:250] LB[0x613000009a40]: done\r\nI1005 19:34:15.665852224  156891 grpclb_end2end_test.cc:141] Backend: shut down\r\nI1005 19:34:15.665869706  156891 grpclb_end2end_test.cc:549] backend about to shutdown\r\nI1005 19:34:15.666483184  156891 grpclb_end2end_test.cc:552] backend shutdown completed\r\nI1005 19:34:15.666535424  156891 grpclb_end2end_test.cc:141] Backend: shut down\r\nI1005 19:34:15.666550492  156891 grpclb_end2end_test.cc:549] backend about to shutdown\r\nI1005 19:34:15.666953983  156891 grpclb_end2end_test.cc:552] backend shutdown completed\r\nI1005 19:34:15.666966769  156891 grpclb_end2end_test.cc:141] Backend: shut down\r\nI1005 19:34:15.666972903  156891 grpclb_end2end_test.cc:549] backend about to shutdown\r\nI1005 19:34:15.667397472  156891 grpclb_end2end_test.cc:552] backend shutdown completed\r\nI1005 19:34:15.667419721  156891 grpclb_end2end_test.cc:141] Backend: shut down\r\nI1005 19:34:15.667427434  156891 grpclb_end2end_test.cc:549] backend about to shutdown\r\ngrpclb_end2end_test: src/core/lib/iomgr/closure.cc:183: void grpc_closure_sched(const char *, int, grpc_exec_ctx *, grpc_closure *, grpc_error *): Assertion `c->cb' failed.\r\n\r\n\r\n\r\n*******************************\r\nCaught signal SIGABRT\r\nbins/asan/grpclb_end2end_test(backtrace+0x61)[0x46b5e1]\r\nbins/asan/grpclb_end2end_test[0xfcfa25]\r\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x10330)[0x7fdd8845d330]\r\n/lib/x86_64-linux-gnu/libc.so.6(gsignal+0x37)[0x7fdd87980c37]\r\n/lib/x86_64-linux-gnu/libc.so.6(abort+0x148)[0x7fdd87984028]\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x2fbf6)[0x7fdd87979bf6]\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x2fca2)[0x7fdd87979ca2]\r\nbins/asan/grpclb_end2end_test[0x6b1549]\r\nbins/asan/grpclb_end2end_test[0xa43a32]\r\nbins/asan/grpclb_end2end_test[0x6b3394]\r\nbins/asan/grpclb_end2end_test[0x6c42f1]\r\nI1005 19:34:15.667926353  156891 grpclb_end2end_test.cc:552] backend shutdown completed\r\nbins/asan/grpclb_end2end_test[0x739c8a]\r\nbins/asan/grpclb_end2end_test[0x72f82f]\r\nbins/asan/grpclb_end2end_test[0x6c2df5]\r\nI1005 19:34:15.667961984  156891 grpclb_end2end_test.cc:265] LB[0x613000009a40]: shut down\r\nbins/asan/grpclb_end2end_test[0x87867d]\r\nbins/asan/grpclb_end2end_test[0x8748af]\r\nI1005 19:34:15.667972461  156891 grpclb_end2end_test.cc:549] balancer about to shutdown\r\nbins/asan/grpclb_end2end_test[0x7a8216]\r\nbins/asan/grpclb_end2end_test[0x78caf8]\r\nbins/asan/grpclb_end2end_test[0x7e5677]\r\nbins/asan/grpclb_end2end_test[0x803fbd]\r\nbins/asan/grpclb_end2end_test[0x803d96]\r\nbins/asan/grpclb_end2end_test[0x80b2ff]\r\nbins/asan/grpclb_end2end_test[0x80b125]\r\nbins/asan/grpclb_end2end_test[0x80b080]\r\nbins/asan/grpclb_end2end_test[0x80aa27]\r\n/usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb1a60)[0x7fdd87fdaa60]\r\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x8184)[0x7fdd88455184]\r\n/lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7fdd87a47ffd]\r\n```\r\n\r\n```\r\n==157272==ERROR: AddressSanitizer: heap-use-after-free on address 0x60300001db98 at pc 0x0000008e74a8 bp 0x7f06dcb38dc0 sp 0x7f06dcb38db8\r\nREAD of size 8 at 0x60300001db98 thread T14\r\n    #0 0x8e74a7 in grpc_subchannel_key_compare /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/subchannel_index.cc:74:11\r\n    #1 0xa33e61 in pf_update_locked(grpc_exec_ctx*, grpc_lb_policy*, grpc_lb_policy_args const*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc:364:11\r\n    #2 0x8dae22 in grpc_lb_policy_update_locked /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/lb_policy.cc:163:3\r\n    #3 0x8d3a0d in on_resolver_result_changed_locked(grpc_exec_ctx*, void*, grpc_error*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/client_channel.cc:443:7\r\n    #4 0x6b3393 in grpc_combiner_continue_exec_ctx /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/combiner.cc:260:5\r\n    #5 0x6c42f0 in grpc_exec_ctx_flush /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/exec_ctx.cc:93:17\r\n    #6 0x73a297 in end_worker(grpc_exec_ctx*, grpc_pollset*, grpc_pollset_worker*, grpc_pollset_worker**) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/ev_epoll1_linux.cc:917:7\r\n    #7 0x72f82e in pollset_work(grpc_exec_ctx*, grpc_pollset*, grpc_pollset_worker**, gpr_timespec, gpr_timespec) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/ev_epoll1_linux.cc:989:3\r\n    #8 0x6c2df4 in grpc_pollset_work /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/ev_posix.cc:210:10\r\n    #9 0x87867c in cq_next(grpc_completion_queue*, gpr_timespec, void*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/surface/completion_queue.cc:897:23\r\n    #10 0x8748ae in grpc_completion_queue_next /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/surface/completion_queue.cc:978:10\r\n    #11 0x7a8215 in grpc::CompletionQueue::AsyncNextInternal(void**, bool*, gpr_timespec) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/cpp/common/completion_queue_cc.cc:56:15\r\n    #12 0x78caf7 in grpc::CompletionQueue::NextStatus grpc::CompletionQueue::AsyncNext<gpr_timespec>(void**, bool*, gpr_timespec const&) /usr/local/google/home/juanlishen/wip/reresolution/grpc/include/grpc++/impl/codegen/completion_queue.h:125:12\r\n    #13 0x7e5676 in grpc::Server::SyncRequestThreadManager::PollForWork(void**, bool*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/cpp/server/server_cc.cc:272:13\r\n    #14 0x803fbc in grpc::ThreadManager::MainWorkLoop() /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/cpp/thread_manager/thread_manager.cc:122:30\r\n    #15 0x803d95 in grpc::ThreadManager::WorkerThread::Run() /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/cpp/thread_manager/thread_manager.cc:38:3\r\n    #16 0x80b2fe in void std::_Mem_fn<void (grpc::ThreadManager::WorkerThread::*)()>::operator()<, void>(grpc::ThreadManager::WorkerThread*) const /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../../include/c++/4.8/functional:601:11\r\n    #17 0x80b124 in void std::_Bind_simple<std::_Mem_fn<void (grpc::ThreadManager::WorkerThread::*)()> (grpc::ThreadManager::WorkerThread*)>::_M_invoke<0ul>(std::_Index_tuple<0ul>) /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../../include/c++/4.8/functional:1731:18\r\n    #18 0x80b07f in std::_Bind_simple<std::_Mem_fn<void (grpc::ThreadManager::WorkerThread::*)()> (grpc::ThreadManager::WorkerThread*)>::operator()() /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../../include/c++/4.8/functional:1720:16\r\n    #19 0x80aa26 in std::thread::_Impl<std::_Bind_simple<std::_Mem_fn<void (grpc::ThreadManager::WorkerThread::*)()> (grpc::ThreadManager::WorkerThread*)> >::_M_run() /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../../include/c++/4.8/thread:115:13\r\n    #20 0x7f08703d0a5f in execute_native_thread_routine /build/gcc-4.8-mW1ufQ/gcc-4.8-4.8.4/build/x86_64-linux-gnu/libstdc++-v3/src/c++11/../../../../../src/libstdc++-v3/src/c++11/thread.cc:84\r\n    #21 0x7f087084b183 in start_thread /build/eglibc-SvCtMH/eglibc-2.19/nptl/pthread_create.c:312\r\n    #22 0x7f086fe3dffc in clone /build/eglibc-SvCtMH/eglibc-2.19/misc/../sysdeps/unix/sysv/linux/x86_64/clone.S:111\r\n\r\n0x60300001db98 is located 8 bytes inside of 24-byte region [0x60300001db90,0x60300001dba8)\r\nfreed by thread T14 here:\r\n    #0 0x4c12ab in free /home/development/llvm/3.8.1/final/llvm.src/projects/compiler-rt/lib/asan/asan_malloc_linux.cc:38:3\r\n    #1 0x812afe in gpr_free /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/support/alloc.cc:78:3\r\n    #2 0x8e7971 in grpc_subchannel_key_destroy /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/subchannel_index.cc:88:3\r\n    #3 0x8df1e9 in subchannel_destroy(grpc_exec_ctx*, void*, grpc_error*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/subchannel.cc:192:3\r\n    #4 0x6b0be6 in closure_wrapper(grpc_exec_ctx*, void*, grpc_error*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/closure.cc:116:3\r\n    #5 0x6c490b in exec_ctx_run(grpc_exec_ctx*, grpc_closure*, grpc_error*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/exec_ctx.cc:70:3\r\n    #6 0x6c428a in grpc_exec_ctx_flush /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/exec_ctx.cc:90:9\r\n    #7 0x73a297 in end_worker(grpc_exec_ctx*, grpc_pollset*, grpc_pollset_worker*, grpc_pollset_worker**) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/ev_epoll1_linux.cc:917:7\r\n    #8 0x72f82e in pollset_work(grpc_exec_ctx*, grpc_pollset*, grpc_pollset_worker**, gpr_timespec, gpr_timespec) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/ev_epoll1_linux.cc:989:3\r\n    #9 0x6c2df4 in grpc_pollset_work /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/ev_posix.cc:210:10\r\n    #10 0x87867c in cq_next(grpc_completion_queue*, gpr_timespec, void*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/surface/completion_queue.cc:897:23\r\n    #11 0x8748ae in grpc_completion_queue_next /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/surface/completion_queue.cc:978:10\r\n    #12 0x7a8215 in grpc::CompletionQueue::AsyncNextInternal(void**, bool*, gpr_timespec) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/cpp/common/completion_queue_cc.cc:56:15\r\n    #13 0x78caf7 in grpc::CompletionQueue::NextStatus grpc::CompletionQueue::AsyncNext<gpr_timespec>(void**, bool*, gpr_timespec const&) /usr/local/google/home/juanlishen/wip/reresolution/grpc/include/grpc++/impl/codegen/completion_queue.h:125:12\r\n    #14 0x7e5676 in grpc::Server::SyncRequestThreadManager::PollForWork(void**, bool*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/cpp/server/server_cc.cc:272:13\r\n    #15 0x803fbc in grpc::ThreadManager::MainWorkLoop() /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/cpp/thread_manager/thread_manager.cc:122:30\r\n    #16 0x803d95 in grpc::ThreadManager::WorkerThread::Run() /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/cpp/thread_manager/thread_manager.cc:38:3\r\n    #17 0x80b2fe in void std::_Mem_fn<void (grpc::ThreadManager::WorkerThread::*)()>::operator()<, void>(grpc::ThreadManager::WorkerThread*) const /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../../include/c++/4.8/functional:601:11\r\n    #18 0x80b124 in void std::_Bind_simple<std::_Mem_fn<void (grpc::ThreadManager::WorkerThread::*)()> (grpc::ThreadManager::WorkerThread*)>::_M_invoke<0ul>(std::_Index_tuple<0ul>) /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../../include/c++/4.8/functional:1731:18\r\n    #19 0x80b07f in std::_Bind_simple<std::_Mem_fn<void (grpc::ThreadManager::WorkerThread::*)()> (grpc::ThreadManager::WorkerThread*)>::operator()() /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../../include/c++/4.8/functional:1720:16\r\n    #20 0x80aa26 in std::thread::_Impl<std::_Bind_simple<std::_Mem_fn<void (grpc::ThreadManager::WorkerThread::*)()> (grpc::ThreadManager::WorkerThread*)> >::_M_run() /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../../include/c++/4.8/thread:115:13\r\n    #21 0x7f08703d0a5f in execute_native_thread_routine /build/gcc-4.8-mW1ufQ/gcc-4.8-4.8.4/build/x86_64-linux-gnu/libstdc++-v3/src/c++11/../../../../../src/libstdc++-v3/src/c++11/thread.cc:84\r\n\r\npreviously allocated by thread T0 here:\r\n    #0 0x4c15cb in __interceptor_malloc /home/development/llvm/3.8.1/final/llvm.src/projects/compiler-rt/lib/asan/asan_malloc_linux.cc:52:3\r\n    #1 0x8127f7 in gpr_malloc /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/support/alloc.cc:56:7\r\n    #2 0x8e70cf in create_key(grpc_subchannel_args const*, grpc_channel_args* (*)(grpc_channel_args const*)) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/subchannel_index.cc:48:51\r\n    #3 0x8e7074 in grpc_subchannel_key_create /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/subchannel_index.cc:64:10\r\n    #4 0x8df46e in grpc_subchannel_create /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/subchannel.cc:288:30\r\n    #5 0x8ee8f6 in client_channel_factory_create_subchannel(grpc_exec_ctx*, grpc_client_channel_factory*, grpc_subchannel_args const*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/transport/chttp2/client/insecure/channel_create.cc:43:24\r\n    #6 0x8d9982 in grpc_client_channel_factory_create_subchannel /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/client_channel_factory.cc:34:10\r\n    #7 0xa348d3 in pf_update_locked(grpc_exec_ctx*, grpc_lb_policy*, grpc_lb_policy_args const*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc:409:35\r\n    #8 0xa32f13 in create_pick_first(grpc_exec_ctx*, grpc_lb_policy_factory*, grpc_lb_policy_args*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc:678:3\r\n    #9 0x716e92 in grpc_lb_policy_factory_create_lb_policy /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/lb_policy_factory.cc:168:10\r\n    #10 0x8db3fa in grpc_lb_policy_create /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/lb_policy_registry.cc:68:7\r\n    #11 0x8d3a4f in on_resolver_result_changed_locked(grpc_exec_ctx*, void*, grpc_error*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/client_channel.cc:447:11\r\n    #12 0x6b3393 in grpc_combiner_continue_exec_ctx /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/combiner.cc:260:5\r\n    #13 0x6c42f0 in grpc_exec_ctx_flush /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/exec_ctx.cc:93:17\r\n    #14 0x6c3ed4 in grpc_exec_ctx_finish /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/iomgr/exec_ctx.cc:56:3\r\n    #15 0x85456d in grpc_call_start_batch /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/lib/surface/call.cc:2088:3\r\n    #16 0x787aeb in grpc::Channel::PerformOpsOnCall(grpc::CallOpSetInterface*, grpc::Call*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/cpp/client/channel_cc.cc:303:3\r\n    #17 0x5438e7 in grpc::Call::PerformOps(grpc::CallOpSetInterface*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/include/grpc++/impl/codegen/call.h:699:5\r\n    #18 0x6458d3 in grpc::Status grpc::BlockingUnaryCall<grpc::testing::EchoRequest, grpc::testing::EchoResponse>(grpc::ChannelInterface*, grpc::RpcMethod const&, grpc::ClientContext*, grpc::testing::EchoRequest const&, grpc::testing::EchoResponse*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/include/grpc++/impl/codegen/client_unary_call.h:58:3\r\n    #19 0x63f5f7 in grpc::testing::EchoTestService::Stub::Echo(grpc::ClientContext*, grpc::testing::EchoRequest const&, grpc::testing::EchoResponse*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/gens/src/proto/grpc/testing/echo.grpc.pb.cc:41:10\r\n    #20 0x59bb8e in grpc::testing::(anonymous namespace)::GrpclbEnd2endTest::SendRpc(grpc::testing::EchoResponse*, int) /usr/local/google/home/juanlishen/wip/reresolution/grpc/test/cpp/end2end/grpclb_end2end_test.cc:495:21\r\n    #21 0x598d93 in grpc::testing::(anonymous namespace)::GrpclbEnd2endTest::CheckRpcSendOk(unsigned long) /usr/local/google/home/juanlishen/wip/reresolution/grpc/test/cpp/end2end/grpclb_end2end_test.cc:503:29\r\n    #22 0x5c630d in grpc::testing::(anonymous namespace)::SingleBalancerTest_DropAll_Test::TestBody() /usr/local/google/home/juanlishen/wip/reresolution/grpc/test/cpp/end2end/grpclb_end2end_test.cc:1132:3\r\n    #23 0x150a4cb in void testing::internal::HandleSehExceptionsInMethodIfSupported<testing::Test, void>(testing::Test*, void (testing::Test::*)(), char const*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/third_party/googletest/googletest/src/gtest.cc:2402:10\r\n    #24 0x14dc4c0 in void testing::internal::HandleExceptionsInMethodIfSupported<testing::Test, void>(testing::Test*, void (testing::Test::*)(), char const*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/third_party/googletest/googletest/src/gtest.cc:2438:14\r\n    #25 0x14a7b99 in testing::Test::Run() /usr/local/google/home/juanlishen/wip/reresolution/grpc/third_party/googletest/googletest/src/gtest.cc:2474:5\r\n    #26 0x14a99fc in testing::TestInfo::Run() /usr/local/google/home/juanlishen/wip/reresolution/grpc/third_party/googletest/googletest/src/gtest.cc:2656:5\r\n    #27 0x14aab91 in testing::TestCase::Run() /usr/local/google/home/juanlishen/wip/reresolution/grpc/third_party/googletest/googletest/src/gtest.cc:2774:5\r\n    #28 0x14ba47c in testing::internal::UnitTestImpl::RunAllTests() /usr/local/google/home/juanlishen/wip/reresolution/grpc/third_party/googletest/googletest/src/gtest.cc:4649:11\r\n    #29 0x1512d16 in bool testing::internal::HandleSehExceptionsInMethodIfSupported<testing::internal::UnitTestImpl, bool>(testing::internal::UnitTestImpl*, bool (testing::internal::UnitTestImpl::*)(), char const*) /usr/local/google/home/juanlishen/wip/reresolution/grpc/third_party/googletest/googletest/src/gtest.cc:2402:10\r\n\r\nThread T14 created by T12 here:\r\n    #0 0x4a9989 in pthread_create /home/development/llvm/3.8.1/final/llvm.src/projects/compiler-rt/lib/asan/asan_interceptors.cc:238:3\r\n    #1 0x7f08703d0cae in __gthread_create /build/gcc-4.8-mW1ufQ/gcc-4.8-4.8.4/build/x86_64-linux-gnu/libstdc++-v3/include/x86_64-linux-gnu/bits/gthr-default.h:662\r\n    #2 0x7f08703d0cae in std::thread::_M_start_thread(std::shared_ptr<std::thread::_Impl_base>) /build/gcc-4.8-mW1ufQ/gcc-4.8-4.8.4/build/x86_64-linux-gnu/libstdc++-v3/src/c++11/../../../../../src/libstdc++-v3/src/c++11/thread.cc:142\r\n    #3 0x7f06ddb3d87f  (<unknown module>)\r\n\r\nThread T12 created by T11 here:\r\n    #0 0x4a9989 in pthread_create /home/development/llvm/3.8.1/final/llvm.src/projects/compiler-rt/lib/asan/asan_interceptors.cc:238:3\r\n    #1 0x7f08703d0cae in __gthread_create /build/gcc-4.8-mW1ufQ/gcc-4.8-4.8.4/build/x86_64-linux-gnu/libstdc++-v3/include/x86_64-linux-gnu/bits/gthr-default.h:662\r\n    #2 0x7f08703d0cae in std::thread::_M_start_thread(std::shared_ptr<std::thread::_Impl_base>) /build/gcc-4.8-mW1ufQ/gcc-4.8-4.8.4/build/x86_64-linux-gnu/libstdc++-v3/src/c++11/../../../../../src/libstdc++-v3/src/c++11/thread.cc:142\r\n    #3 0x15622d2 in _fini (/usr/local/google/home/juanlishen/wip/reresolution/grpc/bins/asan/grpclb_end2end_test+0x15622d2)\r\n\r\nThread T11 created by T0 here:\r\n    #0 0x4a9989 in pthread_create /home/development/llvm/3.8.1/final/llvm.src/projects/compiler-rt/lib/asan/asan_interceptors.cc:238:3\r\n    #1 0x7f08703d0cae in __gthread_create /build/gcc-4.8-mW1ufQ/gcc-4.8-4.8.4/build/x86_64-linux-gnu/libstdc++-v3/include/x86_64-linux-gnu/bits/gthr-default.h:662\r\n    #2 0x7f08703d0cae in std::thread::_M_start_thread(std::shared_ptr<std::thread::_Impl_base>) /build/gcc-4.8-mW1ufQ/gcc-4.8-4.8.4/build/x86_64-linux-gnu/libstdc++-v3/src/c++11/../../../../../src/libstdc++-v3/src/c++11/thread.cc:142\r\n\r\nSUMMARY: AddressSanitizer: heap-use-after-free /usr/local/google/home/juanlishen/wip/reresolution/grpc/src/core/ext/filters/client_channel/subchannel_index.cc:74:11 in grpc_subchannel_key_compare\r\nShadow bytes around the buggy address:\r\n  0x0c067fffbb20: fd fd fa fa fd fd fd fa fa fa fd fd fd fa fa fa\r\n  0x0c067fffbb30: fd fd fd fa fa fa fd fd fd fa fa fa fd fd fd fa\r\n  0x0c067fffbb40: fa fa fd fd fd fd fa fa fd fd fd fa fa fa fd fd\r\n  0x0c067fffbb50: fd fa fa fa fd fd fd fd fa fa fd fd fd fd fa fa\r\n  0x0c067fffbb60: fd fd fd fa fa fa fd fd fd fa fa fa fd fd fd fd\r\n=>0x0c067fffbb70: fa fa fd[fd]fd fa fa fa fd fd fd fa fa fa fd fd\r\n  0x0c067fffbb80: fd fa fa fa fd fd fd fd fa fa fd fd fd fd fa fa\r\n  0x0c067fffbb90: fd fd fd fa fa fa fd fd fd fa fa fa fd fd fd fd\r\n  0x0c067fffbba0: fa fa fd fd fd fd fa fa fd fd fd fa fa fa fd fd\r\n  0x0c067fffbbb0: fd fa fa fa fd fd fd fa fa fa fd fd fd fa fa fa\r\n  0x0c067fffbbc0: fd fd fd fd fa fa fd fd fd fa fa fa fd fd fd fa\r\nShadow byte legend (one shadow byte represents 8 application bytes):\r\n  Addressable:           00\r\n  Partially addressable: 01 02 03 04 05 06 07 \r\n  Heap left redzone:       fa\r\n  Heap right redzone:      fb\r\n  Freed heap region:       fd\r\n  Stack left redzone:      f1\r\n  Stack mid redzone:       f2\r\n  Stack right redzone:     f3\r\n  Stack partial redzone:   f4\r\n  Stack after return:      f5\r\n  Stack use after scope:   f8\r\n  Global redzone:          f9\r\n  Global init order:       f6\r\n  Poisoned by user:        f7\r\n  Container overflow:      fc\r\n  Array cookie:            ac\r\n  Intra object redzone:    bb\r\n  ASan internal:           fe\r\n  Left alloca redzone:     ca\r\n  Right alloca redzone:    cb\r\n==157272==ABORTING\r\n\r\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/334646854",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-334646854",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 334646854,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNDY0Njg1NA==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-06T03:08:22Z",
    "updated_at": "2017-10-06T03:08:22Z",
    "author_association": "NONE",
    "body": "```\n[trickle] No significant performance differences\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/334653646",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-334653646",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 334653646,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNDY1MzY0Ng==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-06T04:15:39Z",
    "updated_at": "2017-10-06T04:15:39Z",
    "author_association": "NONE",
    "body": "```\n[microbenchmarks] No significant performance differences\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/334816835",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-334816835",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 334816835,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNDgxNjgzNQ==",
    "user": {
      "login": "markdroth",
      "id": 18664614,
      "node_id": "MDQ6VXNlcjE4NjY0NjE0",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18664614?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdroth",
      "html_url": "https://github.com/markdroth",
      "followers_url": "https://api.github.com/users/markdroth/followers",
      "following_url": "https://api.github.com/users/markdroth/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdroth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdroth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdroth/subscriptions",
      "organizations_url": "https://api.github.com/users/markdroth/orgs",
      "repos_url": "https://api.github.com/users/markdroth/repos",
      "events_url": "https://api.github.com/users/markdroth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdroth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-06T17:18:00Z",
    "updated_at": "2017-10-06T17:18:00Z",
    "author_association": "MEMBER",
    "body": "Looks like you're on the right track here.  Please let me know if you have any questions about any of this.  Thanks!\n\n---\n\nReviewed 5 of 7 files at r2.\nReview status: all files reviewed at latest revision, 13 unresolved discussions, some commit checks failed.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 371 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmO8jgD7y2iELPz4cL:-KvmO8jgD7y2iELPz4cM:b-5kr3d8) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/client_channel.cc#L371)):*\n> ```cpp\n>   }\n>   channel_data *chand = (channel_data *)arg;\n>   grpc_resolver_channel_saw_error_locked(exec_ctx, chand->resolver);\n> ```\n\nWhat if `chand->resolver` has been set to NULL (which happens when the channel is shutting down) by the time this runs?\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 372 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmMKh2SQcHfkRLgLFL:-KvmMKh2SQcHfkRLgLFM:b-1kvy9f) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/client_channel.cc#L372)):*\n> ```cpp\n>   channel_data *chand = (channel_data *)arg;\n>   grpc_resolver_channel_saw_error_locked(exec_ctx, chand->resolver);\n>   GRPC_CLOSURE_INIT(&chand->lb_policy->request_reresolution,\n> ```\n\nNote that scheduling and running a closure does not modify its callback, argument, or scheduler (the three parameters set when the closure is initialized).  Therefore, there is no need to re-initialize it here -- since we're just resetting these three fields to the same values that had before, this is effectively a no-op.\n\nWhat we actually need here is a way to inform the LB policy that we're giving it back the callback.  See below for details.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 523 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmHKDSfi5a5NYYnaPg:-KvmHKDSfi5a5NYYnaPh:beu55np) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/client_channel.cc#L523)):*\n> ```cpp\n>   // If we have a new LB policy or are shutting down (in which case\n>   // new_lb_policy will be NULL), swap out the LB policy, unreffing the\n>   // old one, removing its fds from chand->interested_parties and cancelling\n> ```\n\nGrammar nit: Please add an Oxford comma here. :)\n\nhttps://www.verbicidemagazine.com/wp-content/uploads/2011/09/Oxford-Comma.jpg\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 538 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmHbRIQDLvDeRZ5CB0:-KvmHbRIQDLvDeRZ5CB1:bbycgug) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/client_channel.cc#L538)):*\n> ```cpp\n>                                        chand->lb_policy->interested_parties,\n>                                        chand->interested_parties);\n>       GRPC_CLOSURE_SCHED(exec_ctx, &chand->lb_policy->request_reresolution,\n> ```\n\nThis is not safe, for two reasons:\n1. We do not know at this moment whether or not the closure has already been scheduled, and if it has, scheduling it a second time will be a use-after-free bug.\n2. The closure will run on the same combiner that we are currently holding, which means that it will not run until after this function returns.  However, the closure is a member of the LB policy object, and we are unreffing that object below, which means that the LB policy object (and hence the closure object) may be destroyed by the time the closure runs, this causing another use-after-free bug.\n\nMore generally, I think it would be useful to take a step back and consider this from a design perspective.\n\nFirst, which module should be responsible for ensuring that the callback is invoked exactly once whenever it is set?  Currently, it looks like you're trying to make the client_channel code responsible for doing that.  However, I don't think that can work, because it's the LB policy code that is responsible for deciding when to schedule it.  If the LB policy code decides when to schedule it, then there's no way that the client_channel code can know when that is happening, so it can't possibly ensure that it gets called exactly once -- it simply doesn't have enough information.  Therefore, it has to be the LB policy's responsibility.\n\nSecond, which module should contain the closure object?  In general, the object whose code is being called should provide the closure object, for two reasons:\n- The lifetimes of the closure object and the object whose code is being called are linked.  The object whose code is being called needs to continue to exist until after the closure runs, and the closure no longer needs to exist after the object whose code is being called is destroyed.  In this case, the client_channel code is being called, so the client_channel code should also own the closure object.\n- It doesn't make sense for the object *scheduling* the closure to own the closure object, because it's the object whose code is being called that needs to set the content of the closure.  In general, we don't want to have one object modifying another object's internal state, since that violates the abstraction being provided by that second object's API.  In this case, we don't want client_channel to modify state owned by the LB policy object.\n\nOkay, so we need to structure the code such that (a) the closure object is owned by the client_channel object and (b) the LB policy provides a guarantee that the closure will be invoked only once.  I suggest the following:\n- The LB policy object will include a pointer to a closure, rather than the closure itself.  Whenever the closure is scheduled, the LB policy will reset its pointer to NULL, to ensure that it cannot be scheduled a second time.\n- The client_channel will pass a pointer to the closure to the LB policy when it creates the LB policy, as part of the `grpc_lb_policy_args` struct.\n- There will be a new method added to the LB policy API to give it a new closure (again, as a pointer) after it has called the previous one.  The callback in the client_channel code will call this method to give the closure back to the LB policy after it has run.\n- When the LB policy's shutdown method is called, it will schedule the closure with `GRPC_ERROR_CANCELLED`.\n- Any place where an LB policy sets the connectivity state to SHUTDOWN *except* for its shutdown method, it should be changed to instead schedule the closure with `GRPC_ERROR_NONE`.\n\nPlease let me know if you have any questions about any of this.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc, line 617 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmXe3_waHBBcVSHfFq:-KvmXe3_waHBBcVSHfFr:by1kdg6) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc#L617)):*\n> ```cpp\n>   switch (rr_state) {\n>     case GRPC_CHANNEL_SHUTDOWN:\n>       GPR_UNREACHABLE_CODE(return );\n> ```\n\nWhen the grpclb policy is shut down (due to the client channel being shut down), we may actually get back SHUTDOWN from the RR policy.  We should just handle that as a no-op.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc, line 542 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmY6ebxAkaUesu7gFW:-KvmY6ebxAkaUesu7gFX:b-mqe3bj) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc#L542)):*\n> ```cpp\n>     return;\n>   } else if (p->selected != NULL) {\n>     if (p->checking_connectivity == GRPC_CHANNEL_TRANSIENT_FAILURE) {\n> ```\n\nRemember that the subchannel code is currently lying -- it will always convert TRANSIENT_FAILURE to SHUTDOWN, so we'll never actually see the former.  But we'll fix that at some point, so let's make sure this code handles both.  We should schedule the closure in either case.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc, line 548 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmZpdvbsQg2nwr9dTv:-KvmZpdvbsQg2nwr9dTw:b-o6g1aa) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc#L548)):*\n> ```cpp\n>     }\n>     grpc_connectivity_state_set(exec_ctx, &p->state_tracker,\n>                                 p->checking_connectivity, GRPC_ERROR_REF(error),\n> ```\n\nIf we get SHUTDOWN, we should set our own state to TRANSIENT_FAILURE instead.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc, line 550 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kvm_L2KO6xQfiWoF5D9:-Kvm_L2KO6xQfiWoF5DA:bfdjr1q) ([raw file](https://github.com/grpc/grpc/blob/998c30dab22b1fb7e15a9b01559a100ea9fdbed3/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc#L550)):*\n>    if (p->checking_connectivity != GRPC_CHANNEL_SHUTDOWN) {\n<details><summary><i alt=\"summary\">Quoted 6 lines of codeâ€¦</i></summary>\n>       grpc_connected_subchannel_notify_on_state_change(\n>           exec_ctx, p->selected, p->base.interested_parties,\n>           &p->checking_connectivity, &p->connectivity_changed);\n>     } else {\n>       GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &p->base, \"pick_first_connectivity\");\n>     }\n</details>\n\nThis code was actually correct as it was.  When a subchannel goes into state SHUTDOWN, it will never come out of that state.  So instead of renewing the connectivity state notification, we should drop the ref that we were holding for the connectivity state callback, just like the code was originally doing.\n\nIn addition, we should also unref `p->selected` and set it to NULL, since that subchannel will never be valid again.  If the resolver returns a new result, we will get an update that will lead to us setting `p->selected` to a new subchannel.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc, line 635 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmaXbylNsO5S71DxA7:-KvmaXbylNsO5S71DxA8:b6dlo4i) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc#L635)):*\n> ```cpp\n>           grpc_connectivity_state_set(exec_ctx, &p->state_tracker,\n>                                       GRPC_CHANNEL_TRANSIENT_FAILURE,\n>                                       GRPC_ERROR_NONE, \"no_more_channels\");\n> ```\n\nWe should use `GRPC_ERROR_REF(error)` instead of `GRPC_ERROR_NONE`.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc, line 639 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmaahQ7OY4eyUEdI63:-KvmaahQ7OY4eyUEdI64:bz10xj3) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc#L639)):*\n> ```cpp\n>                              GRPC_ERROR_NONE);\n>         } else {\n>           grpc_connectivity_state_set(\n> ```\n\nLooks like we're setting the connectivity state the same way in both branches, so let's just do this once before the `if`.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 494 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmbRZLPT6hybMTWG40:-KvmbRZLPT6hybMTWG41:bik0d91) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L494)):*\n> ```cpp\n> }\n> \n> /** Sets the policy's connectivity status based on that of the subchannel list\n> ```\n\nThe original wording of this comment was actually better -- we're looking not just at the subchannel list, but also at the data in `sd` itself.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 495 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmarTLhn98G2w5x81k:-KvmarTLhn98G2w5x81l:b-i2qonn) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L495)):*\n> ```cpp\n> \n> /** Sets the policy's connectivity status based on that of the subchannel list\n>  * \\a sd (the subchannel_data associted with the updated subchannel) belongs to.\n> ```\n\nPre-existing typo: s/associted/associated/\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 509 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kvmf-lYHqUxRrnaLiY4:-Kvmf-lYHqUxRrnaLiY5:b-vofu9j) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L509)):*\n> ```cpp\n>    *    CHECK: sd->curr_connectivity_state == CONNECTING.\n>    *\n>    * 3) RULE: ALL subchannels are IDLE => policy is IDLE.\n> ```\n\nI'm a little leery of changing this logic as part of this PR.  Historically, this logic has been hotly debated, and I'm concerned that it might cause unexpected behavior changes that are visible to users.\n\nI do agree that the existing logic needs improvement, but I would prefer to do that work in a separate PR.  For this PR, let's stick to the existing logic as much as possible, with the only change being how we handle the SHUTDOWN case.\n\n---\n\n\n*Comments from [Reviewable](https://reviewable.io:443/reviews/grpc/grpc/12829#-:-KvmgJ6mbYhMdBjbfVU_:b-78gbyv)*\n<!-- Sent from Reviewable.io -->\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/335318797",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-335318797",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 335318797,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTMxODc5Nw==",
    "user": {
      "login": "AspirinSJL",
      "id": 3314176,
      "node_id": "MDQ6VXNlcjMzMTQxNzY=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/3314176?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AspirinSJL",
      "html_url": "https://github.com/AspirinSJL",
      "followers_url": "https://api.github.com/users/AspirinSJL/followers",
      "following_url": "https://api.github.com/users/AspirinSJL/following{/other_user}",
      "gists_url": "https://api.github.com/users/AspirinSJL/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AspirinSJL/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AspirinSJL/subscriptions",
      "organizations_url": "https://api.github.com/users/AspirinSJL/orgs",
      "repos_url": "https://api.github.com/users/AspirinSJL/repos",
      "events_url": "https://api.github.com/users/AspirinSJL/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AspirinSJL/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-09T23:43:14Z",
    "updated_at": "2017-10-09T23:43:14Z",
    "author_association": "MEMBER",
    "body": "Thanks for the consistently detailed and informative comments! \n\n---\n\nReview status: all files reviewed at latest revision, 13 unresolved discussions, some commit checks failed.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 371 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmO8jgD7y2iELPz4cL:-Kvnd9qrdtT_blF4iEMQ:b-rvtxa8) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/client_channel.cc#L371)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nWhat if `chand->resolver` has been set to NULL (which happens when the channel is shutting down) by the time this runs?\n</blockquote></details>\n\nDone.\n\nI should have considered this availability issue, especially when the original code to do re-resolution also checked it.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 372 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmMKh2SQcHfkRLgLFL:-Kw2PfkNebbnqG5MQDrq:bs7wumb) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/client_channel.cc#L372)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nNote that scheduling and running a closure does not modify its callback, argument, or scheduler (the three parameters set when the closure is initialized).  Therefore, there is no need to re-initialize it here -- since we're just resetting these three fields to the same values that had before, this is effectively a no-op.\n\nWhat we actually need here is a way to inform the LB policy that we're giving it back the callback.  See below for details.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 523 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmHKDSfi5a5NYYnaPg:-Kvnntw_KVhwwqfHc-yA:baaxzny) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/client_channel.cc#L523)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nGrammar nit: Please add an Oxford comma here. :)\n\nhttps://www.verbicidemagazine.com/wp-content/uploads/2011/09/Oxford-Comma.jpg\n</blockquote></details>\n\nDone.\n\nRemembered!\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 538 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmHbRIQDLvDeRZ5CB0:-Kvo3cMy2mDWivWpt4Qs:b-caxlqd) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/client_channel.cc#L538)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nThis is not safe, for two reasons:\n1. We do not know at this moment whether or not the closure has already been scheduled, and if it has, scheduling it a second time will be a use-after-free bug.\n2. The closure will run on the same combiner that we are currently holding, which means that it will not run until after this function returns.  However, the closure is a member of the LB policy object, and we are unreffing that object below, which means that the LB policy object (and hence the closure object) may be destroyed by the time the closure runs, this causing another use-after-free bug.\n\nMore generally, I think it would be useful to take a step back and consider this from a design perspective.\n\nFirst, which module should be responsible for ensuring that the callback is invoked exactly once whenever it is set?  Currently, it looks like you're trying to make the client_channel code responsible for doing that.  However, I don't think that can work, because it's the LB policy code that is responsible for deciding when to schedule it.  If the LB policy code decides when to schedule it, then there's no way that the client_channel code can know when that is happening, so it can't possibly ensure that it gets called exactly once -- it simply doesn't have enough information.  Therefore, it has to be the LB policy's responsibility.\n\nSecond, which module should contain the closure object?  In general, the object whose code is being called should provide the closure object, for two reasons:\n- The lifetimes of the closure object and the object whose code is being called are linked.  The object whose code is being called needs to continue to exist until after the closure runs, and the closure no longer needs to exist after the object whose code is being called is destroyed.  In this case, the client_channel code is being called, so the client_channel code should also own the closure object.\n- It doesn't make sense for the object *scheduling* the closure to own the closure object, because it's the object whose code is being called that needs to set the content of the closure.  In general, we don't want to have one object modifying another object's internal state, since that violates the abstraction being provided by that second object's API.  In this case, we don't want client_channel to modify state owned by the LB policy object.\n\nOkay, so we need to structure the code such that (a) the closure object is owned by the client_channel object and (b) the LB policy provides a guarantee that the closure will be invoked only once.  I suggest the following:\n- The LB policy object will include a pointer to a closure, rather than the closure itself.  Whenever the closure is scheduled, the LB policy will reset its pointer to NULL, to ensure that it cannot be scheduled a second time.\n- The client_channel will pass a pointer to the closure to the LB policy when it creates the LB policy, as part of the `grpc_lb_policy_args` struct.\n- There will be a new method added to the LB policy API to give it a new closure (again, as a pointer) after it has called the previous one.  The callback in the client_channel code will call this method to give the closure back to the LB policy after it has run.\n- When the LB policy's shutdown method is called, it will schedule the closure with `GRPC_ERROR_CANCELLED`.\n- Any place where an LB policy sets the connectivity state to SHUTDOWN *except* for its shutdown method, it should be changed to instead schedule the closure with `GRPC_ERROR_NONE`.\n\nPlease let me know if you have any questions about any of this.\n</blockquote></details>\n\nDone.\n\nSo, generally, the object who schedules the closure should guarantee the exactly-once semantics, and the object whose code will be called back should own the closure. That makes sense to me. \n\nI feel I don't understand \"exactly-once\" clearly. I thought it means any initialized closure should only be invoked (scheduled and run) once, then it's destroyed by the underlying implementation. But as you have mentioned, this is not true. Now my understanding of \"exactly-once\" is like it focuses on ensuring that a closure fulfill its duty to process the resources that we have logically assigned to it. If it's not invoked, we may have memory leak or other issues; if it's invoked multiple times improperly, it's not safe. But it can be scheduled for multiple times once initialized as long as we can ensure those invocations are manipulated into a sequence with proper linking and ending. It's still \"exactly-once\", but in a macro view. \n\nIf the above understanding is correct, should I care about the space a closure itself occupies? Assuming a closure sits in heap memory, how should it be freed? I thought it's done after each invocation. But if not, how does the mechanism works? I haven't found much information by looking at the code.\n\nAlso, if we don't schedule the closure with `GRPC_ERROR_CANCELLED` in client channel, will there be any problem?\n\nThanks!  \n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc, line 617 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmXe3_waHBBcVSHfFq:-Kw1Gti2LdTwDEneB08J:bmfxpif) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc#L617)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nWhen the grpclb policy is shut down (due to the client channel being shut down), we may actually get back SHUTDOWN from the RR policy.  We should just handle that as a no-op.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc, line 542 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmY6ebxAkaUesu7gFW:-Kw1PNE-0A4f6Iv8egMJ:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc#L542)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nRemember that the subchannel code is currently lying -- it will always convert TRANSIENT_FAILURE to SHUTDOWN, so we'll never actually see the former.  But we'll fix that at some point, so let's make sure this code handles both.  We should schedule the closure in either case.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc, line 548 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmZpdvbsQg2nwr9dTv:-Kw1pcIOTB0QuPC7Bdnv:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc#L548)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nIf we get SHUTDOWN, we should set our own state to TRANSIENT_FAILURE instead.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc, line 550 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kvm_L2KO6xQfiWoF5D9:-Kw1paE-VlqDxIifWVhv:bmfxpif) ([raw file](https://github.com/grpc/grpc/blob/998c30dab22b1fb7e15a9b01559a100ea9fdbed3/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc#L550)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\n>    if (p->checking_connectivity != GRPC_CHANNEL_SHUTDOWN) {\n>       grpc_connected_subchannel_notify_on_state_change(\n>           exec_ctx, p->selected, p->base.interested_parties,\n>           &p->checking_connectivity, &p->connectivity_changed);\n>     } else {\n>       GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &p->base, \"pick_first_connectivity\");\n>     }\n\nThis code was actually correct as it was.  When a subchannel goes into state SHUTDOWN, it will never come out of that state.  So instead of renewing the connectivity state notification, we should drop the ref that we were holding for the connectivity state callback, just like the code was originally doing.\n\nIn addition, we should also unref `p->selected` and set it to NULL, since that subchannel will never be valid again.  If the resolver returns a new result, we will get an update that will lead to us setting `p->selected` to a new subchannel.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc, line 635 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmaXbylNsO5S71DxA7:-Kw1qDfdB51D5b152ESi:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc#L635)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nWe should use `GRPC_ERROR_REF(error)` instead of `GRPC_ERROR_NONE`.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc, line 639 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmaahQ7OY4eyUEdI63:-Kw1vm1kWHk9gxYndj2U:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc#L639)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nLooks like we're setting the connectivity state the same way in both branches, so let's just do this once before the `if`.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 494 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmbRZLPT6hybMTWG40:-Kw1xND4ak0QT6JCR1Lk:bz23msg) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L494)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nThe original wording of this comment was actually better -- we're looking not just at the subchannel list, but also at the data in `sd` itself.\n</blockquote></details>\n\nDone.\n\nI thought that generally we are considering the `shubchannel_list`. We need to use `sd` because we don't count the number of `CONNECTING` subchannels.\n\nSo, why don't we count that? Is that because only one subchannel can be in `CONNECTING` status?\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 495 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmarTLhn98G2w5x81k:-Kw1xM209OCMWvsn3Cce:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L495)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nPre-existing typo: s/associted/associated/\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 509 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kvmf-lYHqUxRrnaLiY4:-Kw1y-HmnqbOEi0NGalE:b-afz3jn) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L509)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nI'm a little leery of changing this logic as part of this PR.  Historically, this logic has been hotly debated, and I'm concerned that it might cause unexpected behavior changes that are visible to users.\n\nI do agree that the existing logic needs improvement, but I would prefer to do that work in a separate PR.  For this PR, let's stick to the existing logic as much as possible, with the only change being how we handle the SHUTDOWN case.\n</blockquote></details>\n\nDone.\n\nI see. I will be more conservative when dealing customer-visible changes.\n\n---\n\n\n*Comments from [Reviewable](https://reviewable.io:443/reviews/grpc/grpc/12829#-:-KvnaJn8BXJ89DVynX-l:b-ok988p)*\n<!-- Sent from Reviewable.io -->\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/335320935",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-335320935",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 335320935,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTMyMDkzNQ==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-09T23:58:54Z",
    "updated_at": "2017-10-09T23:58:54Z",
    "author_association": "NONE",
    "body": "```\n****************************************************************\n\nlibgrpc.so\n\n     VM SIZE                                                                                FILE SIZE\n ++++++++++++++ GROWING                                                                  ++++++++++++++\n  +0.1%    +647 [None]                                                                   +2.01Ki  +0.0%\n   +42%    +185 src/core/ext/filters/client_channel/lb_policy.cc                            +185   +42%\n      [NEW]    +111 grpc_lb_policy_try_reresolve_locked                                         +111  [NEW]\n      [NEW]     +59 grpc_lb_policy_set_reresolve_closure_locked                                  +59  [NEW]\n      +9.1%     +12 [Unmapped]                                                                   +12  +9.1%\n      +5.9%      +3 grpc_lb_policy_init                                                           +3  +5.9%\n  +1.3%    +176 src/core/ext/filters/client_channel/client_channel.cc                       +176  +1.3%\n      [NEW]    +162 request_reresolution_locked                                                 +162  [NEW]\n       +17%     +37 [Unmapped]                                                                   +37   +17%\n      +3.3%     +32 cc_init_channel_elem                                                         +32  +3.3%\n      +0.6%     +16 on_resolver_result_changed_locked                                            +16  +0.6%\n      +1.2%      +3 cc_destroy_channel_elem                                                       +3  +1.2%\n      +0.6%      +3 watch_connectivity_state_locked                                               +3  +0.6%\n      +2.9%      +3 grpc_client_channel_check_connectivity_state                                  +3  +2.9%\n\n -------------- SHRINKING                                                                --------------\n  -1.6%    -112 src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc    -112  -1.6%\n      -6.8%    -129 rr_connectivity_changed_locked                                              -129  -6.8%\n  -0.5%     -32 src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc       -32  -0.5%\n      -3.6%     -73 pf_connectivity_changed_locked                                               -73  -3.6%\n\n  +0.1%    +864 TOTAL                                                                    +2.22Ki  +0.0%\n\n\n****************************************************************\n\nlibgrpc++.so\n\n     VM SIZE        FILE SIZE\n ++++++++++++++  ++++++++++++++\n\n  [ = ]       0        0  [ = ]\n\n\n\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/335321877",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-335321877",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 335321877,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTMyMTg3Nw==",
    "user": {
      "login": "AspirinSJL",
      "id": 3314176,
      "node_id": "MDQ6VXNlcjMzMTQxNzY=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/3314176?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AspirinSJL",
      "html_url": "https://github.com/AspirinSJL",
      "followers_url": "https://api.github.com/users/AspirinSJL/followers",
      "following_url": "https://api.github.com/users/AspirinSJL/following{/other_user}",
      "gists_url": "https://api.github.com/users/AspirinSJL/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AspirinSJL/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AspirinSJL/subscriptions",
      "organizations_url": "https://api.github.com/users/AspirinSJL/orgs",
      "repos_url": "https://api.github.com/users/AspirinSJL/repos",
      "events_url": "https://api.github.com/users/AspirinSJL/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AspirinSJL/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-10T00:06:00Z",
    "updated_at": "2017-10-10T00:06:00Z",
    "author_association": "MEMBER",
    "body": "Still has the asan problem."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/335322278",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-335322278",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 335322278,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTMyMjI3OA==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-10T00:08:38Z",
    "updated_at": "2017-10-10T00:08:38Z",
    "author_association": "NONE",
    "body": "```\n[trickle] No significant performance differences\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/335334522",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-335334522",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 335334522,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTMzNDUyMg==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-10T01:40:15Z",
    "updated_at": "2017-10-10T01:40:15Z",
    "author_association": "NONE",
    "body": "```\nCorrupt JSON data (indicates timeout or crash): \n    bm_fullstack_unary_ping_pong.BM_UnaryPingPong_MinTCP_NoOpMutator_NoOpMutator__128M_0.counters.new: 1\n    bm_fullstack_streaming_ping_pong.BM_StreamingPingPongWithCoalescingApi_MinInProcessCHTTP2_NoOpMutator_NoOpMutator__2M_1_0.counters.new: 1\n    bm_fullstack_unary_ping_pong.BM_UnaryPingPong_TCP_NoOpMutator_NoOpMutator__128M_0.counters.new: 2\n    bm_fullstack_unary_ping_pong.BM_UnaryPingPong_MinTCP_NoOpMutator_NoOpMutator__128M_0.opt.new: 2\n    bm_fullstack_unary_ping_pong.BM_UnaryPingPong_TCP_NoOpMutator_NoOpMutator__128M_0.opt.new: 3\n\n\n[microbenchmarks] Performance differences noted:\nBenchmark                                                                              cpu_time    real_time\n-------------------------------------------------------------------------------------  ----------  -----------\nBM_PumpStreamClientToServer<InProcess>/256k                                            +5%         +5%\nBM_PumpStreamClientToServer<InProcess>/32k                                             +6%         +6%\nBM_PumpStreamClientToServer<InProcessCHTTP2>/32k                                       +6%         +6%\nBM_PumpStreamServerToClient<InProcess>/32k                                             +7%         +7%\nBM_PumpStreamServerToClient<InProcessCHTTP2>/32k                                       +4%         +4%\nBM_StreamingPingPong<InProcess, NoOpMutator, NoOpMutator>/256k/2                       -4%         -4%\nBM_StreamingPingPong<InProcessCHTTP2, NoOpMutator, NoOpMutator>/256k/1                 -4%         -4%\nBM_StreamingPingPongMsgs<InProcess, NoOpMutator, NoOpMutator>/32k                      -6%         -6%\nBM_StreamingPingPongMsgs<MinInProcess, NoOpMutator, NoOpMutator>/256k                  -5%         -5%\nBM_StreamingPingPongMsgs<MinInProcess, NoOpMutator, NoOpMutator>/32k                   -5%         -5%\nBM_StreamingPingPongWithCoalescingApi<InProcess, NoOpMutator, NoOpMutator>/256k/1/1    -4%         -4%\nBM_StreamingPingPongWithCoalescingApi<MinInProcess, NoOpMutator, NoOpMutator>/32k/2/0  -4%         -4%\nBM_StreamingPingPongWithCoalescingApi<MinInProcess, NoOpMutator, NoOpMutator>/32k/2/1  -4%         -4%\nBM_UnaryPingPong<InProcess, NoOpMutator, NoOpMutator>/0/256k                           +7%         +7%\nBM_UnaryPingPong<MinInProcess, NoOpMutator, NoOpMutator>/0/256k                        +7%         +7%\nBM_UnaryPingPong<MinInProcess, NoOpMutator, NoOpMutator>/256k/0                        +5%         +5%\nBM_UnaryPingPong<MinInProcess, NoOpMutator, NoOpMutator>/256k/256k                     +4%         +4%\nBM_UnaryPingPong<MinInProcessCHTTP2, NoOpMutator, NoOpMutator>/0/256k                  +4%         +4%\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/335528111",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-335528111",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 335528111,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTUyODExMQ==",
    "user": {
      "login": "markdroth",
      "id": 18664614,
      "node_id": "MDQ6VXNlcjE4NjY0NjE0",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18664614?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdroth",
      "html_url": "https://github.com/markdroth",
      "followers_url": "https://api.github.com/users/markdroth/followers",
      "following_url": "https://api.github.com/users/markdroth/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdroth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdroth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdroth/subscriptions",
      "organizations_url": "https://api.github.com/users/markdroth/orgs",
      "repos_url": "https://api.github.com/users/markdroth/repos",
      "events_url": "https://api.github.com/users/markdroth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdroth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-10T16:19:45Z",
    "updated_at": "2017-10-10T16:19:45Z",
    "author_association": "MEMBER",
    "body": "This is moving in the right direction.  Please let me know if you have any questions about any of this.\n\n---\n\nReviewed 7 of 7 files at r4.\nReview status: all files reviewed at latest revision, 16 unresolved discussions, some commit checks failed.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 538 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmHbRIQDLvDeRZ5CB0:-Kw5mWceg4THsW1Ucpqs:b1d26mj) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/client_channel.cc#L538)):*\n<details><summary><i>Previously, AspirinSJL (Juanli Shen) wroteâ€¦</i></summary><blockquote>\n\nDone.\n\nSo, generally, the object who schedules the closure should guarantee the exactly-once semantics, and the object whose code will be called back should own the closure. That makes sense to me. \n\nI feel I don't understand \"exactly-once\" clearly. I thought it means any initialized closure should only be invoked (scheduled and run) once, then it's destroyed by the underlying implementation. But as you have mentioned, this is not true. Now my understanding of \"exactly-once\" is like it focuses on ensuring that a closure fulfill its duty to process the resources that we have logically assigned to it. If it's not invoked, we may have memory leak or other issues; if it's invoked multiple times improperly, it's not safe. But it can be scheduled for multiple times once initialized as long as we can ensure those invocations are manipulated into a sequence with proper linking and ending. It's still \"exactly-once\", but in a macro view. \n\nIf the above understanding is correct, should I care about the space a closure itself occupies? Assuming a closure sits in heap memory, how should it be freed? I thought it's done after each invocation. But if not, how does the mechanism works? I haven't found much information by looking at the code.\n\nAlso, if we don't schedule the closure with `GRPC_ERROR_CANCELLED` in client channel, will there be any problem?\n\nThanks!  \n</blockquote></details>\n\nThe \"exactly once\" semantic means that *when we give a closure to another API*, the other API should guarantee that the closure will be invoked exactly once.  In this case, we are giving the closure to the LB policy in two places: one is at LB policy creation, and the other is when we call `grpc_lb_policy_set_reresolve_closure_locked()` to give it back to the LB policy after it has been invoked.  Each time we do that, the LB policy needs to ensure that the closure will be invoked exactly once.\n\nYou will find this paradigm in use all over our code-base.  Another example of this is the resolver API: each time we call `grpc_resolver_next_locked()`, we give it a closure to invoke when new data is available, and it guarantees to invoke the closure exactly once.  The client channel code has a single closure that we use with the resolver, which we initialize only once, that points to `on_resolver_result_changed_locked()`.  We initially call `grpc_resolver_next_locked()` in `start_resolving_locked()`, which results in the first call to `on_resolver_result_changed_locked()`.  Then, the last thing we do in `on_resolver_result_changed_locked()` is to call `grpc_resolver_next_locked()` again with the exact same closure that we originally passed to it, thus effectively \"renewing\" the request to the resolver.\n\nThe closure doesn't use any memory that isn't directly stored in the `grpc_closure` struct.  In general, the way you're doing this now (storing the closure as a member of the object that it is calling back into) is the right thing to do, because the closure is then allocated as part of the object that we're allocating anyway, so we avoid a second allocation, which is good for performance reasons.  Note that this is one of the reasons why the closure needs to hold a reference to the object it's calling into: we need to ensure that the closure object will continue to exist until it's actually run.\n\n(There are some rare cases where you want to allocate a closure by itself, rather than as a member of another object.  We have a `GRPC_CLOSURE_CREATE()` function that can be used instead of `GRPC_CLOSURE_INIT()` in that case; it dynamically allocates a closure object that automatically frees itself after the callback is invoked.  However, we try to avoid that whenever feasible, especially for code in the fast path, because there's performance overhead for doing each memory allocation.)\n\nWe should **never** schedule the closure from the client channel code (regardless of whether it's with `GRPC_ERROR_CANCELLED` or some other error).  Since the client channel code has no way of knowing when the LB policy will schedule the closure, we can't possibly do this safely, because the closure might already be pending at the moment we try to schedule it.  Also, even if there was a safe way to do this, there's also no need to do it in the first place, because the LB policy should schedule the closure with `GRPC_ERROR_CANCELLED` when it shuts down.\n\nSo, please remove the `GRPC_CLOSURE_SCHED()` from here.  Instead, please make sure that every LB policy's shutdown method schedules the closure with `GRPC_ERROR_CANCELLED`.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 369 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5l-yn6JJRXmUpbI_e:-Kw5l-yn6JJRXmUpbI_f:b-udt1q2) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L369)):*\n> ```cpp\n> }\n> \n> static void request_reresolution_locked(grpc_exec_ctx *exec_ctx, void *arg,\n> ```\n\nThis callback needs to hold a ref to the client channel.  Otherwise, there's no guarantee that the client channel will still exist by the time the callback runs.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 375 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5lai6iewprRkDLIeA:-Kw5lai6iewprRkDLIeB:bdmpnk0) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L375)):*\n> ```cpp\n>   }\n>   channel_data *chand = (channel_data *)arg;\n>   if (chand->resolver != NULL) {\n> ```\n\nWe also need to check that `error == GRPC_ERROR_NONE`.  If the closure is cancelled by the LB policy shutting down, we don't want to actually trigger re-resolution.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 375 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5tXoFMxcnp_L9-7Gq:-Kw5tXoFMxcnp_L9-7Gr:bg0ce5q) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L375)):*\n> ```cpp\n>   }\n>   channel_data *chand = (channel_data *)arg;\n>   if (chand->resolver != NULL) {\n> ```\n\nI just realized that there's another edge case we need to handle here, which is what happens when we switch LB policies.  The code in `on_resolver_result_changed_locked()` will instantiate a new LB policy instance, unref the original LB policy (thus causing it to shut down), and then reset `chand->lb_policy` to the new LB policy instance.  There are two problems here:\n\n1. When we instantiate the new LB policy instance, we will give it the re-resolution closure, which is already in use by the old LB policy instance.  This could cause the closure to be scheduled twice at the same time.\n2. Even if we were guaranteed that the new LB policy would not actually schedule the closure until after the old LB policy schedules it for the last time, it's possible that the old LB policy might have already scheduled it before we unreffed it, in which case the closure will be invoked with `GRPC_ERROR_NONE` but with `chand->lb_policy` already pointing to the new LB policy.  This would cause us to renew the closure with the wrong LB policy, thus failing to unref the client channel code.\n\nTo solve this, I think that we need the callback to know which LB policy it was called for.  One way of doing this would be to give the LB policy a pointer to `chand`, and then have this callback take the LB policy as its arg instead of `chand`.  Then the callback can check whether `chand->lb_policy` is the same as the LB policy it was called from, in which case it can treat that the same as if the LB policy was shut down.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 382 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5klZSLhOcaL8M52xr:-Kw5klZSLhOcaL8M52xs:b1hi5o1) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L382)):*\n> ```cpp\n>   } else {\n>     if (GRPC_TRACER_ON(grpc_client_channel_trace)) {\n>       gpr_log(GPR_DEBUG, \"chand=%p: no resolver to do re-resolution\", chand);\n> ```\n\nI don't think this needs to be logged; it will be a normal occurrence when shutting down the channel.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 386 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5kXLbbujyqv-e2IIi:-Kw5kXLbbujyqv-e2IIj:b-kwfbjp) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L386)):*\n> ```cpp\n>   }\n>   // Give back the closure to the LB policy.\n>   grpc_lb_policy_set_reresolve_closure_locked(exec_ctx, chand->lb_policy,\n> ```\n\nThis can go inside the `if` block above.  If `chand->resolver` is NULL, then there's no need to give the closure back to the LB policy.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.cc, line 190 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5jvKsQjzD_HBshEcn:-Kw5jvKsQjzD_HBshEco:b-cbpqm4) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy.cc#L190)):*\n> ```cpp\n>     }\n>   }\n> }\n> ```\n\nNit: Please add a trailing newline.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 214 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5jKGWogUp_gwOY-Uz:-Kw5jKGWogUp_gwOY-V-:b26q2js) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy.h#L214)):*\n> ```objc\n>                                   const grpc_lb_policy_args *lb_policy_args);\n> \n> /** Set \\a policy with \\a request_reresolution closure. */\n> ```\n\nThis wording is a bit unclear.  I suggest the following:\n\nSets the re-resolution closure to \\a request_reresolution.  To be invoked by the caller to renew the re-resolution closure after it has been invoked.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 215 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw62pJJ6CtxuUpefVf8:-Kw62pJJ6CtxuUpefVf9:b-hyvnql) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy.h#L215)):*\n> ```objc\n> \n> /** Set \\a policy with \\a request_reresolution closure. */\n> void grpc_lb_policy_set_reresolve_closure_locked(\n> ```\n\nI think this method will need to be added to the vtable, since we'll need to be able to override it for the grpclb LB policy.  See my comment in grpclb.cc about that.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 220 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5j9Sw9P6cbSiZZdGS:-Kw5j9Sw9P6cbSiZZdGT:b-ypjxch) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy.h#L220)):*\n> ```objc\n> \n> /** Try to request a re-resolution. */\n> void grpc_lb_policy_try_reresolve_locked(grpc_exec_ctx *exec_ctx,\n> ```\n\nI don't think we need to expose a method for this, since the re-resolution will never be triggered from outside the LB policy.  And the code to trigger it is simple enough that it can just be inlined into each LB policy.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc, line 1969 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw61wq-Ja811mnxk8uu:-Kw61wq-Ja811mnxk8uv:b-8203ir) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc#L1969)):*\n> ```cpp\n>                     grpc_combiner_scheduler(args->combiner));\n>   grpc_lb_policy_init(&glb_policy->base, &glb_lb_policy_vtable, args->combiner,\n>                       args->request_reresolution);\n> ```\n\nRemember that the LB policy is responsible for guaranteeing that the closure will be invoked exactly once.  However, it looks like we're not actually scheduling this anywhere.\n\nIn the case of the grpclb code, this is particularly tricky, since we probably want to hand off this closure to the RR policy when it exists.  However, if we are shut down before we create an RR policy, then we need to schedule the closure ourselves.\n\nNote that when client_channel calls `grpc_lb_policy_set_reresolve_closure_locked()` to renew the closure, if we already have an RR policy at that point, we need to pass the renewed closure to the RR policy.  This will require adding `grpc_lb_policy_set_reresolve_closure_locked()` to the LB policy vtable, as I mentioned elsewhere.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc, line 296 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5yk0XmIHYI9Aft_vn:-Kw5yk0Yn1hUtQ0FC_Fi:b-uwhdjp) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc#L296)):*\n> ```cpp\n> }\n> \n> static void pf_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,\n> ```\n\nNote that I'm changing a lot of the pick_first logic in #12878, so one of us will have to merge the changes from other PR, depending on which one gets merged first.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 494 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmbRZLPT6hybMTWG40:-Kw5z1KHa3Z9mJ7ausAJ:bbbg5s0) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L494)):*\n<details><summary><i>Previously, AspirinSJL (Juanli Shen) wroteâ€¦</i></summary><blockquote>\n\nDone.\n\nI thought that generally we are considering the `shubchannel_list`. We need to use `sd` because we don't count the number of `CONNECTING` subchannels.\n\nSo, why don't we count that? Is that because only one subchannel can be in `CONNECTING` status?\n</blockquote></details>\n\nNo, multiple subchannels can be in `CONNECTING` state at the same time.  In fact, this will usually happen when the RR policy first starts connecting.\n\nI would assume that the reason we're not counting the number of `CONNECTING` subchannels is just because the current logic doesn't need that.  I suspect this is another way in which the current logic is slightly wrong, and we can address this as part of a future PR.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 506 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw6-4wyu3nMqkX0w17_:-Kw6-4wyu3nMqkX0w17a:b-v3pdr1) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L506)):*\n> ```cpp\n>    * 1) RULE: ANY subchannel is READY => policy is READY.\n>    *    CHECK: subchannel_list->num_ready > 0\n>    *           (i.e., p->ready_list is NOT empty.)\n> ```\n\nYou can remove this line -- the `ready_list` field was removed in #11227, but I forgot to update this comment.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 513 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw6-kbW5bEepL0Xc74I:-Kw6-kbW5bEepL0Xc74J:b-5uhh69) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L513)):*\n> ```cpp\n>    * 3) RULE: ALL subchannels are SHUTDOWN or ALL subchannels are\n>    *          TRANSIENT_FAILURE => policy is TRANSIENT_FAILURE.\n>    *    CHECK: subchannel_list->num_shutdown ==\n> ```\n\nWhat if some subchannels are in `SHUTDOWN` and others are in `TRANSIENT_FAILURE`?  I think we should actually check `subchannel_list->num_shutdown + subchannel_list->num_transient_failure == subchannel_list->num_subchannels`.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 607 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw60ckzPrVJfSDc8TNh:-Kw60ckzPrVJfSDc8TNi:bqvqvjl) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L607)):*\n> ```cpp\n>           sd->subchannel_list->num_transient_failures ==\n>       sd->subchannel_list->num_subchannels) {\n>     grpc_lb_policy_try_reresolve_locked(exec_ctx, &p->base,\n> ```\n\nCould just move this into `update_lb_connectivity_status_locked()`, so that we don't need to check the same condition in two places.\n\n---\n\n\n*Comments from [Reviewable](https://reviewable.io:443/reviews/grpc/grpc/12829#-:-Kw63gYIP0nfIqR8y8-Y:bnu1elp)*\n<!-- Sent from Reviewable.io -->\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336003191",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336003191",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336003191,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjAwMzE5MQ==",
    "user": {
      "login": "AspirinSJL",
      "id": 3314176,
      "node_id": "MDQ6VXNlcjMzMTQxNzY=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/3314176?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AspirinSJL",
      "html_url": "https://github.com/AspirinSJL",
      "followers_url": "https://api.github.com/users/AspirinSJL/followers",
      "following_url": "https://api.github.com/users/AspirinSJL/following{/other_user}",
      "gists_url": "https://api.github.com/users/AspirinSJL/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AspirinSJL/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AspirinSJL/subscriptions",
      "organizations_url": "https://api.github.com/users/AspirinSJL/orgs",
      "repos_url": "https://api.github.com/users/AspirinSJL/repos",
      "events_url": "https://api.github.com/users/AspirinSJL/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AspirinSJL/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-12T02:34:35Z",
    "updated_at": "2017-10-12T02:34:35Z",
    "author_association": "MEMBER",
    "body": "\n\n\n\nReview status: all files reviewed at latest revision, 15 unresolved discussions, some commit checks failed.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 538 at r2](https://reviewable.io:443/reviews/grpc/grpc/12829#-KvmHbRIQDLvDeRZ5CB0:-KwBppSC3fVuLSzDoowf:b-8051yc) ([raw file](https://github.com/grpc/grpc/blob/1dd358b04143bf5e9dcc6ea2f19721cd10859020/src/core/ext/filters/client_channel/client_channel.cc#L538)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nThe \"exactly once\" semantic means that *when we give a closure to another API*, the other API should guarantee that the closure will be invoked exactly once.  In this case, we are giving the closure to the LB policy in two places: one is at LB policy creation, and the other is when we call `grpc_lb_policy_set_reresolve_closure_locked()` to give it back to the LB policy after it has been invoked.  Each time we do that, the LB policy needs to ensure that the closure will be invoked exactly once.\n\nYou will find this paradigm in use all over our code-base.  Another example of this is the resolver API: each time we call `grpc_resolver_next_locked()`, we give it a closure to invoke when new data is available, and it guarantees to invoke the closure exactly once.  The client channel code has a single closure that we use with the resolver, which we initialize only once, that points to `on_resolver_result_changed_locked()`.  We initially call `grpc_resolver_next_locked()` in `start_resolving_locked()`, which results in the first call to `on_resolver_result_changed_locked()`.  Then, the last thing we do in `on_resolver_result_changed_locked()` is to call `grpc_resolver_next_locked()` again with the exact same closure that we originally passed to it, thus effectively \"renewing\" the request to the resolver.\n\nThe closure doesn't use any memory that isn't directly stored in the `grpc_closure` struct.  In general, the way you're doing this now (storing the closure as a member of the object that it is calling back into) is the right thing to do, because the closure is then allocated as part of the object that we're allocating anyway, so we avoid a second allocation, which is good for performance reasons.  Note that this is one of the reasons why the closure needs to hold a reference to the object it's calling into: we need to ensure that the closure object will continue to exist until it's actually run.\n\n(There are some rare cases where you want to allocate a closure by itself, rather than as a member of another object.  We have a `GRPC_CLOSURE_CREATE()` function that can be used instead of `GRPC_CLOSURE_INIT()` in that case; it dynamically allocates a closure object that automatically frees itself after the callback is invoked.  However, we try to avoid that whenever feasible, especially for code in the fast path, because there's performance overhead for doing each memory allocation.)\n\nWe should **never** schedule the closure from the client channel code (regardless of whether it's with `GRPC_ERROR_CANCELLED` or some other error).  Since the client channel code has no way of knowing when the LB policy will schedule the closure, we can't possibly do this safely, because the closure might already be pending at the moment we try to schedule it.  Also, even if there was a safe way to do this, there's also no need to do it in the first place, because the LB policy should schedule the closure with `GRPC_ERROR_CANCELLED` when it shuts down.\n\nSo, please remove the `GRPC_CLOSURE_SCHED()` from here.  Instead, please make sure that every LB policy's shutdown method schedules the closure with `GRPC_ERROR_CANCELLED`.\n</blockquote></details>\n\nThanks! The code seems a lot clearer to me now!\n\nI am sorry that I misread the bullet in your previous comment about scheduling the closure with `GRPC_ERROR_CANCELLED`.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 369 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5l-yn6JJRXmUpbI_e:-Kw7iNkAeBYNylUql_us:b-i8ybm8) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L369)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nThis callback needs to hold a ref to the client channel.  Otherwise, there's no guarantee that the client channel will still exist by the time the callback runs.\n</blockquote></details>\n\nDone.\n\nI see! So this callback is holding a resource (client channel) via a ref.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 375 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5lai6iewprRkDLIeA:-Kw7ive7NH5ccviW3Npn:bnbrqkv) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L375)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nWe also need to check that `error == GRPC_ERROR_NONE`.  If the closure is cancelled by the LB policy shutting down, we don't want to actually trigger re-resolution.\n</blockquote></details>\n\nAlthough it doesn't hurt, do we really need to check that? It's either `GRPC_ERROR_CANCELLED` or `GRPC_ERROR_NONE`, and we've already returned in case of `GRPC_ERROR_CANCELLED` as line 372.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 375 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5tXoFMxcnp_L9-7Gq:-KwBWSGBaTcKx8Xxfhv5:b1mt0pi) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L375)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nI just realized that there's another edge case we need to handle here, which is what happens when we switch LB policies.  The code in `on_resolver_result_changed_locked()` will instantiate a new LB policy instance, unref the original LB policy (thus causing it to shut down), and then reset `chand->lb_policy` to the new LB policy instance.  There are two problems here:\n\n1. When we instantiate the new LB policy instance, we will give it the re-resolution closure, which is already in use by the old LB policy instance.  This could cause the closure to be scheduled twice at the same time.\n2. Even if we were guaranteed that the new LB policy would not actually schedule the closure until after the old LB policy schedules it for the last time, it's possible that the old LB policy might have already scheduled it before we unreffed it, in which case the closure will be invoked with `GRPC_ERROR_NONE` but with `chand->lb_policy` already pointing to the new LB policy.  This would cause us to renew the closure with the wrong LB policy, thus failing to unref the client channel code.\n\nTo solve this, I think that we need the callback to know which LB policy it was called for.  One way of doing this would be to give the LB policy a pointer to `chand`, and then have this callback take the LB policy as its arg instead of `chand`.  Then the callback can check whether `chand->lb_policy` is the same as the LB policy it was called from, in which case it can treat that the same as if the LB policy was shut down.\n</blockquote></details>\n\nWhile doing this change, I encountered a problem. If the callback only uses an arg of the LB policy with a backward pointer to the client channel, we need to ensure that the LB policy still exists when the callback is invoked so that we can find the `chand`. So I tried to ref the LB policy for the callback. Then the callback holds two refs: one to the LB policy, and the other one to the client channel. When I run the grpclb_end2end test, I times out and lead to memory leak. So I guess such two refs will cause some thing like dead lock. \n\nSo I use a new struct to pass both the LB policy and the `chand` to the callback. We don't need to ref the LB policy for the callback in this case because the LB policy pointer is only used as an address or an ID.\n\nThere may be some way to get rid of this new struct.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 382 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5klZSLhOcaL8M52xr:-KwBlZMa6BDtKt8-EayJ:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L382)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nI don't think this needs to be logged; it will be a normal occurrence when shutting down the channel.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 386 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5kXLbbujyqv-e2IIi:-KwBlncSo0F32mghWmY6:b-n2t5e9) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L386)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nThis can go inside the `if` block above.  If `chand->resolver` is NULL, then there's no need to give the closure back to the LB policy.\n</blockquote></details>\n\nDone. \n\nSo the resolver never comes back once it's set to NULL?\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.cc, line 190 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5jvKsQjzD_HBshEcn:-KwBqwkFwlFj5K3htRd7:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy.cc#L190)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nNit: Please add a trailing newline.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 214 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5jKGWogUp_gwOY-Uz:-KwBrbicUiaTujr5ItJk:bwnbi2d) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy.h#L214)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nThis wording is a bit unclear.  I suggest the following:\n\nSets the re-resolution closure to \\a request_reresolution.  To be invoked by the caller to renew the re-resolution closure after it has been invoked.\n</blockquote></details>\n\nDone. \n\nChanged to plural form to be consistent with the surrounding functions' comments.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 215 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw62pJJ6CtxuUpefVf8:-KwC0_xbxgfK7QSeI1BC:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy.h#L215)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nI think this method will need to be added to the vtable, since we'll need to be able to override it for the grpclb LB policy.  See my comment in grpclb.cc about that.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 220 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5j9Sw9P6cbSiZZdGS:-KwC0p4L8Auam9LUaBRi:b-fm08lq) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy.h#L220)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nI don't think we need to expose a method for this, since the re-resolution will never be triggered from outside the LB policy.  And the code to trigger it is simple enough that it can just be inlined into each LB policy.\n</blockquote></details>\n\nDone.\n\nI was actually trying to find a way to reuse the code among all the LB policies. If I do want to create such a function without exposing it, how should I do it?\n\nSide question: now that we've moved to C++, does that mean we can use the native OOP in C++, or we still want to implement our own version?\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc, line 1969 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw61wq-Ja811mnxk8uu:-KwCGpncma-E-YNnKI4t:b-srmwoa) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc#L1969)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nRemember that the LB policy is responsible for guaranteeing that the closure will be invoked exactly once.  However, it looks like we're not actually scheduling this anywhere.\n\nIn the case of the grpclb code, this is particularly tricky, since we probably want to hand off this closure to the RR policy when it exists.  However, if we are shut down before we create an RR policy, then we need to schedule the closure ourselves.\n\nNote that when client_channel calls `grpc_lb_policy_set_reresolve_closure_locked()` to renew the closure, if we already have an RR policy at that point, we need to pass the renewed closure to the RR policy.  This will require adding `grpc_lb_policy_set_reresolve_closure_locked()` to the LB policy vtable, as I mentioned elsewhere.\n</blockquote></details>\n\nDone.\n\nAh.. The code is quite buggy.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc, line 296 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5yk0XmIHYI9Aft_vn:-KwCHGePydPW58FM07_g:b-ciyxvb) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc#L296)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nNote that I'm changing a lot of the pick_first logic in #12878, so one of us will have to merge the changes from other PR, depending on which one gets merged first.\n</blockquote></details>\n\nI see. \n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 506 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw6-4wyu3nMqkX0w17_:-KwCHsmtCOtPSac7I17f:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L506)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nYou can remove this line -- the `ready_list` field was removed in #11227, but I forgot to update this comment.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 513 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw6-kbW5bEepL0Xc74I:-KwCI2ucWuYow97MN14k:b-5vskpu) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L513)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nWhat if some subchannels are in `SHUTDOWN` and others are in `TRANSIENT_FAILURE`?  I think we should actually check `subchannel_list->num_shutdown + subchannel_list->num_transient_failure == subchannel_list->num_subchannels`.\n</blockquote></details>\n\nDone.\n\nBut please note that this will change the old behavior (towards a better one). \n\nWith the old code, we will keep the old state and do nothing. For example, we have 1 `READY` subchannel and 1 `SHUTDOWN`, so we are in `READY`. If we are notified that the first subchannel is now in`TRANSIENT_FAILURE`, we would keep in `READY`. This rule doesn't make much sense to me though.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 607 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw60ckzPrVJfSDc8TNh:-KwCNShDPwfkKyzXgmGN:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L607)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nCould just move this into `update_lb_connectivity_status_locked()`, so that we don't need to check the same condition in two places.\n</blockquote></details>\n\nDone.\n\n---\n\n\n*Comments from [Reviewable](https://reviewable.io:443/reviews/grpc/grpc/12829)*\n<!-- Sent from Reviewable.io -->\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336005390",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336005390",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336005390,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjAwNTM5MA==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-12T02:49:41Z",
    "updated_at": "2017-10-12T02:49:41Z",
    "author_association": "NONE",
    "body": "```\n****************************************************************\n\nlibgrpc.so\n\n     VM SIZE                                                                                            FILE SIZE\n ++++++++++++++ GROWING                                                                              ++++++++++++++\n  +0.1%    +720 [None]                                                                               +7.52Ki  +0.1%\n      +0.1%    +696 [Unmapped]                                                                           +7.50Ki  +0.1%\n     +10.0%      +8 glb_lb_policy_vtable                                                                      +8 +10.0%\n     +10.0%      +8 pick_first_lb_policy_vtable                                                               +8 +10.0%\n     +10.0%      +8 round_robin_lb_policy_vtable                                                              +8 +10.0%\n  +6.3%    +384 src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc                  +384  +6.3%\n       +11%    +233 pf_connectivity_changed_locked                                                          +233   +11%\n       +20%     +59 pf_shutdown_locked                                                                       +59   +20%\n      [NEW]     +59 pf_set_reresolve_closure_locked                                                          +59  [NEW]\n       +13%     +16 [Unmapped]                                                                               +16   +13%\n      +0.5%      +9 pf_update_locked                                                                          +9  +0.5%\n      +6.3%      +8 pf_pick_locked                                                                            +8  +6.3%\n  +1.6%    +224 src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc                          +224  +1.6%\n      [NEW] +1.57Ki rr_handover_locked(grpc_exec_ctx*, glb_lb_policy*) [clone .part.6]                   +1.57Ki  [NEW]\n      [NEW] +1.28Ki query_for_backends_locked(grpc_exec_ctx*, glb_lb_policy*) [clone .part.8]            +1.28Ki  [NEW]\n      [NEW]    +834 build_lb_channel_args(grpc_exec_ctx*, grpc_lb_addresses const*, grpc_fake_resolver_r    +834  [NEW]\n      [NEW]    +210 extract_backend_addresses_locked(grpc_exec_ctx*, grpc_lb_addresses const*) [clone .i    +210  [NEW]\n       +21%     +88 glb_shutdown_locked                                                                      +88   +21%\n      [NEW]     +84 glb_set_reresolve_closure_locked                                                         +84  [NEW]\n      +7.7%     +28 [Unmapped]                                                                               +28  +7.7%\n  +1.5%    +192 src/core/ext/filters/client_channel/client_channel.cc                                   +192  +1.5%\n      [NEW]    +192 set_channel_connectivity_state_locked                                                   +192  [NEW]\n      [NEW]    +156 start_resolving_locked                                                                  +156  [NEW]\n      [NEW]    +140 request_reresolution_locked                                                             +140  [NEW]\n      [NEW]    +116 watch_lb_policy_locked                                                                  +116  [NEW]\n      +3.1%     +80 on_resolver_result_changed_locked                                                        +80  +3.1%\n      [NEW]     +79 lookup_external_connectivity_watcher                                                     +79  [NEW]\n       +12%     +27 [Unmapped]                                                                               +27   +12%\n      +1.7%     +16 cc_init_channel_elem                                                                     +16  +1.7%\n      +1.2%      +3 cc_destroy_channel_elem                                                                   +3  +1.2%\n      +0.6%      +3 watch_connectivity_state_locked                                                           +3  +0.6%\n      +2.9%      +3 grpc_client_channel_check_connectivity_state                                              +3  +2.9%\n  +0.9%     +64 src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc                 +64  +0.9%\n      [NEW]     +59 rr_set_reresolve_closure_locked                                                          +59  [NEW]\n      [NEW]     +57 rr_subchannel_list_ref(rr_subchannel_list*, char const*) [clone .part.1]                 +57  [NEW]\n      +8.6%     +37 rr_shutdown_locked                                                                       +37  +8.6%\n       +16%     +21 [Unmapped]                                                                               +21   +16%\n  +3.7%     +16 src/core/ext/filters/client_channel/lb_policy.cc                                         +16  +3.7%\n       +16%      +8 grpc_lb_policy_init                                                                       +8   +16%\n      [NEW]      +6 grpc_lb_policy_set_reresolve_closure_locked                                               +6  [NEW]\n      +1.5%      +2 [Unmapped]                                                                                +2  +1.5%\n\n  +0.1% +1.56Ki TOTAL                                                                                +8.38Ki  +0.1%\n\n\n****************************************************************\n\nlibgrpc++.so\n\n     VM SIZE        FILE SIZE\n ++++++++++++++  ++++++++++++++\n\n  [ = ]       0        0  [ = ]\n\n\n\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336007410",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336007410",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336007410,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjAwNzQxMA==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-12T03:03:14Z",
    "updated_at": "2017-10-12T03:03:14Z",
    "author_association": "NONE",
    "body": "```\n[trickle] No significant performance differences\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336018067",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336018067",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336018067,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjAxODA2Nw==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-12T04:33:16Z",
    "updated_at": "2017-10-12T04:33:16Z",
    "author_association": "NONE",
    "body": "```\nCorrupt JSON data (indicates timeout or crash): \n    bm_fullstack_streaming_ping_pong.BM_StreamingPingPongWithCoalescingApi_MinInProcessCHTTP2_NoOpMutator_NoOpMutator__2M_1_0.opt.old: 1\n\n\n[microbenchmarks] Performance differences noted:\nBenchmark                          cpu_time    real_time\n---------------------------------  ----------  -----------\nBM_ClosureSched3OnExecCtx          -4%         -4%\nBM_ErrorGetIntFromNoError          +5%         +5%\nBM_ErrorHttpError<ErrorCancelled>  +6%         +6%\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336179095",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336179095",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336179095,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjE3OTA5NQ==",
    "user": {
      "login": "markdroth",
      "id": 18664614,
      "node_id": "MDQ6VXNlcjE4NjY0NjE0",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18664614?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdroth",
      "html_url": "https://github.com/markdroth",
      "followers_url": "https://api.github.com/users/markdroth/followers",
      "following_url": "https://api.github.com/users/markdroth/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdroth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdroth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdroth/subscriptions",
      "organizations_url": "https://api.github.com/users/markdroth/orgs",
      "repos_url": "https://api.github.com/users/markdroth/repos",
      "events_url": "https://api.github.com/users/markdroth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdroth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-12T15:46:06Z",
    "updated_at": "2017-10-12T15:46:06Z",
    "author_association": "MEMBER",
    "body": "This is looking pretty good.  I think the only remaining significant issue is the one about the LB policy lifetime.\n\nPlease let me know if you have any questions about any of this.\n\n---\n\nReviewed 6 of 7 files at r5.\nReview status: all files reviewed at latest revision, 11 unresolved discussions, some commit checks failed.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 375 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5lai6iewprRkDLIeA:-KwG0-KsWfbit_ax1Vud:befyde8) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L375)):*\n<details><summary><i>Previously, AspirinSJL (Juanli Shen) wroteâ€¦</i></summary><blockquote>\n\nAlthough it doesn't hurt, do we really need to check that? It's either `GRPC_ERROR_CANCELLED` or `GRPC_ERROR_NONE`, and we've already returned in case of `GRPC_ERROR_CANCELLED` as line 372.\n</blockquote></details>\n\nWhenever an object provides a callback to another object, there is a race condition when shutting down.  When the object providing the callback (in this case, the client_channel) shuts down the object that it gave the callback to (in this case, the LB policy), the latter will be responsible for invoking the callback with some error to indicate that it was cancelled (this is the \"exactly once\" semantic we discussed previously).  However, it is possible that at the moment that we shut down the other object, the closure has already been scheduled, in which case the shutdown does not cause the closure to be scheduled.  But this means that the callback will run with `GRPC_ERROR_NONE` instead of an error indicating the shutdown.\n\nTo address this, the object that provided the callback needs to record its own state to indicate that it's being shut down (in this case, `chand->resolver == NULL`), and the callback needs to check both the error it was invoked with and the state its object recorded to indicate shutdown -- if either the error is not `GRPC_ERROR_NONE` **or** the object's state indicates shutdown, then it needs to treat it as a shutdown.\n\nSo, the general pattern in a callback is to see a line like this at the top:\n\n```\nif (error != GRPC_ERROR_NONE || this->shutdown) {\n  // ...handle error...\n}\n```\n\nIn this particular case, I suspect that the point is moot now that we're also checking `policy != chand->lb_policy`, since that should always be true if we're shutting down.  But it's still better to explicitly check the error, both for consistency with the usual pattern for callbacks and to protect against possible other causes of errors in the future (e.g., some future code change could make it such that we get an error in a situation other than shutdown).\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 375 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5tXoFMxcnp_L9-7Gq:-KwG3r9rpmQ04oif2bqz:b-mtbwk8) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L375)):*\n<details><summary><i>Previously, AspirinSJL (Juanli Shen) wroteâ€¦</i></summary><blockquote>\n\nWhile doing this change, I encountered a problem. If the callback only uses an arg of the LB policy with a backward pointer to the client channel, we need to ensure that the LB policy still exists when the callback is invoked so that we can find the `chand`. So I tried to ref the LB policy for the callback. Then the callback holds two refs: one to the LB policy, and the other one to the client channel. When I run the grpclb_end2end test, I times out and lead to memory leak. So I guess such two refs will cause some thing like dead lock. \n\nSo I use a new struct to pass both the LB policy and the `chand` to the callback. We don't need to ref the LB policy for the callback in this case because the LB policy pointer is only used as an address or an ID.\n\nThere may be some way to get rid of this new struct.\n</blockquote></details>\n\nGood catch on the LB policy lifetime issue -- I hadn't thought of that.\n\nNote that LB policies have two tiers of references: strong refs and weak refs.  The strong refs are the \"normal\" ones, which are generally held by outside objects (such as the client_channel).  When the strong refcount goes to zero, the LB policy shuts down.  However, it does not actually get destroyed until the weak refcount goes to zero.  The idea here is that weak refs should be used for callbacks that may still be outstanding while the LB policy is shutting down.  The APIs are defined here:\n\nhttps://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/lb_policy.h#L109\nhttps://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/lb_policy.h#L115\n\nSo you're right that taking another strong ref to the LB policy won't help here, because that will effectively prevent it from being shut down.  However, if we take a weak ref instead, that should do what we want here.\n\nAlternatively, if using a weak ref won't work for some reason, then you're right that the other option is to use a separate struct.  However, if we go this route, then I think that we need two other changes.\n\nFirst, the `reresolution_request_args` struct can't be a direct data member of the `channel_data` struct; instead, it will need to be dynamically allocated whenever we create a new LB policy.  This is because when `on_resolver_result_changed_locked()` instantiates a new LB policy and sets the fields of the `reresolution_request_args` struct for the new LB policy, there is still a pending callback for the old LB policy, and we can't change the data until the callback from the old LB policy has run.  Dynamically allocating a separate `reresolution_request_args` struct for each LB policy will eliminate this problem, because we will not alter the values of the struct being used by the callback for the old LB policy when we create the struct for the callback for the new LB policy.\n\nSecond, as a result of the previous change, we are now going to be setting the argument of the closure to a different `reresolution_request_args` instance for each LB policy.  This means that we can't reset the same `grpc_closure` object for use with the new LB policy while the callback has not yet run for the old LB policy.  To solve this, we will need to move the `grpc_closure` object from `channel_data` into the `reresolution_request_args` struct itself.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 386 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5kXLbbujyqv-e2IIi:-KwFxeaBdSjo-_6WDCL9:b-3gq1vk) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L386)):*\n<details><summary><i>Previously, AspirinSJL (Juanli Shen) wroteâ€¦</i></summary><blockquote>\n\nDone. \n\nSo the resolver never comes back once it's set to NULL?\n</blockquote></details>\n\nCorrect, the resolver never comes back once it's set to NULL.  This happens in two places.  One is in `start_transport_op_locked()` where we handle `op->disconnect_with_error`, which effectively tells the channel to start shutting down.  The other is in `on_resolver_result_changed_locked()`, where we shut down the channel if the resolver returns an error.  So when `chand->resolver` is NULL, that means the client channel is shutting down, which means that this callback is the last one we're going to get from the LB policy.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 383 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwG2KBx5YI1IudQAuGd:-KwG2KBynIBfLIArTCxl:bk19n9c) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/client_channel.cc#L383)):*\n> ```cpp\n>   // If this invocation is for a stale LB policy, treat it as an LB shutdown\n>   // signal.\n>   if (policy != chand->lb_policy || error == GRPC_ERROR_CANCELLED ||\n> ```\n\nTo be more general, let's check `error != GRPC_ERROR_NONE` instead of `error == GRPC_ERROR_CANCELLED`.  That way, if we ever somehow get a different error, we will still do the right thing.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 551 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwG-FhouRfG1zaYo9D6:-KwG-FhouRfG1zaYo9D7:bdameyp) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/client_channel.cc#L551)):*\n> ```cpp\n>   chand->method_params_table = method_params_table;\n>   // If we have a new LB policy or are shutting down (in which case\n>   // new_lb_policy will be NULL), swap out the LB policy, unreffing the old one,\n> ```\n\nGrammar nit: Please remove the comma at the end of this line.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.cc, line 36 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwG9D4_X45gIRCBHDgV:-KwG9D4_X45gIRCBHDgW:b2k5ge5) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/lb_policy.cc#L36)):*\n> ```cpp\n>   policy->interested_parties = grpc_pollset_set_create();\n>   policy->combiner = GRPC_COMBINER_REF(combiner, \"lb_policy\");\n>   policy->request_reresolution = NULL;\n> ```\n\nThere's no need to explicitly set this to NULL, since the LB policy objects are already created using `gpr_zalloc()`.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 214 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5jKGWogUp_gwOY-Uz:-KwG9y_JXMbZ5Oc_Padp:btr8kkx) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy.h#L214)):*\n<details><summary><i>Previously, AspirinSJL (Juanli Shen) wroteâ€¦</i></summary><blockquote>\n\nDone. \n\nChanged to plural form to be consistent with the surrounding functions' comments.\n</blockquote></details>\n\nOkay.  Note that the Google style guide says that comments should be descriptive, not imperative:\n\nhttps://google.github.io/styleguide/cppguide.html#Function_Comments\n\nMost of our existing code gets this wrong, and it's reasonable to use imperative style in an existing file for consistency with what's already there, but please be sure to use descriptive style for new code in the future.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 220 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5j9Sw9P6cbSiZZdGS:-KwGAfzd47diy3pnFJui:b-2s6nrh) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy.h#L220)):*\n> I was actually trying to find a way to reuse the code among all the LB policies. If I do want to create such a function without exposing it, how should I do it?\n\nIf we did want to create such a helper function, putting it here would be fine, although it should have a comment saying that it's intended for use by LB policy implementations, not intended as part of the public API.\n\nThe reason I didn't think this was worth sharing is that it's really just 4 lines of code, aside from the logging.  But now that I think about it, the logging may very well be useful, so maybe this is worth sharing.  I'll leave it up to you.\n\n\n> Side question: now that we've moved to C++, does that mean we can use the native OOP in C++, or we still want to implement our own version?\n\nCraig and Vijay and I discussed this just last week.  Here's the roadmap:\n\nhttps://github.com/grpc/grpc/blob/master/doc/core/moving-to-c%2B%2B.md\n\nBasically, for now, let's stick with C-style code structure, and we'll move toward more idiomatic C++ APIs over time.  At some point, I will put together specific API design proposals for things like the resolver and LB policy APIs, and we'll do the work of converting them as those proposals are approved.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 35 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwG9OGuTBnLuRN08dhD:-KwG9OGuTBnLuRN08dhE:b4whe8j) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/lb_policy.h#L35)):*\n> ```objc\n> typedef struct grpc_lb_policy_vtable grpc_lb_policy_vtable;\n> typedef struct grpc_lb_policy_args grpc_lb_policy_args;\n> typedef struct channel_data channel_data;\n> ```\n\nI don't think this is needed.  (And it would probably be inappropriate anyway, since we don't want the LB policy to depend on the client channel -- the dependency should be the reverse.)\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 219 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwGAK91ZzsMxR1Q0fz9:-KwGAK91ZzsMxR1Q0fzA:b48nqeu) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/lb_policy.h#L219)):*\n> ```objc\n>                                   const grpc_lb_policy_args *lb_policy_args);\n> \n> /** Set the re-resolution closure to \\a request_reresolution. To be invoked by\n> ```\n\nActually, now that we're using this to set the re-resolution callback even at LB policy creation, the second sentence is probably not necessary anymore.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 513 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw6-kbW5bEepL0Xc74I:-KwGDsj_HSMWK28ra58l:b-ttmecp) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L513)):*\n<details><summary><i>Previously, AspirinSJL (Juanli Shen) wroteâ€¦</i></summary><blockquote>\n\nDone.\n\nBut please note that this will change the old behavior (towards a better one). \n\nWith the old code, we will keep the old state and do nothing. For example, we have 1 `READY` subchannel and 1 `SHUTDOWN`, so we are in `READY`. If we are notified that the first subchannel is now in`TRANSIENT_FAILURE`, we would keep in `READY`. This rule doesn't make much sense to me though.\n</blockquote></details>\n\nI agree that the new behavior makes more sense.  And given that the subchannel code is currently lying to us by converting `TRANSIENT_FAILURE` to `SHUTDOWN`, I don't think this will actually cause any user-visible behavior change.\n\n---\n\n\n*Comments from [Reviewable](https://reviewable.io:443/reviews/grpc/grpc/12829#-:-KwGFhuJ-jgzuCIitdGN:bh160y8)*\n<!-- Sent from Reviewable.io -->\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336285978",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336285978",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336285978,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjI4NTk3OA==",
    "user": {
      "login": "AspirinSJL",
      "id": 3314176,
      "node_id": "MDQ6VXNlcjMzMTQxNzY=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/3314176?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AspirinSJL",
      "html_url": "https://github.com/AspirinSJL",
      "followers_url": "https://api.github.com/users/AspirinSJL/followers",
      "following_url": "https://api.github.com/users/AspirinSJL/following{/other_user}",
      "gists_url": "https://api.github.com/users/AspirinSJL/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AspirinSJL/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AspirinSJL/subscriptions",
      "organizations_url": "https://api.github.com/users/AspirinSJL/orgs",
      "repos_url": "https://api.github.com/users/AspirinSJL/repos",
      "events_url": "https://api.github.com/users/AspirinSJL/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AspirinSJL/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-12T21:57:55Z",
    "updated_at": "2017-10-12T21:57:55Z",
    "author_association": "MEMBER",
    "body": "Thanks for reviewing! Actually I still have an asan issue to fix. It appeared after the first commit and still exists. I read through the changes to pick_first.c but can't understand why this issue happens. I am thinking that maybe after your subchannel list refactor PR is in, I can find some hint when rebasing and merging my PR. \n\n---\n\nReview status: all files reviewed at latest revision, 6 unresolved discussions, some commit checks failed.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 375 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5lai6iewprRkDLIeA:-KwH3ZXCUBSaM9Cfbm9Q:b2xodyv) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L375)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nWhenever an object provides a callback to another object, there is a race condition when shutting down.  When the object providing the callback (in this case, the client_channel) shuts down the object that it gave the callback to (in this case, the LB policy), the latter will be responsible for invoking the callback with some error to indicate that it was cancelled (this is the \"exactly once\" semantic we discussed previously).  However, it is possible that at the moment that we shut down the other object, the closure has already been scheduled, in which case the shutdown does not cause the closure to be scheduled.  But this means that the callback will run with `GRPC_ERROR_NONE` instead of an error indicating the shutdown.\n\nTo address this, the object that provided the callback needs to record its own state to indicate that it's being shut down (in this case, `chand->resolver == NULL`), and the callback needs to check both the error it was invoked with and the state its object recorded to indicate shutdown -- if either the error is not `GRPC_ERROR_NONE` **or** the object's state indicates shutdown, then it needs to treat it as a shutdown.\n\nSo, the general pattern in a callback is to see a line like this at the top:\n\n```\nif (error != GRPC_ERROR_NONE || this->shutdown) {\n  // ...handle error...\n}\n```\n\nIn this particular case, I suspect that the point is moot now that we're also checking `policy != chand->lb_policy`, since that should always be true if we're shutting down.  But it's still better to explicitly check the error, both for consistency with the usual pattern for callbacks and to protect against possible other causes of errors in the future (e.g., some future code change could make it such that we get an error in a situation other than shutdown).\n</blockquote></details>\n\nUnderstood. Thanks for explaining.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 375 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5tXoFMxcnp_L9-7Gq:-KwHNX0G0z1l9gpZdpMw:b-2v138o) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L375)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nGood catch on the LB policy lifetime issue -- I hadn't thought of that.\n\nNote that LB policies have two tiers of references: strong refs and weak refs.  The strong refs are the \"normal\" ones, which are generally held by outside objects (such as the client_channel).  When the strong refcount goes to zero, the LB policy shuts down.  However, it does not actually get destroyed until the weak refcount goes to zero.  The idea here is that weak refs should be used for callbacks that may still be outstanding while the LB policy is shutting down.  The APIs are defined here:\n\nhttps://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/lb_policy.h#L109\nhttps://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/lb_policy.h#L115\n\nSo you're right that taking another strong ref to the LB policy won't help here, because that will effectively prevent it from being shut down.  However, if we take a weak ref instead, that should do what we want here.\n\nAlternatively, if using a weak ref won't work for some reason, then you're right that the other option is to use a separate struct.  However, if we go this route, then I think that we need two other changes.\n\nFirst, the `reresolution_request_args` struct can't be a direct data member of the `channel_data` struct; instead, it will need to be dynamically allocated whenever we create a new LB policy.  This is because when `on_resolver_result_changed_locked()` instantiates a new LB policy and sets the fields of the `reresolution_request_args` struct for the new LB policy, there is still a pending callback for the old LB policy, and we can't change the data until the callback from the old LB policy has run.  Dynamically allocating a separate `reresolution_request_args` struct for each LB policy will eliminate this problem, because we will not alter the values of the struct being used by the callback for the old LB policy when we create the struct for the callback for the new LB policy.\n\nSecond, as a result of the previous change, we are now going to be setting the argument of the closure to a different `reresolution_request_args` instance for each LB policy.  This means that we can't reset the same `grpc_closure` object for use with the new LB policy while the callback has not yet run for the old LB policy.  To solve this, we will need to move the `grpc_closure` object from `channel_data` into the `reresolution_request_args` struct itself.\n</blockquote></details>\n\nDone. Changing to weak ref works!\n\nI thought that after initialization, the closure would be self-contained. But actually the arg pointer is passed shallowly. Then it makes sense that the arg should be allocated dynamically. \n\nI don't quite understand the second change though. It looks like we shouldn't reset the closure anyway. Because even without introducing `reresolution_request_args`, we reset the argument of the closure to a different LB policy pointer for each new policy. Do the pointer to `reresolution_request_args` and the pointer to an LB policy differ in this case?\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 386 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5kXLbbujyqv-e2IIi:-KwHUKNAJ_Hr22BXf5lL:bqrfan2) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L386)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nCorrect, the resolver never comes back once it's set to NULL.  This happens in two places.  One is in `start_transport_op_locked()` where we handle `op->disconnect_with_error`, which effectively tells the channel to start shutting down.  The other is in `on_resolver_result_changed_locked()`, where we shut down the channel if the resolver returns an error.  So when `chand->resolver` is NULL, that means the client channel is shutting down, which means that this callback is the last one we're going to get from the LB policy.\n</blockquote></details>\n\nUnderstood.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 383 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwG2KBx5YI1IudQAuGd:-KwGpWepYF-t8Sjwtrpa:b-76pmw8) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/client_channel.cc#L383)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nTo be more general, let's check `error != GRPC_ERROR_NONE` instead of `error == GRPC_ERROR_CANCELLED`.  That way, if we ever somehow get a different error, we will still do the right thing.\n</blockquote></details>\n\nDone.\n\nI agree that this can be more flexible. \n\nJust want to make sure: getting a different error just means that maybe in the future we want to add more functionality and schedule the closure with another error, right? Can it happen that we get some unexpected error even though we schedule the closure with `GRPC_ERROR_NONE`?\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 551 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwG-FhouRfG1zaYo9D6:-KwHUSAw8Op0aB-cPcFq:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/client_channel.cc#L551)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nGrammar nit: Please remove the comma at the end of this line.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.cc, line 36 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwG9D4_X45gIRCBHDgV:-KwHUejbefTjv0GyOTDp:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/lb_policy.cc#L36)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nThere's no need to explicitly set this to NULL, since the LB policy objects are already created using `gpr_zalloc()`.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 214 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5jKGWogUp_gwOY-Uz:-KwHXLyoNI3FhZvB6vTa:b-qvsz9h) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy.h#L214)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nOkay.  Note that the Google style guide says that comments should be descriptive, not imperative:\n\nhttps://google.github.io/styleguide/cppguide.html#Function_Comments\n\nMost of our existing code gets this wrong, and it's reasonable to use imperative style in an existing file for consistency with what's already there, but please be sure to use descriptive style for new code in the future.\n</blockquote></details>\n\nI see. Thanks for the reminder!\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 220 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5j9Sw9P6cbSiZZdGS:-KwHY1j4GHY-HYDBblzi:b-ciyxvb) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy.h#L220)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\n> I was actually trying to find a way to reuse the code among all the LB policies. If I do want to create such a function without exposing it, how should I do it?\n\nIf we did want to create such a helper function, putting it here would be fine, although it should have a comment saying that it's intended for use by LB policy implementations, not intended as part of the public API.\n\nThe reason I didn't think this was worth sharing is that it's really just 4 lines of code, aside from the logging.  But now that I think about it, the logging may very well be useful, so maybe this is worth sharing.  I'll leave it up to you.\n\n\n> Side question: now that we've moved to C++, does that mean we can use the native OOP in C++, or we still want to implement our own version?\n\nCraig and Vijay and I discussed this just last week.  Here's the roadmap:\n\nhttps://github.com/grpc/grpc/blob/master/doc/core/moving-to-c%2B%2B.md\n\nBasically, for now, let's stick with C-style code structure, and we'll move toward more idiomatic C++ APIs over time.  At some point, I will put together specific API design proposals for things like the resolver and LB policy APIs, and we'll do the work of converting them as those proposals are approved.\n</blockquote></details>\n\nI see. \n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 35 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwG9OGuTBnLuRN08dhD:-KwHWeWDcyRE9iYqeGT_:b-aqnli) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/lb_policy.h#L35)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nI don't think this is needed.  (And it would probably be inappropriate anyway, since we don't want the LB policy to depend on the client channel -- the dependency should be the reverse.)\n</blockquote></details>\n\nDone.\n\nThanks, that's a bug I was looking for..\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 219 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwGAK91ZzsMxR1Q0fz9:-KwHX7ghz9xj__y0L8Mq:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/lb_policy.h#L219)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nActually, now that we're using this to set the re-resolution callback even at LB policy creation, the second sentence is probably not necessary anymore.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc, line 513 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw6-kbW5bEepL0Xc74I:-KwHYWNqMjgDwLer2WtV:b-5x5hgf) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L513)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nI agree that the new behavior makes more sense.  And given that the subchannel code is currently lying to us by converting `TRANSIENT_FAILURE` to `SHUTDOWN`, I don't think this will actually cause any user-visible behavior change.\n</blockquote></details>\n\nAh, you are right. That example won't happen.\n\n---\n\n\n*Comments from [Reviewable](https://reviewable.io:443/reviews/grpc/grpc/12829#-:-KwGnaFzW3c6SuB94gtU:bjsrfdy)*\n<!-- Sent from Reviewable.io -->\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336291746",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336291746",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336291746,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjI5MTc0Ng==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-12T22:17:05Z",
    "updated_at": "2017-10-12T22:17:05Z",
    "author_association": "NONE",
    "body": "```\n****************************************************************\n\nlibgrpc.so\n\n     VM SIZE                                                                                            FILE SIZE\n ++++++++++++++ GROWING                                                                              ++++++++++++++\n  +0.1%    +744 [None]                                                                               +36.2Ki  +0.7%\n      +0.1%    +752 [Unmapped]                                                                           +36.1Ki  +0.7%\n     +10.0%      +8 glb_lb_policy_vtable                                                                      +8 +10.0%\n     +10.0%      +8 pick_first_lb_policy_vtable                                                               +8 +10.0%\n     +10.0%      +8 round_robin_lb_policy_vtable                                                              +8 +10.0%\n  +6.3%    +384 src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc                  +384  +6.3%\n       +12%    +241 pf_connectivity_changed_locked                                                          +241   +12%\n       +20%     +59 pf_shutdown_locked                                                                       +59   +20%\n      [NEW]     +59 pf_set_reresolve_closure_locked                                                          +59  [NEW]\n      +0.5%      +9 pf_update_locked                                                                          +9  +0.5%\n      +6.3%      +8 pf_pick_locked                                                                            +8  +6.3%\n      +3.4%      +4 [Unmapped]                                                                                +4  +3.4%\n      +2.0%      +4 create_pick_first                                                                         +4  +2.0%\n  +1.6%    +224 src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc                          +224  +1.6%\n      [NEW] +1.57Ki rr_handover_locked(grpc_exec_ctx*, glb_lb_policy*) [clone .part.6]                   +1.57Ki  [NEW]\n      [NEW] +1.28Ki query_for_backends_locked(grpc_exec_ctx*, glb_lb_policy*) [clone .part.8]            +1.28Ki  [NEW]\n      [NEW]    +834 build_lb_channel_args(grpc_exec_ctx*, grpc_lb_addresses const*, grpc_fake_resolver_r    +834  [NEW]\n      [NEW]    +210 extract_backend_addresses_locked(grpc_exec_ctx*, grpc_lb_addresses const*) [clone .i    +210  [NEW]\n       +21%     +88 glb_shutdown_locked                                                                      +88   +21%\n      [NEW]     +84 glb_set_reresolve_closure_locked                                                         +84  [NEW]\n      +7.7%     +28 [Unmapped]                                                                               +28  +7.7%\n  +1.5%    +192 src/core/ext/filters/client_channel/client_channel.cc                                   +192  +1.5%\n      [NEW]    +192 set_channel_connectivity_state_locked                                                   +192  [NEW]\n      [NEW]    +156 start_resolving_locked                                                                  +156  [NEW]\n      [NEW]    +148 request_reresolution_locked                                                             +148  [NEW]\n      [NEW]    +116 watch_lb_policy_locked                                                                  +116  [NEW]\n      +3.1%     +80 on_resolver_result_changed_locked                                                        +80  +3.1%\n      [NEW]     +79 lookup_external_connectivity_watcher                                                     +79  [NEW]\n       +16%     +35 [Unmapped]                                                                               +35   +16%\n      +1.2%      +3 cc_destroy_channel_elem                                                                   +3  +1.2%\n      +0.6%      +3 watch_connectivity_state_locked                                                           +3  +0.6%\n      +2.9%      +3 grpc_client_channel_check_connectivity_state                                              +3  +2.9%\n  +1.1%     +80 src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc                 +80  +1.1%\n      [NEW]     +59 rr_set_reresolve_closure_locked                                                          +59  [NEW]\n      [NEW]     +57 rr_subchannel_list_ref(rr_subchannel_list*, char const*) [clone .part.1]                 +57  [NEW]\n      +8.6%     +37 rr_shutdown_locked                                                                       +37  +8.6%\n       +25%     +33 [Unmapped]                                                                               +33   +25%\n      +2.1%      +4 round_robin_create                                                                        +4  +2.1%\n  +3.7%     +16 src/core/ext/filters/client_channel/lb_policy.cc                                         +16  +3.7%\n      +5.3%      +7 [Unmapped]                                                                                +7  +5.3%\n      [NEW]      +6 grpc_lb_policy_set_reresolve_closure_locked                                               +6  [NEW]\n      +5.9%      +3 grpc_lb_policy_init                                                                       +3  +5.9%\n\n  +0.1% +1.60Ki TOTAL                                                                                +37.0Ki  +0.6%\n\n\n****************************************************************\n\nlibgrpc++.so\n\n     VM SIZE        FILE SIZE\n ++++++++++++++  ++++++++++++++\n\n  [ = ]       0        0  [ = ]\n\n\n\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336292027",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336292027",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336292027,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjI5MjAyNw==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-12T22:18:03Z",
    "updated_at": "2017-10-12T22:18:03Z",
    "author_association": "NONE",
    "body": "```\n****************************************************************\n\nlibgrpc.so\n\n     VM SIZE                                                                                            FILE SIZE\n ++++++++++++++ GROWING                                                                              ++++++++++++++\n  +0.1%    +744 [None]                                                                               +36.2Ki  +0.7%\n      +0.1%    +752 [Unmapped]                                                                           +36.1Ki  +0.7%\n     +10.0%      +8 glb_lb_policy_vtable                                                                      +8 +10.0%\n     +10.0%      +8 pick_first_lb_policy_vtable                                                               +8 +10.0%\n     +10.0%      +8 round_robin_lb_policy_vtable                                                              +8 +10.0%\n  +6.3%    +384 src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc                  +384  +6.3%\n       +12%    +241 pf_connectivity_changed_locked                                                          +241   +12%\n       +20%     +59 pf_shutdown_locked                                                                       +59   +20%\n      [NEW]     +59 pf_set_reresolve_closure_locked                                                          +59  [NEW]\n      +0.5%      +9 pf_update_locked                                                                          +9  +0.5%\n      +6.3%      +8 pf_pick_locked                                                                            +8  +6.3%\n      +3.4%      +4 [Unmapped]                                                                                +4  +3.4%\n      +2.0%      +4 create_pick_first                                                                         +4  +2.0%\n  +1.6%    +224 src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc                          +224  +1.6%\n      [NEW] +1.57Ki rr_handover_locked(grpc_exec_ctx*, glb_lb_policy*) [clone .part.6]                   +1.57Ki  [NEW]\n      [NEW] +1.28Ki query_for_backends_locked(grpc_exec_ctx*, glb_lb_policy*) [clone .part.8]            +1.28Ki  [NEW]\n      [NEW]    +834 build_lb_channel_args(grpc_exec_ctx*, grpc_lb_addresses const*, grpc_fake_resolver_r    +834  [NEW]\n      [NEW]    +210 extract_backend_addresses_locked(grpc_exec_ctx*, grpc_lb_addresses const*) [clone .i    +210  [NEW]\n       +21%     +88 glb_shutdown_locked                                                                      +88   +21%\n      [NEW]     +84 glb_set_reresolve_closure_locked                                                         +84  [NEW]\n      +7.7%     +28 [Unmapped]                                                                               +28  +7.7%\n  +1.5%    +192 src/core/ext/filters/client_channel/client_channel.cc                                   +192  +1.5%\n      [NEW]    +192 set_channel_connectivity_state_locked                                                   +192  [NEW]\n      [NEW]    +156 start_resolving_locked                                                                  +156  [NEW]\n      [NEW]    +148 request_reresolution_locked                                                             +148  [NEW]\n      [NEW]    +116 watch_lb_policy_locked                                                                  +116  [NEW]\n      +3.1%     +80 on_resolver_result_changed_locked                                                        +80  +3.1%\n      [NEW]     +79 lookup_external_connectivity_watcher                                                     +79  [NEW]\n       +16%     +35 [Unmapped]                                                                               +35   +16%\n      +1.2%      +3 cc_destroy_channel_elem                                                                   +3  +1.2%\n      +0.6%      +3 watch_connectivity_state_locked                                                           +3  +0.6%\n      +2.9%      +3 grpc_client_channel_check_connectivity_state                                              +3  +2.9%\n  +1.1%     +80 src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc                 +80  +1.1%\n      [NEW]     +59 rr_set_reresolve_closure_locked                                                          +59  [NEW]\n      [NEW]     +57 rr_subchannel_list_ref(rr_subchannel_list*, char const*) [clone .part.1]                 +57  [NEW]\n      +8.6%     +37 rr_shutdown_locked                                                                       +37  +8.6%\n       +25%     +33 [Unmapped]                                                                               +33   +25%\n      +2.1%      +4 round_robin_create                                                                        +4  +2.1%\n  +3.7%     +16 src/core/ext/filters/client_channel/lb_policy.cc                                         +16  +3.7%\n      +5.3%      +7 [Unmapped]                                                                                +7  +5.3%\n      [NEW]      +6 grpc_lb_policy_set_reresolve_closure_locked                                               +6  [NEW]\n      +5.9%      +3 grpc_lb_policy_init                                                                       +3  +5.9%\n\n  +0.1% +1.60Ki TOTAL                                                                                +37.0Ki  +0.6%\n\n\n****************************************************************\n\nlibgrpc++.so\n\n     VM SIZE        FILE SIZE\n ++++++++++++++  ++++++++++++++\n\n  [ = ]       0        0  [ = ]\n\n\n\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336292333",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336292333",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336292333,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjI5MjMzMw==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-12T22:19:14Z",
    "updated_at": "2017-10-12T22:19:14Z",
    "author_association": "NONE",
    "body": "```\n****************************************************************\n\nlibgrpc.so\n\n     VM SIZE                                                                                            FILE SIZE\n ++++++++++++++ GROWING                                                                              ++++++++++++++\n  +0.1%    +744 [None]                                                                               +36.2Ki  +0.7%\n      +0.1%    +752 [Unmapped]                                                                           +36.1Ki  +0.7%\n     +10.0%      +8 glb_lb_policy_vtable                                                                      +8 +10.0%\n     +10.0%      +8 pick_first_lb_policy_vtable                                                               +8 +10.0%\n     +10.0%      +8 round_robin_lb_policy_vtable                                                              +8 +10.0%\n  +6.3%    +384 src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc                  +384  +6.3%\n       +12%    +241 pf_connectivity_changed_locked                                                          +241   +12%\n       +20%     +59 pf_shutdown_locked                                                                       +59   +20%\n      [NEW]     +59 pf_set_reresolve_closure_locked                                                          +59  [NEW]\n      +0.5%      +9 pf_update_locked                                                                          +9  +0.5%\n      +6.3%      +8 pf_pick_locked                                                                            +8  +6.3%\n      +3.4%      +4 [Unmapped]                                                                                +4  +3.4%\n      +2.0%      +4 create_pick_first                                                                         +4  +2.0%\n  +1.6%    +224 src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc                          +224  +1.6%\n      [NEW] +1.57Ki rr_handover_locked(grpc_exec_ctx*, glb_lb_policy*) [clone .part.6]                   +1.57Ki  [NEW]\n      [NEW] +1.28Ki query_for_backends_locked(grpc_exec_ctx*, glb_lb_policy*) [clone .part.8]            +1.28Ki  [NEW]\n      [NEW]    +834 build_lb_channel_args(grpc_exec_ctx*, grpc_lb_addresses const*, grpc_fake_resolver_r    +834  [NEW]\n      [NEW]    +210 extract_backend_addresses_locked(grpc_exec_ctx*, grpc_lb_addresses const*) [clone .i    +210  [NEW]\n       +21%     +88 glb_shutdown_locked                                                                      +88   +21%\n      [NEW]     +84 glb_set_reresolve_closure_locked                                                         +84  [NEW]\n      +7.7%     +28 [Unmapped]                                                                               +28  +7.7%\n  +1.5%    +192 src/core/ext/filters/client_channel/client_channel.cc                                   +192  +1.5%\n      [NEW]    +192 set_channel_connectivity_state_locked                                                   +192  [NEW]\n      [NEW]    +156 start_resolving_locked                                                                  +156  [NEW]\n      [NEW]    +148 request_reresolution_locked                                                             +148  [NEW]\n      [NEW]    +116 watch_lb_policy_locked                                                                  +116  [NEW]\n      +3.1%     +80 on_resolver_result_changed_locked                                                        +80  +3.1%\n      [NEW]     +79 lookup_external_connectivity_watcher                                                     +79  [NEW]\n       +16%     +35 [Unmapped]                                                                               +35   +16%\n      +1.2%      +3 cc_destroy_channel_elem                                                                   +3  +1.2%\n      +0.6%      +3 watch_connectivity_state_locked                                                           +3  +0.6%\n      +2.9%      +3 grpc_client_channel_check_connectivity_state                                              +3  +2.9%\n  +1.1%     +80 src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc                 +80  +1.1%\n      [NEW]     +59 rr_set_reresolve_closure_locked                                                          +59  [NEW]\n      [NEW]     +57 rr_subchannel_list_ref(rr_subchannel_list*, char const*) [clone .part.1]                 +57  [NEW]\n      +8.6%     +37 rr_shutdown_locked                                                                       +37  +8.6%\n       +25%     +33 [Unmapped]                                                                               +33   +25%\n      +2.1%      +4 round_robin_create                                                                        +4  +2.1%\n  +3.7%     +16 src/core/ext/filters/client_channel/lb_policy.cc                                         +16  +3.7%\n      +5.3%      +7 [Unmapped]                                                                                +7  +5.3%\n      [NEW]      +6 grpc_lb_policy_set_reresolve_closure_locked                                               +6  [NEW]\n      +5.9%      +3 grpc_lb_policy_init                                                                       +3  +5.9%\n\n  +0.1% +1.60Ki TOTAL                                                                                +37.0Ki  +0.6%\n\n\n****************************************************************\n\nlibgrpc++.so\n\n     VM SIZE        FILE SIZE\n ++++++++++++++  ++++++++++++++\n\n  [ = ]       0        0  [ = ]\n\n\n\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336294930",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336294930",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336294930,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjI5NDkzMA==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-12T22:28:24Z",
    "updated_at": "2017-10-12T22:28:24Z",
    "author_association": "NONE",
    "body": "```\n[trickle] No significant performance differences\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336295595",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336295595",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336295595,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjI5NTU5NQ==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-12T22:30:50Z",
    "updated_at": "2017-10-12T22:30:50Z",
    "author_association": "NONE",
    "body": "```\n[trickle] No significant performance differences\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336313206",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336313206",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336313206,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjMxMzIwNg==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-12T23:58:57Z",
    "updated_at": "2017-10-12T23:58:57Z",
    "author_association": "NONE",
    "body": "```\n[microbenchmarks] Performance differences noted:\nBenchmark                                   cpu_time    real_time\n------------------------------------------  ----------  -----------\nBM_ClosureSched3OnExecCtx                   +4%         +4%\nBM_ErrorGetStatusCode<ErrorCancelled>       -5%         -5%\nBM_ErrorGetStatusCode<ErrorWithGrpcStatus>  -5%         -5%\nBM_MetadataRefUnrefExternal                 +5%         +5%\nBM_MetadataRefUnrefStatic                   +12%        +12%\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336313224",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336313224",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336313224,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjMxMzIyNA==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-12T23:59:07Z",
    "updated_at": "2017-10-12T23:59:07Z",
    "author_association": "NONE",
    "body": "```\nCorrupt JSON data (indicates timeout or crash): \n    bm_fullstack_unary_ping_pong.BM_UnaryPingPong_TCP_NoOpMutator_NoOpMutator__128M_0.opt.new: 1\n\n\n[microbenchmarks] Performance differences noted:\nBenchmark                                                                               cpu_time    real_time\n--------------------------------------------------------------------------------------  ----------  -----------\nBM_HasClearGrpcStatus<ErrorWithGrpcStatus>                                              -6%         -6%\nBM_StreamingPingPong<InProcess, NoOpMutator, NoOpMutator>/32k/2                         +4%         +4%\nBM_StreamingPingPong<MinInProcess, NoOpMutator, NoOpMutator>/256k/1                     +7%         +7%\nBM_StreamingPingPong<MinInProcess, NoOpMutator, NoOpMutator>/32k/2                      +4%         +4%\nBM_StreamingPingPongMsgs<InProcess, NoOpMutator, NoOpMutator>/32k                       +6%         +6%\nBM_StreamingPingPongMsgs<MinInProcess, NoOpMutator, NoOpMutator>/256k                   +5%         +5%\nBM_StreamingPingPongMsgs<MinInProcess, NoOpMutator, NoOpMutator>/32k                    +13%        +13%\nBM_StreamingPingPongWithCoalescingApi<MinInProcess, NoOpMutator, NoOpMutator>/256k/1/0  +6%         +6%\nBM_UnaryPingPong<InProcess, NoOpMutator, NoOpMutator>/0/256k                            -6%         -6%\nBM_UnaryPingPong<InProcess, NoOpMutator, NoOpMutator>/256k/0                            -5%         -5%\nBM_UnaryPingPong<MinInProcess, NoOpMutator, NoOpMutator>/256k/0                         -7%         -7%\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336313516",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336313516",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336313516,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjMxMzUxNg==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-13T00:01:02Z",
    "updated_at": "2017-10-13T00:01:02Z",
    "author_association": "NONE",
    "body": "```\nCorrupt JSON data (indicates timeout or crash): \n    bm_fullstack_streaming_ping_pong.BM_StreamingPingPongWithCoalescingApi_InProcessCHTTP2_NoOpMutator_NoOpMutator__2M_2_0.counters.old: 1\n    bm_fullstack_streaming_ping_pong.BM_StreamingPingPongWithCoalescingApi_MinInProcessCHTTP2_NoOpMutator_NoOpMutator__2M_1_0.opt.old: 1\n    bm_fullstack_streaming_ping_pong.BM_StreamingPingPongWithCoalescingApi_InProcessCHTTP2_NoOpMutator_NoOpMutator__2M_1_0.counters.old: 1\n\n\n[microbenchmarks] Performance differences noted:\nBenchmark                          cpu_time    real_time\n---------------------------------  ----------  -----------\nBM_ErrorHttpError<ErrorCancelled>  -6%         -6%\n```"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/336489794",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-336489794",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 336489794,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNjQ4OTc5NA==",
    "user": {
      "login": "markdroth",
      "id": 18664614,
      "node_id": "MDQ6VXNlcjE4NjY0NjE0",
      "avatar_url": "https://avatars2.githubusercontent.com/u/18664614?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/markdroth",
      "html_url": "https://github.com/markdroth",
      "followers_url": "https://api.github.com/users/markdroth/followers",
      "following_url": "https://api.github.com/users/markdroth/following{/other_user}",
      "gists_url": "https://api.github.com/users/markdroth/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/markdroth/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/markdroth/subscriptions",
      "organizations_url": "https://api.github.com/users/markdroth/orgs",
      "repos_url": "https://api.github.com/users/markdroth/repos",
      "events_url": "https://api.github.com/users/markdroth/events{/privacy}",
      "received_events_url": "https://api.github.com/users/markdroth/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-13T15:42:30Z",
    "updated_at": "2017-10-13T15:42:30Z",
    "author_association": "MEMBER",
    "body": "Sorry for steering you wrong about the `reresolution_request_args` struct!\n\nBTW, note that in reviewable, you can mark that you consider a discussion resolved by clicking on your icon in the lower-right corner of the discussion window and clicking on \"resolved\".\n\nPlease let me know if you have any questions about any of this.  Thanks!\n\n---\n\nReviewed 8 of 8 files at r6.\nReview status: all files reviewed at latest revision, 5 unresolved discussions, some commit checks failed.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 375 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5tXoFMxcnp_L9-7Gq:-KwLDgiVbqx94ErlbG0V:b4vwbf9) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L375)):*\n> I thought that after initialization, the closure would be self-contained. But actually the arg pointer is passed shallowly. Then it makes sense that the arg should be allocated dynamically.\n\nRight, the closure argument is just a pointer.  It's the responsibility of the call creating the closure to ensure that the object that the pointer points to remains alive until after the closure runs.  This is usually done by having the closure hold a ref to the object, although it can also be done by dynamically allocating the object and having the callback free it before it returns.  (As I mentioned before, we generally prefer using refs instead of dynamically allocating the object for performance reasons, but there are cases where the latter is necessary for some reason.)\n\n> I don't quite understand the second change though. It looks like we shouldn't reset the closure anyway. Because even without introducing `reresolution_request_args`, we reset the argument of the closure to a different LB policy pointer for each new policy. Do the pointer to `reresolution_request_args` and the pointer to an LB policy differ in this case?\n\nGood catch!  You're right, we do need to change the closure's arg to point to a different LB policy object whenever we instantiate a new one, so we do have this same problem even without introducing `reresolution_request_args`.  And I don't think there's a way to solve this without dynamic allocation, so I think we should go back to using `reresolution_request_args`.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 383 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwG2KBx5YI1IudQAuGd:-KwLAiOyQRssBbH5zPgT:b-kuqj6a) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/client_channel.cc#L383)):*\n<details><summary><i>Previously, AspirinSJL (Juanli Shen) wroteâ€¦</i></summary><blockquote>\n\nDone.\n\nI agree that this can be more flexible. \n\nJust want to make sure: getting a different error just means that maybe in the future we want to add more functionality and schedule the closure with another error, right? Can it happen that we get some unexpected error even though we schedule the closure with `GRPC_ERROR_NONE`?\n</blockquote></details>\n\nA closure will always be run with the error it was scheduled with.\n\nThe closure mechanism itself allows a closure to be scheduled with any arbitrary error.  In this particular case, the code you're adding here will only ever schedule it with `GRPC_ERROR_NONE` or `GRPC_ERROR_CANCELLED`, and we have no plan to change that.  However, it is not inconceivable that someone in the future could change the code to schedule the closure with some other error and forget to update the callback to check for it, so it seems better to be a bit defensive.\n\nThis isn't really a hard and fast rule; it's more of a judgement call based on the likelihood of the problem occurring and the cost of being defensive.  In this case, the likelihood of it happening isn't that high; I can't think of a reason for someone to schedule the closure with a different error, and if they did, they would probably realize that they need to make sure the error is handled properly in the callback.  However, the cost of being defensive is so low that there's no reason not to do so; we were already checking the value of error, so writing the check a little differently didn't cost in terms of performance or maintainability.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 371 at r6](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwLDK33_TTFFciNbvSy:-KwLDK33_TTFFciNbvSz:b-rhfdqe) ([raw file](https://github.com/grpc/grpc/blob/cef527681ee44b85e42c5c36785c33376c1f85b3/src/core/ext/filters/client_channel/client_channel.cc#L371)):*\n> ```cpp\n> static void request_reresolution_locked(grpc_exec_ctx *exec_ctx, void *arg,\n>                                         grpc_error *error) {\n>   grpc_lb_policy *policy = (grpc_lb_policy *)arg;\n> ```\n\nPlease call this `lb_policy`.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.h, line 44 at r6](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwL81-uudLMpMgaO4LL:-KwL81-uudLMpMgaO4LM:b-9scuh8) ([raw file](https://github.com/grpc/grpc/blob/cef527681ee44b85e42c5c36785c33376c1f85b3/src/core/ext/filters/client_channel/client_channel.h#L44)):*\n> ```objc\n> extern const grpc_channel_filter grpc_client_channel_filter;\n> \n> typedef struct channel_data channel_data;\n> ```\n\nBecause C has only a single global namespace for types and symbols, it's important to use a very precise name when exposing types beyond a single module.  All of our exposed types and symbols should start with `grpc_`.  And even beyond that, they need to be a lot more specific than just `channel_data` -- every single filter has channel data, so this name doesn't tell you anything about which filter this is for.  So a better name for this would be `grpc_client_channel_channel_data`.\n\nThat having been said, I don't think we should be exposing this type to begin with.  See my comment below for details.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 35 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwG9OGuTBnLuRN08dhD:-KwL9jHUQ3iImW1S84hf:b8qcr4f) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/lb_policy.h#L35)):*\n<details><summary><i>Previously, AspirinSJL (Juanli Shen) wroteâ€¦</i></summary><blockquote>\n\nDone.\n\nThanks, that's a bug I was looking for..\n</blockquote></details>\n\nI must have been unclear in my comment.  The problem here was not that this typedef was in the wrong header file; it was that this typedef should not be present anywhere outside of client_channel.cc.  The LB policy code should not depend on the client_channel code, which means that this header should not be including client_channel.h, and the LB policy code should not use any type defined by the client channel code.\n\nOne possible way to avoid this would be to have the pointer in the LB policy be something generic like `void *parent_data`, and let the client_channel code populate it with a pointer to its own `channel_data` struct.\n\nThat having been said, given my suggestion above about going back to using the `reresolution_request_args` struct, I don't think we need the LB policy to have a pointer to the client channel anymore, so this is a moot point now.\n\n---\n\n\n*Comments from [Reviewable](https://reviewable.io:443/reviews/grpc/grpc/12829#-:-KwLODxzRLlFZ3h36LnU:b-803rsw)*\n<!-- Sent from Reviewable.io -->\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/337063572",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-337063572",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 337063572,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNzA2MzU3Mg==",
    "user": {
      "login": "AspirinSJL",
      "id": 3314176,
      "node_id": "MDQ6VXNlcjMzMTQxNzY=",
      "avatar_url": "https://avatars0.githubusercontent.com/u/3314176?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AspirinSJL",
      "html_url": "https://github.com/AspirinSJL",
      "followers_url": "https://api.github.com/users/AspirinSJL/followers",
      "following_url": "https://api.github.com/users/AspirinSJL/following{/other_user}",
      "gists_url": "https://api.github.com/users/AspirinSJL/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AspirinSJL/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AspirinSJL/subscriptions",
      "organizations_url": "https://api.github.com/users/AspirinSJL/orgs",
      "repos_url": "https://api.github.com/users/AspirinSJL/repos",
      "events_url": "https://api.github.com/users/AspirinSJL/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AspirinSJL/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-16T22:34:58Z",
    "updated_at": "2017-10-16T22:34:58Z",
    "author_association": "MEMBER",
    "body": "I see! I clicked \"Satisfied\" after modifying the code. Still exploring Reviewable's features.\n\n---\n\nReview status: all files reviewed at latest revision, 4 unresolved discussions, some commit checks failed.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 375 at r4](https://reviewable.io:443/reviews/grpc/grpc/12829#-Kw5tXoFMxcnp_L9-7Gq:-KwbIzJsXVaTkO2nAtlW:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/5c539ac46aabcf3786a3758fd0477d8c879e9fa9/src/core/ext/filters/client_channel/client_channel.cc#L375)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\n> I thought that after initialization, the closure would be self-contained. But actually the arg pointer is passed shallowly. Then it makes sense that the arg should be allocated dynamically.\n\nRight, the closure argument is just a pointer.  It's the responsibility of the call creating the closure to ensure that the object that the pointer points to remains alive until after the closure runs.  This is usually done by having the closure hold a ref to the object, although it can also be done by dynamically allocating the object and having the callback free it before it returns.  (As I mentioned before, we generally prefer using refs instead of dynamically allocating the object for performance reasons, but there are cases where the latter is necessary for some reason.)\n\n> I don't quite understand the second change though. It looks like we shouldn't reset the closure anyway. Because even without introducing `reresolution_request_args`, we reset the argument of the closure to a different LB policy pointer for each new policy. Do the pointer to `reresolution_request_args` and the pointer to an LB policy differ in this case?\n\nGood catch!  You're right, we do need to change the closure's arg to point to a different LB policy object whenever we instantiate a new one, so we do have this same problem even without introducing `reresolution_request_args`.  And I don't think there's a way to solve this without dynamic allocation, so I think we should go back to using `reresolution_request_args`.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 383 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwG2KBx5YI1IudQAuGd:-KwaF8YldNjWeFdZia7i:bqrfan2) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/client_channel.cc#L383)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nA closure will always be run with the error it was scheduled with.\n\nThe closure mechanism itself allows a closure to be scheduled with any arbitrary error.  In this particular case, the code you're adding here will only ever schedule it with `GRPC_ERROR_NONE` or `GRPC_ERROR_CANCELLED`, and we have no plan to change that.  However, it is not inconceivable that someone in the future could change the code to schedule the closure with some other error and forget to update the callback to check for it, so it seems better to be a bit defensive.\n\nThis isn't really a hard and fast rule; it's more of a judgement call based on the likelihood of the problem occurring and the cost of being defensive.  In this case, the likelihood of it happening isn't that high; I can't think of a reason for someone to schedule the closure with a different error, and if they did, they would probably realize that they need to make sure the error is handled properly in the callback.  However, the cost of being defensive is so low that there's no reason not to do so; we were already checking the value of error, so writing the check a little differently didn't cost in terms of performance or maintainability.\n</blockquote></details>\n\nUnderstood.\n\n---\n\n*[src/core/ext/filters/client_channel/client_channel.cc, line 371 at r6](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwLDK33_TTFFciNbvSy:-KwaCwoDnjYTI1xiv2E1:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/cef527681ee44b85e42c5c36785c33376c1f85b3/src/core/ext/filters/client_channel/client_channel.cc#L371)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nPlease call this `lb_policy`.\n</blockquote></details>\n\nDone.\n\n---\n\n*[src/core/ext/filters/client_channel/lb_policy.h, line 35 at r5](https://reviewable.io:443/reviews/grpc/grpc/12829#-KwG9OGuTBnLuRN08dhD:-KwbJRkjwztuaIUOBmGJ:b-896fix) ([raw file](https://github.com/grpc/grpc/blob/09c8ee4bc52079f63d6d0d8d84b5f136ec049750/src/core/ext/filters/client_channel/lb_policy.h#L35)):*\n<details><summary><i>Previously, markdroth (Mark D. Roth) wroteâ€¦</i></summary><blockquote>\n\nI must have been unclear in my comment.  The problem here was not that this typedef was in the wrong header file; it was that this typedef should not be present anywhere outside of client_channel.cc.  The LB policy code should not depend on the client_channel code, which means that this header should not be including client_channel.h, and the LB policy code should not use any type defined by the client channel code.\n\nOne possible way to avoid this would be to have the pointer in the LB policy be something generic like `void *parent_data`, and let the client_channel code populate it with a pointer to its own `channel_data` struct.\n\nThat having been said, given my suggestion above about going back to using the `reresolution_request_args` struct, I don't think we need the LB policy to have a pointer to the client channel anymore, so this is a moot point now.\n</blockquote></details>\n\nDone.\n\n---\n\n\n*Comments from [Reviewable](https://reviewable.io:443/reviews/grpc/grpc/12829#-:-KwYOWjkVX3w-pO-mfLt:b-9u3z63)*\n<!-- Sent from Reviewable.io -->\n"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/337064386",
    "html_url": "https://github.com/grpc/grpc/pull/12829#issuecomment-337064386",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/12829",
    "id": 337064386,
    "node_id": "MDEyOklzc3VlQ29tbWVudDMzNzA2NDM4Ng==",
    "user": {
      "login": "grpc-testing",
      "id": 28024233,
      "node_id": "MDQ6VXNlcjI4MDI0MjMz",
      "avatar_url": "https://avatars1.githubusercontent.com/u/28024233?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/grpc-testing",
      "html_url": "https://github.com/grpc-testing",
      "followers_url": "https://api.github.com/users/grpc-testing/followers",
      "following_url": "https://api.github.com/users/grpc-testing/following{/other_user}",
      "gists_url": "https://api.github.com/users/grpc-testing/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/grpc-testing/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/grpc-testing/subscriptions",
      "organizations_url": "https://api.github.com/users/grpc-testing/orgs",
      "repos_url": "https://api.github.com/users/grpc-testing/repos",
      "events_url": "https://api.github.com/users/grpc-testing/events{/privacy}",
      "received_events_url": "https://api.github.com/users/grpc-testing/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-10-16T22:39:02Z",
    "updated_at": "2017-10-16T22:39:02Z",
    "author_association": "NONE",
    "body": "```\n****************************************************************\n\nlibgrpc.so\n\n     VM SIZE                                                                                            FILE SIZE\n ++++++++++++++ GROWING                                                                              ++++++++++++++\n  +0.1%    +736 [None]                                                                               +3.88Ki  +0.1%\n      +0.1%    +712 [Unmapped]                                                                           +3.86Ki  +0.1%\n     +10.0%      +8 glb_lb_policy_vtable                                                                      +8 +10.0%\n     +10.0%      +8 pick_first_lb_policy_vtable                                                               +8 +10.0%\n     +10.0%      +8 round_robin_lb_policy_vtable                                                              +8 +10.0%\n  +6.3%    +384 src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc                  +384  +6.3%\n       +11%    +233 pf_connectivity_changed_locked                                                          +233   +11%\n       +20%     +59 pf_shutdown_locked                                                                       +59   +20%\n      [NEW]     +59 pf_set_reresolve_closure_locked                                                          +59  [NEW]\n       +13%     +16 [Unmapped]                                                                               +16   +13%\n      +0.5%      +9 pf_update_locked                                                                          +9  +0.5%\n      +6.3%      +8 pf_pick_locked                                                                            +8  +6.3%\n  +1.6%    +224 src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc                          +224  +1.6%\n      [NEW] +1.57Ki rr_handover_locked(grpc_exec_ctx*, glb_lb_policy*) [clone .part.6]                   +1.57Ki  [NEW]\n      [NEW] +1.28Ki query_for_backends_locked(grpc_exec_ctx*, glb_lb_policy*) [clone .part.8]            +1.28Ki  [NEW]\n      [NEW]    +834 build_lb_channel_args(grpc_exec_ctx*, grpc_lb_addresses const*, grpc_fake_resolver_r    +834  [NEW]\n      [NEW]    +210 extract_backend_addresses_locked(grpc_exec_ctx*, grpc_lb_addresses const*) [clone .i    +210  [NEW]\n       +21%     +88 glb_shutdown_locked                                                                      +88   +21%\n      [NEW]     +84 glb_set_reresolve_closure_locked                                                         +84  [NEW]\n      +7.7%     +28 [Unmapped]                                                                               +28  +7.7%\n  +1.3%    +176 src/core/ext/filters/client_channel/client_channel.cc                                   +176  +1.3%\n      [NEW]    +157 request_reresolution_locked                                                             +157  [NEW]\n      +3.7%     +96 on_resolver_result_changed_locked                                                        +96  +3.7%\n      +1.4%      +3 [Unmapped]                                                                                +3  +1.4%\n  +0.9%     +64 src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc                 +64  +0.9%\n      [NEW]     +59 rr_set_reresolve_closure_locked                                                          +59  [NEW]\n      [NEW]     +57 rr_subchannel_list_ref(rr_subchannel_list*, char const*) [clone .part.1]                 +57  [NEW]\n      +8.6%     +37 rr_shutdown_locked                                                                       +37  +8.6%\n       +16%     +21 [Unmapped]                                                                               +21   +16%\n  +3.7%     +16 src/core/ext/filters/client_channel/lb_policy.cc                                         +16  +3.7%\n      +7.6%     +10 [Unmapped]                                                                               +10  +7.6%\n      [NEW]      +6 grpc_lb_policy_set_reresolve_closure_locked                                               +6  [NEW]\n\n  +0.1% +1.56Ki TOTAL                                                                                +4.73Ki  +0.1%\n\n\n****************************************************************\n\nlibgrpc++.so\n\n     VM SIZE        FILE SIZE\n ++++++++++++++  ++++++++++++++\n\n  [ = ]       0        0  [ = ]\n\n\n\n```"
  }
]
