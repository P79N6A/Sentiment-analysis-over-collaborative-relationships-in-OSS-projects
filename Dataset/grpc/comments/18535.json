[
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/477276462",
    "html_url": "https://github.com/grpc/grpc/issues/18535#issuecomment-477276462",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/18535",
    "id": 477276462,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3NzI3NjQ2Mg==",
    "user": {
      "login": "lidizheng",
      "id": 7394928,
      "node_id": "MDQ6VXNlcjczOTQ5Mjg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/7394928?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lidizheng",
      "html_url": "https://github.com/lidizheng",
      "followers_url": "https://api.github.com/users/lidizheng/followers",
      "following_url": "https://api.github.com/users/lidizheng/following{/other_user}",
      "gists_url": "https://api.github.com/users/lidizheng/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lidizheng/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lidizheng/subscriptions",
      "organizations_url": "https://api.github.com/users/lidizheng/orgs",
      "repos_url": "https://api.github.com/users/lidizheng/repos",
      "events_url": "https://api.github.com/users/lidizheng/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lidizheng/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-27T17:47:07Z",
    "updated_at": "2019-03-27T17:47:07Z",
    "author_association": "CONTRIBUTOR",
    "body": "@yutkin In modern server architecture, usually the bottleneck will more likely be database, network bandwidth. In those scenario, increasing threads number in Python works because when one thread is blocked by IO, another thread can continue its execution.\r\n\r\nFor CPU-bound tasks, your statement is correct. The GIL makes multi-threading in Python useless. If you want Python utilize all of your cores, you may want to spawn multiple processes (one example [here](https://github.com/grpc/grpc/tree/master/examples/python/multiprocessing)). I don't have much detail about your case, if your TensorFlow model does not depend on certain server state, I will recommend use subprocess to invoke another Python interpreter to perform the computation and send the response back."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/477343166",
    "html_url": "https://github.com/grpc/grpc/issues/18535#issuecomment-477343166",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/18535",
    "id": 477343166,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3NzM0MzE2Ng==",
    "user": {
      "login": "yutkin",
      "id": 2982775,
      "node_id": "MDQ6VXNlcjI5ODI3NzU=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/2982775?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/yutkin",
      "html_url": "https://github.com/yutkin",
      "followers_url": "https://api.github.com/users/yutkin/followers",
      "following_url": "https://api.github.com/users/yutkin/following{/other_user}",
      "gists_url": "https://api.github.com/users/yutkin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/yutkin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/yutkin/subscriptions",
      "organizations_url": "https://api.github.com/users/yutkin/orgs",
      "repos_url": "https://api.github.com/users/yutkin/repos",
      "events_url": "https://api.github.com/users/yutkin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/yutkin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-27T20:53:28Z",
    "updated_at": "2019-03-27T20:53:28Z",
    "author_association": "NONE",
    "body": "@lidizheng Thank you for your answer! I'm not trying to speed up my service using threads (of course, threads won't speed up model inference). I just want to figure out how this thread pool is used inside gRPC. \r\n\r\nFor example, If I set `max_workers=1`, will health-check servicer block while another servicer is running?"
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/477360897",
    "html_url": "https://github.com/grpc/grpc/issues/18535#issuecomment-477360897",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/18535",
    "id": 477360897,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3NzM2MDg5Nw==",
    "user": {
      "login": "lidizheng",
      "id": 7394928,
      "node_id": "MDQ6VXNlcjczOTQ5Mjg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/7394928?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lidizheng",
      "html_url": "https://github.com/lidizheng",
      "followers_url": "https://api.github.com/users/lidizheng/followers",
      "following_url": "https://api.github.com/users/lidizheng/following{/other_user}",
      "gists_url": "https://api.github.com/users/lidizheng/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lidizheng/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lidizheng/subscriptions",
      "organizations_url": "https://api.github.com/users/lidizheng/orgs",
      "repos_url": "https://api.github.com/users/lidizheng/repos",
      "events_url": "https://api.github.com/users/lidizheng/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lidizheng/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-27T21:49:59Z",
    "updated_at": "2019-03-27T21:49:59Z",
    "author_association": "CONTRIBUTOR",
    "body": "@yutkin gRPC Python server currently will package each RPC request as a future, and submit it to the thread pool. If the thread pool runs out of available thread, it will spawn a new one and process the future. In another word, each RPC will run in a dedicated thread, and if the RPC is blocked the thread will be blocked as well.\r\n\r\nBack to your example, if you set `max_workers=1` and you are using the [Watch](https://github.com/grpc/grpc/blob/master/src/proto/grpc/health/v1/health.proto#L62) Health-Check method, you will end up deadlocking. The `max_workers=1` will only work, if your method handlers will end soon and only use [Check](https://github.com/grpc/grpc/blob/master/src/proto/grpc/health/v1/health.proto#L45) Health-Check method."
  },
  {
    "url": "https://api.github.com/repos/grpc/grpc/issues/comments/477825307",
    "html_url": "https://github.com/grpc/grpc/issues/18535#issuecomment-477825307",
    "issue_url": "https://api.github.com/repos/grpc/grpc/issues/18535",
    "id": 477825307,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ3NzgyNTMwNw==",
    "user": {
      "login": "lidizheng",
      "id": 7394928,
      "node_id": "MDQ6VXNlcjczOTQ5Mjg=",
      "avatar_url": "https://avatars3.githubusercontent.com/u/7394928?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/lidizheng",
      "html_url": "https://github.com/lidizheng",
      "followers_url": "https://api.github.com/users/lidizheng/followers",
      "following_url": "https://api.github.com/users/lidizheng/following{/other_user}",
      "gists_url": "https://api.github.com/users/lidizheng/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/lidizheng/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/lidizheng/subscriptions",
      "organizations_url": "https://api.github.com/users/lidizheng/orgs",
      "repos_url": "https://api.github.com/users/lidizheng/repos",
      "events_url": "https://api.github.com/users/lidizheng/events{/privacy}",
      "received_events_url": "https://api.github.com/users/lidizheng/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-03-29T01:00:46Z",
    "updated_at": "2019-03-29T01:00:46Z",
    "author_association": "CONTRIBUTOR",
    "body": "I'm closing this issue. If you have more questions, feel free to open it again."
  }
]
